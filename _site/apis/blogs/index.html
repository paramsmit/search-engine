[
  {
  "title": "What Are Your Enterprise API Capabilities?",
  "date": "22 Oct 2018",
  "body": "<br />I spend a lot of time helping enterprise organizations discover their APIs. All of the organizations I talk to have trouble knowing where all of their APIs are–even the most organized of them. Development and IT groups have just been moving too fast over the last decade to know where all of their web services, and APIs are. Resulting in large organizations not fully understanding what all of their capabilities are, even if it is something they actively operate, and may drive existing web or mobile applications.<br /><br />Each individual API within the enterprise represents a single capability. The ability to accomplish a specific enterprise tasks that is valuable to the business. While each individual engineer might be aware of the capabilities present on their team, without group wide, and comprehensive API discovery across an organization, the extent of the enterprise capabilities is rarely known. If architects, business leadership, and any other stakeholder can’t browse, list, search, and quickly get access to all of the APIs that exist, the knowledge of the enterprise capabilities will not be able to be quantified or articulated as part of regular business operations.<br /><br />In 2018, the capabilities of any individual API is articulated by it’s machine readable definition. Most likely OpenAPI, but could also be something like API Blueprint, RAML, or other specification. For these definitions to speak to not just the technical capabilities of each individual API, but also the business capabilities, they will have to be complete. Utilizing a higher level strategic set of tags that help label and organize each API into a meaningful set of business capabilities that best describes what each API delivers. Providing a sort of business capabilities taxonomy that can be applied to each API’s definition and used across the rest of the API lifecycle, but most importantly as part of API discovery, and the enterprise digital product catalog.<br /><br />One of the first things I ask any enterprise organization I’m working with upon arriving, is “do you know where all of your APIs are?” The answer is always no. Many will have a web services or API catalog, but it almost always is out of date, and not used religiously across all groups. Even when there are OpenAPI definitions present in a catalog, they rarely contain the meta data needed to truly understand the capabilities of each API. Leaving developer and IT operations existing as black holes when it comes to enterprise capabilities, sucking up resources, but letting very little light out when it comes to what is happening on the inside. Making it very difficult for developers, architects, and business users to articulate what their enterprise capabilities are, and often times reinventing the wheel when it comes to what the enterprise delivers on the ground each day.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/machine-road_copper_circuit.jpg"
  },
  {
  "title": "The Layers Of Completeness For An OpenAPI Definition",
  "date": "09 Oct 2018",
  "body": "Everyone wants their OpenAPIs to be complete, but what that really means will depend on who you are, what your knowledge of OpenAPI is, as well as being driven by your motivation for having an OpenAPI in the first place. I wanted to take a crack at articulating a complete(enough) definition for OpenAPIs I create, based upon what I’m needing them to do.<br /><br />Info &amp;amp; Base - Give the basic information I need to understand who is behind, and where I can access the API.<br /><br /><br />Paths - Provide an entry for every path that is available for an API, and should be included in this definition.<br /><br /><br />Parameters - Provide a complete list of all path, query, and header parameters that can be used as part of an API.<br />https://gist.github.com/kinlane/29d0247d6ff4aaa39db4dc793df4a2f9<br /><br />Descriptions - Flesh out descriptions for all the path and parameter descriptions, helping describe an API does.<br /><br /><br />Enums - Publish a list of all the enumerated values that are possible for each parameter used as part of an API.<br />https://gist.github.com/kinlane/444731f0214cab5efcc3ae77011823ba<br /><br />Definitions - Document the underlying schema being returned by creating a JSON schema definition for the API.<br /><br /><br />Responses - Associate the definition for the API with the path using a response reference, connecting the dots regarding what will be returned.<br /><br /><br />Tags - Tag each path with a meaningful set of tags, describing what resources are available in short, concise terms and phrases.<br /><br /><br />Contacts - Provide contact information for whoever can answer questions about an API, and provide a URL to any support resources.<br /><br /><br />Create Security Definitions - Define the security for accessing the API, providing details on how each API request will be authenticated.<br /><br /><br />Apply Security Definitions - Apply the security definition to each individual path, associating common security definitions across all paths.<br /><br /><br />Complete(enough) - That should give us a complete (enough) API description.<br /><br /><br />Obviously there is more we can do to make an OpenAPI even more complete and precise as a business contract, hopefully speaking to both developers and business people. Having OpenAPI definitions are important, and having them be up to date, complete (enough), and useful is even more important. OpenAPIs provide much more than documentation for an API. They provide all the technical details an API consumer will need to successfully work with an API.<br /><br />While there are obvious payoffs for having an OpenAPI, like being able to publish documentation, and generate code libraries. There are many other uses for an OpenAPI like loading into Postman, Stoplight, and many other API services and tooling that helps developers understand what an API does, and reduce friction when they integrate, and have to maintain their applications. Having an OpenAPI available is becoming a default mode of operation, and something every API provider should have.<br />",
  "url": "http://localhost:4000",
  "image": "https://gist.github.com/kinlane/5e52d6063a0744d711795beb6e60365f.js"
  },
  {
  "title": "A Quick Manual Way To Create An OpenAPI From A GET API Request",
  "date": "09 Oct 2018",
  "body": "I have numerous tools that help me create OpenAPIs from the APIs I stumble across each day. Ideally I’m crawling, scraping, harvesting, and auto-generating OpenAPIs, but inevitably the process gets a little manual. To help reduce friction in these manual processes, I try to have a variety of services, tools, and scripts I can use to make my life easier, when it comes to create a machine readable definition of an API I am using.<br /><br /><br /><br />One way I’ll create an OpenAPI from a simple GET API request, providing me with a machine readable definition of the surface area of that API, is using Postman. When you have the URL copied onto your clipboard, open up your Postman, and paste the URL with all the query parameters present.<br /><br /><br /><br />You’ll have to save your API request, and add it to a collection, but then you can choose to share the collection, and retrieve the URL to this specific requests Postman Collection.<br /><br /><br /><br />This gives you a machine readable definition of the surface area of this particular API, defining the host, baseURL, path, and parameters, but it doesn’t give me more detail about the underlying schema being returned. To begin crafting the schema for the underlying definition of the API, and connect it to the response for my API definition, I’ll need an OpenAPI–which I can create from my Postman Collection using API Transformer from APIMATIC.<br /><br /><br /><br />After pasting the URL for the Postman Collection into the API transformer form, you can generate an OpenAPI from the definition. Now you have an OpenAPI, except it is missing the underlying schema, which I will just grab the response from my last request, and convert it into JSON schema using JSONSchema.net. I’ll just grab the properties section of these, as the bottom definitions portion of the OpenAPI specification is just JSON Schema.<br /><br /><br /><br />I can merge my JSON schema with my OpenAPI, adding it to the definition collection at the bottom. With a little more love, adding a more coherent title, description, and fluffing up some of the summaries, descriptions, tags, etc., I now have a fairly robust profile of this particular API. Ideally, this is something the API provider would do, but in the absence of an OpenAPI or Postman Collection, this is a pretty quick and dirty way to produce an OpenAPI and Postman Collection from a simple GET API, but the formula works for other types of API requests as well–leaving me with a machine readable definition for an API I will be integrating with.<br /><br /><br /><br />There are definitely other ways of scraping API documentation, processing .HAR files generated from a proxy, but I think this is a way that anyone, even a non-developer can accomplish. I did my version in JSON, but the same process will work for YAML, making the resulting definition a little more human readable, while still maintaining it’s machine readability. I like documenting these little processes so that my readers can put to use, but it also provides a nice definition that I can use to remember how I get things done–my memory isn’t what it used to be.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/api-definition-stories/xignite-api-url.png"
  },
  {
  "title": "Understanding The Event-Driven API Infrastructure Opportunity That Exists Across The API Landscape",
  "date": "18 Sep 2018",
  "body": "<br />I am at the Kong Summit in San Francisco all day tomorrow. I’m going to be speaking about research into the event-driven architectural layers I’ve been mapping out across the API space. Looking for the opportunity to augment existing APIs with push technology like webhooks, and streaming technology like SSE, as well as pipe data in an out of Kafka, fill data lakes, and train machine learning models. I’ll be sharing what I’m finding from some of the more mature API providers when it comes to their investment in event-driven infrastructure, focusing in on Twilio, SendGrid, Stripe, Slack, and GitHub.<br /><br />As I am profiling APIs for inclusion in my API Stack research, and in the API Gallery, I create an APIs.json, OpenAPI, Postman Collection(s), and sometimes an AsyncAPI definition for each API. All of my API catalogs, and API discovery collections use APIs.json + OpenAPI by default. One of the things I profile in each of my APIs.json, is the usage of webhooks as part of API operations. You can see collections of them that I’ve published to the API Gallery, aggregating many different approaches in what I consider to be the 101 of event-driven architecture, built on top of existing request and response HTTP API infrastructure. Allowing me to better understand how people are doing webhooks, and beginning to sketch out plans for a more event-driven approach to delivering resources, and managing activity on any platform that is scaling.<br /><br />While studying APIs at this level you begin to see patterns across how providers are doing what they are doing, even amidst a lack of standards for things like webhooks. API providers emulate each other, it is how much of the API space has evolved in the last decade. You see patterns like how leading API providers are defining their event types. Naming, describing, and allowing API consumers to subscribe to a variety of events, and receive webhook pings or pushes of data, as well as other types of notifications. Helping establish a vocabulary for defining the most meaningful events that are occurring across an API platform, and then providing an even-driven framework for subscribing to push data out when something occurs, as well as sustained API connections in the form of server-sent event (SSE), HTTP long polling, and other long running HTTP connections.<br /><br />As I said, webhooks is the 101 of event-driven technology, and once API providers evolve in their journey you begin to see investment in the 201 level solutions like SSE, WebSub, and more formal approaches to delivering resources as real time streams and publish / subscribe solutions. Then you see platforms begin to mature and evolve into other 301 and beyond courses, with AMQP, Kafka, and often times other Apache Projects. Sure, some API providers begin their journey here, but for many API providers, they are having to ease into the world of event-driven architecture, getting their feet wet with managing their request and response API infrastructure, and slowly evolving with webhooks. Then as API operations harden, mature, and become more easily managed, API providers can confidently begin evolving into using more sophisticated approaches to delivering data where it needs to be, when it is needed.<br /><br />From what I’ve gathered, the more mature API providers, who are further along in their API journey have invested in some key areas, which has allowed them to continue investing in some other key ways:<br /><br /><br />  Defined Resources - These API providers have their APIs well defined, with master planned designs for their suite of services, possessing machine readable definitions like OpenAPI, Postman Collections, and AsyncAPI.<br />  Request / Response - Who have fined tuned their approach to delivering their HTTP based request and response structure, along with their infrastructure being so well defined.<br />  Known Event Types - Which has resulted in having a handle on what is changing, and what the most important events are for API providers, as well as API consumers.<br />  Push Technology - Having begun investing in webhooks, and other push technology to make sure their API infrastructure is a two-way street, and they can easily push data out based upon any event.<br />  Query Language - Understanding the value of investment in a coherent querying strategy for their infrastructure that can work seamlessly with the defining, triggering, and overall management of event driven infrastructure.<br />  Stream Technology - Having a solid understanding of what data changes most frequently, as well as the topics people are most interested, and augmenting push technology with streaming subscriptions that consumers can tap into.<br /><br /><br />At this point in most API providers journey, they are successfully operating a full suite of event-driven solutions that can be tapped internally, and externally with partners, and other 3rd party developers. They probably are already investing in Kafka, and other Apache projects, an getting more sophisticated with their event-driven API orchestration. Request and response API infrastructure is well documented with OpenAPI, and groups are looking at event-driven specifications like AsyncAPI to continue to ensure all resources, messages, events, topics, and other moving parts are well defined.<br /><br />I’ll be showcasing the event-driven approaches of Twilio, SendGrid, Stripe, Slack, and GitHub at the Kong Summit tomorrow. I’ll also be looking at streaming approaches by Twitter, Slack, SalesForce, and Xignite. Which is just the tip of the event-driven API architecture opportunity I’m seeing across the existing API landscape. After mapping out several hundred API providers, and over 30K API paths using OpenAPI, and then augmenting and extending what is possible using AsyncAPI, you begin to see the event-driven opportunity that already exists out there. When you look at how API pioneers are investing in their event-driven approaches, it is easy to get a glimpse at what all API providers will be doing in 3-5 years, once they are further along in their API journey, and have continued to mature their approach to moving their valuable bits an bytes around using the web.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/kong/kong-summit-2018.jpg"
  },
  {
  "title": "Please Refer The Engineer From Your API Team To This Story",
  "date": "13 Sep 2018",
  "body": "<br />I reach out to API providers on a regular basis, asking them if they have an OpenAPI or Postman Collection available behind the scenes. I am adding these machine readable API definitions to my index of APIs that I monitor, while also publishing them out to my API Stack research, the API Gallery, APIs.io, work to get them published in the Postman Network, and syndicated as part of my wider work as an OpenAPI member. However, even beyond my own personal needs for API providers to have a machine readable definition of their API, and helping them get more syndication and exposure for their API, having an definition present significantly reduces friction when on-boarding with their APIs at almost every stop along a developer’s API integration journey.<br /><br />One of the API providers I reached out to recently responded with this, “I spoke with one of our engineers and he asked me to refer you to https://developer.[company].com/”. Ok. First, I spend over 30 minutes there just the other day. Learning about what you do, reading through documentation, and thinking about what was possible–which I referenced in my email. At this point I’m guessing that the engineer in question doesn’t know what an OpenAPI or Postman Collection is, they do not understand the impact these specifications are having on the wider API ecosystem, and lastly, I’m guessing they don’t have any idea who I am(ego taking control). All of which provides me with the signals I need to make an assessment of where any API is in their overall journey. Demonstrating to me that they have a long ways to go when it comes to understanding the wider API landscape in which they are operating in, and they are too busy to really come out of their engineering box and help their API consumers truly be successful in integrating with their platform.<br /><br />I see this a lot. It isn’t that I expect everyone to understand what OpenAPI and Postman Collections are, or even know who I am. However, I do expect people doing APIs to come out of their boxes a little bit, and be willing to maybe Google a topic before responding to question, or maybe Google the name of the person they are responding to. I don’t use a gmail.com address to communicate, I am using apievangelist.com, and if you are using a solution like Clearbit, or other business intelligence solution, you should always be retrieving some basic details about who you are communicating with, before you ever respond. That is, you do all of this kind of stuff if you are truly serious about operating your API, helping your API consumers be more successful, and taking the time to provide them with the resources they need  along the way–things like an OpenAPI, or Postman Collections.<br /><br />Ok, so why was this response so inadequate?<br /><br /><br />  No API Team Present - It shows me that your company doesn’t have any humans their to support the humans that will be using your API. My email went from general support, to a backend engineer who doesn’t care about who I am, and about what I need. This is a sign of what the future will hold if I actually bake their API into my applications–I don’t need my questions lost between support and engineering, with no dedicated API team to talk to.<br />  No Business Intelligence - It shows me that your company has put zero thought into the API business model, on-boarding, and support process. Which means you do not have a feedback loop established for your platform, and your API will always be deficient of the nutrients it needs to grow. Always make sure you conduct a lookup based upon on the domain, or Twitter handle or your consumers to get the context you need to understand who you are talking to.<br />  Stuck In Your Bubble - You aren’t aware of the wider API community, and the impact OpenAPI, and Postman are having on the on-boarding, documentation, and other stops along the API lifecycle. Which means you probably aren’t going to keep your platform evolving with where things are headed.<br /><br /><br />Ok, so why should you have an OpenAPI and Postman Collection?<br /><br /><br />  Reduce Onboarding Friction - As a developer I won’t always have the time to spend absorbing your documentation. Let me import your OpenAPI or Postman Collection into my client tooling of choice, register for a key and begin making API calls in seconds, or minutes. Make learning about your API a hands on experience, something I’m not going to get from your static documentation.<br />  Interactive API Documentation - Having a machine readable definition for your API allows you to easily keep your documentation up to date, and make it a more interactive experience. Rather than just reading your API documentation, I should be able to make calls, see responses, errors, and other elements I will need to truly understand what you do. There are plenty of open source interactive API documentation solutions that are driven by OpenAPI and Postman, but you’d know this if you were aware of the wider landscape.<br />  Generate SDKs, and Other Code - Please do not make me hand code the integration with each of your API endpoints, crafting each request and response manually. Allow me to autogenerate the most mundane aspects of integration, allowing OpenAPI and Postman Collection to act as the integration contract.<br />  Discovery - Please don’t expect your potential consumers to always know about your company, and regularly return to your developer.[company].com portal. Please make your APIs portable so that they can be published in any directory, catalog, gallery, marketplace, and platform that I’m already using, and frequent as part of my daily activities. If you are in my Postman Client, I’m more likely to remember that you exist in my busy world.<br /><br /><br />These are just a few of the basics of why this type of response to my question was inadequate, and why you’d want to have OpenAPI and Postman Collections available. My experience on-boarding will be similar to that of other developers, it just happens that the application I’m developing are out of the normal range of web and mobile applications you have probably been thinking about when publishing your API. But this is why we do APIs, to reach the long tail users, and encourage innovate around our platforms. I just stepped up and gave 30 minutes of my time (now 60 minutes with this story) to learning about your platform, and pointing me to your developer.[company].com page was all you could muster in return?<br /><br />Just like other developers will, if I can’t onboard with your API without friction, and I can’t tell if there is anyone home, and willing to give me the time of day when I have questions, I’m going to move on. There are other platforms that will accommodate me. The other downside of your response, and me moving on to another platform, is that now I’m not going to write about your API on my blog. Oh well? After eight years of blogging on APIs, and getting 5-10K page views per day, I can write about a topic or industry, and usually dominate the SEO landscape for that API search term(s) (ego still has control). But…I am moving on, no story to be told here. The best part of my job is there are always stories to be told somewhere else, and I get to just move on, and avoid the friction wherever possible when learning how to put APIs to work.<br /><br />I just needed this single link to provide in response to my email response, before I moved on!<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/mosaic-face_blue_circuit.jpg"
  },
  {
  "title": "Provide Your API Developers With A Forkable Example of API Documentation In Action",
  "date": "27 Aug 2018",
  "body": "<br />I responded about how teams should be documenting their APIs when they have both legacy and new APIs the other day. I wanted to keep the conversation thread going with an example of one possible API documentation implementation. The best way to deliver API documentation guidance in any organization is to provide a forkable, downloadable example of whatever you are talking about. To help illustrate what I am talking about, I wanted to take one documentation solution, and publish it as a GitHub repository.<br /><br />I chose to go with a simple OpenAPI 3.0 defined API contract, driving a Swagger UI driven API documentation, hosted using GitHub Pages, and managed as a GitHub repository. In my story about how teams should be documenting their APIs, I provided several API definition formations, and API documentation options–for this walk-through I wanted to narrow it down to a single combination, providing the minimum(alist) viable options possible using OpenAPI 3.0 and SwaggerUI. Of course, any federal agency implementing such a solution should wrap the documentation with their own branding, similar to the City Pairs API prototype out of GSA, which originated over at CFPB.<br /><br />I used the VA Facilities API definition from the developer.va.gov portal for this sample. Mostly because it was ready to go, and relevant to the VA efforts, but also because it was using OpenAPI 3.0–I think it is worth making sure all API documentation moving forward supports is supporting the latest version of OpenAPI. The API documentation is here, the OpenAPI definition is here, and the Github repository is here, showing what is possible. There are plenty of other things I’d like to see in a baseline API documentation template, but this provides a good first draft for a true minimum viable definition.<br /><br />The goal with this project is to provide a basic seed that any team could use. Next, I will add in some other building blocks, and implementation a ReDoc, DapperDox, or WSDLDoc version. Providing four separate documentation examples that developers can fork and use to document the APIs they are working on. In my opinion, one or more API documentation templates like this should be available for teams to fork or download and implement within any organization. All API governance guidance like this should have the text describing the policy, as well as one or many examples of the policy being delivered. Hopefully this projects shows an example of this in action.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/va-working/va-demo-swagger-ui-documentation.png"
  },
  {
  "title": "May Contain Nuts: The Case for API Labeling by Erik Wilde (@dret), API Academy (@apiacademy)",
  "date": "24 Aug 2018",
  "body": "<br />We are getting closer to the 9th edition of APIStrat happening in Nashville, TN this September 24th through 26th. The schedule for the conference is up, along with the first lineup of keynote speakers, and my drumbeat of stories about the event continues here on the blog. Next up in our session lineup is “May Contain Nuts: The Case for API Labeling“ by Erik Wilde (@dret), API Academy (@apiacademy) on September 25th.<br /><br />Here is Erik’s background set the stage for his session:<br /><br />Erik is a frequent speaker at both industry and academia events. In his current role at the API Academy, his work revolves around API strategy, design, and management, and how to help organizations with their digital transformation. Based on his extensive background in Web architecture and technologies, Erik combines deep expertise in protocols and representations with insights into API practices at today’s organizations.<br /><br />Before joining API Academy and working in the API space full-time, Erik spent time at Siemens and EMC, in both cases working at ways how APIs could be used for their internal service ecosystems, as well as for better ways for customers to use services and products. Before that, Erik spent most of his life in academia, working at UC Berkeley and ETH Zürich. Erik received his Ph.D. in computer science from ETH Zürich, and his diploma in computer science from TU Berlin.<br /><br />Erik nows his stuff, and can be found on the road with the CA API Academy, making this stop in Nashville, TN a pretty special opportunity. You can register for the event here, and there are still sponsorship opportunities available. Don’t miss out on APIStrat this year–it is going to be a good time in Nashville as we continue the conversation we started back in 2012 with the initial edition of the API industry event in New York City.<br /><br />I am looking forward to seeing you all in Nashville next month!<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/events/apistrat-2018/erik-wilde.jpg"
  },
  {
  "title": "How Should Teams Be Documenting Their APIs When You Have Both Legacy And New APIs?",
  "date": "24 Aug 2018",
  "body": "I’m continuing my work to help the Department of Veterans Affairs (VA) move forward their API strategy. One area I’m happy to help the federal agency with, is just being available to answer  questions, which I also find make for great stories here on the blog–helping other federal agencies also learn along the way. One question I got from the agency recently, is regarding how the teams should be documenting their APIs, taking into consideration that many of them are supporting legacy services like SOAP.<br /><br />From my vantage point, minimum viable API documentation should always include a machine readable definition, and some autogenerated documentation within a portal at a known location. If it is a SOAP service, WSDL is the format. If it is REST, OpenAPI (fka Swagger) is the format. If its XML RPC, you can bend OpenAPI to work. If it is GraphQL, it should come with its own definitions. All of these machine readable definitions should exist within a known location, and used as the central definition for the documentation user interface. Documentation should not be hand generated anymore with the wealth of open source API documentation available.<br /><br />Each service should have its own GitHub/BitBucket/GitLab repository with the following:<br /><br /><br />  README - Providing a concise title and description for the service, as well as links to all documentation, definitions, and other resources.<br />  Definitions - Machine readable API definitions for the APIs underlying schema, and the surface area of the API.<br />  Documentation - Autogenerated documentation for the API, driven by its machine readable definition.<br /><br /><br />Depending on the type of API being deployed and managed, there should be one or more of these definition formats in place:<br /><br /><br />  Web Services Description Language (WSDL) - The XML-based interface definition used for describing the functionality offered by the service.<br />  OpenAPI - The YAML or JSON based OpenAPI specification format managed by the OpenAPI Initiative as part of the Linux Foundation.<br />  JSON Schema - The vocabulary that allows for the annotation and validation of the schema for the service being offered–it is part of OpenAPI specification as well.<br />  Postman Collections - JSON based specification format created and maintained by the Postman client and development environment.<br />  API Blueprint - The markdown based API specification format created and maintained by the Apiary API design environment, now owned by Oracle.<br />  RAML - The YAML based API specification format created and maintained by Mulesoft.<br /><br /><br />Ideally, OpenAPI / JSON Schema is established as the primary format for defining the contract for each API, but teams should also be able to stick with what they were given (legacy), and run with the tools they’ve already purchased (RAML &amp;amp; API Blueprint), and convert between specifications using API Transformer.<br /><br />API documentation should be published to it’s GitHub/GitLab/BitBucket repository, and hosted using one of the service static project site solutions with one of the following open source documentation:<br /><br /><br />  Swagger UI - Open source API documentation driven by OpenAPI.<br />  ReDoc - Open source API documentation driven by OpenAPI.<br />  RAML - Open source API documentation driven by RAML.<br />  DapperDox - DapperDox is Open-Source, and provides rich, out-of-the-box, rendering of your OpenAPI specifications, seamlessly combined with your GitHub flavoured Markdown documentation, guides and diagrams.<br /><br /><br />There are other open source solutions available for auto-generating API documentation using the core API’s definition, but these represent the leading solutions out there. Depending on the solution being used to deploy or manage an API, there might be built-in, ready to go options for deploying documentation based upon the OpenAPI, WSDL, RAML or other using AWS API Gateway, Mulesoft, or other existing vendor solution already in place to support API operations.<br /><br />Even with all this effort, a repository, with a machine readable API definition, and autogenerated documentation still doesn’t provide enough of a baseline for API teams to follow. Each API documentation should possess the following within those building blocks:<br /><br /><br />  Title and Description - Provide the concise description of what an API does from the README, and make sure it is based into the APIs definition.<br />  Base URL - Have the base URL, or variable representation for a base URL present in API definitions.<br />  Base Path - Provide any base path that is constant across paths available for any single API.<br />  Content Types - List what content types an API accepts and returns as part of its operations.<br />  Paths - List all available paths for an API, with summary and descriptions, making sure the entire surface area of an API is documented.<br />  Parameters - Provide details on the header, path, and query parameters used for API path being documented.<br />  Body - Provide details on the schema for the body of each API path that accepts a body as part of its operations.<br />  Responses - Provide HTTP status code and reference to the schema being returned for each path.<br />  Examples - Provide example requests and response for each API path being documented.<br />  Schema - Document all schema being used as part of requests and responses for all APIs paths being documented.<br /><br /><br />If EVERY API possesses its own repository, and README to get going, guiding all API consumers to complete, up to date, and informative documentation that is auto-generated, a significant amount of friction during the on-boarding process can be eliminated. Additionally, friction at the time of hand-off for any service from on team to another, or one vendor to another, will be significantly reduced–with all relevant documentation available within the project’s repository.<br /><br />API documentation delivered in this way provides a single known location for any human to go when putting an API to work. It also provides a single known location to find a machine readable definition that can be used to on-board using an API client like Postman, PAW, or Insomnia. The API definition provides the contract for the API documentation, but it also provides what is needed across other stops along the API lifecycle, like monitoring, testing, SDK generation, security, and client integration–reducing the friction across many stops along the API journey.<br /><br />This should provide a baseline for API documentation across teams. No matter how big or small the API, or how new or old the API is. Each API should have API documentation available in a consistent, and usable way. Providing a human and programmatic way for understanding what an API does, that can be use to on-board and maintain integrations with each application. The days of PDF and static API documentation are over, and the baseline for each APIs documentation always involves having a machine readable contract as the core, and managing the documentation as part of the pipeline used to deploy and manage the rest of the API lifecycle.<br />",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/algorotoscope/builder/filtered/23_19_800_500_0_max_0_-5_-1.jpg"
  },
  {
  "title": "The Importance Of Postman API Environment Files",
  "date": "23 Aug 2018",
  "body": "I’m a big fan of Postman, and the power of their development environment, as well as their Postman Collection format. I think their approach to not just integrating with APIs, but also enabling the development and delivery of APIs has shifted the conversation around APIs in the last couple of years–not too many API service providers accomplish this in my experience. There are several dimensions to what Postman does that I think are pushing the API conversation forward, but one that has been capturing my attention lately are Postman Environment Files.<br /><br />Using Postman, you can manage many different environments used for working with APIs, and if you are a pro or enterprise customer, you can export a file that represents an environment, making each of these API definitions more portable and collaborative. Managing the variety of environments for the hundreds of APIs I use is one of the biggest pain points I have. Postman has significantly helped me get a handle on the tokens and keys I use across the internal, as well as partner and public APIs that I depend on each day to operate API Evangelist.<br /><br />Postman environments allows me to define environments within the Postman application, and then share them as part of the pro / enterprise team experience. You can also manage your environments through the Postman API, if you need to more deeply integrate with your operations. The Postman Environment File makes all of this portable, sharable, and used across environments. It is one of the reasons that makes Postman Collections more valuable to some users, in specific contexts, because it has that run time aspect to what it does. Postman let’s you communicate effectively around the APIs you are deploying and integrating with, and solves relevant pain points like API environment management, that can stand in the way of integration.<br /><br />There aren’t many features of API service providers I get very excited about, but the potential of Postman as an environment management solution is significant. If Postman is able to establish itself as the broker of credentials at the API environment level, it will give them a significant advantage of other service providers. With the size of their developer base, having visibility at the environment level puts their finger on the pulse of what is going on in the API economy, from both an API provider and consumer perspective. With Postman Environment Files acting as a sort of key, or currency, that has to exist before any API transaction can be executed. And, as the number of APIs we depend on increases, the importance of having a strategy (and solution) for managing our environment will grow exponentially–putting Postman in a pretty sweet position.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/postman/postman-environments.png"
  },
  {
  "title": "Any Way You Want It: Extending Swagger UI for Fun and Profit by Kyle Shockey (@kyshoc) of SmartBear Software (@SmartBear) At @APIStrat In Nashville",
  "date": "23 Aug 2018",
  "body": "<br />We are getting closer to the 9th edition of APIStrat happening in Nashville, TN this September 24th through 26th. The schedule for the conference is up, along with the first lineup of keynote speakers, and my drumbeat of stories about the event continues here on the blog. Next up in our session lineup is “Any Way You Want It: Extending Swagger UI for Fun and Profit” by Kyle Shockey (@kyshoc) of SmartBear Software (@SmartBear) on September 25th.<br /><br />Here is Kyle’s abstract for the session:<br /><br />Your APIs are tailored to your needs - shouldn’t your tools be as well? In this talk, we’ll explore how Swagger UI 3 makes it easier than ever to create custom functionality, and common use cases for the power that the UI’s plugin system provides.<br /><br />Learn how to:<br /><br />- Create plugins that extend existing features and define new functionality<br />- Integrate Swagger UI seamlessly by defining a custom layout<br />- Package and share plugins that can be reused by the community (or your organization)<br /><br />Swagger UI has changed the conversation around how we document our APIs, and being able to extend the interface is an important part of keeping the API documentation conversation evolving, and APIStrat is where this type of discussion is happening. You can register for the event here, and there are still sponsorship opportunities available. Don’t miss out on APIStrat this year–it is going to be a good time in Nashville as we continue the conversation we started back in 2012 with the initial edition of the API industry event in New York City.<br /><br />I am looking forward to seeing you all in Nashville next month!<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/events/apistrat-2018/kyle-shocky-smarbear.jpeg"
  },
  {
  "title": "Searching For APIs That Possess Relevant Company Information",
  "date": "22 Aug 2018",
  "body": "<br />I’m evolving the search for the Streamdata.io API Gallery I’ve been working on lately. I’m looking to move the basic keywords search that searches the API name and description, as well as the API path, summary, and description using a key word or phrase, to also be about searching parameters in a meaningful way. Each of the APIs in the Streamdata.io API have an OpenAPI definition. It is how I render each of the individual API paths using Jekyll and Github Pages. These parameters give me another dimension of data in which I can index, and use as a facet in my API gallery search.<br /><br />I am developing different sets of vocabulary to help me search against the parameters used across APIs, with one of them being focused on company related information. I’m trying to find APIs that provide the ability to add, update, and search against company related data, content, and execute algorithms that help make sense of company resources. There is no perfect way to search for API parameters that touch on company resources, but right now I’m looking for a handful of fields: company, organization, business, enterprise, agency, ticker, corporate, and employer. Returning APIs that have a parameter with any of those words in the path or summary, and weighting differently if it is in the description or tags for each API path.<br /><br />Next, I’m also tagging each API path that has a URL field, because this will allow me to connect the dot to a company, organization, or other entity via the domain. This is all I’m trying to do, is connect the dots using the parameter structure of an API. I find that there is an important story being told at the API design layer, and API search and discovery is how we are going to bring this story out. Connecting the dots at the corporate level is just one of many interesting stories out there, just waiting to be told. Pushing forward the conversation around how we understand the corporate digital landscape, and what resources they have available.<br /><br />You can do a basic API search at the bottom of the Streamdata.io API Gallery main page. I do not have my parameter search available publicly yet. I want to spend more time refining my vocabularies, and also look at searching the request and response bodies for each path–I’m guessing this won’t be as straightforward, as parameters has been. Right now I’m immersed in understanding the words we use to design our APIs, and craft our API documentation. It is fascinating to see how people describe their resources, and how they think (or don’t think) about making these resources available to other people. OpenAPI definitions provide a fascinating way to look at how APIs are opening up access to company information, establishing the digital vocabulary for how we exchange data and content, and apply algorithms to help us better understand the business world around us.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories-new/cityscape_copper_circuit.jpg"
  },
  {
  "title": "It Is Hard To Go API Define First",
  "date": "22 Aug 2018",
  "body": "<br />Last year I started saying API define first, instead of API design first. In response to many of the conversations out there about designing, then mocking, and eventually deploying your APIs into a production environment. I agree that you should design and iterate before writing code, but I feel like we should be defining our APIs even before we get to the API design phase. Without the proper definitions on the table, our design phase is going to be a lot more deficient in standards, common patterns, goals, and objectives, making it important to invest some energy in defining what is happening first–then iterate on the API definitions throughout the API lifecycle, not just design.<br /><br />I prefer to have a handful of API definitions drafted, before I move onto to the API design phase:<br /><br /><br />  Title - A simple, concise title for my API.<br />  Description - A simple, concise description for my API.<br />  JSON Schema - A set of JSON schema for my APIs<br />  OpenAPI - An OpenAPI for the surface area of my API.<br />  Assertions - A list of what my API should be delivering.<br />  Standards - What standards are being applied with this API.<br />  Patterns - What common web patterns will be used with this API.<br />  Goals - What are the goals for this particular API.<br /><br /><br />I like having all of this in a GitHub repository before I get to work, actually designing my APIs. It provides me with the base set of definitions I need to go to be as effective as I can in my API design phase. Of course, each of these definitions will be iterated, added to, and evolved as part of the API design phase, and beyond. The goal is to just get a base set of building blocks on the workbench, properly setting the tone for what my API will be doing. Grounding my API work early on in the API lifecycle, in a consistent way that I can apply across many different APIs.<br /><br />The problem with all of this, is that it is easier said than done. I still like to hand code my APIs. It is something I’ve been doing for 20 years, and it is a habit that is hard to kick. When designing an API, often times I do not know what is possible, and I need to hack on the solution for a while. I need to hack on and massage some data, content, or push forward my algorithm a little. All of this has to happen before I can articulate the interface will look like. Sure, I might have some basic RESTful notions about what API paths will be, and the schema I’ve gathered will drive some of the conversation, but I still need to hack together a little goodness, before I can design.<br /><br />This is ok. With some APIs I will be able to define and then design without ever touching any code. While others I will still have to prototype at least a function to prove the concept behind the API. Once I have the proof of concept, then I can start crafting a sensible interface using OpenAPI, then mock, and work with the concept a little more within an API design phase. Ultimately, I do not think there is any RIGHT WAY to develop an API. I think there are healthier, and less healthier ways. I think there are more hardened, and proven ways, but I also think there should be experimental, and even legacy ways of doing things. My goal is to always make sure the process is as sensible and pragmatic as it can be, while meeting the immediate, and long term business goals of my company, as well as my partners.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories-new/69_120_800_500_0_max_0_1_-1.jpg"
  },
  {
  "title": "Describing Your API with OpenAPI 3.0 by Anthony Eden (@aeden), DNSimple (@dnsimple) At @APIStrat In Nashville",
  "date": "21 Aug 2018",
  "body": "<br />We are getting closer to the 9th edition of APIStrat happening in Nashville, TN this September 24th through 26th. The schedule for the conference is up, along with the first lineup of keynote speakers, and my drumbeat of stories about the event continues here on the blog. Next up in our session lineup is “Describing Your API with OpenAPI 3.0” by Anthony Eden (@aeden), DNSimple (@dnsimple) on September 25th.<br /><br />Here is Christian’s abstract for the session:<br /><br />For the last 10 years, DNSimple has operated a comprehensive web API for buying, connecting, and operating domain names. After hearing about OpenAPI at APIStrat 2017, we decided to describe the DNSimple API using the OpenAPI v3 specification - this is the story of why we did it, how we did it, and where we are today.<br /><br />By the end of this presentation you will have the tools you’ll need to evaluate your own API and decide if implementing OpenAPI makes sense for you, and if so, how you can get started. You’ll have a better understanding of the tools available to you to help write your OpenAPI 3 definition, as well the basics on how to write your own definition for your APIs.<br /><br />We are all still working to make the switch from OpenAPI 2.0 to 3.0, and with APIStrat being owned and operated by the OpenAPI Initiative, it will definitely be the place to have face to face discussions that influence the road map for the API specification. You can register for the event here, and there are still sponsorship opportunities available. Don’t miss out on APIStrat this year–it is going to be a good time in Nashville as we continue the conversation we started back in 2012 with the initial edition of the API industry event in New York City.<br /><br />I am looking forward to seeing you all in Nashville next month!<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/events/apistrat-2018/anthony-eden-dns-simple.jpeg"
  },
  {
  "title": "Working With My OpenAPI Definitions In An API Editor Helps Stabilize Them",
  "date": "07 Aug 2018",
  "body": "<br />I’m deploying three new APIs right now, using a new experimental serverless approach I’m evolving. One is a location API, another providing API access to companies, and the third involves working with patents. I will be evolving these three simple web APIs to meet the specific needs of some applications I’m building, but then I will also be selling retail and wholesale access to each API once they’ve matured enough. With all three APIs of these APIs, I began with a simple JSON schema from the data source, which I used to generate three rough OpenAPI definitions that will acts the contract seed for my three services.<br /><br />Once I had three separate OpenAPI contracts for the services I was delivering, I wanted to spend some time hand designing each of the APIs before I imported into AWS API Gateway, generating Lambda functions, loading in Postman, and used to support other stops along the API lifecycle. I still use a localized version of Swagger Editor for my OpenAPI design space, but I’m working to migrate to OpenAPI-GUI as soon as I can. I still very much enjoy the side by side design experience in Swagger Editor, but I want to push forward the GUI side of the conversation, while still retaining quick access to the RAW OpenAPI for editing.<br /><br />One of the reasons why I still use Swagger Editor is because of the schema validation it does behind the scenes. Which is one of the reasons I need to learn more about Speccy, as it is going to help me decouple validation from my editor, and all me to use it as part of my wider governance strategy, not just at design time. However, for now I am highly dependent on my OpenAPI editor helping me standardize and stabilize my OpenAPI definitions, before I use them along other stops along the API lifecycle. These three APIs I’m developing are going straight to deployment, because they are simple datasets, where I’m the only consumer (for now), but I still need to make sure my API contract is solid before I move to other stops along the API lifecycle.<br /><br />Right now, loading up an OpenAPI in Swagger Editor is the best sanity check I have. Not just making sure everything validates, but also making sure it is all coherent, and renders into something that will make sense to anyone reviewing the contract. Once I’ve spend some time polishing the rough corners of an OpenAPI, adding summary, descriptions, tags, and other detail, I feel like I can begin using to generate mocks, deploy in a gateway, and begin managing the access to each API, as well as the documentation, testing, monitoring, and other stops using the OpenAPI contract. Making this manual stop in the evolution of my APIs a pretty critical one for helping me stabilize each API’s definition before I move on. Eventually, I’d like to automate the validation and governance of my APIs at scale, but for now I’m happy just getting a handle on it as part of this API design stop along my life cycle.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/openapi/swagger-editor-screenshot.png"
  },
  {
  "title": "We Need Your Help Moving The AsyncAPI Specification Forward",
  "date": "31 Jul 2018",
  "body": "<br />We need your help moving the AsyncAPI specification forward. Ok, first, what is the AsyncAPI specification? “The AsyncAPI Specification is a project used to describe and document Asynchronous APIs. The AsyncAPI Specification defines a set of files required to describe such an API. These files can then be used to create utilities, such as documentation, integration and/or testing tools.” AsyncAPI is a sister specification to OpenAPI, but instead of describing the request and response HTTP API landscape, AsyncAPI is describing the message, topic, event, and streaming API landscape across the HTTP and TCP landscape. It is how we are going to continue to ensure there is machine readable descriptions of this portion of the API landscape, for use in tooling and services.<br /><br />My friend Fran Mendez (@fmvilas) is the creator and maintainer of the specification, and he is doing way too much of the work on this important specification and he needs our help. Here is Fran’s request for our help to contribute:<br /><br /><br />  AsyncAPI is an open source project that’s currently maintained by me, with no company or funds behind. More and more companies are using AsyncAPI and the work needed is becoming too much work for a single person working in his spare time. E.g., for each release of the specification, tooling and documentation should be updated. One could argue that I should be dedicating full time to the project, but it’s in this point where it’s too much for spare time and very little to get enough money to live. I want to keep everything for free, because I firmly believe that engineering must be democratized. Also, don’t get me wrong, this is not a complaint. I’m going to continue running the project either with or without contributors, because I love it. This is just a call-out to you, the AsyncAPI lover. I’d be very grateful if you could lend a hand, or even raise your hand and become a co-maintainer. Up to you 😊<br /><br /><br /><br />  On the other hand, I only have good words for all of you who use and/or contribute to the project. Without you, it would be just another crazy idea from another crazy developer 😄<br /><br /><br /><br />  Thank you very much! 🙌<br /><br /><br /><br />  – Fran Mendez<br /><br /><br />When it comes to contributing to the AsyncAPI, Fran has laid out some pretty clear ways in which he needs our help, providing a range of options for you to pitch in and help, depending on what your skills are, and the bandwidth you have in your day.<br /><br />1. The specification<br />There is always work to do in the spec. It goes from fixing typos to writing and reviewing new proposals. I try to keep releases small, to give time to tooling authors to update their software. If you want to start contributing, take a look at https://github.com/asyncapi/asyncapi/issues, pick one, and start working on it. It’s always a good idea to leave a comment in the issue saying that you’re going to work on it, just so other people know about it.<br /><br />2. Tooling<br />As developers, this is sometimes the most straightforward way to contribute. Adding features to the existing tools or creating new ones if needed. Examples of tools are:<br /><br /><br />  Code generators (multiple languages):<br />    <br />      https://github.com/asyncapi/generator<br />      https://github.com/asyncapi/node-codegen (going to be deprecated soon in favor of https://github.com/asyncapi/generator)<br />    <br />  <br />  Documentation generators (multiple formats):<br />    <br />      https://github.com/asyncapi/generator<br />      https://github.com/asyncapi/docgen (going to be deprecated soon in favor of https://github.com/asyncapi/generator)<br />      https://github.com/Mermade/widdershins<br />      https://github.com/asyncapi/asyncapi-node<br />      https://github.com/asyncapi/editor<br />    <br />  <br />  Validation CLI tool (nobody implemented it yet)<br />  API mocking (nobody implemented it yet)<br />  API gateways (nobody implemented it yet)<br /><br /><br />As always, usually the best way to contribute is to pick an issue and chat about it before you create a pull request.<br /><br />3. Evangelizing<br />Sometimes the best way to help a project like AsyncAPI is to simply talk about it. It can be inside your company, in a technology meetup or speaking at a conference. I’ll be happy to help with whatever material you need to create or with arguments to convince your colleagues that using AsyncAPI is a good idea 😊<br /><br />4. Documentation<br />Oh! documentation! We’re trying to convince people that documenting your message-driven APIs is a good idea, but we lack documentation, especially in tooling. This is often a task nobody wants to do, but the best way to get great knowledge about a technology is to write documentation about it. It doesn’t need to be rewriting the whole documentation from scratch, but just identifying the questions you had when started using it and document them.<br /><br />5. Tutorials<br />We learn by examples. It’s a fact. Write tutorials on how to use AsyncAPI in your blog, Medium, etc. As always, count on me if you need ideas or help while writing or reviewing.<br /><br />6. Stories<br />You have a blog and write about the technology you use? Writing about success stories, how-to’s, etc., really helps people to find the project and decide whether they should bet on AsyncAPI or not.<br /><br />7. Podcasts/Videos<br />You have a Youtube channel or your own podcast? Talk about AsyncAPI. Tutorials, interviews, informal chats, discussions, panels, etc. I’ll be happy to help with any material you need or finding the right person for your interview.<br /><br /><br />I’m going to take the liberty and add an 8th option, because I’m so straightforward when it comes to this game, and I know where Fran needs help.<br /><br />8. Money <br />AsyncAPI needs investment to help push forward, allowing Fran to carve out time, work on tooling, and pay for travel expenses when it comes to attending events and getting the word out about what it does. There is no legal entity setup for AsyncAPI, but I’m sure with the right partner(s) behind it, we can make something happen. Step up.<br /><br />AsyncAPI is important. We all need to jump in and help. I’ve been investing as many cycles as I can in helping learn about the specification, and tell stories about why it is important. I’ve been working hard to learn more about it so I can contribute to the roadmap. I’m using it as one of the key definition formats driving my Streamdata.io API Gallery work, which is all driven using APIs.json, OpenAPI, and provides Postman Collections as well as AsyncAPI definitions when a message, topic, event, or streaming API is present. AsyncAPI is where OpenAPI (Swagger) was in 2011/2012, and with more investment, and a couple more years of adoption and maturing, it will be just as important for working with the evolving API landscape as OpenAPI and Postman Collections are.<br /><br />If you want to get involved with AsyncAPI, feel free to reach out to me. I’m happy to help you get up to speed on why it is so important. I’m happy to help you understand how it can be applied, and where it fits in with your API infrastructure. You are also welcome to just dive in, as Fran has done an amazing job of making sure everything is available in the Github organization for the project, where you can submit pull requests, and issues regarding whatever you are working on and contributing. Thanks for your help in making AsyncAPI evolve, and something that will continue to help us understand, quantify, and communicate about the diverse API landscape.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/asyncapi/asyncapi-define-your-message-driven-apis.png"
  },
  {
  "title": "TVMaze Uses HAL For Their API Media Type",
  "date": "16 Jul 2018",
  "body": "<br />One of the layers of the API universe where I come across an increased number Hypermedia APIs is in the movie, television, and entertainment space. Where having a more flowing API experience makes a lot of sense, and the extra investment in link relations will pay off. One example of this I recently came across was over at TVMaze, who has a pretty robust hypermedia API, where they opted for using HAL as their media type.<br /><br />Like any good hypermedia should, TVMaze begins with its root URL: http://api.tvmaze.com, and provides a robust set of endpoints from there:<br /><br />Search&amp;lt;/a&amp;gt;<br /><br />  Show Search<br />  Show single search<br />  Show Lookup<br />  People search<br /><br /><br />Schedule&amp;lt;/a&amp;gt;<br /><br />  Full Schedule<br /><br /><br />Shows&amp;lt;/a&amp;gt;<br /><br />  Show main information<br />  Show episode list<br />  Episode by number<br />  Episodes by date<br />  Show seasons<br />  Season episodes<br />  Show cast<br />  Show crew<br />  Show AKA’s<br />  Show index<br /><br /><br />People&amp;lt;/a&amp;gt;<br /><br />  Person main information<br />  Person cast credits<br />  Person crew credits<br /><br /><br />Updates&amp;lt;/a&amp;gt;<br /><br />  Show updates<br /><br /><br />The TVMaze API isn’t an overly complex hypermedia API. I think it is simple, elegant, and shows how you can use link relations to establish a more meaningful experience for API consumers. Allowing you to navigate the large, ever-changing catalog of television shows, allowing the API client to do the heavy lifting of navigating the shows, schedules, and people involved with each production.<br /><br />There hasn’t been enough showcasing of the hypermedia APIs available out there. Usually once a year I remember to give the subject some attention, or when I come across interesting ones like TVMaze. Hypermedia isn’t just an academic idea anymore, and is something that has gotten traction in a number of sectors, and I keep seeing signs of growth and adoption. I don’t think it will be the API solution most hypermedia believers envisioned it, but I do think it is a viable tool in our API toolbox, and for the right projects it makes a lot of sense.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/tv-maze/tvm_api.png"
  },
  {
  "title": "If A Search For Swagger or OpenAPI Does Yield Results I Try For A Postman Collection Next",
  "date": "16 Jul 2018",
  "body": "<br />While profiling any company, a couple of the Google searches I will execute right away are for “[Company Name] Swagger” and “[Company Name] OpenAPI”, hoping that a provide is progressive enough to have published an OpenAPI definition–saving me hours of work understanding what their API does. I’ve added a third search to my toolbox, if these other two searches do not yield results, searching for “[Company Name] Postman”, revealing whether or not a company has published a Postman Collection for their API–another sign of a progressive, outward thinking API provider in my book.<br /><br />A machine readable definition for an API tells me more about what a company, organization, institution, or government agency does, than anything else I can dig up on their website, or social media profiles. An OpenAPI definition or Postman Collection is a much more honest view of what an organization does, than the marketing blah blah that is often available on a website. Making machine readable definitions something I look for almost immediately, and prioritize profiling, reviewing, and understanding the entities I come across with a machine readable definition, over those that do not. I only have so much time in a day, and I will prioritize an entity with an OpenAPI or Postman, over those who do not.<br /><br />The presence of an OpenAPI and / or Postman Collection isn’t just about believing in the tooling benefits these definitions provide. It is about API providers thinking externally about their API consumers. I’ve met a lot of API providers who are dismissive of these machine readable definitions as trends, which demonstrates they aren’t paying attention to the wider API space, and aren’t thinking about how they can make their API consumers lives easier–they are focused on doing what they do. In my experience these API programs tend to not grow as fast, focus on the needs of their integrators and consumers, and often get shut down after they don’t get the results they thought they’d see. APIs are all about having that outward focus, and the presence of OpenAPI and Postman Collection are a sign that a provider is looking outward.<br /><br />While I’m heavily invested in OpenAPI (I am member), I’m also invested in Postman. More importantly, I’m invested in supporting well defined APIs that provide solutions to developers. When an API has an OpenAPI for delivering mocks, documentation, testing, monitoring, and other solutions, and they provide a Postman Collection that allows you to get up an running making API calls in seconds or minutes, instead of hours or days–it is an API I want to know more about. Making these potential searches the deciding factor between whether or not I will continue profiling and reviewing an API, or just flagging it for future consideration, and moving on to the next API in the queue. I can’t keep up with the number of APIs I have in my queue, and it is signals like this that help me prioritize my world, and get my work done on a regular basis.<br />",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/algorotoscope/builder/filtered/80_86_800_500_0_max_0_1_-1.jpg"
  },
  {
  "title": "People Do Not Use Tags In Their OpenAPI Definitions",
  "date": "10 Jul 2018",
  "body": "<br />I import and work with a number of OpenAPI definitions that I come across in the wild. When I come across a version 1.2, 2.0, 3.0 OpenAPI, I import them into my API monitoring system for publishing as part of my research. After the initial import of any OpenAPI definition, the first thing I look for is the consistent in the naming of paths, the availability of summary, descriptions, as well as tags. The naming conventions used is paths is all over the place, some are cleaner than others. Most have a summary, with fewer having descriptions, but I’d say about 80% of them do not have any tags available for each API path.<br /><br />Tags for each API path are essential to labeling the value a resource delivers. I’m surprised that API providers don’t see the need for applying these tags. I’m guessing it is because they don’t have to work with many external APIs, and really haven’t put much thought into other people working with their OpenAPI definition beyond it just driving their own documentation. Many people still see OpenAPI as simply a driver of API documentation on their portal, and not as an API discovery, or complete lifecycle solution that is portable beyond their platform. Not considering how tags applied to each API resource will help others index, categorize, and organize APIs based upon the value in delivers.<br /><br />I have a couple of algorithms that help me parse the path, summary, and description to generate tags for each path, but it is something I’d love for API providers to think more deeply about. It goes beyond just the resources available via each path, and the tags should reflect the overall value an API delivers. If it is a product, event, messaging, or other resource, I can extract a tag from the path, but the path doesn’t always provide a full picture, and I regularly find myself adding more tags to each API(if I have the time). This means that many of the APIs I’m profiling, and adding to my API Stack, API Gallery, and other work isn’t as complete with metadata as they possibly could be. Something API providers should be more aware of, and helping define as part of their hand crafting, or auto-generation of OpenAPI definitions.<br /><br />It is important for API providers to see their OpenAPI definitions as more than just a localized, static feature of their platforms, and as a portable definition that will be used by 3rd party API service providers, as well as their API consumers. They should be linking their OpenAPI prominently from your API documentation, and not hiding behind the JavaScript voodoo that generates your docs. They should be making sure OpenAPI definitions are as complete as you possibly can, with as much metadata as possible, describing the value that it delivers. Loading up OpenAPI definitions into a variety of API design, documentation, discovery, testing, and other tooling to see what it looks like and how it behaves. API providers will find that tags are beginning to be used for much more than just grouping of paths in your API documentation, and it is how gateways are organizing resources, management solutions are defining monetization and billing, and API discovery solutions are using to drive their API search solutions–to just point out a couple of ways in which they are used.<br /><br />Tag your APIs as part of your OpenAPI definitions! I know that many API providers are still auto-generating from a system, but once they have published the latest copy, make sure you load up in one of the leading API design tools, and give that last little bit of polish. Think of it as that last bit of API editorial workflow that ensures your API definitions speak to the widest possible audience, and are as coherent as it possibly can. Your API definitions tell a story about the resources you are making available, and the tags help provide a much more precise way to programmatically interpret what APIs actually deliver. Without them APIs might not properly show up in search engine and Github searches, or render coherently in other API services and tooling. OpenAPI tags are an essential part of defining and organizing your API resources–give them the attention they deserve.<br />",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/algorotoscope/builder/filtered/68_158_800_500_0_max_0_-5_-1.jpg"
  },
  {
  "title": "Using OpenAPI And JSON PATCH To Articulate Changes For Your API Road Map",
  "date": "10 Jul 2018",
  "body": "<br />I’m doing a lot of thinking regarding how JSON PATCH can be applied because of my work with Streamdata.io. When you proxy an existing JSON API with Streamdata.io, after the initial response, every update sent over the wire is articulated as a JSON PATCH update, showing only what has changed. It is an efficient, and useful way to show what has changed with any JSON API response, while being very efficient about what you transmit with each API response, reducing polling, and taking advantage of HTTP caching.<br /><br />As I’m writing an OpenAPI diff solution, helping understand the differences between OpenAPI definitions I’m importing, and allowing me to understand what has changed over time, I can’t help but think that JSON PATCH would be a great way to articulate change of the surface area of an API over time–that is, if everyone loyally used OpenAPI as their API contract. Providing an OpenAPI diff using JSON PATCH would be a great way to articulate an API road map, and tooling could be developed around it to help API providers publish their road map to their portal, and push out communications with API consumers. Helping everyone understand exactly what is changing in way that could be integrated into existing services, tooling, and systems–making change management a more real time, “pipelinable” (making this word up) affair.<br /><br />I feel like this could help API providers better understand and articulate what might be breaking changes. There could be tooling and services that help quantify the scope of changes during the road map planning process, and teams could submit OpenAPI definitions before they ever get to work writing code, helping them better see how changes to the API contract will impact the road map. Then the same tooling and services could be used to articulate the road map to consumers, as the road map becomes approved, developed, and ultimately rolled out. With each OpenAPI JSON PATCH moving from road map to change log, keeping all stakeholders up to speed on what is happening across all API resources they depend on–documenting everything along the way.<br /><br />I am going to think more about this as I evolve my open API lifecycle. How I can iterate a version of my OpenAPI definitions, evaluate the difference, and articulate each update using JSON PATCH. Since more of my API lifecycle is machine readable, I’m guessing I’m going to be able to use this approach beyond just the surface area of my API. I’m going to be able to use it to articulate the changes in my API pricing and plans, as well as licensing, terms of service, and other evolving elements of my operations. It is a concept that will take some serious simmering on the back burners of my platform, but a concept I haven’t been able to shake. So I might as well craft some stories about the approach, and see what I can move forward as I continue to define, design, and iterate on the APIs that drive my platform and API research forward.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/downtheline_dali_three.jpg"
  },
  {
  "title": "Not Liking OpenAPI (fka Swagger) When You Have No Idea What It Does",
  "date": "26 Jun 2018",
  "body": "<br />People love to hate in the API space. Ok, I guess its not exclusive to the API space, but it is a significant aspect of the community. I receive a regular amount of people hating on my work, for no reason at all. I also see people doing it to others in the API space on a regular basis. It always makes me sad to see, and have always worked to try to be as nice as I can to counteract the male negativity and competitive tone that often exists. While I feel bad for the people on the receiving end of all of this, I often times feel bad for the people on the giving end of things, as they are often not the most informed and up to speed folks, who seem to enjoy opening their mouth before they understand what is happening.<br /><br />One thing I notice regularly, is that these same people like to bash on is OpenAPI (fka Swagger). I regularly see people (still) say how bad of an idea it is, and how it has done nothing for the API space. One common thread I see with these folks, which prevents me from saying anything to them, is that it is clear they really don’t have an informed view of what OpenAPI is. Most people spend a few minutes looking it, maybe read a few blog posts, and then establish their opinions about what it is, or what it isn’t. I regularly find people who are using it as part of their work, and don’t actually understand the scope of the specification and tooling, so when someone is being vocal about it and doesn’t use actually it, it is usually pretty clear pretty quickly how uninformed they are about the specification, tooling, and scope of the community.<br /><br />I’ve been tracking on it since 2011, and I still have trouble finding OpenAPI specifications, and grasping all of the ways it is being used. When you are a sideline pundit, you are most likely seeing about 1-2% of what OpenAPI does–I am a full time pundit in the game and I see about 60%. The first sign that someone isn’t up to speed is they still call it Swagger. The second sign is they often refer to it as documentation. Thirdly, they often refer to code generation with Swagger as a failure. All three of these views date someone’s understanding to about a 2013 level. If someone is forming assumptions, opinions, and making business decisions about OpenAPI, and being public about it, I’d hate to see what the rest of their technology views look like. In the end, I just don’t even feel like picking on them, challenging them on their assumptions, because their regular world is probably already kicking their ass on a regular basis–no assistance is needed.<br /><br />I do not feel OpenAPI is the magical solution to fix all the challenges the API space, but it does help reduce friction at almost every stop along the API lifecycle. In my experience, 98% of the people who are hating on it do not have a clue what OpenAPI is, or what it does. I used to challenge folks, and try to educate them. Over the years I’ve converted a lot of folks from skeptics to believers, but in 2018, I think I’m done. If someone is openly criticizing it, I’m guessing it is more about their relationship to tech, and their lack of awareness of delivering APIs at scale, and they probably exist in a pretty entrenched position because of their existing view of the landscape–they don’t need me piling on. However, if people aren’t aware of the landscape, and ask questions about how OpenAPI works, I’m always more than happy to help open their eyes to how the API definition is serving almost every stop along the API lifecycle from design to deprecation, and everything in between.<br />",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/algorotoscope/builder/filtered/64_181_800_500_0_max_0_1_-1.jpg"
  },
  {
  "title": "The Importance Of OpenAPI Tooling",
  "date": "18 Jun 2018",
  "body": "<br />In my world, OpenAPI is always a primary actor, and the tooling and services that put it to work are always secondary. However, I’d say that 80% of the people I talk with are the opposite, putting OpenAPI tooling in a primary role, and the OpenAPI specification in a secondary role. This is the primary reason that many still see Swagger tooling as the value, and haven’t made the switch to the concept of OpenAPI, or understand the separation between the specification and the tooling.<br /><br />Another way in which you can see the importance of OpenAPI tooling is the slow migration of OpenAPI 2.0 to 3.0 users. Many folks I’ve talked to about OpenAPI 3.0 tell me that they haven’t made the jump because of the lack of tooling available for the specification. This isn’t always about the external services and tooling that supports OpenAPI 3.0, it is also about the internal tooling that supports it. It demonstrates the importance of tooling when it comes to the evolution, and adoption of OpenAPI. It demonstrates the need for the OAI community to keep investing in the development and evangelism of tooling for the latest version.<br /><br />I am going to work to invest more time into rounding up OpenAPI tooling, and getting to know the developers behind them, as I prepare APIStrat in Nashville, TN. I’m also going to invest in my own migration to OpenAPI 3.0. The reason I haven’t evolved isn’t because of lack tooling, it is because of a lack of time, and the cognitive load involved with thinking new ways. I fully grasp the differences between 2.0 and 3.0, but I just don’t have intuitive knowledge of 3.0 in the way I do for 2.0. I’ve spent hundreds of hours developing around 2.0, and I just don’t have the time in my schedule to make similar investment in 3.0–soon!<br /><br />If you need to get up to speed on the latest when it comes to OpenAPI 3.0 tooling I recommend checking out OpenAPI.Tools from Matt Trask (@matthewtrask) and Crashy McCiderface (aka Phil Sturgeon) (@philsturgeon). It is the best source of OpenAPI tooling out there right now. If you are still struggling with the migration from 2.0 to 3.0, or would like to see a specific solution developed on top of OpenAPI 3.0, I’d love to hear from you. I’m working to help shape the evolution of the OpenAPI tooling conversation, as well as tell stories about what tools are available, or should be available, and how they are can be put to work on the ground at companies, organizations, institutions, and government agencies.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/openapi/OpenAPI_Pantone.png"
  },
  {
  "title": "Opportunity For OpenAPI-Driven Open Source Testing, Performance, Security, And Other Modules",
  "date": "15 May 2018",
  "body": "<br />I’ve been on five separate government reflated projects lately where finding modular OpenAPI-driven open source tooling has been a top priority. All of these projects are microservice-focused and OpenAPI-driven, and are investing significant amounts of time looking open source tools that will help with design governance, monitoring, testing, and security, and interact with the Jenkins pipeline. Helping government agencies find success as their API journey picks up speed, and the number of APIs grows exponentially.<br /><br />Selling to the federal government can be a long journey in itself. They can’t always use the SaaS solutions many of us fire up to get the job done in our startup or enterprise lives. Increasingly government agencies are depending on open source solutions to help them move projects forward. Every agency I’m working with is using OpenAPI (Swagger) to drive their API lifecycle. While not all have gone design (define) first, they are using them as the contract for mocking, documentation, testing, monitoring, and security. The teams I’m working with are investing a lot of energy looking for, vetting, and testing out different open source modules on Github–with varying degrees of success.<br /><br />Ideally, there was an OpenAPI-driven marketplace, or federated set of marketplaces like OpenAPI.Tools. I’ve had one for a while, but haven’t kept up to date–I will invest some time / resources into it soon. My definition of an OpenAPI tool marketplace would be that it is OpenAPI-driven, and open source. I’m fine with there being other marketplaces of OpenAPI-driven services, but I want a way to get at just the actively maintained open source tools. When it comes to serving government this is an important, and meaningful distinction. I’d also like to encourage many of the project owners to ensure there is CI/CD integration, as well as make sure their projects are actively supported, and they are willing to entertain commercial implementations.<br /><br />While there wouldn’t always be direct commercial opportunities for open source tooling owners to engage with federal agencies, there would be through contractors and subcontractors. Working for federal agencies is a maze of forms and hoop jumping, but working with contractors can be pretty straightforward if you find the right ones. I don’t think you will get rich developing OpenAPI-driven tooling that serves the API lifecycle, but I think with the right solutions, support, and team behind them, you can make a decent living developing them. Especially as the lifecycle expands, and the number of services being delivered grows, the need for specialized, OpenAPI-driven tools to apply across the API lifecycle is only going to increase. Making it something I’ll be writing more stories about as I hear more stories from the API trenches.<br /><br />I’m going to try and spend time working with Phil Sturgeon (@philsturgeon) and Matt Trask (@matthewtrask) on API.Tools, as well as give my own toolbox some love. If you have an open source OpenAPI-driven tool you’d like to get some attention feel free to ping me, and make sure its part of API.Tools. Also, if you have a directory, catalog, or marketplace of tools you’d like to showcase, ping me as well, I’m all about supporting diversity of choice in the space. I have multiple federal agencies ear right now when it comes to delivering along the API lifecycle, and I’m happy to point agencies and their contractors to specific tools, if it makes sense. Like I said, there won’t always be direct revenue opportunities, but they are implementations that will undoubtedly lead to commercial opportunities in the form of consulting, advising, and development opportunities with the contractors and subcontractors who are delivering on federal agency contracts.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/openapi/openapi-icons-gears.png"
  },
  {
  "title": "Looking At 20 Microservices In Concert",
  "date": "14 May 2018",
  "body": "<br />I checked out the Github repositories for twenty microservices of one of my clients recently, looking understand what is being accomplished across all these services as they work independently to accomplish a single collective objective. I’m being contracted with to help come in blindly and provide feedback on the design of the APIs being exposed across services, and help provide guidance on their API lifecycle, as well as eventually API governance when things have matured to that level. Right now we are addressing pretty fundamental definition and design issues, but eventually we’ll hopefully graduate to the next level.<br /><br />A complete and up to date README for each microservice is essential to understanding what is going on with a service, and a robust OpenAPI definition is critical to breaking down the details of what each API delivers. When you aren’t part of each service’s development team it can be difficult to understand what each service does, but with an up to date README and OpenAPI, you can get up to speed pretty quickly. If an service is well documented via its README, and the API is well designed, and the surface area is reflected in it’s OpenAPI, you can go from not knowing what a service does to, understanding its value within hopefully minutes, not hours.<br /><br />When each service possesses an OpenAPI it becomes possible to evaluate what they deliver at scale. You can take all APIs, their paths, headers, parameters, and schema and out them in different ways so that you can begin to paint a picture of what they deliver in aggregate. Bringing all the disparate services back together to perform together in a sort of monolith concert, while still acknowledging they all do their own thing independently. Allowing us to look at how many different service can be used in concert to deliver a single application, or potentially a variety of application instances. Thinking critically about each independent service, but more importantly how they all work together.<br /><br />I feel like many groups are still struggling with decomposing their monolithic systems into separate services, and while some are doing so in a domain-driven way, few are beginning to invest in understanding how they move forward with services in concert to deliver on application needs. Many of the groups I’m working with are so focused on decomposing and tearing down, they aren’t thinking too critically about how they will make all of this begin work together again. I see monolith systems working like a massive church organ which take a lot of maintenance, and require a single (or handful) of knowledgeable operators to play. Where microservices are much more like an orchestra, where every individual player has a role, but they play in concert, directed by a conductor. I feel like most groups I’m talking with are just beginning the process of hiring a conductor, and have a bunch of musicians roaming around–not quite ready to play any significant productions quite yet.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/losangeles-from-observatory_free_woman.jpg"
  },
  {
  "title": "API Discovery is for Internal or External Services",
  "date": "10 May 2018",
  "body": "<br />The topic of API discovery has been picking up momentum in 2018. It is something I’ve worked on for years, but with the number of microservices emerging out there, it is something I’m seeing become a concern amongst providers. It is also something I’m seeing more potential vendor chatter, looking to provide more services and tooling to help alleviate API discovery pain. Even with all this movement, there is still a lot of education and discussion to occur on the subject to help bring people up to speed on what is API discovery.<br /><br />The most common view of what is API discovery, is when you need to find an API for developing an application. You have a need for a resource in your application, and you need to look across your internal and partner resources to find what you are looking for. Beyond that, you will need to search for publicly available API resources, using Google, Github, ProgrammableWeb, and other common ways to find popular APIs. This is definitely the most prominent perspective when it comes to API discovery, but it isn’t the only dimension of this problem. There are several dimensions to this stop along the API lifecycle, that I’d like to flesh out further, so that I can better articulate across conversations I am having.<br /><br />Another area that gets lumped in with API discovery is the concept of service discovery, or how your APIs will find their backend services that they use to make the magic happen. Service discovery focuses on the initial discovery, connectivity, routing, and circuit breaker patterns involved with making sure an API is able to communicate with any service it depends on. With the growth of microservices there are a number of solutions like Consul that have emerged, and cloud providers like AWS are evolving their own service discovery mechanisms. Providing one dimension to the API discovery conversation, but different from, and often confused with front-end API discovery and how developers and applications find services.<br /><br />One of the least discussed areas of API discovery, but is one that is picking up momentum, is finding APIs when you are developing APIs, to make sure you aren’t building something that has already been developed. I come across many organizations who have duplicate and overlapping APIs that do similar things due to lack of communication and a central directory of APIs. I’m getting asked by more groups regarding how they can be conducting API discovery by default across organizations, sniffing out APIs from log files, on Github, and other channels in use by existing development teams. Many groups just haven’t been good at documenting and communicating around what has been developed, as well as beginning new projects without seeing what already exists–something that will only become a great problem as the number of microservices grows.<br /><br />The other dimension of API discovery I’m seeing emerge is discovery in the service of governance. Understand what APIs exist across teams so that definitions, schema, and other elements can be aggregated, measured, secured, and governed. EVERY organization I work with is unaware of all the data sources, web services, and APIs that exist across teams. Few want to admit it, but it is a reality. The reality is that you can’t govern or secure what you don’t know you have. Things get developed so rapidly, and baked into web, mobile, desktop, network, and device applications so regularly, that you just can’t see everything. Before companies, organizations, institutions, and government agencies are going to be able to govern anything, they are going to have begin addressing the API discovery problem that exists across their teams.<br /><br />API discovery is a discipline that is well over a decade old. It is one I’ve been actively working on for over 5 years. It is something that is only now getting the discussion it needs, because it is a growing concern. It will be come a major concern with each passing day of the microservice evolution. People are jumping on the microservices bandwagon without any coherent way to organize schema, vocabulary, or API definitions. Let alone any strategy for indexing, cataloging, sharing, communicating, and registering services. I’m continuing my work on APIs.json, and the API Stack, as well as pushing forward my usage of OpenAPI, Postman, and AsyncAPI, which all contribute to API discovery. I’m going to continue thinking about how we can publish open source directories, catalogs, and search engines, and even some automated scanning of logs and other ways to conduct discovery in the background. Eventually, we will begin to find more solutions that work–it will just take time.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/vancouver_light_dali.jpg"
  },
  {
  "title": "Making the OpenAPI Contract Friendlier For Developers and Business Stakeholders",
  "date": "08 May 2018",
  "body": "<br />I was in a conference session about an API design tool today, and someone asked if you could get at the OpenAPI definition behind the solution. They said yes, but quickly also said that the definition is boring and that you don’t want to be in there, you want to be in the interface. I get that service providers want you to focus on their interface, but we shouldn’t be burying, or abstracting away the API contract for APIs, we should always be educating people about it, an bringing it front and center in any service, tooling, or conversation.<br /><br />Technology folks burying or devaluing the OpenAPI definition with business users is common, but I also see technology folks doing it to each other. Reducing OpenAPI to be just another machine readable artifact alongside other components of delivering API infrastructure today. I think this begins with people not understanding what OpenAPI is, but I think it is sustained by people’s view of what is technological magic and should remain in the hands of the wizards, and what should be accessible to a wider audience. If you limit who has access and knowledge, you can usually maintain a higher level of control, so they use your interface in the case of a vendor, or they come to you develop and build an API in the case of a developer.<br /><br />There is nothing in a YAML OpenAPI definition that business users won’t be able to understand. OpenAPIs aren’t anymore boring than a Word document or Spreadsheet. If you are a stakeholder in the service, you should be able to read, understand, and engage with the OpenAPI contract. If we teach people to be afraid of the OpenAPI definitions we are repeating the past, and maintaining the canyon that can exist between business and IT/Developer groups. If you are in the business of burying the OpenAPI definition, I’m guessing you don’t understand the portable API lifecycle potential of this API contract, and simply see it as a config, documentation, or other technical artifiact. Or you are just in the business of maintaining control and power by being the gatekeeper for the API contract, similar to how we see database people defend their domain.<br /><br />Please do not devalue or hide away the OpenAPI contract. It isn’t your secret sauce. It isn’t boring. It isn’t too technical. It is the contract for how a service will work, that will speak to business and technical groups. It is the contract that all the services and tools you will use along the API lifecycle will understand. It is fine to have the OpenAPI right behind the scenes, but always provide a button, link, or other way to quickly see the latest version, and definitely do not scare people away or devalue it when you are talking. If you are doing APIs, you should be encouraging, and investing in everyone being able to have a conversation around the API contract behind any service you are putting forward.<br />",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/algorotoscope/builder/filtered/64_98_800_500_0_max_0_1_-1.jpg"
  },
  {
  "title": "Constraints Introduced By Supporting Standardized API Definitions and Schema",
  "date": "08 May 2018",
  "body": "I’ve had a few API groups contact me lately regarding the challenges they are facing when it comes to supporting organizational, or industry-wide API definitions and schema. They were eager to support common definitions and schema that have been standardized, but were getting frustrated by not being able to do everything they wanted, and having to live within the constraints introduced by the standardized definitions. Which is something that doesn’t get much discussion by those of use who are advocating for standardization of APIs and schema.<br /><br />Web APIs Come With Their Own Constraints<br />We all want more developers to use our APIs. However, with more usage, comes more responsibility. Also, to get more usage our APIs need to speak to a wider audience, something that common API definitions and schema will help with. This is why web APIs are working, because they speak to a wider audience, however with this architectural decision we are making some tradeoffs, and accepting some constraints in how we do our APIs. This is why REST is just one tool in our toolbox, so we can use the right tool, establish the right set of constraints, to allow our APIs to be successful. The wider our API toolbox, the wider the number options we will have available when it comes to how we design our APIs, and what schema we can employ<br /><br />Allowing For Content Negotiation By Consumers<br />One way I’ve encouraged folks to help alleviate some of the pain around the adoption of common API definitions and schema is to provide content negotiation to consumers, allowing them to obtain the response they are looking for. If people want the standardized approaches they can choose those, and if they want something more precise, or custom they can choose that. This also allows API providers to work around the API standards that have become bottlenecks, while still supporting them where they matter. Having the best of both worlds, where you are supporting the common approach, but still able to do what you want when you feel it is important. Allowing for experimentation as well as standardization using the same APIs.<br /><br />Participate In Standards Body and Process<br />Another way to help move things forward is to participate in the standards body that is moving an API definition or schema forward. Make sure you have a seat at the table so that you can present your case for where the problems are, and how to improve on the design, definition, and schema being evolved. Taking a lead in creating the world you want to see when it comes to API and schema standards, and not just sitting back being frustrated because it doesn’t do what you want it to do. Having a role in the standards body, and actively participating in the process isn’t easy, and it can be time consuming, but it can be worth it down the road and helping you better achieve your goals when it comes to your APIs operating as you aspect, as well as the wider community and industry you are serving.<br /><br />Delivering APIs at scale won’t be easy. To reach a wide audience with your API it helps to be speaking a common vocabulary. This doesn’t always allow you to move as fast as you’d like, and do everything exactly as you envision. You will have to compromise. Operate within constraints. However, it can be worth it. Not just for your organization, but for the overall health of your community, and the industry you operate in. You never know, with a little patience, collaboration, and communication, you might learn even new approaches to defining your APIs and schema that you didn’t think about in isolation. Also, experimentation with new patterns will still be important, even while working to standardize things. In the end, a balance between standardized and custom will make the most sense, and hopefully alleviate your frustrations in moving things forward.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/server-cloud1_feed_people.jpg"
  },
  {
  "title": "Turning The Stack Exchange Questions API Into 25 Separate Tech Topic Streaming APIs",
  "date": "07 May 2018",
  "body": "<br />I’m turning different APIs into topical streams using Streamdata.io. I have been profiling hundreds of different APIs as part of my work to build out the Streamdata.io API Gallery, and as I’m creating OpenAPI definitions for each API, I’m realizing the potential for event and topical driven streams across many existing web APIs. One thing I am doing after profiling each API is that I benchmark them to see how often the data changes, applying what we are calling StreamRank to each API path. Then I try to make sure all the parameters, and even enum values for each parameter are represented for each API definition, helping me see the ENTIRE surface area of an API. Which is something that really illuminates the possibilities surrounding each API.<br /><br />After profiling the Stack Exchange Questions API, I began to see how much functionality and data is buried within a single API endpoint, and was something I wanted to expose and make much easier to access. Taking a single OpenAPI definition for the Stack Exchange Questions API:<br /><br /><br /><br />Then exploding it into 25 separate tech topic streaming APIs. Taking the top 25 enum value for the tags parameter for the Stack Overflow site, and exploding into 25 separate streaming API resources. To do this, I’m taking each OpenAPI definition, and generating an AsyncAPI definition to represent each possible stream:<br /><br /><br /><br />I’m not 100% sure I’m properly generating the AsyncAPI currently, as I’m still learning about how to use the topics and streams collections properly. However, the OpenAPI definition above is meant to represent the web API resource, and the AsyncAPI definition is meant to represent the streaming edition of the same resource. Something that can be replicated for any tag, or any site that is available via the Stack Exchange API. Turning the existing Stack Exchange API into streaming topic APIs, that people can subscribe to only the topics they are interested in receiving updates.<br /><br />At this point I’m just experimenting with what is possible with OpenAPI and AsyncAPI specifications, and understanding what I can do with some of the existing APIs I am already using each day. I’m going to try and turn this into a prototype, delivering streaming APIs for all 25 of the top Stack Overflow tags. To demonstrate what is possible on Stack Exchange, but also to establish a proof of concept that I can apply to other APIs like Reddit, Github, and others. Then eventually automating the creation of streaming topic APIs using the OpenAPI definitions for common APIs, and the Streamdata.io service.<br />",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/algorotoscope/builder/filtered/80_168_800_500_0_max_0_1_-1.jpg"
  },
  {
  "title": "Proprietary Views Of Your Taxonomy",
  "date": "14 Jun 2017",
  "body": "<br />I’ve been investing a lot more energy into open data and APIs involved with city government, something I’ve dabbled in as long as I’ve been doing API Evangelist, but is something I’ve ratcheted up pretty significantly over the last couple of years. As part of this work, I’ve increasingly come across some pretty proprietary stances when it comes to data that is part of city operations–this stuff has been seen as gold, long before Silicon Valley came along, with long lines of folks looking to lock it up and control it.<br /><br />Helping civic data stakeholders separate the licensing layers around their open data and APIs is something I do as the API Evangelist. Another layer I will be adding to this discussion is around taxonomy. How city data folks are categorizing, organizing, and classifying the valuable data needed to make our cities work. I’ve been coming across more vendors in the city open data world who feel their taxonomy is their secret sauce and falls under intellectual property protection. I don’t have any wisdom regarding why this is a bad idea, but I will keep writing about as part of my wider API licensing work to help flesh out my ideas, and create a more coherent and precise argument.<br /><br />I understand that some companies put a lot of work into taxonomies, and the description behind how they organize things, but like API definitions and schema, these are aspects of your open data and API operations you want to be a widely understood, shared, and reusable knowledge within your systems, as well as the 3rd party integration of your partners and customers. Making your taxonomy proprietary isn’t going to help your brand, or get you ahead in the game. I recommend focusing on other aspects of the value you bring to the table and keep your taxonomy as openly licensed as you possibly can, encouraging adoption by others. I’ll work on a more robust argument as I work through a variety of projects that will potentially be hurt by the proprietary views on taxonomy I’m seeing.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-taxonomy.png"
  },
  {
  "title": "KDL: A Graphical Notation for Kubernetes API Objects",
  "date": "08 Jun 2017",
  "body": "<br />I am learning about the Kubernetes Deployment Language (KDL) today, trying to understand their approach to defining their notion of Kubernetes API objects. It feels like an interesting evolution in how we define our infrastructure, and begin standardizing the API layer for it so that we can orchestrate as we need.<br /><br />They are standardizing the Kubernetes API objects into the following buckets:<br /><br />Cluster - The orchestration level of things.<br />Compute - The individual compute level.<br />Networking - The networking layer of it all.<br />Storage - Storage behind our APIs.<br /><br />This has elements of my API lifecycle research, as well as a containerized, clustered, BaaS 2.0 in my view. Standardizing how we define and describe the essential layers of our API and application infrastructure. I could also see standardizing the testing, monitoring, performance, security, and other critical aspects of doing this at scale.<br /><br />I’m also fascinated at how fast YAML has become the default orchestration template language for folks in the cloud containerization space. I’ll add KDL to my API definition and container research and keep an eye on what they are up to, and keep an eye out for other approaches to standardizing the API layer for deploying, managing, and scaling our increasingly containerized API infrastructure.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/openshift/kubernetes-kdl-deploy-image19-24.png"
  },
  {
  "title": "Examples Of The OpenAPI Specification Used For Government APIs",
  "date": "07 Jun 2017",
  "body": "<br />I was answering some questions for my partners over at DreamFactory when it comes to APIs in government, and one of the questions they asked was about some examples of the OpenAPI specification being used in government. To help out, I started going through  my list of government API looking for any examples in the wild–here is what I found:<br /><br /><br />  <br />    Federal Election Commission (FEC) (OpenAPI)<br />  <br />  <br />    System for Award Management (SAM) (OpenAPI)<br />  <br />  <br />    US Digital Registry (OpenAPI)<br />  <br />  <br />    18F Open Source Micro Purchasing API (OpenAPI)<br />  <br />  <br />    NASA (Couldn’t find OpenAPI in less than 30 seconds)<br />  <br />  <br />    Centers for Medicare &amp;amp; Medicaid Services (CMS) API for Quality Payment Program Measures (OpenAPI)<br />  <br />  <br />    National Renewal Energy Labratory Transportation Laws and Incentives API (OpenAPI)<br />  <br /><br /><br />I am sure there are more OpenAPI in use across government, but this is what I could find in a five-minute search of my API database. It provides us with seven quality examples of OpenAPI being used for documenting government APIs. I don’t see the OpenAPI used for much beyond documentation, but it is still a good start.<br /><br />If you know of any government APIs that use OpenAPI feel free to let me know. I’d love to keep adding examples to my research so I can pull up quickly when I am asked questions like this in the future, and be able to highlight best practices for API operations in city, county, state, and federal levels of government.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/cms/cms-quality-payment-program.png"
  },
  {
  "title": "Patent US 8997069: API Descriptions",
  "date": "06 Jun 2017",
  "body": "<br />There are so many API patents out there, I’m going to have to start posting one a day just to keep up. Lucky for you I begin to get really depressed by all the API patents I lose interest in reading them and begin to work harder looking for positive examples of API in the world, but until then here is today’s depressing as fuck API patent.<br /><br />Title: API descriptions<br />Number: US 8997069<br />Owner: Microsoft Technology Licensing, LLC<br />Abstract: API description techniques are described for consumption by dynamically-typed languages. In one or more implementations, machine-readable data is parsed to locate descriptions of one or more application programming interfaces (APIs). The descriptions of the one or more application programming interfaces are projected into an alternate form that is different than a form of the machine-readable data.<br /><br />I don’t mean to be a complete dick here, but why would you think this is a good idea? I get that companies want their employees to develop a patent portfolio, but this one is patenting an essential ingredient that makes APIs work. If you enforce this patent it will be worthless because this whole API thing won’t work, and if you don’t enforce it, it will be worthless because it does nothing–money well spent on the filing fee.<br /><br />I just need to file my patent on patenting APIs and end all of this nonsense. I know y’all think I’m crazy for my beliefs that APIs shouldn’t be patented, but every time I dive into my patent research I can’t help but think y’all are the crazy ones, and I’m actually sane. I just do not understand how this patent is going to help anyone and represents any of the value that APIs and even a patent can bring to the table.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-definition.png"
  },
  {
  "title": "APIs Are How Our Digital Selves are Learning To Speak With Each Other",
  "date": "06 Jun 2017",
  "body": "I know this will sound funny to many folks, but when I see APIs, I see language and communication, and humans learning to speak with each other in this new digital world we are creating for ourselves. My friend Erik Wilde (@dret) tweeted a reminder for me that APIs are indeed a language.<br /><br />APIs are languages. show me one #API aspect that cannot be adequately framed in the context of language design practices and challenges.&amp;mdash; Erik Wilde (@dret) June 4, 2017<br /><br /><br />Every second on our laptops and mobile phone we are communicating with many different companies and individuals. With each wall post, Tweet, photo push, or video stream we are communicating with our friends, family, and the public. Each of these interactions is being defined and facilitated using an API. An API call just for saying something in text, in an image, or video. API is the digital language we use to communicate online and via our mobile devices.<br /><br />Uber geeks like me spend their days trying to map out and understand these direct interactions, as well as the growing number of indirect interactions. For every direct communication, there are usually numerous other indirect communications with advertisers, platform providers, or maybe even law enforcement, researchers, or anyone else with access to the communication channels. We aren’t just learning to directly communicate, we are also being conditioned to participate indirectly in conversations we can’t see–unless you are tuned into the bigger picture of the API economy.<br /><br /><br /><br />When we post that photo, companies are whispering about what is in the photo, where it was taken, and what meaning it has. When we share that news link of Facebook, companies have a discussion about the truthfulness and impact of the link, maybe the psychological profile behind the link and where we fit into their psychological profile database. In some scenarios, they are talking directly about us personally like we are sitting in the room, other times they are talking about us like we are just a number in a larger demographic pool.<br /><br />In alignment with the real world, the majority of these conversations being held between men, behind closed doors. Publicly the conversations are usually directed by people with a bullhorn, talking over others, as well as whispering behind, and around people while they completely unaware that these conversations about them are even occurring. The average person is completely unaware these conversations are happening. They can’t hear the whispering, or just do not speak the language that is being used around them, about them, each moment of each day.<br /><br />Those of us in the know are scrambling to understand, control, and direct the conversations that are occuring. There is a lot of money to be made when you are part of these conversations. Or at least have a whole bunch of people on your platform to have a conversation about, or around. People don’t realize that for every direct conversation you have online, there are probably 20 conversations going on about this conversation. What will they buy next? Who do they know? What is in that photo they just shared? Is this related post interesting to them? API-driven echoes of conversation upon conversations into infinity.<br /><br />Sometimes I feel like Dr. Xavier from the X-men in that vault room connected to the machine when I am on the Internet studying APIs. I’m seeing millions of conversations going on–it is deafening. I don’t just see or hear the direct conversations, I hear the deafening sounds of advertisers, hackers, researchers, police, government, and everyone having a conversation around us. Many folks feel like the average person shouldn’t be included in the conversation–they do not have the interest or awareness to even engage. To me, it just feels like a new secretive world augmenting our physical worlds, where our digital selves are learning to speak with each other. What troubles me though, is that not everyone is actually engaged in the conversations they are included in, and are often asleep or sedated while their personal digital self is being manipulated, exploited, and p0wn3d.<br />",
  "url": "http://localhost:4000",
  "image": ""
  },
  {
  "title": "The Github Repo Stripe Uses To Manage Their OpenAPI",
  "date": "02 Jun 2017",
  "body": "I’m beating a drum every time I find a company managing their OpenAPI on Github, like we would the other code elements of our API operations. Today’s drumbeat comes from my friend Nicolas Grenié (@picsoung), who posted Stripe’s Github repository for their OpenAPI in our Slack channel for the super cool API Evangelists in the sector. ;-)<br /><br />Along with the New York Times, Box, and other API providers, Stripe has a dedicated Github repo for managing their OpenAPI definition. This opens up the Stripe API for easily loading in client tools like Restlet Client, and Postman, as we as generating code samples and SDKs using services like APIMATIC. Most importantly, it allows for developers to easily understand the surface area of the Stripe API, in a way that is machine-readable, and portable.<br /><br />It makes me happy to see leading API providers manage their own OpenAPI using Github like this. The API sector will be able to reach new heights when every single API provider manages their API definitions like this. I know, I know hypermedia folks–everyone should just do hypermedia. Yes, they should. However, we need some initial steps to occur before that is possible, and API providers being able to effectively communicate their API surface area to API consumers in a way that scales and can be used across the API lifecycle is an important part of this evolution. With each OpenAPI I find like this, I get more optimistic that we are getting closer to the future that RESTafarians and hypermedia folks envision–providers are doing the hard work of thinking about the definitions used in their APIs in the context of the entire API lifecycle, and the API consumers who exist along the way.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/stripe/stripes-openapi-specification-on-github.png"
  },
  {
  "title": "Managing Your Postman Collection Using Github",
  "date": "01 Jun 2017",
  "body": "<br />I have been encouraging API providers to publish and manage their API definitions using Github similar to how you’d manage any code. Companies like Box and NY Times are publishing their OpenAPI definitions to a single repository, allowing partners and API consumers to pull the latest version of the API definition and use throughout the API lifecycle.<br /><br />I stumbled across another example of managing your API definitions using Github, but this time it is the management of your Postman Collections in a Github repo from API management provider Apigee (now Google). The Postman Collection provides a complete description of the Apigee API management surface area, allowing API providers to easily automate or orchestrate their API operations using Apigee.<br /><br />The Github repository providers a complete Postman Collection, along with instructions on how to load, as well as a Run in Postman button allowing any consumer to instantly load the entire surface area of the Apigee API management solution into their Postman Client. I am a big fan of managing your Postman Collections, as well as OpenAPI definitions in this way, managing the definitions for your API similar to how you manage your code, but also making available for forking, checking out, and integration of these machine-readable definitions anywhere across the API lifecycle.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/apigee/apigee-postman-collection-on-github.png"
  },
  {
  "title": "Adding Three APIMATIC OpenAPI Extensions To The OpenAPI Toolbox",
  "date": "31 May 2017",
  "body": "<br />I’ve added three OpenAPI extensions from APIMATIC to my OpenAPI Toolbox, adding to the number of extensions I’m tracking on that service providers and tooling developers are using as part of their API solutions. APIMATIC provides SDK code generation services, so their OpenAPI extensions are all about customizing how you deploy code as part of the integration process.<br /><br />These are the three OpenAPI extensions I am adding from them:<br /><br /><br />  x-codegen-settings - These settings are globally applicable to all operations and schema definitions.<br />  x-operation-settings - These settings can be specified inside an operation object.<br />  x-additional-headers - These headers are in addition to any headers required for authentication or defined as parameters.<br /><br /><br />If you have ever used APIMATIC you know that you can do a lot more than just “SDK generation”, which often has a bad reputation. APIMATIC provides some interesting ways you can use OpenAPI to dial in your SDK, script, and code generation as part of any continuous integration lifecycle.<br /><br />Providing another example of how you don’t have to live within the constraints of the current OpenAPI spec. Anyone can augment, and extend the current specification to meet your unique needs. Then who knows, maybe it will become useful enough, and something that might eventually be added to the core specification. Which is part of the reason I’m aggregating these specifications, and including them in the OpenAPI Toolbox.<br />",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/apimatic_dx_kits.png"
  },
  {
  "title": "Every API Should Begin With A Github Repository",
  "date": "25 May 2017",
  "body": "<br />I’m working on my API definition and design strategy for my human services API work, and as I was doing this Box went all in on Opening, adding to the number of API providers I track on who not just have an OpenAPI but they also use Github as the core management for their API definition.<br /><br />Part of my API definition and design advice for human service API providers, and the vendors who sell software to them is that they have an OpenAPI and JSON schema defined for their API, and share this either publicly or privately using a Github repository. When I evaluate a new vendor or service provider as part of the Human Services Data API (HSDA) specification I’m beginning to require that they share their API definition and schema using Github–if you don’t have one, I’ll create it for you. Having a machine-readable definition of the surface area of an API, and the underlying schema in a Github repo I can checkout, commit to, and access via an API is essential.<br /><br />Every API should begin with a Github repository in my opinion, where you can share the API definition, documentation, schema, and have a conversation around these machine readable docs using Github issues. Approaching your API in this way doesn’t just make it easier to find when it comes to API discovery, but it also makes your API contract available at all steps of the API design lifecycle, from design to deprecation.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/open-referral/open-referral-github-repo-api-spec.png"
  },
  {
  "title": "Craft Your API Design Guide So You Can Move To Other Areas of The Lifecycle",
  "date": "25 May 2017",
  "body": "<br />I am working on an API definition and design guide for my human services API work, helping establish a framework for approaching API design as part of the human services data and API specification, but also for implementers to follow in their own individual deployments. Every time I work on the subject of API design, I’m reminded of how far behind the API sector is when it comes to standardizing what it is we do.<br /><br />Every month or so I see a new company publicly share their API design guide. When they do my friend Arnaud always adds to his API Stylebook, adding it to the wealth of information available in his work. I’m happy to see each API design guide release, but in reality, ALL API providers should have an API design guide, and they should also be open to publishing it publicly, showing their consumers they have their act together, and sharing with the wider API community the best practices in play.<br /><br />The lack of companies sharing their API design practices and their API definitions is why we have such a deficiency when it comes to common API patterns in use. It is why we have so many variations of web APIs, as well as the underlying schema. We have an API industry because early practitioners like SalesForce, Amazon, eBay, Flickr, Delicious, Twitter, Youtube, and others were open with their API operations. People emulate what they see and know. Each wave of the API sector depends on the previous wave sharing what they do publicly–it is how this all works.<br /><br />To demonstrate even further about how deficient we are, I do not find companies sharing their guides for API deployment, management, testing, monitoring, clients, and other stops along the API lifecycle. I’m glad we are seeing an uptick in the number of API design guides, but we need this practice to spread to every other stop. We need successful providers to share how they deploy their APIs, and when any company hires a new developer, you should ALWAYS be given a standard guide for deploying, managing, testing, as well as designing APIs.<br /><br />It’s not rocket science, and honestly, it’s not even technical. It just means pausing for a moment, thinking about how we approach each stop in the API lifecycle, writing up an overview, publishing, and sharing it with API stakeholders, and even the wider API community. Every company doing APIs in 2017 should be crafting an API design guide so you can get to work on guides for the other areas of your lifecycle, thinking through and standardizing your approach, and making it known to every person involved–ideally, you are also being very public about all of this, and sharing your work with me and Arnaud, so we can get the word out about the good stuff you are up to! ;-)<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/talks/november-2015/api-lifecycle-tag-cloud.png"
  },
  {
  "title": "Considering Using HTTP Prefer Header Instead Of Field Filtering For This API",
  "date": "24 May 2017",
  "body": "<br />I am working my way through a variety of API design considerations for the Human Services Data API (HSDA)that I’m working on with Open Referral. I was working through my thoughts on how I wanted to approach the filtering of the underlying data schema of the API, and Shelby Switzer (@switzerly) suggested I follow Irakli Nadareishvili’s advice and consider using RFC 7240 -the Prefer Header for HTTP, instead of some of the commonly seen approaches to filtering which fields are returned in an API response.<br /><br />I find this approach to be of interest for this Human Services Data API implementation because I want to lean on API design, over providing parameters for consumers to dial in the query they are looking for. While I’m not opposed to going down the route of providing a more parameter based approach to defining API responses, in the beginning I want to carefully craft endpoints for specific use cases, and I think the usage of the HTTP Prefer Header helps extend this to the schema, allowing me to craft simple, full, or specialized representations of the schema for a variety of potential use cases. (ie. mobile, voice, bot)<br /><br />It adds a new dimension to API design for me. Since I’ve been using OpenAPI I’ve gotten better at considering the schema alongside the surface area of the APIs I design, showing how it is used in the request and response structure of my APIs. I like the idea of providing tailored schema in responses over allowing consumers to dynamically filter the schema that is returned using request parameters. At some point, I can see embracing a GraphQL approach to this, but I don’t think that human service data stewards will always know what they want, and we need to invest in a thoughtful set design patterns that reflect exactly the schema they will need.<br /><br />Early on in this effort, I like allowing API consumers to request minimal, standard or full schema for human service organizations, locations, and services, using the Prefer header, over adding another set of parameters that filter the fields–it reduces the cognitive load for them in the beginning. Before I introduce any more parameters to the surface area, I want to better understand some of the other aspects of taxonomy and metadata proposed as part of HSDS. At this point, I’m just learning about the Prefer header, and suggesting it as a possible solution for allowing human services API consumers to have more control over the schema that is returned to them, without too much overhead.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/http-prefer-header.png"
  },
  {
  "title": "Some Thoughts On OpenAPI Not Being The Solution",
  "date": "23 May 2017",
  "body": "<br />I get regular waves of folks who chime in anytime I push on one of the hot-button topics on my site like hypermedia and OpenAPI. I have a couple of messages in my inbox regarding some recent stories I’ve done about OpenAPI recently, and how it isn’t sustainable, and we should be putting hypermedia practices to work. I’m still working on my responses, but I wanted to think through some of my thoughts here on the blog before I respond–I like to simmer on these things, releasing the emotional exhaust before I  respond.<br /><br />When it comes to the arguments from the hypermedia folks, the short answer is that I agree. I think many of the APIs I’m seeing designed using OpenAPI would benefit from some hypermedia patterns. However, there is such a big gap between where people are, and where we need to be for hypermedia to become the default, and getting people there is easier said than done. I view OpenAPI as a scaffolding or bridge to transport API designers, developers, and architects at scale from where we are, to where we need to be–at scale.<br /><br />I wish I could snap my fingers and everyone understood how the web works and understood the pros and cons of each of the leading hypermedia types. Many developers do not even understand how the web works. Hell, I’m still learning new things every day, and I’ve been doing this full time for seven years. Most developers still do not even properly include and use HTTP status codes in their simple API designs, let alone understand the intricate relationship possibilities between their resources, and the clients that will be consuming them. Think about it, as developer, I don’t even have time, budget or care to articulate the details of why a response failed, and you expect that I have the time, budget, are care about link relations, and the evolution of the clients build on top of my APIs? Really?<br /><br />I get it. You want everyone to see the world like you do. You are seeing us headed down a bad road, and want to do something about it. So do I. I’m doing something about it full time, telling stories about hypermedia APIs that exist out there, and even crafting my own hypermedia implementations, and telling the story around them. What are you doing to help equip folks, and educate them about best practices? I think once you hit the road doing this type of storytelling in a sustained way, you will see things differently, and begin to see how much investment we need in basic web literacy–something the OpenAPI spec is helping break down for folks, and providing them with a bridge to incrementally get from where they are at, to where they need to be.<br /><br />Folks need to learn about consistent design patterns for their requests and responses. Think about getting their schema house in order. Think through content negotiation in a consistent way. Be able to see plainly that they only use three HTTP status codes 200, 404, and 500. OpenAPI provides a scaffolding for API developers to begin thinking about design, learn how the web works, and begin to share and communicate around what they’ve learned using a common language. It also allows them to learn from other API designers who are further along in their journey or just have had success with a single API pattern.<br /><br />For you (the hypermedia guru), OpenAPI is redundant, meaningless, and unnecessary. For many others, it provides them with a healthy blueprint to follow and allows you to be spoon fed web literacy, and good API design practices in the increments your daily job, and current budget allows. Few API practitioners have the luxury of immersing them in deep thought about the architectural styles and the design of network-based software architectures or wading through W3C standards. They just need to get their job done, and the API deployed, with very little time for much else.<br /><br />It is up to us leaders in the space to help provide them with the knowledge they’ll need. Not just in book format. Not everyone learns this way. We need to also point out the existing healthy patterns in use already. We need to invest in more blueprints, prototypes, and working examples of good API design. I think my default response for folks who tell me that OpenAPI isn’t a solution will be to ask them to send me a link to all the working examples and stories of the future they envision. I think until you’ve paid your dues in this area, you won’t see how hard it is to educate the masses and actually get folks headed in the right direction at scale.<br /><br />I often get frustrated with the speed at which things move when I’m purely looking at things from what I want and what I know and understand. However, when I step back and think about what it will truly take to get the masses of developers and business users on-boarded with the API economy–the OpenAPI specification makes a lot more sense as a scaffolding for helping us get where we need. Oh, and also I watch Darrel Miller (@darrel_miller) push on the specification on a daily basis, and I know things are going to be ok.<br />",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/algorotoscope/losangelescloudy/blue_circuit/file-00_00_35_50.jpg"
  },
  {
  "title": "Keen IO Pushing Forward The Data Schema Conversation",
  "date": "22 May 2017",
  "body": "<br />I wrote earlier this year that I would like us all to focus more on our schema and definitions of our data we use across API operations. Since then I’ve been keeping an eye out for any other interesting signs in this area like Postman with their data editor, and now I’ve come across the Streams Manager for inspecting the data schema of your event collections in Keen IO..<br /><br />With Streams Manager you can:<br /><br /><br />  Inspect and review the data schema for each of your event collections<br />  Review the last 10 events for each of your event collections<br />  Delete event collections that are no longer needed<br />  Inspect the trends across your combined data streams over the last 30-day period<br /><br /><br />Keen IO provides us with an interesting approach to getting in tune with the schema across your event collections. I’d like to see more of this across the API lifecycle. I understand that companies like Runscope, Stoplight, Postman, and others already let us peek inside of each API call, which includes a look at the schema in play. This is good, but I’d like to see more schema management solutions at this layer helping API providers from design to deprecation.<br /><br />In 2017 we all have an insane amount of bits and bytes flowing around us in our daily business operations. APIs are only enabling this to grow, opening up access to our bits to our partners and on the open web. We need more solutions like Keen’s Stream Manager, but for every layer of the API stack, allowing us to get our schema house in order, and make sense of the growing data bits we are producing, managing, and sharing.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/keen/1-6YVuTRnIIEM7o6XQO-QtMA.png"
  },
  {
  "title": "A Working Example Of OpenAPI Version 3.0 To Learn From",
  "date": "22 May 2017",
  "body": "<br />I learn almost everything I know by reverse engineering what I come across doing my monitoring of the API space. I feel it is important for leaders in the API space to share a significant portion of our work publicly, and tell the story behind our work so that others can learn from us. Whether folks realize it or not, this is why much of the wider API community works as it does, and has accumulated much of the forward motion we all enjoy today.<br /><br />I have been getting a lot of questions lately regarding tooling for version 3.0 of the OpenAPI specification. I’m working to evolve my OpenAPI toolbox, and populate with any services or tools I come across that support version 3.0. I have also been getting requests from folks about if I know where there are any working examples of OpenAPI definitions in the version 3.0 format. So I reached out to my friend Mike Ralphson (@PermittedSoc), who is doing interesting work when it comes to OpenAPI and GraphQL, and he responded with a working example for us of moving from version 2.0 to 3.0 of the OpenAPI spec.<br /><br />He took the version 2.0 from the Authentiq Connect API:<br /><br /><br /><br />Then he converted it to version 3.0:<br /><br /><br /><br />Mike accomplished all of this with his OpenAPI 2.0 to 3.0 converter and validator that he has published to Github. His Github organization is always full of interesting work, I recommend staying in tune with whatever he is committing.<br /><br />Thanks for sharing Mike! Hopefully, it provides a reference for folks seeking a working example of OpenAPI 3.0 out in the wild. I’ll be keeping an eye out for additional version 3.0 OpenAPI examples, as well as any other tooling like swagger2openapi that I can add to the toolbox.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/mermade/mermade-swagger2openapi-logo.png"
  },
  {
  "title": "Box Goes All In On OpenAPI",
  "date": "22 May 2017",
  "body": "<br />Box has gone all in on OpenAPI. They have published an OpenAPI for their document and storage API on Github, where it can be used in a variety of tools and services, as well as be maintained as part of the Box platform operations. Adding to the number of high-profile APIs managing their OpenAPI definitions on Github, like Box, and the NY Times.<br /><br />As part of their OpenaPI release, Box published a blog post that touches on all the major benefits of having an OpenAPI, like forking on Github for integration into your workflow, generating documentation and visualizations, code, mock APIs, and even monitoring and testing using Runscope. It’s good to see a major API provider drinking the OpenAPI Kool-Aid, and working to reduce friction for their developers.<br /><br />I would love to not be in the business of crafting complete OpenAPIs for API providers. I would like every single API provider to be maintaining their own OpenAPI on Github like Box and [NY Times(http://apievangelist.com/2017/03/01/new-york-times-manages-their-openapi-using-github/) does. Then I (we) could spend time indexing, curating, and developing interesting tooling and visualizations to help us tell stories around APIs, helping developers and business owners understand what is possible with the growing number of APIs available today.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/box/embracing-openapi-at-box"
  },
  {
  "title": "Key Factors Determining Who Succeeds In The API and ML Marketplace Game",
  "date": "16 May 2017",
  "body": "<br />I was having a discussion with an investor today about the potential of algorithmic-centered API marketplaces. I’m not talking about API marketplaces like Mashape, I’m more talking about ML API marketplaces like Algorithmia. This conversation spans multiple areas of my API lifecycle research, so I wanted to explore my thoughts on the subject some more.<br /><br />I really do not get excited about API marketplaces when you think just about API discovery–how do I find an API? We need solutions in this area, but I feel good implementations will immediately move from useful to commodity, with companies like Amazon already pushing this towards a reality.<br /><br />There are a handful of key factors for determining who ultimately wins the API Machine Learning (ML) marketplace game:<br /><br /><br />  Always Modular - Everything has to be decoupled and deliver micro value. Vendors will be tempted to build in dependency and emphasize relationships and partnerships, but the smaller and more modular will always win out.<br />  Easy Multi-Cloud - Whatever is available in a marketplace has to be available on all major platforms. Even if the marketplace is AWS, each unit of compute has to be transferrable to Google or Azure cloud without ANY friction.<br />  Enterprise Ready - The biggest failure of API marketplaces has always been being public. On-premise and private cloud API ML marketplaces will always be more successful that their public counterparts. The marketplace that caters to the enterprise will do well.<br />  Financial Engine - The key to markets are their financial engines. This is one area AWS is way ahead of the game, with their approach to monetizing digital bits, and their sophisticated market creating pricing calculators for estimating and predicting costs gives them a significant advantage. Whichever marketplaces allows for innovation at the financial engine level will win.<br />  Definition Driven - Marketplaces of the future will have to be definition driven. Everything has to have a YAML or JSON definition, from the API interface, and schema defining inputs and outputs, to the pricing, licensing, TOS, and SLA. The technology, business, and politics of the marketplace needs to be defined in a machine-readable way that can be measured, exchanged, and syndicated as needed.<br /><br /><br />Google has inroads into this realm with their GSuite Marketplace, and Play Marketplaces, but it feels more fragmented than Azure and AWS approaches. None of them are as far along as Algorithmia when it comes to specifically ML focused APIs. In coming months I will invest more time into mapping out what is available via marketplaces, trying to better understand their contents–whether application, SaaS, and data, content, or algorithmic API.<br /><br />I feel like many marketplace conversations often get lost in the discovery layer. In my opinion, there are many other contributing factors beyond just finding things. I talked about the retail and wholesale economics of Algorithmia’s approach back in January, and I continue to think the economic engine will be one of the biggest factors in any API ML marketplace success–how it allows marketplace vendors to understand, experiment, and scale the revenue part of things without giving up to big of a slice of the pie.<br /><br />Beyond revenue, the modularity and portability will be equally important as the financial engine, providing vital relief valves for some of the classic silo and walled garden effects we’ve seen the impact the success of previous marketplace efforts. I’ll keep studying the approach of smaller providers like Algorithmia, as well as those of the cloud giants, and see where all of this goes. It is natural to default to AWS lead when it comes to the cloud, but I’m continually impressed with what I’m seeing out of Azure, as well as feel that Google has a significant advantage when it comes to TensorFlow, as well as their overall public API experience–we will see.<br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-marketplace.png"
  },
  {
  "title": "Simple APIs With Jekyll And Github With Data Managed Via Google Spreadsheets",
  "date": "10 May 2017",
  "body": "<br />Im always looking for simpler, and cheaper ways of doing APIs that can help anyone easily manage data while making it available in both a human and machine readable way--preferably&amp;nbsp;something developers and non-developers both will find useful. I&#39;ve pushed forward my use of Github when it comes to managing simple datasets, and have a new approach I want to share, and potentially use across other projects.<br />You can find a working example of this in action with my OpenAPI Toolbox, where I&#39;m looking to manage and share a listing of tooling that is built on top of the OpenAPI specification. Like the rest of my API research, I am looking manage the data in a simple and cheap way that I can offload&amp;nbsp;the storage, compute, and bandwidth to other providers, preferably&amp;nbsp;ones that don&#39;t cost me a dime. While not a solution that would work in every API scenario, I am pretty happy with the formula I&#39;ve come up with for my OpenAPI Toolbox.<br />Data Storage and Management In Google SheetsThe data used in the OpenAPI Toolbox comes from a public Google Sheet. I manage all the tools in the toolbox via this spreadsheet, tracking title, description, URL, image, organization, types, tags, and license using the spreadsheet. I have two separate worksheets, one of which tracks details on the organizations, and the other keeping track of each individual tool in the toolbox. This allows for the data to be managed by anyone I give access to the sheet using Google Docs, offloading storage and data management to Google. Sure, it has its limitations, but for simple datasets, it works better than a database in my opinion.<br />Website and Basic API Hosting Using GithubFirst, and foremost the data in the OpenAPI Toolbox is meant to be accessible by any human on the web. Github, using their Github Pages solution, combined with the static website tool Jekyll, provides a rich environment for managing this data-driven toolbox. Jekyll provides the ability to store YAML data in its _data folder, which I can then use across static HTML pages which display the data using Liquid syntax. This approach to managing data allows for easy publishing of static representations in HTML, JSON, and YAML, making the data easily consumable by humans and machines, in an environment that is version controlled, forkable, and free for publicly available projects.<br />JavaScript Spreadsheet Sync To YAML Data StoreTo keep the data in the Google Spreadsheet in sync with the YAML data store in the Github hosted repository I use a simple JavaScript driven page on the website. To make it work you have to provide a valid Github OAuth token to be passed along as query string like this http://openapi.toolbox.apievangelist.com/pull-spreadsheet/?token=[github token]. The token can be acquired by doing the usual OAuth dance with Github or using the Github account of any user where you can issue personal tokens. If the user is a valid contributor on the repository, the JavaScript will pull a recent copy of the data in the Google Spreadsheet, and publish as YAML in the _data folder for the toolbox repository successfully--otherwise, it just throws an error.<br /><br />HTML Toolbox For Humans To Browse The ToolboxJekyll provides a static website that acts as the public face for the OpenAPI Toolbox. The home page provides icon links to each of the types of tools I have indexed, as well as to specific tags I&#39;ve selected, such as the programming language of each tool. Each page of the website is an HTML page that uses Liquid to display data stored in the central YAML store. Liquid handles the filtering of data by type, tags, or any other criteria I choose. Soon I will be adding a search, and other ways to browse the data in the toolbox as the data store grows, and I obtain more data points to slice and dice things on.&amp;nbsp;<br />JSON API To Put To Use Across Other ApplicationsTo provide the API-esque functionality I also use Liquid to display data from the YAML data store, but instead of publishing as HTML, I publish as JSON, essentially providing a static API facade. The primary objective of this type of implementation is to allow for GET requests on a variety of machine-readable paths for the toolbox. I published a full JSON listing of the entire toolbox, as well as more precise paths for getting at types of tools, and specific programming language tools. Similar to the human side of the toolbox, I will be adding more paths as more data points become available in the OpenAPI toolbox data store.<br />Documentation Using Liquid and OpenAPI DefinitionRather than just making the data available via JSON files, I wanted to also provide simple API documentation demonstrating what was possible with the data stored in the toolbox. I crafted an OpenAPI for the OpenAPI Toolbox API, providing a machine readable definition of all the paths available. Again, using Liquid I generate simple API documentation and schema, that actually allows you to make calls against the API, using a simple interactive JavaScript interface. While the OpenAPI Toolbox is technically static, using Liquid and OpenAPI I was able to mimic much of the functionality developers are used to when it comes to API integration.<br />Project Support and Road Map Using Github IssuesAs with all of my projects I am using the underlying issue management system to help me manage support and the roadmap for the project. Anyone can submit an issue regarding a tool they&#39;d like to see in the toolbox, regarding API integration, or possibly new APIs they would like to see published. I can use the Github issue management to handle general support requests, and communication around the project, as well as incrementally manage the data, schema, website, and API for the toolbox.&amp;nbsp;<br /><br />Indexed In Machine Readable Way With APIs.jsonThe entire project is indexed using APIs.json, providing metadata for the project as well as other indexes for the API, support, and other aspects of operating the project. APIs.json is meant to provide a machine readable index for not just the API, which is already defined using OpenAPI, but for the rest of the project, including documentation and support, and eventually a road map, blog, and other supporting elements. Using the APIs.json index, other systems can easily discover the API, and programmatically access the data via the APIs, or even access the repository for the spreadsheet via the Github API, or the Google Sheet via its API--all the information is available in the APIs.json for use.<br />A Free Forkable Way To Manage Simple Data And APIsThis approach to doing APIs won&#39;t&#39; be something you will want to do for every API implementation, but for simple data-driven projects like the OpenAPI Toolbox, it works great. Google Sheets and Github are both free, so I am offloading the storage, hosting, and bandwidth to another provider, while I am managing things in a way that any tech-savvy user could engage with. Anyone could manage entries in the toolbox using the Google Sheet and even engage with humans, and other applications via the published project toolbox.<br />I am going to continue evolving this approach to fit some of my other data-driven projects. I really like having all my projects self-contained as individual repositories, and the public side of things running using Jekyll--the entire API Evangelist network runs this way. I also like having the data managed in individual Google Sheets like this. it gives me simple data stores that I can easily manage with the help of other data stewards. Each of the resulting projects exists as a static representation of each data set--in this case an OpenAPI toolbox. I have many other toolboxes, toolkits, curriculum, and API research areas that are data driven, and will benefit from this approach.<br />What really makes me smile about this is that each project has an API representation of its core. Sure, I don&#39;t have POST, PUT, and DELETE capabilities for these APIs, or even advanced search capabilities, but for projects that are heavily read only--this works just fine. If you think about it though, I can easily access the data for reading and writing using the Google Sheets or Github APIs, depending on which layer I want to get access at. Really I am just looking to allow for easy management of data using Google Sheets, and simple publishing as YAML, JSON, and HTML, so that humans can browse, as well as put to use in other applications.m always looking for simpler, and cheaper ways of doing APIs that can help anyone easily manage data while making it available in both a human and machine readable way--preferably&amp;nbsp;something developers and non-developers both will find useful. Ive pushed forward my use of Github when it comes to managing simple datasets, and have a new approach I want to share, and potentially use across other projects.<br />You can find a working example of this in action with my OpenAPI Toolbox, where I&#39;m looking to manage and share a listing of tooling that is built on top of the OpenAPI specification. Like the rest of my API research, I am looking manage the data in a simple and cheap way that I can offload&amp;nbsp;the storage, compute, and bandwidth to other providers, preferably&amp;nbsp;ones that don&#39;t cost me a dime. While not a solution that would work in every API scenario, I am pretty happy with the formula I&#39;ve come up with for my OpenAPI Toolbox.<br />Data Storage and Management In Google SheetsThe data used in the OpenAPI Toolbox comes from a public Google Sheet. I manage all the tools in the toolbox via this spreadsheet, tracking title, description, URL, image, organization, types, tags, and license using the spreadsheet. I have two separate worksheets, one of which tracks details on the organizations, and the other keeping track of each individual tool in the toolbox. This allows for the data to be managed by anyone I give access to the sheet using Google Docs, offloading storage and data management to Google. Sure, it has its limitations, but for simple datasets, it works better than a database in my opinion.<br />Website and Basic API Hosting Using GithubFirst, and foremost the data in the OpenAPI Toolbox is meant to be accessible by any human on the web. Github, using their Github Pages solution, combined with the static website tool Jekyll, provides a rich environment for managing this data-driven toolbox. Jekyll provides the ability to store YAML data in its _data folder, which I can then use across static HTML pages which display the data using Liquid syntax. This approach to managing data allows for easy publishing of static representations in HTML, JSON, and YAML, making the data easily consumable by humans and machines, in an environment that is version controlled, forkable, and free for publicly available projects.<br />JavaScript Spreadsheet Sync To YAML Data StoreTo keep the data in the Google Spreadsheet in sync with the YAML data store in the Github hosted repository I use a simple JavaScript driven page on the website. To make it work you have to provide a valid Github OAuth token to be passed along as query string like this http://openapi.toolbox.apievangelist.com/pull-spreadsheet/?token=[github token]. The token can be acquired by doing the usual OAuth dance with Github or using the Github account of any user where you can issue personal tokens. If the user is a valid contributor on the repository, the JavaScript will pull a recent copy of the data in the Google Spreadsheet, and publish as YAML in the _data folder for the toolbox repository successfully--otherwise, it just throws an error.<br /><br />HTML Toolbox For Humans To Browse The ToolboxJekyll provides a static website that acts as the public face for the OpenAPI Toolbox. The home page provides icon links to each of the types of tools I have indexed, as well as to specific tags I&#39;ve selected, such as the programming language of each tool. Each page of the website is an HTML page that uses Liquid to display data stored in the central YAML store. Liquid handles the filtering of data by type, tags, or any other criteria I choose. Soon I will be adding a search, and other ways to browse the data in the toolbox as the data store grows, and I obtain more data points to slice and dice things on.&amp;nbsp;<br />JSON API To Put To Use Across Other ApplicationsTo provide the API-esque functionality I also use Liquid to display data from the YAML data store, but instead of publishing as HTML, I publish as JSON, essentially providing a static API facade. The primary objective of this type of implementation is to allow for GET requests on a variety of machine-readable paths for the toolbox. I published a full JSON listing of the entire toolbox, as well as more precise paths for getting at types of tools, and specific programming language tools. Similar to the human side of the toolbox, I will be adding more paths as more data points become available in the OpenAPI toolbox data store.<br />Documentation Using Liquid and OpenAPI DefinitionRather than just making the data available via JSON files, I wanted to also provide simple API documentation demonstrating what was possible with the data stored in the toolbox. I crafted an OpenAPI for the OpenAPI Toolbox API, providing a machine readable definition of all the paths available. Again, using Liquid I generate simple API documentation and schema, that actually allows you to make calls against the API, using a simple interactive JavaScript interface. While the OpenAPI Toolbox is technically static, using Liquid and OpenAPI I was able to mimic much of the functionality developers are used to when it comes to API integration.<br />Project Support and Road Map Using Github IssuesAs with all of my projects I am using the underlying issue management system to help me manage support and the roadmap for the project. Anyone can submit an issue regarding a tool they&#39;d like to see in the toolbox, regarding API integration, or possibly new APIs they would like to see published. I can use the Github issue management to handle general support requests, and communication around the project, as well as incrementally manage the data, schema, website, and API for the toolbox.&amp;nbsp;<br /><br />Indexed In Machine Readable Way With APIs.jsonThe entire project is indexed using APIs.json, providing metadata for the project as well as other indexes for the API, support, and other aspects of operating the project. APIs.json is meant to provide a machine readable index for not just the API, which is already defined using OpenAPI, but for the rest of the project, including documentation and support, and eventually a road map, blog, and other supporting elements. Using the APIs.json index, other systems can easily discover the API, and programmatically access the data via the APIs, or even access the repository for the spreadsheet via the Github API, or the Google Sheet via its API--all the information is available in the APIs.json for use.<br />A Free Forkable Way To Manage Simple Data And APIsThis approach to doing APIs won&#39;t&#39; be something you will want to do for every API implementation, but for simple data-driven projects like the OpenAPI Toolbox, it works great. Google Sheets and Github are both free, so I am offloading the storage, hosting, and bandwidth to another provider, while I am managing things in a way that any tech-savvy user could engage with. Anyone could manage entries in the toolbox using the Google Sheet and even engage with humans, and other applications via the published project toolbox.<br />I am going to continue evolving this approach to fit some of my other data-driven projects. I really like having all my projects self-contained as individual repositories, and the public side of things running using Jekyll--the entire API Evangelist network runs this way. I also like having the data managed in individual Google Sheets like this. it gives me simple data stores that I can easily manage with the help of other data stewards. Each of the resulting projects exists as a static representation of each data set--in this case an OpenAPI toolbox. I have many other toolboxes, toolkits, curriculum, and API research areas that are data driven, and will benefit from this approach.<br />What really makes me smile about this is that each project has an API representation of its core. Sure, I don&#39;t have POST, PUT, and DELETE capabilities for these APIs, or even advanced search capabilities, but for projects that are heavily read only--this works just fine. If you think about it though, I can easily access the data for reading and writing using the Google Sheets or Github APIs, depending on which layer I want to get access at. Really I am just looking to allow for easy management of data using Google Sheets, and simple publishing as YAML, JSON, and HTML, so that humans can browse, as well as put to use in other applications.ve pushed forward my use of Github when it comes to managing simple datasets, and have a new approach I want to share, and potentially use across other projects.<br />You can find a working example of this in action with my OpenAPI Toolbox, where Im looking to manage and share a listing of tooling that is built on top of the OpenAPI specification. Like the rest of my API research, I am looking manage the data in a simple and cheap way that I can offload&amp;nbsp;the storage, compute, and bandwidth to other providers, preferably&amp;nbsp;ones that don&#39;t cost me a dime. While not a solution that would work in every API scenario, I am pretty happy with the formula I&#39;ve come up with for my OpenAPI Toolbox.<br />Data Storage and Management In Google SheetsThe data used in the OpenAPI Toolbox comes from a public Google Sheet. I manage all the tools in the toolbox via this spreadsheet, tracking title, description, URL, image, organization, types, tags, and license using the spreadsheet. I have two separate worksheets, one of which tracks details on the organizations, and the other keeping track of each individual tool in the toolbox. This allows for the data to be managed by anyone I give access to the sheet using Google Docs, offloading storage and data management to Google. Sure, it has its limitations, but for simple datasets, it works better than a database in my opinion.<br />Website and Basic API Hosting Using GithubFirst, and foremost the data in the OpenAPI Toolbox is meant to be accessible by any human on the web. Github, using their Github Pages solution, combined with the static website tool Jekyll, provides a rich environment for managing this data-driven toolbox. Jekyll provides the ability to store YAML data in its _data folder, which I can then use across static HTML pages which display the data using Liquid syntax. This approach to managing data allows for easy publishing of static representations in HTML, JSON, and YAML, making the data easily consumable by humans and machines, in an environment that is version controlled, forkable, and free for publicly available projects.<br />JavaScript Spreadsheet Sync To YAML Data StoreTo keep the data in the Google Spreadsheet in sync with the YAML data store in the Github hosted repository I use a simple JavaScript driven page on the website. To make it work you have to provide a valid Github OAuth token to be passed along as query string like this http://openapi.toolbox.apievangelist.com/pull-spreadsheet/?token=[github token]. The token can be acquired by doing the usual OAuth dance with Github or using the Github account of any user where you can issue personal tokens. If the user is a valid contributor on the repository, the JavaScript will pull a recent copy of the data in the Google Spreadsheet, and publish as YAML in the _data folder for the toolbox repository successfully--otherwise, it just throws an error.<br /><br />HTML Toolbox For Humans To Browse The ToolboxJekyll provides a static website that acts as the public face for the OpenAPI Toolbox. The home page provides icon links to each of the types of tools I have indexed, as well as to specific tags I&#39;ve selected, such as the programming language of each tool. Each page of the website is an HTML page that uses Liquid to display data stored in the central YAML store. Liquid handles the filtering of data by type, tags, or any other criteria I choose. Soon I will be adding a search, and other ways to browse the data in the toolbox as the data store grows, and I obtain more data points to slice and dice things on.&amp;nbsp;<br />JSON API To Put To Use Across Other ApplicationsTo provide the API-esque functionality I also use Liquid to display data from the YAML data store, but instead of publishing as HTML, I publish as JSON, essentially providing a static API facade. The primary objective of this type of implementation is to allow for GET requests on a variety of machine-readable paths for the toolbox. I published a full JSON listing of the entire toolbox, as well as more precise paths for getting at types of tools, and specific programming language tools. Similar to the human side of the toolbox, I will be adding more paths as more data points become available in the OpenAPI toolbox data store.<br />Documentation Using Liquid and OpenAPI DefinitionRather than just making the data available via JSON files, I wanted to also provide simple API documentation demonstrating what was possible with the data stored in the toolbox. I crafted an OpenAPI for the OpenAPI Toolbox API, providing a machine readable definition of all the paths available. Again, using Liquid I generate simple API documentation and schema, that actually allows you to make calls against the API, using a simple interactive JavaScript interface. While the OpenAPI Toolbox is technically static, using Liquid and OpenAPI I was able to mimic much of the functionality developers are used to when it comes to API integration.<br />Project Support and Road Map Using Github IssuesAs with all of my projects I am using the underlying issue management system to help me manage support and the roadmap for the project. Anyone can submit an issue regarding a tool they&#39;d like to see in the toolbox, regarding API integration, or possibly new APIs they would like to see published. I can use the Github issue management to handle general support requests, and communication around the project, as well as incrementally manage the data, schema, website, and API for the toolbox.&amp;nbsp;<br /><br />Indexed In Machine Readable Way With APIs.jsonThe entire project is indexed using APIs.json, providing metadata for the project as well as other indexes for the API, support, and other aspects of operating the project. APIs.json is meant to provide a machine readable index for not just the API, which is already defined using OpenAPI, but for the rest of the project, including documentation and support, and eventually a road map, blog, and other supporting elements. Using the APIs.json index, other systems can easily discover the API, and programmatically access the data via the APIs, or even access the repository for the spreadsheet via the Github API, or the Google Sheet via its API--all the information is available in the APIs.json for use.<br />A Free Forkable Way To Manage Simple Data And APIsThis approach to doing APIs won&#39;t&#39; be something you will want to do for every API implementation, but for simple data-driven projects like the OpenAPI Toolbox, it works great. Google Sheets and Github are both free, so I am offloading the storage, hosting, and bandwidth to another provider, while I am managing things in a way that any tech-savvy user could engage with. Anyone could manage entries in the toolbox using the Google Sheet and even engage with humans, and other applications via the published project toolbox.<br />I am going to continue evolving this approach to fit some of my other data-driven projects. I really like having all my projects self-contained as individual repositories, and the public side of things running using Jekyll--the entire API Evangelist network runs this way. I also like having the data managed in individual Google Sheets like this. it gives me simple data stores that I can easily manage with the help of other data stewards. Each of the resulting projects exists as a static representation of each data set--in this case an OpenAPI toolbox. I have many other toolboxes, toolkits, curriculum, and API research areas that are data driven, and will benefit from this approach.<br />What really makes me smile about this is that each project has an API representation of its core. Sure, I don&#39;t have POST, PUT, and DELETE capabilities for these APIs, or even advanced search capabilities, but for projects that are heavily read only--this works just fine. If you think about it though, I can easily access the data for reading and writing using the Google Sheets or Github APIs, depending on which layer I want to get access at. Really I am just looking to allow for easy management of data using Google Sheets, and simple publishing as YAML, JSON, and HTML, so that humans can browse, as well as put to use in other applications.m looking to manage and share a listing of tooling that is built on top of the OpenAPI specification. Like the rest of my API research, I am looking manage the data in a simple and cheap way that I can offload&amp;nbsp;the storage, compute, and bandwidth to other providers, preferably&amp;nbsp;ones that dont cost me a dime. While not a solution that would work in every API scenario, I am pretty happy with the formula I&#39;ve come up with for my OpenAPI Toolbox.<br />Data Storage and Management In Google SheetsThe data used in the OpenAPI Toolbox comes from a public Google Sheet. I manage all the tools in the toolbox via this spreadsheet, tracking title, description, URL, image, organization, types, tags, and license using the spreadsheet. I have two separate worksheets, one of which tracks details on the organizations, and the other keeping track of each individual tool in the toolbox. This allows for the data to be managed by anyone I give access to the sheet using Google Docs, offloading storage and data management to Google. Sure, it has its limitations, but for simple datasets, it works better than a database in my opinion.<br />Website and Basic API Hosting Using GithubFirst, and foremost the data in the OpenAPI Toolbox is meant to be accessible by any human on the web. Github, using their Github Pages solution, combined with the static website tool Jekyll, provides a rich environment for managing this data-driven toolbox. Jekyll provides the ability to store YAML data in its _data folder, which I can then use across static HTML pages which display the data using Liquid syntax. This approach to managing data allows for easy publishing of static representations in HTML, JSON, and YAML, making the data easily consumable by humans and machines, in an environment that is version controlled, forkable, and free for publicly available projects.<br />JavaScript Spreadsheet Sync To YAML Data StoreTo keep the data in the Google Spreadsheet in sync with the YAML data store in the Github hosted repository I use a simple JavaScript driven page on the website. To make it work you have to provide a valid Github OAuth token to be passed along as query string like this http://openapi.toolbox.apievangelist.com/pull-spreadsheet/?token=[github token]. The token can be acquired by doing the usual OAuth dance with Github or using the Github account of any user where you can issue personal tokens. If the user is a valid contributor on the repository, the JavaScript will pull a recent copy of the data in the Google Spreadsheet, and publish as YAML in the _data folder for the toolbox repository successfully--otherwise, it just throws an error.<br /><br />HTML Toolbox For Humans To Browse The ToolboxJekyll provides a static website that acts as the public face for the OpenAPI Toolbox. The home page provides icon links to each of the types of tools I have indexed, as well as to specific tags I&#39;ve selected, such as the programming language of each tool. Each page of the website is an HTML page that uses Liquid to display data stored in the central YAML store. Liquid handles the filtering of data by type, tags, or any other criteria I choose. Soon I will be adding a search, and other ways to browse the data in the toolbox as the data store grows, and I obtain more data points to slice and dice things on.&amp;nbsp;<br />JSON API To Put To Use Across Other ApplicationsTo provide the API-esque functionality I also use Liquid to display data from the YAML data store, but instead of publishing as HTML, I publish as JSON, essentially providing a static API facade. The primary objective of this type of implementation is to allow for GET requests on a variety of machine-readable paths for the toolbox. I published a full JSON listing of the entire toolbox, as well as more precise paths for getting at types of tools, and specific programming language tools. Similar to the human side of the toolbox, I will be adding more paths as more data points become available in the OpenAPI toolbox data store.<br />Documentation Using Liquid and OpenAPI DefinitionRather than just making the data available via JSON files, I wanted to also provide simple API documentation demonstrating what was possible with the data stored in the toolbox. I crafted an OpenAPI for the OpenAPI Toolbox API, providing a machine readable definition of all the paths available. Again, using Liquid I generate simple API documentation and schema, that actually allows you to make calls against the API, using a simple interactive JavaScript interface. While the OpenAPI Toolbox is technically static, using Liquid and OpenAPI I was able to mimic much of the functionality developers are used to when it comes to API integration.<br />Project Support and Road Map Using Github IssuesAs with all of my projects I am using the underlying issue management system to help me manage support and the roadmap for the project. Anyone can submit an issue regarding a tool they&#39;d like to see in the toolbox, regarding API integration, or possibly new APIs they would like to see published. I can use the Github issue management to handle general support requests, and communication around the project, as well as incrementally manage the data, schema, website, and API for the toolbox.&amp;nbsp;<br /><br />Indexed In Machine Readable Way With APIs.jsonThe entire project is indexed using APIs.json, providing metadata for the project as well as other indexes for the API, support, and other aspects of operating the project. APIs.json is meant to provide a machine readable index for not just the API, which is already defined using OpenAPI, but for the rest of the project, including documentation and support, and eventually a road map, blog, and other supporting elements. Using the APIs.json index, other systems can easily discover the API, and programmatically access the data via the APIs, or even access the repository for the spreadsheet via the Github API, or the Google Sheet via its API--all the information is available in the APIs.json for use.<br />A Free Forkable Way To Manage Simple Data And APIsThis approach to doing APIs won&#39;t&#39; be something you will want to do for every API implementation, but for simple data-driven projects like the OpenAPI Toolbox, it works great. Google Sheets and Github are both free, so I am offloading the storage, hosting, and bandwidth to another provider, while I am managing things in a way that any tech-savvy user could engage with. Anyone could manage entries in the toolbox using the Google Sheet and even engage with humans, and other applications via the published project toolbox.<br />I am going to continue evolving this approach to fit some of my other data-driven projects. I really like having all my projects self-contained as individual repositories, and the public side of things running using Jekyll--the entire API Evangelist network runs this way. I also like having the data managed in individual Google Sheets like this. it gives me simple data stores that I can easily manage with the help of other data stewards. Each of the resulting projects exists as a static representation of each data set--in this case an OpenAPI toolbox. I have many other toolboxes, toolkits, curriculum, and API research areas that are data driven, and will benefit from this approach.<br />What really makes me smile about this is that each project has an API representation of its core. Sure, I don&#39;t have POST, PUT, and DELETE capabilities for these APIs, or even advanced search capabilities, but for projects that are heavily read only--this works just fine. If you think about it though, I can easily access the data for reading and writing using the Google Sheets or Github APIs, depending on which layer I want to get access at. Really I am just looking to allow for easy management of data using Google Sheets, and simple publishing as YAML, JSON, and HTML, so that humans can browse, as well as put to use in other applications.t cost me a dime. While not a solution that would work in every API scenario, I am pretty happy with the formula Ive come up with for my OpenAPI Toolbox.<br />Data Storage and Management In Google SheetsThe data used in the OpenAPI Toolbox comes from a public Google Sheet. I manage all the tools in the toolbox via this spreadsheet, tracking title, description, URL, image, organization, types, tags, and license using the spreadsheet. I have two separate worksheets, one of which tracks details on the organizations, and the other keeping track of each individual tool in the toolbox. This allows for the data to be managed by anyone I give access to the sheet using Google Docs, offloading storage and data management to Google. Sure, it has its limitations, but for simple datasets, it works better than a database in my opinion.<br />Website and Basic API Hosting Using GithubFirst, and foremost the data in the OpenAPI Toolbox is meant to be accessible by any human on the web. Github, using their Github Pages solution, combined with the static website tool Jekyll, provides a rich environment for managing this data-driven toolbox. Jekyll provides the ability to store YAML data in its _data folder, which I can then use across static HTML pages which display the data using Liquid syntax. This approach to managing data allows for easy publishing of static representations in HTML, JSON, and YAML, making the data easily consumable by humans and machines, in an environment that is version controlled, forkable, and free for publicly available projects.<br />JavaScript Spreadsheet Sync To YAML Data StoreTo keep the data in the Google Spreadsheet in sync with the YAML data store in the Github hosted repository I use a simple JavaScript driven page on the website. To make it work you have to provide a valid Github OAuth token to be passed along as query string like this http://openapi.toolbox.apievangelist.com/pull-spreadsheet/?token=[github token]. The token can be acquired by doing the usual OAuth dance with Github or using the Github account of any user where you can issue personal tokens. If the user is a valid contributor on the repository, the JavaScript will pull a recent copy of the data in the Google Spreadsheet, and publish as YAML in the _data folder for the toolbox repository successfully--otherwise, it just throws an error.<br /><br />HTML Toolbox For Humans To Browse The ToolboxJekyll provides a static website that acts as the public face for the OpenAPI Toolbox. The home page provides icon links to each of the types of tools I have indexed, as well as to specific tags I&#39;ve selected, such as the programming language of each tool. Each page of the website is an HTML page that uses Liquid to display data stored in the central YAML store. Liquid handles the filtering of data by type, tags, or any other criteria I choose. Soon I will be adding a search, and other ways to browse the data in the toolbox as the data store grows, and I obtain more data points to slice and dice things on.&amp;nbsp;<br />JSON API To Put To Use Across Other ApplicationsTo provide the API-esque functionality I also use Liquid to display data from the YAML data store, but instead of publishing as HTML, I publish as JSON, essentially providing a static API facade. The primary objective of this type of implementation is to allow for GET requests on a variety of machine-readable paths for the toolbox. I published a full JSON listing of the entire toolbox, as well as more precise paths for getting at types of tools, and specific programming language tools. Similar to the human side of the toolbox, I will be adding more paths as more data points become available in the OpenAPI toolbox data store.<br />Documentation Using Liquid and OpenAPI DefinitionRather than just making the data available via JSON files, I wanted to also provide simple API documentation demonstrating what was possible with the data stored in the toolbox. I crafted an OpenAPI for the OpenAPI Toolbox API, providing a machine readable definition of all the paths available. Again, using Liquid I generate simple API documentation and schema, that actually allows you to make calls against the API, using a simple interactive JavaScript interface. While the OpenAPI Toolbox is technically static, using Liquid and OpenAPI I was able to mimic much of the functionality developers are used to when it comes to API integration.<br />Project Support and Road Map Using Github IssuesAs with all of my projects I am using the underlying issue management system to help me manage support and the roadmap for the project. Anyone can submit an issue regarding a tool they&#39;d like to see in the toolbox, regarding API integration, or possibly new APIs they would like to see published. I can use the Github issue management to handle general support requests, and communication around the project, as well as incrementally manage the data, schema, website, and API for the toolbox.&amp;nbsp;<br /><br />Indexed In Machine Readable Way With APIs.jsonThe entire project is indexed using APIs.json, providing metadata for the project as well as other indexes for the API, support, and other aspects of operating the project. APIs.json is meant to provide a machine readable index for not just the API, which is already defined using OpenAPI, but for the rest of the project, including documentation and support, and eventually a road map, blog, and other supporting elements. Using the APIs.json index, other systems can easily discover the API, and programmatically access the data via the APIs, or even access the repository for the spreadsheet via the Github API, or the Google Sheet via its API--all the information is available in the APIs.json for use.<br />A Free Forkable Way To Manage Simple Data And APIsThis approach to doing APIs won&#39;t&#39; be something you will want to do for every API implementation, but for simple data-driven projects like the OpenAPI Toolbox, it works great. Google Sheets and Github are both free, so I am offloading the storage, hosting, and bandwidth to another provider, while I am managing things in a way that any tech-savvy user could engage with. Anyone could manage entries in the toolbox using the Google Sheet and even engage with humans, and other applications via the published project toolbox.<br />I am going to continue evolving this approach to fit some of my other data-driven projects. I really like having all my projects self-contained as individual repositories, and the public side of things running using Jekyll--the entire API Evangelist network runs this way. I also like having the data managed in individual Google Sheets like this. it gives me simple data stores that I can easily manage with the help of other data stewards. Each of the resulting projects exists as a static representation of each data set--in this case an OpenAPI toolbox. I have many other toolboxes, toolkits, curriculum, and API research areas that are data driven, and will benefit from this approach.<br />What really makes me smile about this is that each project has an API representation of its core. Sure, I don&#39;t have POST, PUT, and DELETE capabilities for these APIs, or even advanced search capabilities, but for projects that are heavily read only--this works just fine. If you think about it though, I can easily access the data for reading and writing using the Google Sheets or Github APIs, depending on which layer I want to get access at. Really I am just looking to allow for easy management of data using Google Sheets, and simple publishing as YAML, JSON, and HTML, so that humans can browse, as well as put to use in other applications.ve come up with for my OpenAPI Toolbox.<br />Data Storage and Management In Google SheetsThe data used in the OpenAPI Toolbox comes from a public Google Sheet. I manage all the tools in the toolbox via this spreadsheet, tracking title, description, URL, image, organization, types, tags, and license using the spreadsheet. I have two separate worksheets, one of which tracks details on the organizations, and the other keeping track of each individual tool in the toolbox. This allows for the data to be managed by anyone I give access to the sheet using Google Docs, offloading storage and data management to Google. Sure, it has its limitations, but for simple datasets, it works better than a database in my opinion.<br />Website and Basic API Hosting Using GithubFirst, and foremost the data in the OpenAPI Toolbox is meant to be accessible by any human on the web. Github, using their Github Pages solution, combined with the static website tool Jekyll, provides a rich environment for managing this data-driven toolbox. Jekyll provides the ability to store YAML data in its _data folder, which I can then use across static HTML pages which display the data using Liquid syntax. This approach to managing data allows for easy publishing of static representations in HTML, JSON, and YAML, making the data easily consumable by humans and machines, in an environment that is version controlled, forkable, and free for publicly available projects.<br />JavaScript Spreadsheet Sync To YAML Data StoreTo keep the data in the Google Spreadsheet in sync with the YAML data store in the Github hosted repository I use a simple JavaScript driven page on the website. To make it work you have to provide a valid Github OAuth token to be passed along as query string like this http://openapi.toolbox.apievangelist.com/pull-spreadsheet/?token=[github token]. The token can be acquired by doing the usual OAuth dance with Github or using the Github account of any user where you can issue personal tokens. If the user is a valid contributor on the repository, the JavaScript will pull a recent copy of the data in the Google Spreadsheet, and publish as YAML in the _data folder for the toolbox repository successfully--otherwise, it just throws an error.<br /><br />HTML Toolbox For Humans To Browse The ToolboxJekyll provides a static website that acts as the public face for the OpenAPI Toolbox. The home page provides icon links to each of the types of tools I have indexed, as well as to specific tags Ive selected, such as the programming language of each tool. Each page of the website is an HTML page that uses Liquid to display data stored in the central YAML store. Liquid handles the filtering of data by type, tags, or any other criteria I choose. Soon I will be adding a search, and other ways to browse the data in the toolbox as the data store grows, and I obtain more data points to slice and dice things on.&amp;nbsp;<br />JSON API To Put To Use Across Other ApplicationsTo provide the API-esque functionality I also use Liquid to display data from the YAML data store, but instead of publishing as HTML, I publish as JSON, essentially providing a static API facade. The primary objective of this type of implementation is to allow for GET requests on a variety of machine-readable paths for the toolbox. I published a full JSON listing of the entire toolbox, as well as more precise paths for getting at types of tools, and specific programming language tools. Similar to the human side of the toolbox, I will be adding more paths as more data points become available in the OpenAPI toolbox data store.<br />Documentation Using Liquid and OpenAPI DefinitionRather than just making the data available via JSON files, I wanted to also provide simple API documentation demonstrating what was possible with the data stored in the toolbox. I crafted an OpenAPI for the OpenAPI Toolbox API, providing a machine readable definition of all the paths available. Again, using Liquid I generate simple API documentation and schema, that actually allows you to make calls against the API, using a simple interactive JavaScript interface. While the OpenAPI Toolbox is technically static, using Liquid and OpenAPI I was able to mimic much of the functionality developers are used to when it comes to API integration.<br />Project Support and Road Map Using Github IssuesAs with all of my projects I am using the underlying issue management system to help me manage support and the roadmap for the project. Anyone can submit an issue regarding a tool they&#39;d like to see in the toolbox, regarding API integration, or possibly new APIs they would like to see published. I can use the Github issue management to handle general support requests, and communication around the project, as well as incrementally manage the data, schema, website, and API for the toolbox.&amp;nbsp;<br /><br />Indexed In Machine Readable Way With APIs.jsonThe entire project is indexed using APIs.json, providing metadata for the project as well as other indexes for the API, support, and other aspects of operating the project. APIs.json is meant to provide a machine readable index for not just the API, which is already defined using OpenAPI, but for the rest of the project, including documentation and support, and eventually a road map, blog, and other supporting elements. Using the APIs.json index, other systems can easily discover the API, and programmatically access the data via the APIs, or even access the repository for the spreadsheet via the Github API, or the Google Sheet via its API--all the information is available in the APIs.json for use.<br />A Free Forkable Way To Manage Simple Data And APIsThis approach to doing APIs won&#39;t&#39; be something you will want to do for every API implementation, but for simple data-driven projects like the OpenAPI Toolbox, it works great. Google Sheets and Github are both free, so I am offloading the storage, hosting, and bandwidth to another provider, while I am managing things in a way that any tech-savvy user could engage with. Anyone could manage entries in the toolbox using the Google Sheet and even engage with humans, and other applications via the published project toolbox.<br />I am going to continue evolving this approach to fit some of my other data-driven projects. I really like having all my projects self-contained as individual repositories, and the public side of things running using Jekyll--the entire API Evangelist network runs this way. I also like having the data managed in individual Google Sheets like this. it gives me simple data stores that I can easily manage with the help of other data stewards. Each of the resulting projects exists as a static representation of each data set--in this case an OpenAPI toolbox. I have many other toolboxes, toolkits, curriculum, and API research areas that are data driven, and will benefit from this approach.<br />What really makes me smile about this is that each project has an API representation of its core. Sure, I don&#39;t have POST, PUT, and DELETE capabilities for these APIs, or even advanced search capabilities, but for projects that are heavily read only--this works just fine. If you think about it though, I can easily access the data for reading and writing using the Google Sheets or Github APIs, depending on which layer I want to get access at. Really I am just looking to allow for easy management of data using Google Sheets, and simple publishing as YAML, JSON, and HTML, so that humans can browse, as well as put to use in other applications.ve selected, such as the programming language of each tool. Each page of the website is an HTML page that uses Liquid to display data stored in the central YAML store. Liquid handles the filtering of data by type, tags, or any other criteria I choose. Soon I will be adding a search, and other ways to browse the data in the toolbox as the data store grows, and I obtain more data points to slice and dice things on.&amp;nbsp;<br />JSON API To Put To Use Across Other ApplicationsTo provide the API-esque functionality I also use Liquid to display data from the YAML data store, but instead of publishing as HTML, I publish as JSON, essentially providing a static API facade. The primary objective of this type of implementation is to allow for GET requests on a variety of machine-readable paths for the toolbox. I published a full JSON listing of the entire toolbox, as well as more precise paths for getting at types of tools, and specific programming language tools. Similar to the human side of the toolbox, I will be adding more paths as more data points become available in the OpenAPI toolbox data store.<br />Documentation Using Liquid and OpenAPI DefinitionRather than just making the data available via JSON files, I wanted to also provide simple API documentation demonstrating what was possible with the data stored in the toolbox. I crafted an OpenAPI for the OpenAPI Toolbox API, providing a machine readable definition of all the paths available. Again, using Liquid I generate simple API documentation and schema, that actually allows you to make calls against the API, using a simple interactive JavaScript interface. While the OpenAPI Toolbox is technically static, using Liquid and OpenAPI I was able to mimic much of the functionality developers are used to when it comes to API integration.<br />Project Support and Road Map Using Github IssuesAs with all of my projects I am using the underlying issue management system to help me manage support and the roadmap for the project. Anyone can submit an issue regarding a tool theyd like to see in the toolbox, regarding API integration, or possibly new APIs they would like to see published. I can use the Github issue management to handle general support requests, and communication around the project, as well as incrementally manage the data, schema, website, and API for the toolbox.&amp;nbsp;<br /><br />Indexed In Machine Readable Way With APIs.jsonThe entire project is indexed using APIs.json, providing metadata for the project as well as other indexes for the API, support, and other aspects of operating the project. APIs.json is meant to provide a machine readable index for not just the API, which is already defined using OpenAPI, but for the rest of the project, including documentation and support, and eventually a road map, blog, and other supporting elements. Using the APIs.json index, other systems can easily discover the API, and programmatically access the data via the APIs, or even access the repository for the spreadsheet via the Github API, or the Google Sheet via its API--all the information is available in the APIs.json for use.<br />A Free Forkable Way To Manage Simple Data And APIsThis approach to doing APIs won&#39;t&#39; be something you will want to do for every API implementation, but for simple data-driven projects like the OpenAPI Toolbox, it works great. Google Sheets and Github are both free, so I am offloading the storage, hosting, and bandwidth to another provider, while I am managing things in a way that any tech-savvy user could engage with. Anyone could manage entries in the toolbox using the Google Sheet and even engage with humans, and other applications via the published project toolbox.<br />I am going to continue evolving this approach to fit some of my other data-driven projects. I really like having all my projects self-contained as individual repositories, and the public side of things running using Jekyll--the entire API Evangelist network runs this way. I also like having the data managed in individual Google Sheets like this. it gives me simple data stores that I can easily manage with the help of other data stewards. Each of the resulting projects exists as a static representation of each data set--in this case an OpenAPI toolbox. I have many other toolboxes, toolkits, curriculum, and API research areas that are data driven, and will benefit from this approach.<br />What really makes me smile about this is that each project has an API representation of its core. Sure, I don&#39;t have POST, PUT, and DELETE capabilities for these APIs, or even advanced search capabilities, but for projects that are heavily read only--this works just fine. If you think about it though, I can easily access the data for reading and writing using the Google Sheets or Github APIs, depending on which layer I want to get access at. Really I am just looking to allow for easy management of data using Google Sheets, and simple publishing as YAML, JSON, and HTML, so that humans can browse, as well as put to use in other applications.d like to see in the toolbox, regarding API integration, or possibly new APIs they would like to see published. I can use the Github issue management to handle general support requests, and communication around the project, as well as incrementally manage the data, schema, website, and API for the toolbox.&amp;nbsp;<br /><br />Indexed In Machine Readable Way With APIs.jsonThe entire project is indexed using APIs.json, providing metadata for the project as well as other indexes for the API, support, and other aspects of operating the project. APIs.json is meant to provide a machine readable index for not just the API, which is already defined using OpenAPI, but for the rest of the project, including documentation and support, and eventually a road map, blog, and other supporting elements. Using the APIs.json index, other systems can easily discover the API, and programmatically access the data via the APIs, or even access the repository for the spreadsheet via the Github API, or the Google Sheet via its API--all the information is available in the APIs.json for use.<br />A Free Forkable Way To Manage Simple Data And APIsThis approach to doing APIs wont&#39; be something you will want to do for every API implementation, but for simple data-driven projects like the OpenAPI Toolbox, it works great. Google Sheets and Github are both free, so I am offloading the storage, hosting, and bandwidth to another provider, while I am managing things in a way that any tech-savvy user could engage with. Anyone could manage entries in the toolbox using the Google Sheet and even engage with humans, and other applications via the published project toolbox.<br />I am going to continue evolving this approach to fit some of my other data-driven projects. I really like having all my projects self-contained as individual repositories, and the public side of things running using Jekyll--the entire API Evangelist network runs this way. I also like having the data managed in individual Google Sheets like this. it gives me simple data stores that I can easily manage with the help of other data stewards. Each of the resulting projects exists as a static representation of each data set--in this case an OpenAPI toolbox. I have many other toolboxes, toolkits, curriculum, and API research areas that are data driven, and will benefit from this approach.<br />What really makes me smile about this is that each project has an API representation of its core. Sure, I don&#39;t have POST, PUT, and DELETE capabilities for these APIs, or even advanced search capabilities, but for projects that are heavily read only--this works just fine. If you think about it though, I can easily access the data for reading and writing using the Google Sheets or Github APIs, depending on which layer I want to get access at. Really I am just looking to allow for easy management of data using Google Sheets, and simple publishing as YAML, JSON, and HTML, so that humans can browse, as well as put to use in other applications.t be something you will want to do for every API implementation, but for simple data-driven projects like the OpenAPI Toolbox, it works great. Google Sheets and Github are both free, so I am offloading the storage, hosting, and bandwidth to another provider, while I am managing things in a way that any tech-savvy user could engage with. Anyone could manage entries in the toolbox using the Google Sheet and even engage with humans, and other applications via the published project toolbox.<br />I am going to continue evolving this approach to fit some of my other data-driven projects. I really like having all my projects self-contained as individual repositories, and the public side of things running using Jekyll--the entire API Evangelist network runs this way. I also like having the data managed in individual Google Sheets like this. it gives me simple data stores that I can easily manage with the help of other data stewards. Each of the resulting projects exists as a static representation of each data set--in this case an OpenAPI toolbox. I have many other toolboxes, toolkits, curriculum, and API research areas that are data driven, and will benefit from this approach.<br />What really makes me smile about this is that each project has an API representation of its core. Sure, I don&#39;t have POST, PUT, and DELETE capabilities for these APIs, or even advanced search capabilities, but for projects that are heavily read only--this works just fine. If you think about it though, I can easily access the data for reading and writing using the Google Sheets or Github APIs, depending on which layer I want to get access at. Really I am just looking to allow for easy management of data using Google Sheets, and simple publishing as YAML, JSON, and HTML, so that humans can browse, as well as put to use in other applications. be something you will want to do for every API implementation, but for simple data-driven projects like the OpenAPI Toolbox, it works great. Google Sheets and Github are both free, so I am offloading the storage, hosting, and bandwidth to another provider, while I am managing things in a way that any tech-savvy user could engage with. Anyone could manage entries in the toolbox using the Google Sheet and even engage with humans, and other applications via the published project toolbox.<br />I am going to continue evolving this approach to fit some of my other data-driven projects. I really like having all my projects self-contained as individual repositories, and the public side of things running using Jekyll--the entire API Evangelist network runs this way. I also like having the data managed in individual Google Sheets like this. it gives me simple data stores that I can easily manage with the help of other data stewards. Each of the resulting projects exists as a static representation of each data set--in this case an OpenAPI toolbox. I have many other toolboxes, toolkits, curriculum, and API research areas that are data driven, and will benefit from this approach.<br />What really makes me smile about this is that each project has an API representation of its core. Sure, I dont have POST, PUT, and DELETE capabilities for these APIs, or even advanced search capabilities, but for projects that are heavily read only--this works just fine. If you think about it though, I can easily access the data for reading and writing using the Google Sheets or Github APIs, depending on which layer I want to get access at. Really I am just looking to allow for easy management of data using Google Sheets, and simple publishing as YAML, JSON, and HTML, so that humans can browse, as well as put to use in other applications.t have POST, PUT, and DELETE capabilities for these APIs, or even advanced search capabilities, but for projects that are heavily read only--this works just fine. If you think about it though, I can easily access the data for reading and writing using the Google Sheets or Github APIs, depending on which layer I want to get access at. Really I am just looking to allow for easy management of data using Google Sheets, and simple publishing as YAML, JSON, and HTML, so that humans can browse, as well as put to use in other applications.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/openapi_toolbox_home_page.png"
  },
  {
  "title": "Adding An Extensions Category To The OpenAPI Toolbox",
  "date": "10 May 2017",
  "body": "<br />I added another type of tool to my OpenAPI Toolbox, this time it is extensions. They used to be called Swagger vendor extensions, and now they are simply called OpenAPI extensions, which allow any implementor to extend the schema outside the current version of the API specification. All you do to add an OpenAPI extension is prepend x- to any value&amp;nbsp;that you wish to include in your OpenAPI, and the validator will overlook it as part of the specification.<br />I have a whole list of vendor extensions Id like to add, but I&#39;ve started with a handful from Microsoft Flow, and my friends over at APIMATIC. Two great examples of how OpenAPI extensions can be used in the API lifecycle. In this case, one is for integration platform as a service (iPaaS), and the other is SDK generation and continuous integration. Both vendors needed to extend the specification to meet a specific need, so they just extended it as required--you can find the extensions in the new section of the toolbox.<br />My goal in adding the section to the OpenAPI toolbox is to highlight how people are evolving the specification outside the core working group. While some of the extensions are pretty unique, some of them have a potential common purpose. I will be adding some discovery focused extensions next week from the OpenAPI directory APIs.guru, which I will be adopting and using in my own definitions to help me articulate the provenance of any OpenAPI definition in my catalog(s). Plus, I find it to be a learning experience to see how different vendors are putting them to work.&amp;nbsp;<br />If you know of any OpenAPI extensions that are not in the toolbox currently feel free to submit an issue on the Github repository for the project. I&#39;d like to evolve the collection to be a comprehensive look at how OpenAPI extensions are being used across the sector, from a diverse number of providers. I&#39;m going to be teaching my own OpenAPI crawler to identify extensions within any OpenAPI it comes across, and automatically submit an issue on the toolbox, rapidly expanding the discovery of how they are used across a variety of implementations in coming months.d like to add, but Ive started with a handful from Microsoft Flow, and my friends over at APIMATIC. Two great examples of how OpenAPI extensions can be used in the API lifecycle. In this case, one is for integration platform as a service (iPaaS), and the other is SDK generation and continuous integration. Both vendors needed to extend the specification to meet a specific need, so they just extended it as required--you can find the extensions in the new section of the toolbox.<br />My goal in adding the section to the OpenAPI toolbox is to highlight how people are evolving the specification outside the core working group. While some of the extensions are pretty unique, some of them have a potential common purpose. I will be adding some discovery focused extensions next week from the OpenAPI directory APIs.guru, which I will be adopting and using in my own definitions to help me articulate the provenance of any OpenAPI definition in my catalog(s). Plus, I find it to be a learning experience to see how different vendors are putting them to work.&amp;nbsp;<br />If you know of any OpenAPI extensions that are not in the toolbox currently feel free to submit an issue on the Github repository for the project. I&#39;d like to evolve the collection to be a comprehensive look at how OpenAPI extensions are being used across the sector, from a diverse number of providers. I&#39;m going to be teaching my own OpenAPI crawler to identify extensions within any OpenAPI it comes across, and automatically submit an issue on the toolbox, rapidly expanding the discovery of how they are used across a variety of implementations in coming months.ve started with a handful from Microsoft Flow, and my friends over at APIMATIC. Two great examples of how OpenAPI extensions can be used in the API lifecycle. In this case, one is for integration platform as a service (iPaaS), and the other is SDK generation and continuous integration. Both vendors needed to extend the specification to meet a specific need, so they just extended it as required--you can find the extensions in the new section of the toolbox.<br />My goal in adding the section to the OpenAPI toolbox is to highlight how people are evolving the specification outside the core working group. While some of the extensions are pretty unique, some of them have a potential common purpose. I will be adding some discovery focused extensions next week from the OpenAPI directory APIs.guru, which I will be adopting and using in my own definitions to help me articulate the provenance of any OpenAPI definition in my catalog(s). Plus, I find it to be a learning experience to see how different vendors are putting them to work.&amp;nbsp;<br />If you know of any OpenAPI extensions that are not in the toolbox currently feel free to submit an issue on the Github repository for the project. Id like to evolve the collection to be a comprehensive look at how OpenAPI extensions are being used across the sector, from a diverse number of providers. I&#39;m going to be teaching my own OpenAPI crawler to identify extensions within any OpenAPI it comes across, and automatically submit an issue on the toolbox, rapidly expanding the discovery of how they are used across a variety of implementations in coming months.d like to evolve the collection to be a comprehensive look at how OpenAPI extensions are being used across the sector, from a diverse number of providers. Im going to be teaching my own OpenAPI crawler to identify extensions within any OpenAPI it comes across, and automatically submit an issue on the toolbox, rapidly expanding the discovery of how they are used across a variety of implementations in coming months.m going to be teaching my own OpenAPI crawler to identify extensions within any OpenAPI it comes across, and automatically submit an issue on the toolbox, rapidly expanding the discovery of how they are used across a variety of implementations in coming months.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/openapi_extensions_in_the_openapi_toolbox.png"
  },
  {
  "title": "The List Of API Signals I Track On In My API Stack Research",
  "date": "09 May 2017",
  "body": "<br />I keep an eye on several thousand companies as part of my research into the API space&amp;nbsp;and publish over a thousand of these profiles in my API Stack project. Across the over 1,100 companies, organizations, institutions, and government agencies Im regularly running&amp;nbsp;into a growing number of signals that tune me into what is going on with each API provider, or service provider.&amp;nbsp;<br />Here are the almost 100 types of signals I am tuning into as I keep an eye on the world of APIs, each contributing to my unique awareness of what is going on with everything API.<br /><br />Account Settings&amp;nbsp;(x-account-settings) - Does an API provider allow me to manage the settings for my account?<br />Android SDK&amp;nbsp;(x-android-sdk) - Is there an Android SDK present?<br />Angular&amp;nbsp;(x-angularjs)&amp;nbsp;- Is there an Angular SDK present?<br />API Explorer&amp;nbsp;(x-api-explorer) - Does a provider have an interactive API explorer?<br />Application Gallery&amp;nbsp;(x-application-gallery) - Is there a gallery of applications build on an API available?<br />Application Manager&amp;nbsp;(x-application-manager) - Does the platform allow me to management my APIs?<br />Authentication Overview&amp;nbsp;(x-authentication-overview) - Is there a page dedicated to educating users about authentication?<br />Base URL for API&amp;nbsp;(x-base-url-for-api) - What is the base URL(s) for the API?<br />Base URL for Portal&amp;nbsp;(x-base-url-for-portal) - What is the base URL for the developer portal?<br />Best Practices&amp;nbsp;(x-best-practices) - Is there a page outlining best practices for integrating with an API?<br />Billing history&amp;nbsp;(x-billing-history) - As a developer, can I get at the billing history for my API consumption?<br />Blog&amp;nbsp;(x-blog) - Does the API have a blog, either at the company level, but preferably at the API and developer level as well?<br />Blog RSS Feed&amp;nbsp;(x-blog-rss-feed) - Is there an RSS feed for the blog?<br />Branding page&amp;nbsp;(x-branding-page) - Is there a dedicated branding page as part of API operations?<br />Buttons&amp;nbsp;(x-buttons) - Are there any embeddable buttons available as part of API operations.<br />C# SDK&amp;nbsp;(x-c-sharp) -&amp;nbsp;Is there a C# SDK present?<br />Case Studies&amp;nbsp;(x-case-studies) - Are there case studies available, showcasing implementations on top of an API?<br />Change Log&amp;nbsp;(x-change-log) - Does a platform provide a change log?<br />Chrome Extension&amp;nbsp;(x-chrome-extension) - Does a platform offer up open-source or white label chrome extensions?<br />Code builder&amp;nbsp;(x-code-builder) - Is there some sort of code generator or builder as part of platform operations?<br />Code page&amp;nbsp;(x-code-page) - Is there a dedicated code page for all the samples, libraries, and SDKs?<br />Command Line Interface&amp;nbsp;(x-command-line-interface) - Is there a command line interface (CLI) alongside the API?<br />Community Supported Libraries&amp;nbsp;(x-community-supported-libraries) - Is there a page or section dedicated to code that is developed by the API and developer community?<br />Compliance&amp;nbsp;(x-compliance) - Is there a section dedicated to industry compliance?<br />Contact form&amp;nbsp;(x-contact-form) - Is there a contact form for getting in touch?<br />Crunchbase&amp;nbsp;(x-crunchbase) - Is there a Crunchbase profile for an API or its company?<br />Dedicated plans pricing page&amp;nbsp;(x-dedicated-plans--pricing-page)<br />Deprecation policy&amp;nbsp;(x-deprecation-policy) - Is there a page dedicated to deprecation of APIs?<br />Developer Showcase&amp;nbsp;(x--developer-showcase) - Is there a page that showcases API developers?<br />Documentation&amp;nbsp;(x-documentation) - Where is the documentation for an API?<br />Drupal&amp;nbsp;(x-drupal) - Is there Drupal code, SDK, or modules available for an API?<br />Email&amp;nbsp;(x-email) - Is an email address available for a platform?<br />Embeddable page&amp;nbsp;(x-embeddable-page) - Is there a page of embeddable tools available for a platform?<br />Error response codes&amp;nbsp;(x-error-response-codes) - Is there a listing or page dedicated to API error responses?<br />Events&amp;nbsp;(x-events) - Is there a calendar of events related to platform operations?<br />Facebook&amp;nbsp;(x-facebook) - Is there a Facebook page available for an API?<br />Faq&amp;nbsp;(x-faq) - Is there an FAQ section available for the platform?<br />Forum&amp;nbsp;(x-forum) - Does a provider have a forum for support and asynchronous conversations?<br />Forum rss&amp;nbsp;(x-forum-rss) - If there is a forum, does it have an RSS feed?<br />Getting started&amp;nbsp;(x-getting-started) - Is there a getting started page for an API?<br />Github&amp;nbsp;(x-github) - Does a provider have a Github account for the API or company?<br />Glossary&amp;nbsp;(x-glossary) - Is there a glossary of terms available for a platform?<br />Heroku&amp;nbsp;(x-heroku) - Are there Heroku SDKs, or deployment solutions?<br />How-To Guides&amp;nbsp;(x-howto-guides) - Does a provider offer how-to guides as part of operations?<br />Interactive documentation&amp;nbsp;(x-interactive-documentation) - Is there interactive documentation available as part of operatoins?<br />IoS SDK&amp;nbsp;(x-ios-sdk) - Is there an IoS SDK for Objective-C or Swift?<br />Issues&amp;nbsp;(x-issues) - Is there an issue management page or repo for the platform?<br />Java&amp;nbsp;SDK (x-java) - Is there a Java SDK for the platform?<br />JavaScript API&amp;nbsp;(x-javascript-api) - Is there a JavaScript SDK available for a platform?<br />Joomla&amp;nbsp;(x-joomla) - Is there Joomla plug for the platform?<br />Knowledgebase&amp;nbsp;(x-knowledgebase) - Is there a knowledgebase for the platform?<br />Labs&amp;nbsp;(x-labs) - Is there a labs environment for the API platform?<br />Licensing (x-licensing) - Is there licensing for the API, schema, and code involved?<br />Message Center&amp;nbsp;(x-message-center) - Is there a messaging center available for developers?<br />Mobile Overview&amp;nbsp;(x-mobile-overview) - Is there a section or page dedicated to mobile applications?<br />Node.js&amp;nbsp;(x-nodejs) - Is there a Node.js SDK available for the API?<br />Oauth Scopes&amp;nbsp;(x-oauth-scopes) - Does a provider offer details on the available OAuth scopes?<br />Openapi spec&amp;nbsp;(x-openapi-spec) - Is there an OpenAPI available for the API?<br />Overview&amp;nbsp;(x-overview) - Does a platform have a simple, concise description of what they do?<br />Paid support plans&amp;nbsp;(x-paid-support-plans) - Are there paid support plans available for a platform?<br />Postman Collections (x-postman) - Are there any Postman Collections available?<br />Partner&amp;nbsp;(x-partner) - Is there a partner program available as part of API operations?<br />Phone&amp;nbsp;(x-phone) - Does a provider publish a phone number?<br />PHP SDK&amp;nbsp;(x-php) - Is there a PHP SDK available for an API?<br />Privacy Policy&amp;nbsp;(x-privacy-policy-page) - Does a platform have a privacy policy?<br />PubSub&amp;nbsp;(x-pubsubhubbub) - Does a platform provide a PubSub feed?<br />Python SDK&amp;nbsp;(x-python) - Is there a Python SDK for an API?<br />Rate Limiting&amp;nbsp;(x-rate-limiting) - Does a platform provide information on API rate limiting?<br />Real Time Solutions&amp;nbsp;(x-real-time-page) - Are there real-time solutions available as part of the platform?<br />Road Map&amp;nbsp;(x-road-map) - Does a provider share their roadmap publicly?<br />Ruby SDK&amp;nbsp;(x-ruby) - Is there a Ruby SDK available for the API?<br />Sandbox&amp;nbsp;(x-sandbox) - Is there a sandbox for the platform?<br />Security&amp;nbsp;(x-security) - Does a platform provide an overview of security practices?<br />Self-Service registration&amp;nbsp;(x-self-service-registration) - Does a platform allow for self-service registration?<br />Service Level Agreement&amp;nbsp;(x-service-level-agreement) - Is an SLA available as part of platform integration?<br />Slideshare&amp;nbsp;(x-slideshare) - Does a provider publish talks on Slideshare?<br />Stack Overflow&amp;nbsp;(x-stack-overflow) - Does a provider actively use Stack Overflow as part of platform operations?<br />Starter Projects&amp;nbsp;(x-starter-projects) - Are there start projects available as part of platform operations?<br />Status Dashboard&amp;nbsp;(x-status-dashboard) - Is there a status dashboard available as part of API operations.<br />Status History&amp;nbsp;(x-status-history) - Can you get at the history involved with API operations?<br />Status RSS&amp;nbsp;(x-status-rss) - Is there an RSS feed available as part of the platform status dashboard?<br />Support Page&amp;nbsp;(x-support-overview-page) - Is there a page or section dedicated to support?<br />Terms of Service&amp;nbsp;(x-terms-of-service-page) - Is there a terms of service page?<br />Ticket System&amp;nbsp;(x-ticket-system) - Does a platform offer a ticketing system for support?<br />Tour&amp;nbsp;(x-tour) - Is a tour available to walk a developer through platforms operations?<br />Trademarks&amp;nbsp;(x-trademarks) - Is there details about trademarks, and how to use them?<br />Twitter&amp;nbsp;(x-twitter) - Does a platform have a Twitter account dedicated to the API or even company?<br />Videos&amp;nbsp;(x-videos) - Is there a page, YouTube, or other account dedicated to videos about the API?<br />Webhooks&amp;nbsp;(x-webhook) - Are there webhooks available for an API?<br />Webinars&amp;nbsp;(x-webinars) - Does an API conduct webinars to support operations?<br />White papers&amp;nbsp;(x-white-papers) - Does a platform provide white papers as part of operations?<br />Widgets&amp;nbsp;(x-widgets) - Are there widgets available for use as part of integration?<br />Wordpress&amp;nbsp;(x-wordpress) - Are there WordPress plugins or code available?<br /><br />There are hundreds of other building blocks I track on as part of API operations, but this list represents the most common, that often have dedicated URLs available for exploring, and have the most significant impact on API integrations. You&#39;ll notice there is an x- representation for each one, which I use as part of APIs.json indexes for all the APIs I track on. Some of these signal types are machine readable like OpenAPIs or a Blog RSS, with others machine readable because there is another API behind, like Twitter or Github, but most of them are just static pages, where a human (me) can visit and stay in tune with signals.<br />I have two primary objectives with this work: 1) identify the important signals, that impact integration, and will keep me and my readers in tune with what is going on, and 2) identify the common channels, and help move the more important ones to be machine-readable, allowing us to scale the monitoring of important signals like pricing and terms of service. My API Stack research provides me wit a nice listing of APIs, as well as more individualized stacks like Microsoft, Google, Microsoft, and Facebook, or even industry stacks like SMS, Email, and News. It also provides me with a wealth of signals we can tune into better understand the scope and health of the API sector, and any individual business vertical that is being touched by APIs.<br /><br />m regularly running&amp;nbsp;into a growing number of signals that tune me into what is going on with each API provider, or service provider.&amp;nbsp;<br />Here are the almost 100 types of signals I am tuning into as I keep an eye on the world of APIs, each contributing to my unique awareness of what is going on with everything API.<br /><br />Account Settings&amp;nbsp;(x-account-settings) - Does an API provider allow me to manage the settings for my account?<br />Android SDK&amp;nbsp;(x-android-sdk) - Is there an Android SDK present?<br />Angular&amp;nbsp;(x-angularjs)&amp;nbsp;- Is there an Angular SDK present?<br />API Explorer&amp;nbsp;(x-api-explorer) - Does a provider have an interactive API explorer?<br />Application Gallery&amp;nbsp;(x-application-gallery) - Is there a gallery of applications build on an API available?<br />Application Manager&amp;nbsp;(x-application-manager) - Does the platform allow me to management my APIs?<br />Authentication Overview&amp;nbsp;(x-authentication-overview) - Is there a page dedicated to educating users about authentication?<br />Base URL for API&amp;nbsp;(x-base-url-for-api) - What is the base URL(s) for the API?<br />Base URL for Portal&amp;nbsp;(x-base-url-for-portal) - What is the base URL for the developer portal?<br />Best Practices&amp;nbsp;(x-best-practices) - Is there a page outlining best practices for integrating with an API?<br />Billing history&amp;nbsp;(x-billing-history) - As a developer, can I get at the billing history for my API consumption?<br />Blog&amp;nbsp;(x-blog) - Does the API have a blog, either at the company level, but preferably at the API and developer level as well?<br />Blog RSS Feed&amp;nbsp;(x-blog-rss-feed) - Is there an RSS feed for the blog?<br />Branding page&amp;nbsp;(x-branding-page) - Is there a dedicated branding page as part of API operations?<br />Buttons&amp;nbsp;(x-buttons) - Are there any embeddable buttons available as part of API operations.<br />C# SDK&amp;nbsp;(x-c-sharp) -&amp;nbsp;Is there a C# SDK present?<br />Case Studies&amp;nbsp;(x-case-studies) - Are there case studies available, showcasing implementations on top of an API?<br />Change Log&amp;nbsp;(x-change-log) - Does a platform provide a change log?<br />Chrome Extension&amp;nbsp;(x-chrome-extension) - Does a platform offer up open-source or white label chrome extensions?<br />Code builder&amp;nbsp;(x-code-builder) - Is there some sort of code generator or builder as part of platform operations?<br />Code page&amp;nbsp;(x-code-page) - Is there a dedicated code page for all the samples, libraries, and SDKs?<br />Command Line Interface&amp;nbsp;(x-command-line-interface) - Is there a command line interface (CLI) alongside the API?<br />Community Supported Libraries&amp;nbsp;(x-community-supported-libraries) - Is there a page or section dedicated to code that is developed by the API and developer community?<br />Compliance&amp;nbsp;(x-compliance) - Is there a section dedicated to industry compliance?<br />Contact form&amp;nbsp;(x-contact-form) - Is there a contact form for getting in touch?<br />Crunchbase&amp;nbsp;(x-crunchbase) - Is there a Crunchbase profile for an API or its company?<br />Dedicated plans pricing page&amp;nbsp;(x-dedicated-plans--pricing-page)<br />Deprecation policy&amp;nbsp;(x-deprecation-policy) - Is there a page dedicated to deprecation of APIs?<br />Developer Showcase&amp;nbsp;(x--developer-showcase) - Is there a page that showcases API developers?<br />Documentation&amp;nbsp;(x-documentation) - Where is the documentation for an API?<br />Drupal&amp;nbsp;(x-drupal) - Is there Drupal code, SDK, or modules available for an API?<br />Email&amp;nbsp;(x-email) - Is an email address available for a platform?<br />Embeddable page&amp;nbsp;(x-embeddable-page) - Is there a page of embeddable tools available for a platform?<br />Error response codes&amp;nbsp;(x-error-response-codes) - Is there a listing or page dedicated to API error responses?<br />Events&amp;nbsp;(x-events) - Is there a calendar of events related to platform operations?<br />Facebook&amp;nbsp;(x-facebook) - Is there a Facebook page available for an API?<br />Faq&amp;nbsp;(x-faq) - Is there an FAQ section available for the platform?<br />Forum&amp;nbsp;(x-forum) - Does a provider have a forum for support and asynchronous conversations?<br />Forum rss&amp;nbsp;(x-forum-rss) - If there is a forum, does it have an RSS feed?<br />Getting started&amp;nbsp;(x-getting-started) - Is there a getting started page for an API?<br />Github&amp;nbsp;(x-github) - Does a provider have a Github account for the API or company?<br />Glossary&amp;nbsp;(x-glossary) - Is there a glossary of terms available for a platform?<br />Heroku&amp;nbsp;(x-heroku) - Are there Heroku SDKs, or deployment solutions?<br />How-To Guides&amp;nbsp;(x-howto-guides) - Does a provider offer how-to guides as part of operations?<br />Interactive documentation&amp;nbsp;(x-interactive-documentation) - Is there interactive documentation available as part of operatoins?<br />IoS SDK&amp;nbsp;(x-ios-sdk) - Is there an IoS SDK for Objective-C or Swift?<br />Issues&amp;nbsp;(x-issues) - Is there an issue management page or repo for the platform?<br />Java&amp;nbsp;SDK (x-java) - Is there a Java SDK for the platform?<br />JavaScript API&amp;nbsp;(x-javascript-api) - Is there a JavaScript SDK available for a platform?<br />Joomla&amp;nbsp;(x-joomla) - Is there Joomla plug for the platform?<br />Knowledgebase&amp;nbsp;(x-knowledgebase) - Is there a knowledgebase for the platform?<br />Labs&amp;nbsp;(x-labs) - Is there a labs environment for the API platform?<br />Licensing (x-licensing) - Is there licensing for the API, schema, and code involved?<br />Message Center&amp;nbsp;(x-message-center) - Is there a messaging center available for developers?<br />Mobile Overview&amp;nbsp;(x-mobile-overview) - Is there a section or page dedicated to mobile applications?<br />Node.js&amp;nbsp;(x-nodejs) - Is there a Node.js SDK available for the API?<br />Oauth Scopes&amp;nbsp;(x-oauth-scopes) - Does a provider offer details on the available OAuth scopes?<br />Openapi spec&amp;nbsp;(x-openapi-spec) - Is there an OpenAPI available for the API?<br />Overview&amp;nbsp;(x-overview) - Does a platform have a simple, concise description of what they do?<br />Paid support plans&amp;nbsp;(x-paid-support-plans) - Are there paid support plans available for a platform?<br />Postman Collections (x-postman) - Are there any Postman Collections available?<br />Partner&amp;nbsp;(x-partner) - Is there a partner program available as part of API operations?<br />Phone&amp;nbsp;(x-phone) - Does a provider publish a phone number?<br />PHP SDK&amp;nbsp;(x-php) - Is there a PHP SDK available for an API?<br />Privacy Policy&amp;nbsp;(x-privacy-policy-page) - Does a platform have a privacy policy?<br />PubSub&amp;nbsp;(x-pubsubhubbub) - Does a platform provide a PubSub feed?<br />Python SDK&amp;nbsp;(x-python) - Is there a Python SDK for an API?<br />Rate Limiting&amp;nbsp;(x-rate-limiting) - Does a platform provide information on API rate limiting?<br />Real Time Solutions&amp;nbsp;(x-real-time-page) - Are there real-time solutions available as part of the platform?<br />Road Map&amp;nbsp;(x-road-map) - Does a provider share their roadmap publicly?<br />Ruby SDK&amp;nbsp;(x-ruby) - Is there a Ruby SDK available for the API?<br />Sandbox&amp;nbsp;(x-sandbox) - Is there a sandbox for the platform?<br />Security&amp;nbsp;(x-security) - Does a platform provide an overview of security practices?<br />Self-Service registration&amp;nbsp;(x-self-service-registration) - Does a platform allow for self-service registration?<br />Service Level Agreement&amp;nbsp;(x-service-level-agreement) - Is an SLA available as part of platform integration?<br />Slideshare&amp;nbsp;(x-slideshare) - Does a provider publish talks on Slideshare?<br />Stack Overflow&amp;nbsp;(x-stack-overflow) - Does a provider actively use Stack Overflow as part of platform operations?<br />Starter Projects&amp;nbsp;(x-starter-projects) - Are there start projects available as part of platform operations?<br />Status Dashboard&amp;nbsp;(x-status-dashboard) - Is there a status dashboard available as part of API operations.<br />Status History&amp;nbsp;(x-status-history) - Can you get at the history involved with API operations?<br />Status RSS&amp;nbsp;(x-status-rss) - Is there an RSS feed available as part of the platform status dashboard?<br />Support Page&amp;nbsp;(x-support-overview-page) - Is there a page or section dedicated to support?<br />Terms of Service&amp;nbsp;(x-terms-of-service-page) - Is there a terms of service page?<br />Ticket System&amp;nbsp;(x-ticket-system) - Does a platform offer a ticketing system for support?<br />Tour&amp;nbsp;(x-tour) - Is a tour available to walk a developer through platforms operations?<br />Trademarks&amp;nbsp;(x-trademarks) - Is there details about trademarks, and how to use them?<br />Twitter&amp;nbsp;(x-twitter) - Does a platform have a Twitter account dedicated to the API or even company?<br />Videos&amp;nbsp;(x-videos) - Is there a page, YouTube, or other account dedicated to videos about the API?<br />Webhooks&amp;nbsp;(x-webhook) - Are there webhooks available for an API?<br />Webinars&amp;nbsp;(x-webinars) - Does an API conduct webinars to support operations?<br />White papers&amp;nbsp;(x-white-papers) - Does a platform provide white papers as part of operations?<br />Widgets&amp;nbsp;(x-widgets) - Are there widgets available for use as part of integration?<br />Wordpress&amp;nbsp;(x-wordpress) - Are there WordPress plugins or code available?<br /><br />There are hundreds of other building blocks I track on as part of API operations, but this list represents the most common, that often have dedicated URLs available for exploring, and have the most significant impact on API integrations. Youll notice there is an x- representation for each one, which I use as part of APIs.json indexes for all the APIs I track on. Some of these signal types are machine readable like OpenAPIs or a Blog RSS, with others machine readable because there is another API behind, like Twitter or Github, but most of them are just static pages, where a human (me) can visit and stay in tune with signals.<br />I have two primary objectives with this work: 1) identify the important signals, that impact integration, and will keep me and my readers in tune with what is going on, and 2) identify the common channels, and help move the more important ones to be machine-readable, allowing us to scale the monitoring of important signals like pricing and terms of service. My API Stack research provides me wit a nice listing of APIs, as well as more individualized stacks like Microsoft, Google, Microsoft, and Facebook, or even industry stacks like SMS, Email, and News. It also provides me with a wealth of signals we can tune into better understand the scope and health of the API sector, and any individual business vertical that is being touched by APIs.<br /><br />ll notice there is an x- representation for each one, which I use as part of APIs.json indexes for all the APIs I track on. Some of these signal types are machine readable like OpenAPIs or a Blog RSS, with others machine readable because there is another API behind, like Twitter or Github, but most of them are just static pages, where a human (me) can visit and stay in tune with signals.<br />I have two primary objectives with this work: 1) identify the important signals, that impact integration, and will keep me and my readers in tune with what is going on, and 2) identify the common channels, and help move the more important ones to be machine-readable, allowing us to scale the monitoring of important signals like pricing and terms of service. My API Stack research provides me wit a nice listing of APIs, as well as more individualized stacks like Microsoft, Google, Microsoft, and Facebook, or even industry stacks like SMS, Email, and News. It also provides me with a wealth of signals we can tune into better understand the scope and health of the API sector, and any individual business vertical that is being touched by APIs.<br /><br />",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-signals.png"
  },
  {
  "title": "Participating In The OpenAPI Feedback Loop",
  "date": "08 May 2017",
  "body": "<br />When you are an individual in a sea of tech giants, and startups who are moving technical conversations forward, it can be easy to just sit back, stay quiet, and go with the flow. As a single person, it feels like our voice will not be heard, or even listened to when it comes to moving forward standards and specifications like the OpenAPI, but in reality, every single voice that speaks up is important, and has the potential to bring a new perspective regarding what the future should hold when it comes to the roadmap.<br />If you are building any services or tooling that supports version 2.0 of the OpenAPI specification and will be looking to evolve your services or tooling to support version 3.0, you need to make sure and share your views. No matter where you are in the development of your tooling, planning or even deployment, you should make sure you gather and share your thoughts with the OpenAPI Initiative (OAI)--they have a form for tooling developers to submit their feedback and details about what you are up to.<br />Whether or not you submit your&amp;nbsp;OAI tooling and service plans via the form they provide, you should be also telling your story on your blog. You dont have to have a big audience for your blog, you just need to make sure and publicly share the details of your tools and services, and your perspective of both the OpenAPI 2.0 and 3.0 versions. If you tell your story on your&amp;nbsp;blog, and Tweet or email a link to me, I may even craft my own story based on your perspective, and publish to API Evangelist, and put in my&amp;nbsp;OpenAPI Toolbox. Storytelling around the specification plays an important role in helping evolve the specification, as well as help onboard other folks to the API specification format.<br />As the only individual in the OAI, I can testify that I often feel like my voice is too small to make a difference. This is not true. Whether it&#39;s via the Open API Github repo, directly via OpenAPI tooling feedback forms, or even via our blogs on the open Internet, your perspective on OpenAPI matters. Makes sure it gets heard--if you don&#39;t step up and share via one of these open channels, you are guaranteeing that you won&#39;t be heard, and your views definitely will not matter. Make sure you step up, there is too much at stake when it comes to API definitions right now.&amp;nbsp;t have to have a big audience for your blog, you just need to make sure and publicly share the details of your tools and services, and your perspective of both the OpenAPI 2.0 and 3.0 versions. If you tell your story on your&amp;nbsp;blog, and Tweet or email a link to me, I may even craft my own story based on your perspective, and publish to API Evangelist, and put in my&amp;nbsp;OpenAPI Toolbox. Storytelling around the specification plays an important role in helping evolve the specification, as well as help onboard other folks to the API specification format.<br />As the only individual in the OAI, I can testify that I often feel like my voice is too small to make a difference. This is not true. Whether its via the Open API Github repo, directly via OpenAPI tooling feedback forms, or even via our blogs on the open Internet, your perspective on OpenAPI matters. Makes sure it gets heard--if you don&#39;t step up and share via one of these open channels, you are guaranteeing that you won&#39;t be heard, and your views definitely will not matter. Make sure you step up, there is too much at stake when it comes to API definitions right now.&amp;nbsp;s via the Open API Github repo, directly via OpenAPI tooling feedback forms, or even via our blogs on the open Internet, your perspective on OpenAPI matters. Makes sure it gets heard--if you dont step up and share via one of these open channels, you are guaranteeing that you won&#39;t be heard, and your views definitely will not matter. Make sure you step up, there is too much at stake when it comes to API definitions right now.&amp;nbsp;t step up and share via one of these open channels, you are guaranteeing that you wont be heard, and your views definitely will not matter. Make sure you step up, there is too much at stake when it comes to API definitions right now.&amp;nbsp;t be heard, and your views definitely will not matter. Make sure you step up, there is too much at stake when it comes to API definitions right now.&amp;nbsp;",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/oai_silverbadge_text.png"
  },
  {
  "title": "OpenAPI-Driven Documentation For Your API With ReDoc",
  "date": "08 May 2017",
  "body": "<br />ReDoc is the responsive, three-panel, OpenAPI specification driven documentation for your API that you were looking for. Swagger UI is still reigning king when it comes to API documentation generated using the OpenAPI Spec, but ReDoc provides a simple, attractive, and clean alternative to documentation.<br />ReDoc is deployable to any web page with just two tags--with the resulting documentation looking attractive on both web and mobile devices. Now you can have it all, your API documentation looking good, interactive, and driven by a machine-readable definition that will help you keep everything up to date.<br />All you need to fire up ReDoc is two lines of HTML on your web page:<br /><br />The quickest way to deploy ReDoc is using the CDN step shown above, but they also provide bower or npm solutions, if that is your desire. There is also a Yeoman generator to help you share your OpenAPIs that are central of your web application operation, something we will write about in future posts here on the blog.<br />ReDoc leverages a custom HTML tag, and provides you with a handful of attributes for defining, and customizing their documentation, including specurl, scroll-y-offset, suppress-warnings, lazy-rendering, hid-hostname, and expand-responses--providing some quick ways to get exactly what you need, on any web page.<br />There is a handful of APIs who have put ReDocs to use as API documentation for their platform:<br /><br /> Rebilly <br /> Docker Engine <br />Zuora <br />Shopify Draft Orders <br />Discourse <br />APIs.guru <br /><br />There also provide a live demo of ReDoc, allowing you to kick the tires some more before you deploy, and make sure it does what you will need it to before you fork.<br />ReDoc provides a simple, OpenAPI spec compliant way of delivering attractive, interactive, responsive and up to date documentation that can be deployed anywhere, including integration into your existing continuous integration, and API lifecycle. ReDoc reflects a new generation of very modular, plug and play API tooling that can be put to use immediately as part of an OpenAPI Spec-driven web, mobile, and device application development cycle(s).<br />ReDoc is available on Github: https://github.com/Rebilly/ReDoc, as an open source solution brought to you by Rebilly, &amp;ldquo;the worlds first subscription and recurring profit maximization company.s first subscription and recurring profit maximization company.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/api-evangelist/redoc/redoc-demo.png"
  },
  {
  "title": "Quantifying The Data A Company Possesses Using APIs",
  "date": "05 May 2017",
  "body": "<br />Profiling APIs always provides me with a nice bulleted list of what a company does or doesnt do. In my&amp;nbsp;work as the API Evangelist, I can read marketing and communications to find out what a company does, but I find that profiling their APIs provides a more honest view of what is going on. The lack of a public API always sets the tone for how I view what a company is up to, but when there is a public API, profiling it always provides a nice distillation of what a company does, in a nice bulleted list I can share with my readers.<br />When I profile the APIs of companies like Amazon, Google, and Microsoft, I come out of it with a nice bulleted list of what is possible, but when I go even further, making sure each API profile has accompanying&amp;nbsp;schema definitions, a nice list of what data company&amp;nbsp;begins to emerge. When I profile an API using OpenAPI I always start by profiling the request layer of an API, the paths, parameters, and other elements. Next, I get to work describing the schema definitions of data used in these requests, as well as the structure of the responses--providing me with a nice bulleted list of the data that a company has.&amp;nbsp;<br />You can see this in action with my Facebook API profiling work. There is a bulleted list of what is possible (API definition), as well as what data is sent, received, and stored (API schema). This work provides me with a&amp;nbsp;nice look at the data Facebook gathers and stores about everyone. It is FAR from a complete picture of the data Facebook gathers, but it does provide us with a snapshot to consider, as well as a model we can ask Facebook to share more schema about the data points that they track. API and data specification formats like JSON Schema, and OpenAPI provides us with a toolbox to help us quantify and share the details of what data a company has, and what is possible when it comes to using this data in web, mobile, and device based applications.<br />I fully aware of the boldness of this statement, but I feel that ALL companies should have a public API definition, including a catalog of the schema for data in use. Ideally, this schema would employ commonly used standards like Schema.org, but just having a machine-readable catalog of the schema would go a long way to helping pull back the curtain of how companies are using our data. I am not asking for companies to make data public, I am asking for companies to make the schema for this data public, showing what they track and store about us. I know many people view this as intellectual property, but in an increasingly un/insecure online world of digital privacy, we are going to have to begin pulling back the curtain a little bit, otherwise, a rich environment for exploitation and abuse will continue to develop.t do. In my&amp;nbsp;work as the API Evangelist, I can read marketing and communications to find out what a company does, but I find that profiling their APIs provides a more honest view of what is going on. The lack of a public API always sets the tone for how I view what a company is up to, but when there is a public API, profiling it always provides a nice distillation of what a company does, in a nice bulleted list I can share with my readers.<br />When I profile the APIs of companies like Amazon, Google, and Microsoft, I come out of it with a nice bulleted list of what is possible, but when I go even further, making sure each API profile has accompanying&amp;nbsp;schema definitions, a nice list of what data company&amp;nbsp;begins to emerge. When I profile an API using OpenAPI I always start by profiling the request layer of an API, the paths, parameters, and other elements. Next, I get to work describing the schema definitions of data used in these requests, as well as the structure of the responses--providing me with a nice bulleted list of the data that a company has.&amp;nbsp;<br />You can see this in action with my Facebook API profiling work. There is a bulleted list of what is possible (API definition), as well as what data is sent, received, and stored (API schema). This work provides me with a&amp;nbsp;nice look at the data Facebook gathers and stores about everyone. It is FAR from a complete picture of the data Facebook gathers, but it does provide us with a snapshot to consider, as well as a model we can ask Facebook to share more schema about the data points that they track. API and data specification formats like JSON Schema, and OpenAPI provides us with a toolbox to help us quantify and share the details of what data a company has, and what is possible when it comes to using this data in web, mobile, and device based applications.<br />I fully aware of the boldness of this statement, but I feel that ALL companies should have a public API definition, including a catalog of the schema for data in use. Ideally, this schema would employ commonly used standards like Schema.org, but just having a machine-readable catalog of the schema would go a long way to helping pull back the curtain of how companies are using our data. I am not asking for companies to make data public, I am asking for companies to make the schema for this data public, showing what they track and store about us. I know many people view this as intellectual property, but in an increasingly un/insecure online world of digital privacy, we are going to have to begin pulling back the curtain a little bit, otherwise, a rich environment for exploitation and abuse will continue to develop.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/facebook_schema_feed_files.png"
  },
  {
  "title": "Quantifying The API Landscape Across Amazon, Google, and Microsoft",
  "date": "01 May 2017",
  "body": "<br />I work to develop OpenAPI definitions for 3rd party APIs because it helps me understand what is being offered by a company. Even when Im able to autogenerate an OpenAPI for an API, or come across an existing one, I still spend time going through the finer details of what an API does, or doesn&#39;t do. I find the process to be one of the best ways to learn about an API, stopping short of actually integrating with it.<br />Over the last couple of months, I&#39;ve aggregated, generated, and crafted OpenAPI and APIs.json definitions for the top three cloud API providers out there. I wanted to be able to easily see the surface area for as many of the APIs as I could find for these three companies:<br /><br />Amazon - 2222 paths (or methods) across&amp;nbsp;65 of the Amazon Web Services - you can find the APIs.json, and OpenAPI behind in the Github repository.<br />Google - 2089 paths across&amp;nbsp;75 of the Google services I&#39;m profiling&amp;nbsp;- you can find the APIs.json, and OpenAPI behind in the Github repository.<br />Microsoft - 2109 paths across&amp;nbsp;41 of the Microsoft and Azure services.&amp;nbsp;- you can find the APIs.json, and OpenAPI behind in the Github repository.<br /><br />I learned a lot about all three providers in the process. I filled my notebook with stories about their approaches. I also ended up with three separate Github repositories with APIs.json&amp;nbsp;indexed OpenAPI definitions for as many of their APIs as I could process. They are far from complete, but I feel like they paint a pretty interesting picture of the API landscape across these three tech giants.<br />So far there are 6,420 paths across&amp;nbsp;181 individual services. I&#39;m still working on the summary and tags for each path, which are the two most important elements for me. I think the list of 6,420 actions you can take via an API across three of the biggest cloud providers gives us a lot of insight into what these companies are up to. There are a lot of valuable resources in there, ranging from cloud to machine learning. These three projects are an going part of my API stack research, and I will be adding to them as I have time. I&#39;m looking to keep developing simple JavaScript and Liquid tooling on top of the repos, and YAML data behind--further helping me make sense of Amazon, Google, and Microsoft APIs.&amp;nbsp;m able to autogenerate an OpenAPI for an API, or come across an existing one, I still spend time going through the finer details of what an API does, or doesnt do. I find the process to be one of the best ways to learn about an API, stopping short of actually integrating with it.<br />Over the last couple of months, I&#39;ve aggregated, generated, and crafted OpenAPI and APIs.json definitions for the top three cloud API providers out there. I wanted to be able to easily see the surface area for as many of the APIs as I could find for these three companies:<br /><br />Amazon - 2222 paths (or methods) across&amp;nbsp;65 of the Amazon Web Services - you can find the APIs.json, and OpenAPI behind in the Github repository.<br />Google - 2089 paths across&amp;nbsp;75 of the Google services I&#39;m profiling&amp;nbsp;- you can find the APIs.json, and OpenAPI behind in the Github repository.<br />Microsoft - 2109 paths across&amp;nbsp;41 of the Microsoft and Azure services.&amp;nbsp;- you can find the APIs.json, and OpenAPI behind in the Github repository.<br /><br />I learned a lot about all three providers in the process. I filled my notebook with stories about their approaches. I also ended up with three separate Github repositories with APIs.json&amp;nbsp;indexed OpenAPI definitions for as many of their APIs as I could process. They are far from complete, but I feel like they paint a pretty interesting picture of the API landscape across these three tech giants.<br />So far there are 6,420 paths across&amp;nbsp;181 individual services. I&#39;m still working on the summary and tags for each path, which are the two most important elements for me. I think the list of 6,420 actions you can take via an API across three of the biggest cloud providers gives us a lot of insight into what these companies are up to. There are a lot of valuable resources in there, ranging from cloud to machine learning. These three projects are an going part of my API stack research, and I will be adding to them as I have time. I&#39;m looking to keep developing simple JavaScript and Liquid tooling on top of the repos, and YAML data behind--further helping me make sense of Amazon, Google, and Microsoft APIs.&amp;nbsp;t do. I find the process to be one of the best ways to learn about an API, stopping short of actually integrating with it.<br />Over the last couple of months, Ive aggregated, generated, and crafted OpenAPI and APIs.json definitions for the top three cloud API providers out there. I wanted to be able to easily see the surface area for as many of the APIs as I could find for these three companies:<br /><br />Amazon - 2222 paths (or methods) across&amp;nbsp;65 of the Amazon Web Services - you can find the APIs.json, and OpenAPI behind in the Github repository.<br />Google - 2089 paths across&amp;nbsp;75 of the Google services I&#39;m profiling&amp;nbsp;- you can find the APIs.json, and OpenAPI behind in the Github repository.<br />Microsoft - 2109 paths across&amp;nbsp;41 of the Microsoft and Azure services.&amp;nbsp;- you can find the APIs.json, and OpenAPI behind in the Github repository.<br /><br />I learned a lot about all three providers in the process. I filled my notebook with stories about their approaches. I also ended up with three separate Github repositories with APIs.json&amp;nbsp;indexed OpenAPI definitions for as many of their APIs as I could process. They are far from complete, but I feel like they paint a pretty interesting picture of the API landscape across these three tech giants.<br />So far there are 6,420 paths across&amp;nbsp;181 individual services. I&#39;m still working on the summary and tags for each path, which are the two most important elements for me. I think the list of 6,420 actions you can take via an API across three of the biggest cloud providers gives us a lot of insight into what these companies are up to. There are a lot of valuable resources in there, ranging from cloud to machine learning. These three projects are an going part of my API stack research, and I will be adding to them as I have time. I&#39;m looking to keep developing simple JavaScript and Liquid tooling on top of the repos, and YAML data behind--further helping me make sense of Amazon, Google, and Microsoft APIs.&amp;nbsp;ve aggregated, generated, and crafted OpenAPI and APIs.json definitions for the top three cloud API providers out there. I wanted to be able to easily see the surface area for as many of the APIs as I could find for these three companies:<br /><br />Amazon - 2222 paths (or methods) across&amp;nbsp;65 of the Amazon Web Services - you can find the APIs.json, and OpenAPI behind in the Github repository.<br />Google - 2089 paths across&amp;nbsp;75 of the Google services Im profiling&amp;nbsp;- you can find the APIs.json, and OpenAPI behind in the Github repository.<br />Microsoft - 2109 paths across&amp;nbsp;41 of the Microsoft and Azure services.&amp;nbsp;- you can find the APIs.json, and OpenAPI behind in the Github repository.<br /><br />I learned a lot about all three providers in the process. I filled my notebook with stories about their approaches. I also ended up with three separate Github repositories with APIs.json&amp;nbsp;indexed OpenAPI definitions for as many of their APIs as I could process. They are far from complete, but I feel like they paint a pretty interesting picture of the API landscape across these three tech giants.<br />So far there are 6,420 paths across&amp;nbsp;181 individual services. I&#39;m still working on the summary and tags for each path, which are the two most important elements for me. I think the list of 6,420 actions you can take via an API across three of the biggest cloud providers gives us a lot of insight into what these companies are up to. There are a lot of valuable resources in there, ranging from cloud to machine learning. These three projects are an going part of my API stack research, and I will be adding to them as I have time. I&#39;m looking to keep developing simple JavaScript and Liquid tooling on top of the repos, and YAML data behind--further helping me make sense of Amazon, Google, and Microsoft APIs.&amp;nbsp;m profiling&amp;nbsp;- you can find the APIs.json, and OpenAPI behind in the Github repository.<br />Microsoft - 2109 paths across&amp;nbsp;41 of the Microsoft and Azure services.&amp;nbsp;- you can find the APIs.json, and OpenAPI behind in the Github repository.<br /><br />I learned a lot about all three providers in the process. I filled my notebook with stories about their approaches. I also ended up with three separate Github repositories with APIs.json&amp;nbsp;indexed OpenAPI definitions for as many of their APIs as I could process. They are far from complete, but I feel like they paint a pretty interesting picture of the API landscape across these three tech giants.<br />So far there are 6,420 paths across&amp;nbsp;181 individual services. Im still working on the summary and tags for each path, which are the two most important elements for me. I think the list of 6,420 actions you can take via an API across three of the biggest cloud providers gives us a lot of insight into what these companies are up to. There are a lot of valuable resources in there, ranging from cloud to machine learning. These three projects are an going part of my API stack research, and I will be adding to them as I have time. I&#39;m looking to keep developing simple JavaScript and Liquid tooling on top of the repos, and YAML data behind--further helping me make sense of Amazon, Google, and Microsoft APIs.&amp;nbsp;m still working on the summary and tags for each path, which are the two most important elements for me. I think the list of 6,420 actions you can take via an API across three of the biggest cloud providers gives us a lot of insight into what these companies are up to. There are a lot of valuable resources in there, ranging from cloud to machine learning. These three projects are an going part of my API stack research, and I will be adding to them as I have time. Im looking to keep developing simple JavaScript and Liquid tooling on top of the repos, and YAML data behind--further helping me make sense of Amazon, Google, and Microsoft APIs.&amp;nbsp;m looking to keep developing simple JavaScript and Liquid tooling on top of the repos, and YAML data behind--further helping me make sense of Amazon, Google, and Microsoft APIs.&amp;nbsp;",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/microsoft_graph_api_surface.png"
  },
  {
  "title": "Expressing What An API Does As Well As What Is Possible Using OpenAPI",
  "date": "01 May 2017",
  "body": "<br />I am working to update my OpenAPI definitions for AWS, Google, and Microsoft using some other OpenAPIs Ive discovered on Github. When a new OpenAPI has entirely new paths available, I just insert them, but when it has an existing path I have to think more critically about what is next. Sometimes I dismiss the metadata about the API path as incomplete or lower quality than the one I have already. Other times the content is actually more superior than mine, and I incorporate it into my work. Now I&#39;m also finding that in some cases I want to keep my representation, as well as the one I discovered, side by side--both having value.<br />This is one reason I&#39;m not 100% sold on the fact that just API providers should be crafting their own OpenAPis--sure, the API space would be waaaaaay better if ALL API providers had machine readable OpenAPIs for all their services, but I would want it to end here. You see, API providers are good (sometimes) at defining what their API does, but they often suck at telling you what is possible--which is why they are doing APIs. I have a lot of people who push back on me creating OpenAPIs for popular APIs, telling me that API providers should be the ones doing the hard work, otherwise it doesn&#39;t matter. I&#39;m just not sold that this is the case, and there is an opportunity for evolving the definition&amp;nbsp;of an API by external entities using OpenAPI.<br />To help me explore this idea, and push the boundaries of how I use OpenAPI in my API storytelling, I wanted to frame this in the context of the Amazon EC2 API, which allows me to deploy a single unit of compute into the cloud using an API, a pretty fundamental component of our digital worlds. To make any call against the Amazon EC2 I send all my calls to a single base URL:<br />ec2.amazonaws.com<br />With this API call I pass in the action I&#39;d like to be taken:<br />?Action=RunInstances<br />Along with this base action parameter, I pass in a handful of other parameters to further define things:<br />&amp;amp;ImageId=ami-60a54009&amp;amp;MaxCount=1&amp;amp;KeyName=my-key-pair&amp;amp;Placement.AvailabilityZone=us-east-1d<br />Amazon has never been known for superior API design, but it gets the job done. With this single API call I can launch a server in the clouds. When I was first able to do this with APIs, is when the light really went on in my head regarding the potential of APIs. However, back to my story on expressing what an API does, as well as what is possible using OpenAPI. AWS has done an OK job at expressing what Amazon EC2 API does, however they suck at expressing what is possible. This is where API consumers like me step up with OpenAPI and provide some alternative representations of what is possible with the highly valuable API.<br />When I define the Amazon EC2 API using the OpenAPI specification I use the following:<br /> swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: The Amazon EC2 service&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: ec2API &amp;nbsp; &amp;nbsp; &amp;nbsp;parameters:&amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;- in: query &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action <br />The AWS API design pattern doesn&#39;t lend itself to reuse&amp;nbsp;when it comes to documentation and storytelling, but I&#39;m always looking for an opportunity to push the boundaries, and I&#39;m able to better outline all available actions, as individual API paths by appending the action parameter to the path:<br /> swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/?Action=RunInstances/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance<br />Now I&#39;m able to describe all 228 actions you can take with the single Amazon EC2 API path as separate paths in any OpenAPI generated API documentation and tooling. I can give them unique summaries, descriptions, and operationId. OpenAPI allows me to describe what is possible with an API, going well beyond what the API provider was able to define. I&#39;ve been using this approach to better quantify the surface area of APIs like Amazon, Flickr, and others who use this pattern for a while now, but as I was looking to update my work, I wanted to take this concept even further.<br />While appending query parameters to the path definition has allowed me to expand how I describe the surface area of an API using OpenAPI, I&#39;d rather keep these parameters defined properly using the OpenAPI specification, and define an alternative way to make the path unique. To do this, I am exploring the usage of #bookmarks, to help make duplicate API paths more unqiue in the eyes of the schema validators, but invisible to the server side of things--something like this:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;ve discovered on Github. When a new OpenAPI has entirely new paths available, I just insert them, but when it has an existing path I have to think more critically about what is next. Sometimes I dismiss the metadata about the API path as incomplete or lower quality than the one I have already. Other times the content is actually more superior than mine, and I incorporate it into my work. Now Im also finding that in some cases I want to keep my representation, as well as the one I discovered, side by side--both having value.<br />This is one reason I&#39;m not 100% sold on the fact that just API providers should be crafting their own OpenAPis--sure, the API space would be waaaaaay better if ALL API providers had machine readable OpenAPIs for all their services, but I would want it to end here. You see, API providers are good (sometimes) at defining what their API does, but they often suck at telling you what is possible--which is why they are doing APIs. I have a lot of people who push back on me creating OpenAPIs for popular APIs, telling me that API providers should be the ones doing the hard work, otherwise it doesn&#39;t matter. I&#39;m just not sold that this is the case, and there is an opportunity for evolving the definition&amp;nbsp;of an API by external entities using OpenAPI.<br />To help me explore this idea, and push the boundaries of how I use OpenAPI in my API storytelling, I wanted to frame this in the context of the Amazon EC2 API, which allows me to deploy a single unit of compute into the cloud using an API, a pretty fundamental component of our digital worlds. To make any call against the Amazon EC2 I send all my calls to a single base URL:<br />ec2.amazonaws.com<br />With this API call I pass in the action I&#39;d like to be taken:<br />?Action=RunInstances<br />Along with this base action parameter, I pass in a handful of other parameters to further define things:<br />&amp;amp;ImageId=ami-60a54009&amp;amp;MaxCount=1&amp;amp;KeyName=my-key-pair&amp;amp;Placement.AvailabilityZone=us-east-1d<br />Amazon has never been known for superior API design, but it gets the job done. With this single API call I can launch a server in the clouds. When I was first able to do this with APIs, is when the light really went on in my head regarding the potential of APIs. However, back to my story on expressing what an API does, as well as what is possible using OpenAPI. AWS has done an OK job at expressing what Amazon EC2 API does, however they suck at expressing what is possible. This is where API consumers like me step up with OpenAPI and provide some alternative representations of what is possible with the highly valuable API.<br />When I define the Amazon EC2 API using the OpenAPI specification I use the following:<br /> swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: The Amazon EC2 service&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: ec2API &amp;nbsp; &amp;nbsp; &amp;nbsp;parameters:&amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;- in: query &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action <br />The AWS API design pattern doesn&#39;t lend itself to reuse&amp;nbsp;when it comes to documentation and storytelling, but I&#39;m always looking for an opportunity to push the boundaries, and I&#39;m able to better outline all available actions, as individual API paths by appending the action parameter to the path:<br /> swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/?Action=RunInstances/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance<br />Now I&#39;m able to describe all 228 actions you can take with the single Amazon EC2 API path as separate paths in any OpenAPI generated API documentation and tooling. I can give them unique summaries, descriptions, and operationId. OpenAPI allows me to describe what is possible with an API, going well beyond what the API provider was able to define. I&#39;ve been using this approach to better quantify the surface area of APIs like Amazon, Flickr, and others who use this pattern for a while now, but as I was looking to update my work, I wanted to take this concept even further.<br />While appending query parameters to the path definition has allowed me to expand how I describe the surface area of an API using OpenAPI, I&#39;d rather keep these parameters defined properly using the OpenAPI specification, and define an alternative way to make the path unique. To do this, I am exploring the usage of #bookmarks, to help make duplicate API paths more unqiue in the eyes of the schema validators, but invisible to the server side of things--something like this:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;m also finding that in some cases I want to keep my representation, as well as the one I discovered, side by side--both having value.<br />This is one reason Im not 100% sold on the fact that just API providers should be crafting their own OpenAPis--sure, the API space would be waaaaaay better if ALL API providers had machine readable OpenAPIs for all their services, but I would want it to end here. You see, API providers are good (sometimes) at defining what their API does, but they often suck at telling you what is possible--which is why they are doing APIs. I have a lot of people who push back on me creating OpenAPIs for popular APIs, telling me that API providers should be the ones doing the hard work, otherwise it doesn&#39;t matter. I&#39;m just not sold that this is the case, and there is an opportunity for evolving the definition&amp;nbsp;of an API by external entities using OpenAPI.<br />To help me explore this idea, and push the boundaries of how I use OpenAPI in my API storytelling, I wanted to frame this in the context of the Amazon EC2 API, which allows me to deploy a single unit of compute into the cloud using an API, a pretty fundamental component of our digital worlds. To make any call against the Amazon EC2 I send all my calls to a single base URL:<br />ec2.amazonaws.com<br />With this API call I pass in the action I&#39;d like to be taken:<br />?Action=RunInstances<br />Along with this base action parameter, I pass in a handful of other parameters to further define things:<br />&amp;amp;ImageId=ami-60a54009&amp;amp;MaxCount=1&amp;amp;KeyName=my-key-pair&amp;amp;Placement.AvailabilityZone=us-east-1d<br />Amazon has never been known for superior API design, but it gets the job done. With this single API call I can launch a server in the clouds. When I was first able to do this with APIs, is when the light really went on in my head regarding the potential of APIs. However, back to my story on expressing what an API does, as well as what is possible using OpenAPI. AWS has done an OK job at expressing what Amazon EC2 API does, however they suck at expressing what is possible. This is where API consumers like me step up with OpenAPI and provide some alternative representations of what is possible with the highly valuable API.<br />When I define the Amazon EC2 API using the OpenAPI specification I use the following:<br /> swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: The Amazon EC2 service&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: ec2API &amp;nbsp; &amp;nbsp; &amp;nbsp;parameters:&amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;- in: query &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action <br />The AWS API design pattern doesn&#39;t lend itself to reuse&amp;nbsp;when it comes to documentation and storytelling, but I&#39;m always looking for an opportunity to push the boundaries, and I&#39;m able to better outline all available actions, as individual API paths by appending the action parameter to the path:<br /> swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/?Action=RunInstances/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance<br />Now I&#39;m able to describe all 228 actions you can take with the single Amazon EC2 API path as separate paths in any OpenAPI generated API documentation and tooling. I can give them unique summaries, descriptions, and operationId. OpenAPI allows me to describe what is possible with an API, going well beyond what the API provider was able to define. I&#39;ve been using this approach to better quantify the surface area of APIs like Amazon, Flickr, and others who use this pattern for a while now, but as I was looking to update my work, I wanted to take this concept even further.<br />While appending query parameters to the path definition has allowed me to expand how I describe the surface area of an API using OpenAPI, I&#39;d rather keep these parameters defined properly using the OpenAPI specification, and define an alternative way to make the path unique. To do this, I am exploring the usage of #bookmarks, to help make duplicate API paths more unqiue in the eyes of the schema validators, but invisible to the server side of things--something like this:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;m not 100% sold on the fact that just API providers should be crafting their own OpenAPis--sure, the API space would be waaaaaay better if ALL API providers had machine readable OpenAPIs for all their services, but I would want it to end here. You see, API providers are good (sometimes) at defining what their API does, but they often suck at telling you what is possible--which is why they are doing APIs. I have a lot of people who push back on me creating OpenAPIs for popular APIs, telling me that API providers should be the ones doing the hard work, otherwise it doesnt matter. I&#39;m just not sold that this is the case, and there is an opportunity for evolving the definition&amp;nbsp;of an API by external entities using OpenAPI.<br />To help me explore this idea, and push the boundaries of how I use OpenAPI in my API storytelling, I wanted to frame this in the context of the Amazon EC2 API, which allows me to deploy a single unit of compute into the cloud using an API, a pretty fundamental component of our digital worlds. To make any call against the Amazon EC2 I send all my calls to a single base URL:<br />ec2.amazonaws.com<br />With this API call I pass in the action I&#39;d like to be taken:<br />?Action=RunInstances<br />Along with this base action parameter, I pass in a handful of other parameters to further define things:<br />&amp;amp;ImageId=ami-60a54009&amp;amp;MaxCount=1&amp;amp;KeyName=my-key-pair&amp;amp;Placement.AvailabilityZone=us-east-1d<br />Amazon has never been known for superior API design, but it gets the job done. With this single API call I can launch a server in the clouds. When I was first able to do this with APIs, is when the light really went on in my head regarding the potential of APIs. However, back to my story on expressing what an API does, as well as what is possible using OpenAPI. AWS has done an OK job at expressing what Amazon EC2 API does, however they suck at expressing what is possible. This is where API consumers like me step up with OpenAPI and provide some alternative representations of what is possible with the highly valuable API.<br />When I define the Amazon EC2 API using the OpenAPI specification I use the following:<br /> swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: The Amazon EC2 service&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: ec2API &amp;nbsp; &amp;nbsp; &amp;nbsp;parameters:&amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;- in: query &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action <br />The AWS API design pattern doesn&#39;t lend itself to reuse&amp;nbsp;when it comes to documentation and storytelling, but I&#39;m always looking for an opportunity to push the boundaries, and I&#39;m able to better outline all available actions, as individual API paths by appending the action parameter to the path:<br /> swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/?Action=RunInstances/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance<br />Now I&#39;m able to describe all 228 actions you can take with the single Amazon EC2 API path as separate paths in any OpenAPI generated API documentation and tooling. I can give them unique summaries, descriptions, and operationId. OpenAPI allows me to describe what is possible with an API, going well beyond what the API provider was able to define. I&#39;ve been using this approach to better quantify the surface area of APIs like Amazon, Flickr, and others who use this pattern for a while now, but as I was looking to update my work, I wanted to take this concept even further.<br />While appending query parameters to the path definition has allowed me to expand how I describe the surface area of an API using OpenAPI, I&#39;d rather keep these parameters defined properly using the OpenAPI specification, and define an alternative way to make the path unique. To do this, I am exploring the usage of #bookmarks, to help make duplicate API paths more unqiue in the eyes of the schema validators, but invisible to the server side of things--something like this:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;t matter. Im just not sold that this is the case, and there is an opportunity for evolving the definition&amp;nbsp;of an API by external entities using OpenAPI.<br />To help me explore this idea, and push the boundaries of how I use OpenAPI in my API storytelling, I wanted to frame this in the context of the Amazon EC2 API, which allows me to deploy a single unit of compute into the cloud using an API, a pretty fundamental component of our digital worlds. To make any call against the Amazon EC2 I send all my calls to a single base URL:<br />ec2.amazonaws.com<br />With this API call I pass in the action I&#39;d like to be taken:<br />?Action=RunInstances<br />Along with this base action parameter, I pass in a handful of other parameters to further define things:<br />&amp;amp;ImageId=ami-60a54009&amp;amp;MaxCount=1&amp;amp;KeyName=my-key-pair&amp;amp;Placement.AvailabilityZone=us-east-1d<br />Amazon has never been known for superior API design, but it gets the job done. With this single API call I can launch a server in the clouds. When I was first able to do this with APIs, is when the light really went on in my head regarding the potential of APIs. However, back to my story on expressing what an API does, as well as what is possible using OpenAPI. AWS has done an OK job at expressing what Amazon EC2 API does, however they suck at expressing what is possible. This is where API consumers like me step up with OpenAPI and provide some alternative representations of what is possible with the highly valuable API.<br />When I define the Amazon EC2 API using the OpenAPI specification I use the following:<br /> swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: The Amazon EC2 service&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: ec2API &amp;nbsp; &amp;nbsp; &amp;nbsp;parameters:&amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;- in: query &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action <br />The AWS API design pattern doesn&#39;t lend itself to reuse&amp;nbsp;when it comes to documentation and storytelling, but I&#39;m always looking for an opportunity to push the boundaries, and I&#39;m able to better outline all available actions, as individual API paths by appending the action parameter to the path:<br /> swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/?Action=RunInstances/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance<br />Now I&#39;m able to describe all 228 actions you can take with the single Amazon EC2 API path as separate paths in any OpenAPI generated API documentation and tooling. I can give them unique summaries, descriptions, and operationId. OpenAPI allows me to describe what is possible with an API, going well beyond what the API provider was able to define. I&#39;ve been using this approach to better quantify the surface area of APIs like Amazon, Flickr, and others who use this pattern for a while now, but as I was looking to update my work, I wanted to take this concept even further.<br />While appending query parameters to the path definition has allowed me to expand how I describe the surface area of an API using OpenAPI, I&#39;d rather keep these parameters defined properly using the OpenAPI specification, and define an alternative way to make the path unique. To do this, I am exploring the usage of #bookmarks, to help make duplicate API paths more unqiue in the eyes of the schema validators, but invisible to the server side of things--something like this:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;m just not sold that this is the case, and there is an opportunity for evolving the definition&amp;nbsp;of an API by external entities using OpenAPI.<br />To help me explore this idea, and push the boundaries of how I use OpenAPI in my API storytelling, I wanted to frame this in the context of the Amazon EC2 API, which allows me to deploy a single unit of compute into the cloud using an API, a pretty fundamental component of our digital worlds. To make any call against the Amazon EC2 I send all my calls to a single base URL:<br />ec2.amazonaws.com<br />With this API call I pass in the action Id like to be taken:<br />?Action=RunInstances<br />Along with this base action parameter, I pass in a handful of other parameters to further define things:<br />&amp;amp;ImageId=ami-60a54009&amp;amp;MaxCount=1&amp;amp;KeyName=my-key-pair&amp;amp;Placement.AvailabilityZone=us-east-1d<br />Amazon has never been known for superior API design, but it gets the job done. With this single API call I can launch a server in the clouds. When I was first able to do this with APIs, is when the light really went on in my head regarding the potential of APIs. However, back to my story on expressing what an API does, as well as what is possible using OpenAPI. AWS has done an OK job at expressing what Amazon EC2 API does, however they suck at expressing what is possible. This is where API consumers like me step up with OpenAPI and provide some alternative representations of what is possible with the highly valuable API.<br />When I define the Amazon EC2 API using the OpenAPI specification I use the following:<br /> swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: The Amazon EC2 service&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: ec2API &amp;nbsp; &amp;nbsp; &amp;nbsp;parameters:&amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;- in: query &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action <br />The AWS API design pattern doesn&#39;t lend itself to reuse&amp;nbsp;when it comes to documentation and storytelling, but I&#39;m always looking for an opportunity to push the boundaries, and I&#39;m able to better outline all available actions, as individual API paths by appending the action parameter to the path:<br /> swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/?Action=RunInstances/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance<br />Now I&#39;m able to describe all 228 actions you can take with the single Amazon EC2 API path as separate paths in any OpenAPI generated API documentation and tooling. I can give them unique summaries, descriptions, and operationId. OpenAPI allows me to describe what is possible with an API, going well beyond what the API provider was able to define. I&#39;ve been using this approach to better quantify the surface area of APIs like Amazon, Flickr, and others who use this pattern for a while now, but as I was looking to update my work, I wanted to take this concept even further.<br />While appending query parameters to the path definition has allowed me to expand how I describe the surface area of an API using OpenAPI, I&#39;d rather keep these parameters defined properly using the OpenAPI specification, and define an alternative way to make the path unique. To do this, I am exploring the usage of #bookmarks, to help make duplicate API paths more unqiue in the eyes of the schema validators, but invisible to the server side of things--something like this:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;d like to be taken:<br />?Action=RunInstances<br />Along with this base action parameter, I pass in a handful of other parameters to further define things:<br />&amp;amp;ImageId=ami-60a54009&amp;amp;MaxCount=1&amp;amp;KeyName=my-key-pair&amp;amp;Placement.AvailabilityZone=us-east-1d<br />Amazon has never been known for superior API design, but it gets the job done. With this single API call I can launch a server in the clouds. When I was first able to do this with APIs, is when the light really went on in my head regarding the potential of APIs. However, back to my story on expressing what an API does, as well as what is possible using OpenAPI. AWS has done an OK job at expressing what Amazon EC2 API does, however they suck at expressing what is possible. This is where API consumers like me step up with OpenAPI and provide some alternative representations of what is possible with the highly valuable API.<br />When I define the Amazon EC2 API using the OpenAPI specification I use the following:<br /> swagger: 2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: The Amazon EC2 service&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: ec2API &amp;nbsp; &amp;nbsp; &amp;nbsp;parameters:&amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;- in: query &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action <br />The AWS API design pattern doesn&#39;t lend itself to reuse&amp;nbsp;when it comes to documentation and storytelling, but I&#39;m always looking for an opportunity to push the boundaries, and I&#39;m able to better outline all available actions, as individual API paths by appending the action parameter to the path:<br /> swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/?Action=RunInstances/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance<br />Now I&#39;m able to describe all 228 actions you can take with the single Amazon EC2 API path as separate paths in any OpenAPI generated API documentation and tooling. I can give them unique summaries, descriptions, and operationId. OpenAPI allows me to describe what is possible with an API, going well beyond what the API provider was able to define. I&#39;ve been using this approach to better quantify the surface area of APIs like Amazon, Flickr, and others who use this pattern for a while now, but as I was looking to update my work, I wanted to take this concept even further.<br />While appending query parameters to the path definition has allowed me to expand how I describe the surface area of an API using OpenAPI, I&#39;d rather keep these parameters defined properly using the OpenAPI specification, and define an alternative way to make the path unique. To do this, I am exploring the usage of #bookmarks, to help make duplicate API paths more unqiue in the eyes of the schema validators, but invisible to the server side of things--something like this:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;2.0info:title: Amazon EC2host: ec2.amazonaws.compaths:/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: The Amazon EC2 service&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: ec2API &amp;nbsp; &amp;nbsp; &amp;nbsp;parameters:&amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;- in: query &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action <br />The AWS API design pattern doesn&#39;t lend itself to reuse&amp;nbsp;when it comes to documentation and storytelling, but I&#39;m always looking for an opportunity to push the boundaries, and I&#39;m able to better outline all available actions, as individual API paths by appending the action parameter to the path:<br /> swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/?Action=RunInstances/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance<br />Now I&#39;m able to describe all 228 actions you can take with the single Amazon EC2 API path as separate paths in any OpenAPI generated API documentation and tooling. I can give them unique summaries, descriptions, and operationId. OpenAPI allows me to describe what is possible with an API, going well beyond what the API provider was able to define. I&#39;ve been using this approach to better quantify the surface area of APIs like Amazon, Flickr, and others who use this pattern for a while now, but as I was looking to update my work, I wanted to take this concept even further.<br />While appending query parameters to the path definition has allowed me to expand how I describe the surface area of an API using OpenAPI, I&#39;d rather keep these parameters defined properly using the OpenAPI specification, and define an alternative way to make the path unique. To do this, I am exploring the usage of #bookmarks, to help make duplicate API paths more unqiue in the eyes of the schema validators, but invisible to the server side of things--something like this:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;info:title: Amazon EC2host: ec2.amazonaws.compaths:/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: The Amazon EC2 service&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: ec2API &amp;nbsp; &amp;nbsp; &amp;nbsp;parameters:&amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;- in: query &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action <br />The AWS API design pattern doesnt lend itself to reuse&amp;nbsp;when it comes to documentation and storytelling, but I&#39;m always looking for an opportunity to push the boundaries, and I&#39;m able to better outline all available actions, as individual API paths by appending the action parameter to the path:<br /> swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/?Action=RunInstances/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance<br />Now I&#39;m able to describe all 228 actions you can take with the single Amazon EC2 API path as separate paths in any OpenAPI generated API documentation and tooling. I can give them unique summaries, descriptions, and operationId. OpenAPI allows me to describe what is possible with an API, going well beyond what the API provider was able to define. I&#39;ve been using this approach to better quantify the surface area of APIs like Amazon, Flickr, and others who use this pattern for a while now, but as I was looking to update my work, I wanted to take this concept even further.<br />While appending query parameters to the path definition has allowed me to expand how I describe the surface area of an API using OpenAPI, I&#39;d rather keep these parameters defined properly using the OpenAPI specification, and define an alternative way to make the path unique. To do this, I am exploring the usage of #bookmarks, to help make duplicate API paths more unqiue in the eyes of the schema validators, but invisible to the server side of things--something like this:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;t lend itself to reuse&amp;nbsp;when it comes to documentation and storytelling, but Im always looking for an opportunity to push the boundaries, and I&#39;m able to better outline all available actions, as individual API paths by appending the action parameter to the path:<br /> swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/?Action=RunInstances/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance<br />Now I&#39;m able to describe all 228 actions you can take with the single Amazon EC2 API path as separate paths in any OpenAPI generated API documentation and tooling. I can give them unique summaries, descriptions, and operationId. OpenAPI allows me to describe what is possible with an API, going well beyond what the API provider was able to define. I&#39;ve been using this approach to better quantify the surface area of APIs like Amazon, Flickr, and others who use this pattern for a while now, but as I was looking to update my work, I wanted to take this concept even further.<br />While appending query parameters to the path definition has allowed me to expand how I describe the surface area of an API using OpenAPI, I&#39;d rather keep these parameters defined properly using the OpenAPI specification, and define an alternative way to make the path unique. To do this, I am exploring the usage of #bookmarks, to help make duplicate API paths more unqiue in the eyes of the schema validators, but invisible to the server side of things--something like this:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;m always looking for an opportunity to push the boundaries, and Im able to better outline all available actions, as individual API paths by appending the action parameter to the path:<br /> swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/?Action=RunInstances/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance<br />Now I&#39;m able to describe all 228 actions you can take with the single Amazon EC2 API path as separate paths in any OpenAPI generated API documentation and tooling. I can give them unique summaries, descriptions, and operationId. OpenAPI allows me to describe what is possible with an API, going well beyond what the API provider was able to define. I&#39;ve been using this approach to better quantify the surface area of APIs like Amazon, Flickr, and others who use this pattern for a while now, but as I was looking to update my work, I wanted to take this concept even further.<br />While appending query parameters to the path definition has allowed me to expand how I describe the surface area of an API using OpenAPI, I&#39;d rather keep these parameters defined properly using the OpenAPI specification, and define an alternative way to make the path unique. To do this, I am exploring the usage of #bookmarks, to help make duplicate API paths more unqiue in the eyes of the schema validators, but invisible to the server side of things--something like this:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;m able to better outline all available actions, as individual API paths by appending the action parameter to the path:<br /> swagger: 2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/?Action=RunInstances/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance<br />Now I&#39;m able to describe all 228 actions you can take with the single Amazon EC2 API path as separate paths in any OpenAPI generated API documentation and tooling. I can give them unique summaries, descriptions, and operationId. OpenAPI allows me to describe what is possible with an API, going well beyond what the API provider was able to define. I&#39;ve been using this approach to better quantify the surface area of APIs like Amazon, Flickr, and others who use this pattern for a while now, but as I was looking to update my work, I wanted to take this concept even further.<br />While appending query parameters to the path definition has allowed me to expand how I describe the surface area of an API using OpenAPI, I&#39;d rather keep these parameters defined properly using the OpenAPI specification, and define an alternative way to make the path unique. To do this, I am exploring the usage of #bookmarks, to help make duplicate API paths more unqiue in the eyes of the schema validators, but invisible to the server side of things--something like this:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;2.0info:title: Amazon EC2host: ec2.amazonaws.compaths:/?Action=RunInstances/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance<br />Now I&#39;m able to describe all 228 actions you can take with the single Amazon EC2 API path as separate paths in any OpenAPI generated API documentation and tooling. I can give them unique summaries, descriptions, and operationId. OpenAPI allows me to describe what is possible with an API, going well beyond what the API provider was able to define. I&#39;ve been using this approach to better quantify the surface area of APIs like Amazon, Flickr, and others who use this pattern for a while now, but as I was looking to update my work, I wanted to take this concept even further.<br />While appending query parameters to the path definition has allowed me to expand how I describe the surface area of an API using OpenAPI, I&#39;d rather keep these parameters defined properly using the OpenAPI specification, and define an alternative way to make the path unique. To do this, I am exploring the usage of #bookmarks, to help make duplicate API paths more unqiue in the eyes of the schema validators, but invisible to the server side of things--something like this:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;info:title: Amazon EC2host: ec2.amazonaws.compaths:/?Action=RunInstances/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance<br />Now Im able to describe all 228 actions you can take with the single Amazon EC2 API path as separate paths in any OpenAPI generated API documentation and tooling. I can give them unique summaries, descriptions, and operationId. OpenAPI allows me to describe what is possible with an API, going well beyond what the API provider was able to define. I&#39;ve been using this approach to better quantify the surface area of APIs like Amazon, Flickr, and others who use this pattern for a while now, but as I was looking to update my work, I wanted to take this concept even further.<br />While appending query parameters to the path definition has allowed me to expand how I describe the surface area of an API using OpenAPI, I&#39;d rather keep these parameters defined properly using the OpenAPI specification, and define an alternative way to make the path unique. To do this, I am exploring the usage of #bookmarks, to help make duplicate API paths more unqiue in the eyes of the schema validators, but invisible to the server side of things--something like this:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;m able to describe all 228 actions you can take with the single Amazon EC2 API path as separate paths in any OpenAPI generated API documentation and tooling. I can give them unique summaries, descriptions, and operationId. OpenAPI allows me to describe what is possible with an API, going well beyond what the API provider was able to define. Ive been using this approach to better quantify the surface area of APIs like Amazon, Flickr, and others who use this pattern for a while now, but as I was looking to update my work, I wanted to take this concept even further.<br />While appending query parameters to the path definition has allowed me to expand how I describe the surface area of an API using OpenAPI, I&#39;d rather keep these parameters defined properly using the OpenAPI specification, and define an alternative way to make the path unique. To do this, I am exploring the usage of #bookmarks, to help make duplicate API paths more unqiue in the eyes of the schema validators, but invisible to the server side of things--something like this:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;ve been using this approach to better quantify the surface area of APIs like Amazon, Flickr, and others who use this pattern for a while now, but as I was looking to update my work, I wanted to take this concept even further.<br />While appending query parameters to the path definition has allowed me to expand how I describe the surface area of an API using OpenAPI, Id rather keep these parameters defined properly using the OpenAPI specification, and define an alternative way to make the path unique. To do this, I am exploring the usage of #bookmarks, to help make duplicate API paths more unqiue in the eyes of the schema validators, but invisible to the server side of things--something like this:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;d rather keep these parameters defined properly using the OpenAPI specification, and define an alternative way to make the path unique. To do this, I am exploring the usage of #bookmarks, to help make duplicate API paths more unqiue in the eyes of the schema validators, but invisible to the server side of things--something like this:<br />swagger: 2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;2.0info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: &#39;2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default: RunInstances&amp;nbsp;<br />I am considering how we can further make the path unique, by predefining other parameters using default or enum:<br />swagger: 2.0&#39;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;2.0info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but I&#39;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;info:title: Amazon EC2host: ec2.amazonaws.compaths:/#RunWebSiteInstance/:&amp;nbsp; &amp;nbsp; &amp;nbsp;get:&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;summary: Run a new Amazon EC2 website instance&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;description: The ability to launch a new website running on its own Amazon EC2 instance, from a predefined AWS AMI.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;operationId: runWebServerInstance &amp;nbsp; parameters: &amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: action&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;RunInstances&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;- in: query&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: ImageId&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&amp;nbsp;ami-60a54009&amp;nbsp;<br />I am still drawing&amp;nbsp;in the lines of what the API provider has given me, but Im now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I can&#39;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;m now augmenting with a better summary and description of what is possible using OpenAPI, which can now be reflected in documentation and other tooling that is OpenAPI compliant. I can even prepopulate the default values, or available options using enum settings, tailoring to my team, company, or other specific needs. Taking an existing API definition beyond its provider interpretation of what it does, and getting to work on being more creative around what is possible.<br />Let me know how incoherent this is. I cant tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a provider&#39;s definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;t tell sometimes. Maybe I need more examples of this in action. I feel like it might be a big piece of the puzzle that has been missing for me regarding how we tell stories about what is possible with APIs. When it comes to API definitions, documentation, and discovery I feel like we are chained to a providers definition of what is possible, when in reality this shouldn&#39;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;s definition of what is possible, when in reality this shouldnt be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;t be what drives the conversation. There should be definitions, documentation, and discovery documents created by API providers that help articulate what an API does, but more importantly, there should be a wealth of&amp;nbsp;definitions, documentation, and discovery documents created by API consumers that help articulate what is possible.&amp;nbsp;",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/tool/openapi-spec.png"
  },
  {
  "title": "SDK Generation, API Validation And Transformation Using The APIMATIC CLI",
  "date": "27 Apr 2017",
  "body": "<br />Continuing a growing number of command line interfaces (CLI) being deployed side by side with APIs, SDK generation provider APIMATIC just released a CLI for their platform, continuing their march towards being a continuous&amp;nbsp;integration provider. There was a great post the other day on Nordic APIs about CLI, highlighting one way API providers seem to be investing in CLIs to help increase the chances that their services will get baked into applications and system integrations.<br />APIMatic CLI is a command line tool written in Python which serves as a wrapper over our own Python SDK. It is available in the form of a small windows executable so you can easily plug it into your build cycle. You no longer have to write your own code or set up a development environment for the consumption of our APIs.<br />SDK generation, API validation and API transformation baked into your workflow, all driven by API definitions available via any URL. This is a pretty important layer of your API lifecycle, something that isnt easily done if you are still battling the monolith system, but when you&#39;ve gone full microservices, DevOps, Continous Integration Kung Fu (tm), it provides you with a pretty easy way to define, deploy, and validate API endpoints, as well as the system integrations that consume those APIs--all driven and choreographed by your API definitions.<br />I&#39;m still very API-centric in my workflows and use the APIMATIC API to generate SDKs, and API Transformer to translate API definitions from one format to the other, but I understand that a CLI is more practical for the way some teams operate. API service providers seem to be getting the message and responding to developers with a fully functional CLI, as well as API&amp;nbsp;like Zapier did the other day with the release of their CLI--pushing the boundaries of what is a continuous integration platform as a service.<br />I asked Adeel of APIMATIC when they would have a CLI generator based upon API definitions. I mean their&amp;nbsp;CLI is a tool that wraps the APIMATIC SDK, which I assume is generated by APIMATIC, using an API definition. Why can&#39;t they just autogenerate a CLI for their customers using the same API definition being used to generated the SDK? He responded with a smile. ;-)<br />Disclosure: I am an advisor to APIMATIC.t easily done if you are still battling the monolith system, but when youve gone full microservices, DevOps, Continous Integration Kung Fu (tm), it provides you with a pretty easy way to define, deploy, and validate API endpoints, as well as the system integrations that consume those APIs--all driven and choreographed by your API definitions.<br />I&#39;m still very API-centric in my workflows and use the APIMATIC API to generate SDKs, and API Transformer to translate API definitions from one format to the other, but I understand that a CLI is more practical for the way some teams operate. API service providers seem to be getting the message and responding to developers with a fully functional CLI, as well as API&amp;nbsp;like Zapier did the other day with the release of their CLI--pushing the boundaries of what is a continuous integration platform as a service.<br />I asked Adeel of APIMATIC when they would have a CLI generator based upon API definitions. I mean their&amp;nbsp;CLI is a tool that wraps the APIMATIC SDK, which I assume is generated by APIMATIC, using an API definition. Why can&#39;t they just autogenerate a CLI for their customers using the same API definition being used to generated the SDK? He responded with a smile. ;-)<br />Disclosure: I am an advisor to APIMATIC.ve gone full microservices, DevOps, Continous Integration Kung Fu (tm), it provides you with a pretty easy way to define, deploy, and validate API endpoints, as well as the system integrations that consume those APIs--all driven and choreographed by your API definitions.<br />Im still very API-centric in my workflows and use the APIMATIC API to generate SDKs, and API Transformer to translate API definitions from one format to the other, but I understand that a CLI is more practical for the way some teams operate. API service providers seem to be getting the message and responding to developers with a fully functional CLI, as well as API&amp;nbsp;like Zapier did the other day with the release of their CLI--pushing the boundaries of what is a continuous integration platform as a service.<br />I asked Adeel of APIMATIC when they would have a CLI generator based upon API definitions. I mean their&amp;nbsp;CLI is a tool that wraps the APIMATIC SDK, which I assume is generated by APIMATIC, using an API definition. Why can&#39;t they just autogenerate a CLI for their customers using the same API definition being used to generated the SDK? He responded with a smile. ;-)<br />Disclosure: I am an advisor to APIMATIC.m still very API-centric in my workflows and use the APIMATIC API to generate SDKs, and API Transformer to translate API definitions from one format to the other, but I understand that a CLI is more practical for the way some teams operate. API service providers seem to be getting the message and responding to developers with a fully functional CLI, as well as API&amp;nbsp;like Zapier did the other day with the release of their CLI--pushing the boundaries of what is a continuous integration platform as a service.<br />I asked Adeel of APIMATIC when they would have a CLI generator based upon API definitions. I mean their&amp;nbsp;CLI is a tool that wraps the APIMATIC SDK, which I assume is generated by APIMATIC, using an API definition. Why cant they just autogenerate a CLI for their customers using the same API definition being used to generated the SDK? He responded with a smile. ;-)<br />Disclosure: I am an advisor to APIMATIC.t they just autogenerate a CLI for their customers using the same API definition being used to generated the SDK? He responded with a smile. ;-)<br />Disclosure: I am an advisor to APIMATIC.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/introducing_apimatic_cli.png"
  },
  {
  "title": "API Definitions Should Be Done By The API Provider",
  "date": "27 Apr 2017",
  "body": "<br />I talk to a lot of API service and tooling providers about API definitions. Ive long been an advocate for API service providers supporting OpenAPI, as well as a variety of API definition formats--if you are having trouble doing this, check out API Transformer. While service providers are an important link in the API definition chain, support of API specification by API providers themselves, and the availability of definitions for all of their APIs is another very critical link in this API supply chain.<br />During a discussion with an iPaaS provider this week about the availability of OpenAPI definitions, a comment was made about there not being enough good sources of usable definitions, specifically from API providers themselves. While it is true, and there is not as much adoption by leading API providers as I would like to see, it still is pretty easy to find numerous proactive efforts by APIs providers like SendGrid, NY Times, and Azure-- just to name a few. Of course, I want ALL API providers to maintain an accurate, comprehensive set of API definitions for the operations, but I don&#39;t think is the reality we live in, or even where all API definition creation should occur.<br />It is part of the API DNA for the lion share of the innovation to come from external sources. Sure, I think every API provider would be better off if they maintained their own OpenAPI, generating documentation, code, and other resources. But, I also think it is perfectly acceptable for the community to do some of this heavy lifting. Not all API providers are going to have the skills, time, and other resources to make this happen--often times this is precisely why they are doing APIs, to outsource, and share the innovation load.<br />I see API definitions and discovery as a community thing, something API providers, consumers, as well as API service providers should all be contributing to. No matter where you operate in the space, you should be sharing your API definitions using Github, even if they are for the 3rd party API providers you depend on and might seem duplicative. You never know when your definition might have a piece of the puzzle, another developer is looking for, allowing them to build on top of your existing work, and vice versa. When you define your APIs out in the open like this, we all win, because API definitions benefit the API provider, consumer, services, and tooling&amp;nbsp;developers.ve long been an advocate for API service providers supporting OpenAPI, as well as a variety of API definition formats--if you are having trouble doing this, check out API Transformer. While service providers are an important link in the API definition chain, support of API specification by API providers themselves, and the availability of definitions for all of their APIs is another very critical link in this API supply chain.<br />During a discussion with an iPaaS provider this week about the availability of OpenAPI definitions, a comment was made about there not being enough good sources of usable definitions, specifically from API providers themselves. While it is true, and there is not as much adoption by leading API providers as I would like to see, it still is pretty easy to find numerous proactive efforts by APIs providers like SendGrid, NY Times, and Azure-- just to name a few. Of course, I want ALL API providers to maintain an accurate, comprehensive set of API definitions for the operations, but I dont think is the reality we live in, or even where all API definition creation should occur.<br />It is part of the API DNA for the lion share of the innovation to come from external sources. Sure, I think every API provider would be better off if they maintained their own OpenAPI, generating documentation, code, and other resources. But, I also think it is perfectly acceptable for the community to do some of this heavy lifting. Not all API providers are going to have the skills, time, and other resources to make this happen--often times this is precisely why they are doing APIs, to outsource, and share the innovation load.<br />I see API definitions and discovery as a community thing, something API providers, consumers, as well as API service providers should all be contributing to. No matter where you operate in the space, you should be sharing your API definitions using Github, even if they are for the 3rd party API providers you depend on and might seem duplicative. You never know when your definition might have a piece of the puzzle, another developer is looking for, allowing them to build on top of your existing work, and vice versa. When you define your APIs out in the open like this, we all win, because API definitions benefit the API provider, consumer, services, and tooling&amp;nbsp;developers.t think is the reality we live in, or even where all API definition creation should occur.<br />It is part of the API DNA for the lion share of the innovation to come from external sources. Sure, I think every API provider would be better off if they maintained their own OpenAPI, generating documentation, code, and other resources. But, I also think it is perfectly acceptable for the community to do some of this heavy lifting. Not all API providers are going to have the skills, time, and other resources to make this happen--often times this is precisely why they are doing APIs, to outsource, and share the innovation load.<br />I see API definitions and discovery as a community thing, something API providers, consumers, as well as API service providers should all be contributing to. No matter where you operate in the space, you should be sharing your API definitions using Github, even if they are for the 3rd party API providers you depend on and might seem duplicative. You never know when your definition might have a piece of the puzzle, another developer is looking for, allowing them to build on top of your existing work, and vice versa. When you define your APIs out in the open like this, we all win, because API definitions benefit the API provider, consumer, services, and tooling&amp;nbsp;developers.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-puzzle-piece-gear.png"
  },
  {
  "title": "Separating The Licensing Layers Of Your Valuable Data Using APIs",
  "date": "24 Apr 2017",
  "body": "<br />Data is power. If you have valuable data, people want it. While this is the current way of doing things on the Internet, it really isnt a new concept. The data in databases has always been wielded alongside business and political objectives. I have worked professionally as a database engineer for 30 years this year, with my first job building COBOL databases for use in schools across the State of Oregon in 1987, and have seen many different ways that data is the fuel for the engines of power.<br />Data is valuable. We put a lot of work into acquiring, creating, normalizing, updating, and maintaining our data. However, this value only goes so far if we keep it siloed, and isolated. We have to be able to open up our data to other stakeholders, partners, or possibly even the public. This is where modern approaches to APIs can help us in some meaningful ways, allowing data stewards to sensibly, and securely open up access to valuable API resources using low-cost web technology. One of the most common obstacles I see impeding companies, organizations, institutions, and agencies from achieving API success, center around restrictive views on data licensing, not being able to separate the data layers by using APIs, and being overly concerned about a loss of power when you publish APIs.<br />You worked hard to develop the data you have, but you also want to make accessible. To protect our interests I see many folks impose pretty proprietary restrictions around their data, which ends up hurting its usage and viability in partner systems, and introducing friction when it comes to accessing and putting data to work--when this is the thing you really want as a data steward. Let me take a stab at helping you reduce this friction by better understanding how APIs can help you peel the licensing onion layers back when it comes to your valuable data.<br /><br /><br /><br /><br /><br />Your Valuable DataThis is an example point of contact record. I&#39;ve worked hard to create this bit of data (not really), and maintain a relationship with this point of contact. It takes time to validate that their record is up to date, always relfecting reality in my database.<br />While openly licensed data is one important piece of the puzzle, and data should be openly licensed when it makes sense, this is the layer of this discussion you may want to be a little more controlling in who has access to, and how partners and the public are able to put your data to use in their operations.<br />In an online, always on, digital environment, you want data accessible, but to be able to do this you need to think critically about how you peel back the licensing onion when it comes to this data.<br /><br /><br /><br /><br /><br />The Schema For Your DataThe first layer to peel back when you are looking to make data more accessible with APIs is at the schema level. This is the names, description, data type, and other details about the meta layer of your valuable data--it isn&#39;t the data, but the description of the structure of your data.<br />Ideally, your schema already employs predefined schemas like we find at Schema.org, or Open Referral. Following common definitions will significantly widen the audience for any dataset, allowing data to seamlessly be used across a variety of systems. These forms of schema or openly licensed, usually putting into the public domain.<br />The schema layer of open data can often resemble the data itself, using machine readable formats like XML, JSON, and YAML. This is most likely the biggest contributing factor for data stewards failing to see this as a separate layer of access from the data itself, and sometimes applying a restrictive license, or forgetting to license it at all.<br />Data is often more ephemeral than the schema. Ideally, schemas do not change often, are shared and resused, as well as free from restrictive licensing. For system integrations to work, and for partnerships to be sustainable, we need to speak a common language, and schema is how we describe our data so it can be put to use outside our firewall.<br />Make sure the schema for your data is well-defined, machine readable, and openly licensed for the widest possible use.<br /><br /><br /><br /><br /><br />Defining Access To Data Using OpenAPI&amp;nbsp;The third layer of this licensing onion is the API layer, which governs access to data, defining how requests are made upon data, and how responses are structured. Many API providers are putting OpenAPI to work to define this layer of data operations.<br />As with the schema layer of data operations, you are hoping that other companies, organizations, institutions, and government agencies will integrate this layer into their operations. This layer is much more permanent than the ephermeral data layer, and should be well defined, ideally sharing common patterns, and free from restrictive licensing.<br />Per the Oracle v Google Java API copyright case in the United States, the API layer is subject to copyright enforcement, meaning the naming, ordering of the surface area of your API can be copyright. If you are looking for others to comfortably integrate this definition into their operations, it should be openly licensed.&amp;nbsp;<br />The API layer is not your data. It defines how data will be accessed, and put to use. It is important to separate this layer of your data operations, allowing it to shared, reused, and implemented in many different ways supporting web, mobile, voice, bot, and a growing number of API driven applications.<br />Make sure the API layer to data operations is well-defined, machine readable, and free from restrictive licensing when possible.&amp;nbsp;<br />&amp;nbsp;<br /><br /><br /><br /><br />Currently, many data providers I talk to see this all as a single entity. It&#39;s our data. It&#39;s valuable. We need to protect it. Even at the same time they really want it simultaneously put to work in other systems, by partners, or even the public. Because they cannot separate the layers, and understand the need for separate licensing considerations, they end up being very closed with the data, schema, and API layers of their operations--introducing friciton at all steps of the application and data life cycle.<br />Modern approaches to API management and logging at the API layer is how savvy data stewards are simultaenoulsy opening up access, and maintaing control over data, while also increasing awareness around how data is being put to use, or not used. Key-based access, rate limits, access plans, are all approaches to opening up access to data, while maximizing control, and maintaining a desired balance of power between steward, partners, and consumers. In this model, your schema and API definition needs to be open, accessible, and shareable, where the data itself can be much more tightly controlled, depending on the goals of the data steward, and the needs of consumers.<br />Let me know if you want to talk through the separation of these layers of licensing and access around your data resources. I&#39;m all for helping you protect your valuable data, but in a pragrmatic way. If you want to be successful in partnering with other stakeholders, you need to be thinking more critically about separating the layers of your data operations, and getting better at peeling back the onion of your data operations--something that seems to leave many folks with tears in their eyes.t a new concept. The data in databases has always been wielded alongside business and political objectives. I have worked professionally as a database engineer for 30 years this year, with my first job building COBOL databases for use in schools across the State of Oregon in 1987, and have seen many different ways that data is the fuel for the engines of power.<br />Data is valuable. We put a lot of work into acquiring, creating, normalizing, updating, and maintaining our data. However, this value only goes so far if we keep it siloed, and isolated. We have to be able to open up our data to other stakeholders, partners, or possibly even the public. This is where modern approaches to APIs can help us in some meaningful ways, allowing data stewards to sensibly, and securely open up access to valuable API resources using low-cost web technology. One of the most common obstacles I see impeding companies, organizations, institutions, and agencies from achieving API success, center around restrictive views on data licensing, not being able to separate the data layers by using APIs, and being overly concerned about a loss of power when you publish APIs.<br />You worked hard to develop the data you have, but you also want to make accessible. To protect our interests I see many folks impose pretty proprietary restrictions around their data, which ends up hurting its usage and viability in partner systems, and introducing friction when it comes to accessing and putting data to work--when this is the thing you really want as a data steward. Let me take a stab at helping you reduce this friction by better understanding how APIs can help you peel the licensing onion layers back when it comes to your valuable data.<br /><br /><br /><br /><br /><br />Your Valuable DataThis is an example point of contact record. Ive worked hard to create this bit of data (not really), and maintain a relationship with this point of contact. It takes time to validate that their record is up to date, always relfecting reality in my database.<br />While openly licensed data is one important piece of the puzzle, and data should be openly licensed when it makes sense, this is the layer of this discussion you may want to be a little more controlling in who has access to, and how partners and the public are able to put your data to use in their operations.<br />In an online, always on, digital environment, you want data accessible, but to be able to do this you need to think critically about how you peel back the licensing onion when it comes to this data.<br /><br /><br /><br /><br /><br />The Schema For Your DataThe first layer to peel back when you are looking to make data more accessible with APIs is at the schema level. This is the names, description, data type, and other details about the meta layer of your valuable data--it isn&#39;t the data, but the description of the structure of your data.<br />Ideally, your schema already employs predefined schemas like we find at Schema.org, or Open Referral. Following common definitions will significantly widen the audience for any dataset, allowing data to seamlessly be used across a variety of systems. These forms of schema or openly licensed, usually putting into the public domain.<br />The schema layer of open data can often resemble the data itself, using machine readable formats like XML, JSON, and YAML. This is most likely the biggest contributing factor for data stewards failing to see this as a separate layer of access from the data itself, and sometimes applying a restrictive license, or forgetting to license it at all.<br />Data is often more ephemeral than the schema. Ideally, schemas do not change often, are shared and resused, as well as free from restrictive licensing. For system integrations to work, and for partnerships to be sustainable, we need to speak a common language, and schema is how we describe our data so it can be put to use outside our firewall.<br />Make sure the schema for your data is well-defined, machine readable, and openly licensed for the widest possible use.<br /><br /><br /><br /><br /><br />Defining Access To Data Using OpenAPI&amp;nbsp;The third layer of this licensing onion is the API layer, which governs access to data, defining how requests are made upon data, and how responses are structured. Many API providers are putting OpenAPI to work to define this layer of data operations.<br />As with the schema layer of data operations, you are hoping that other companies, organizations, institutions, and government agencies will integrate this layer into their operations. This layer is much more permanent than the ephermeral data layer, and should be well defined, ideally sharing common patterns, and free from restrictive licensing.<br />Per the Oracle v Google Java API copyright case in the United States, the API layer is subject to copyright enforcement, meaning the naming, ordering of the surface area of your API can be copyright. If you are looking for others to comfortably integrate this definition into their operations, it should be openly licensed.&amp;nbsp;<br />The API layer is not your data. It defines how data will be accessed, and put to use. It is important to separate this layer of your data operations, allowing it to shared, reused, and implemented in many different ways supporting web, mobile, voice, bot, and a growing number of API driven applications.<br />Make sure the API layer to data operations is well-defined, machine readable, and free from restrictive licensing when possible.&amp;nbsp;<br />&amp;nbsp;<br /><br /><br /><br /><br />Currently, many data providers I talk to see this all as a single entity. It&#39;s our data. It&#39;s valuable. We need to protect it. Even at the same time they really want it simultaneously put to work in other systems, by partners, or even the public. Because they cannot separate the layers, and understand the need for separate licensing considerations, they end up being very closed with the data, schema, and API layers of their operations--introducing friciton at all steps of the application and data life cycle.<br />Modern approaches to API management and logging at the API layer is how savvy data stewards are simultaenoulsy opening up access, and maintaing control over data, while also increasing awareness around how data is being put to use, or not used. Key-based access, rate limits, access plans, are all approaches to opening up access to data, while maximizing control, and maintaining a desired balance of power between steward, partners, and consumers. In this model, your schema and API definition needs to be open, accessible, and shareable, where the data itself can be much more tightly controlled, depending on the goals of the data steward, and the needs of consumers.<br />Let me know if you want to talk through the separation of these layers of licensing and access around your data resources. I&#39;m all for helping you protect your valuable data, but in a pragrmatic way. If you want to be successful in partnering with other stakeholders, you need to be thinking more critically about separating the layers of your data operations, and getting better at peeling back the onion of your data operations--something that seems to leave many folks with tears in their eyes.ve worked hard to create this bit of data (not really), and maintain a relationship with this point of contact. It takes time to validate that their record is up to date, always relfecting reality in my database.<br />While openly licensed data is one important piece of the puzzle, and data should be openly licensed when it makes sense, this is the layer of this discussion you may want to be a little more controlling in who has access to, and how partners and the public are able to put your data to use in their operations.<br />In an online, always on, digital environment, you want data accessible, but to be able to do this you need to think critically about how you peel back the licensing onion when it comes to this data.<br /><br /><br /><br /><br /><br />The Schema For Your DataThe first layer to peel back when you are looking to make data more accessible with APIs is at the schema level. This is the names, description, data type, and other details about the meta layer of your valuable data--it isnt the data, but the description of the structure of your data.<br />Ideally, your schema already employs predefined schemas like we find at Schema.org, or Open Referral. Following common definitions will significantly widen the audience for any dataset, allowing data to seamlessly be used across a variety of systems. These forms of schema or openly licensed, usually putting into the public domain.<br />The schema layer of open data can often resemble the data itself, using machine readable formats like XML, JSON, and YAML. This is most likely the biggest contributing factor for data stewards failing to see this as a separate layer of access from the data itself, and sometimes applying a restrictive license, or forgetting to license it at all.<br />Data is often more ephemeral than the schema. Ideally, schemas do not change often, are shared and resused, as well as free from restrictive licensing. For system integrations to work, and for partnerships to be sustainable, we need to speak a common language, and schema is how we describe our data so it can be put to use outside our firewall.<br />Make sure the schema for your data is well-defined, machine readable, and openly licensed for the widest possible use.<br /><br /><br /><br /><br /><br />Defining Access To Data Using OpenAPI&amp;nbsp;The third layer of this licensing onion is the API layer, which governs access to data, defining how requests are made upon data, and how responses are structured. Many API providers are putting OpenAPI to work to define this layer of data operations.<br />As with the schema layer of data operations, you are hoping that other companies, organizations, institutions, and government agencies will integrate this layer into their operations. This layer is much more permanent than the ephermeral data layer, and should be well defined, ideally sharing common patterns, and free from restrictive licensing.<br />Per the Oracle v Google Java API copyright case in the United States, the API layer is subject to copyright enforcement, meaning the naming, ordering of the surface area of your API can be copyright. If you are looking for others to comfortably integrate this definition into their operations, it should be openly licensed.&amp;nbsp;<br />The API layer is not your data. It defines how data will be accessed, and put to use. It is important to separate this layer of your data operations, allowing it to shared, reused, and implemented in many different ways supporting web, mobile, voice, bot, and a growing number of API driven applications.<br />Make sure the API layer to data operations is well-defined, machine readable, and free from restrictive licensing when possible.&amp;nbsp;<br />&amp;nbsp;<br /><br /><br /><br /><br />Currently, many data providers I talk to see this all as a single entity. It&#39;s our data. It&#39;s valuable. We need to protect it. Even at the same time they really want it simultaneously put to work in other systems, by partners, or even the public. Because they cannot separate the layers, and understand the need for separate licensing considerations, they end up being very closed with the data, schema, and API layers of their operations--introducing friciton at all steps of the application and data life cycle.<br />Modern approaches to API management and logging at the API layer is how savvy data stewards are simultaenoulsy opening up access, and maintaing control over data, while also increasing awareness around how data is being put to use, or not used. Key-based access, rate limits, access plans, are all approaches to opening up access to data, while maximizing control, and maintaining a desired balance of power between steward, partners, and consumers. In this model, your schema and API definition needs to be open, accessible, and shareable, where the data itself can be much more tightly controlled, depending on the goals of the data steward, and the needs of consumers.<br />Let me know if you want to talk through the separation of these layers of licensing and access around your data resources. I&#39;m all for helping you protect your valuable data, but in a pragrmatic way. If you want to be successful in partnering with other stakeholders, you need to be thinking more critically about separating the layers of your data operations, and getting better at peeling back the onion of your data operations--something that seems to leave many folks with tears in their eyes.t the data, but the description of the structure of your data.<br />Ideally, your schema already employs predefined schemas like we find at Schema.org, or Open Referral. Following common definitions will significantly widen the audience for any dataset, allowing data to seamlessly be used across a variety of systems. These forms of schema or openly licensed, usually putting into the public domain.<br />The schema layer of open data can often resemble the data itself, using machine readable formats like XML, JSON, and YAML. This is most likely the biggest contributing factor for data stewards failing to see this as a separate layer of access from the data itself, and sometimes applying a restrictive license, or forgetting to license it at all.<br />Data is often more ephemeral than the schema. Ideally, schemas do not change often, are shared and resused, as well as free from restrictive licensing. For system integrations to work, and for partnerships to be sustainable, we need to speak a common language, and schema is how we describe our data so it can be put to use outside our firewall.<br />Make sure the schema for your data is well-defined, machine readable, and openly licensed for the widest possible use.<br /><br /><br /><br /><br /><br />Defining Access To Data Using OpenAPI&amp;nbsp;The third layer of this licensing onion is the API layer, which governs access to data, defining how requests are made upon data, and how responses are structured. Many API providers are putting OpenAPI to work to define this layer of data operations.<br />As with the schema layer of data operations, you are hoping that other companies, organizations, institutions, and government agencies will integrate this layer into their operations. This layer is much more permanent than the ephermeral data layer, and should be well defined, ideally sharing common patterns, and free from restrictive licensing.<br />Per the Oracle v Google Java API copyright case in the United States, the API layer is subject to copyright enforcement, meaning the naming, ordering of the surface area of your API can be copyright. If you are looking for others to comfortably integrate this definition into their operations, it should be openly licensed.&amp;nbsp;<br />The API layer is not your data. It defines how data will be accessed, and put to use. It is important to separate this layer of your data operations, allowing it to shared, reused, and implemented in many different ways supporting web, mobile, voice, bot, and a growing number of API driven applications.<br />Make sure the API layer to data operations is well-defined, machine readable, and free from restrictive licensing when possible.&amp;nbsp;<br />&amp;nbsp;<br /><br /><br /><br /><br />Currently, many data providers I talk to see this all as a single entity. Its our data. It&#39;s valuable. We need to protect it. Even at the same time they really want it simultaneously put to work in other systems, by partners, or even the public. Because they cannot separate the layers, and understand the need for separate licensing considerations, they end up being very closed with the data, schema, and API layers of their operations--introducing friciton at all steps of the application and data life cycle.<br />Modern approaches to API management and logging at the API layer is how savvy data stewards are simultaenoulsy opening up access, and maintaing control over data, while also increasing awareness around how data is being put to use, or not used. Key-based access, rate limits, access plans, are all approaches to opening up access to data, while maximizing control, and maintaining a desired balance of power between steward, partners, and consumers. In this model, your schema and API definition needs to be open, accessible, and shareable, where the data itself can be much more tightly controlled, depending on the goals of the data steward, and the needs of consumers.<br />Let me know if you want to talk through the separation of these layers of licensing and access around your data resources. I&#39;m all for helping you protect your valuable data, but in a pragrmatic way. If you want to be successful in partnering with other stakeholders, you need to be thinking more critically about separating the layers of your data operations, and getting better at peeling back the onion of your data operations--something that seems to leave many folks with tears in their eyes.s our data. Its valuable. We need to protect it. Even at the same time they really want it simultaneously put to work in other systems, by partners, or even the public. Because they cannot separate the layers, and understand the need for separate licensing considerations, they end up being very closed with the data, schema, and API layers of their operations--introducing friciton at all steps of the application and data life cycle.<br />Modern approaches to API management and logging at the API layer is how savvy data stewards are simultaenoulsy opening up access, and maintaing control over data, while also increasing awareness around how data is being put to use, or not used. Key-based access, rate limits, access plans, are all approaches to opening up access to data, while maximizing control, and maintaining a desired balance of power between steward, partners, and consumers. In this model, your schema and API definition needs to be open, accessible, and shareable, where the data itself can be much more tightly controlled, depending on the goals of the data steward, and the needs of consumers.<br />Let me know if you want to talk through the separation of these layers of licensing and access around your data resources. I&#39;m all for helping you protect your valuable data, but in a pragrmatic way. If you want to be successful in partnering with other stakeholders, you need to be thinking more critically about separating the layers of your data operations, and getting better at peeling back the onion of your data operations--something that seems to leave many folks with tears in their eyes.s valuable. We need to protect it. Even at the same time they really want it simultaneously put to work in other systems, by partners, or even the public. Because they cannot separate the layers, and understand the need for separate licensing considerations, they end up being very closed with the data, schema, and API layers of their operations--introducing friciton at all steps of the application and data life cycle.<br />Modern approaches to API management and logging at the API layer is how savvy data stewards are simultaenoulsy opening up access, and maintaing control over data, while also increasing awareness around how data is being put to use, or not used. Key-based access, rate limits, access plans, are all approaches to opening up access to data, while maximizing control, and maintaining a desired balance of power between steward, partners, and consumers. In this model, your schema and API definition needs to be open, accessible, and shareable, where the data itself can be much more tightly controlled, depending on the goals of the data steward, and the needs of consumers.<br />Let me know if you want to talk through the separation of these layers of licensing and access around your data resources. Im all for helping you protect your valuable data, but in a pragrmatic way. If you want to be successful in partnering with other stakeholders, you need to be thinking more critically about separating the layers of your data operations, and getting better at peeling back the onion of your data operations--something that seems to leave many folks with tears in their eyes.m all for helping you protect your valuable data, but in a pragrmatic way. If you want to be successful in partnering with other stakeholders, you need to be thinking more critically about separating the layers of your data operations, and getting better at peeling back the onion of your data operations--something that seems to leave many folks with tears in their eyes.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-onion.png"
  },
  {
  "title": "YAML Templates For API Operations",
  "date": "18 Apr 2017",
  "body": "<br />I am seeing a significant number of infrastructure orchestration solutions in the cloud start using YAML templates as the core setting of settings and instructions for workflows. Amazon recently introduced YAML templates for your AWS CloudFormations, where you can define the infrastructure templates you are using throughout the API life cycle. These AWS YAML templates are fast becoming the central definition to be used across AWS operations, with support in the AWS Service Catalog.<br />Whether you use AWS or not, working to define your infrastructure using YAML templates help define what is going on. Im seeing significant adoption of OpenAPIs in YAML, and I&#39;m even beginning to create API operational indexes using APIs.json&amp;nbsp;converted into YAML (there is a naming lesson in there). I also have YAML templates for each area of my API lifecycle research, providing me machine readable definitions for everything from news to patents, that I then use across my API research&amp;nbsp;and storytelling.<br />I feel the same way about YAML as I did about JSON a decade ago, and it is quickly becoming my preferred format for any structured data, no matter where it is used in my operations. YAML + Github is quickly becoming the engine for some interesting ways of delivering infrastructure, and specifically API infrastructure, in a consistent way that is easy to communicate with others. This example focuses on AWS usage of YAML, but it is something I&#39;m seeing from Google&amp;nbsp;and other tech giants. I think the readability of YAML (minus quotes and brackets) makes it accessible to a wider audience beyond developer groups, something that is going to be critical to doing APIs at scale.m seeing significant adoption of OpenAPIs in YAML, and Im even beginning to create API operational indexes using APIs.json&amp;nbsp;converted into YAML (there is a naming lesson in there). I also have YAML templates for each area of my API lifecycle research, providing me machine readable definitions for everything from news to patents, that I then use across my API research&amp;nbsp;and storytelling.<br />I feel the same way about YAML as I did about JSON a decade ago, and it is quickly becoming my preferred format for any structured data, no matter where it is used in my operations. YAML + Github is quickly becoming the engine for some interesting ways of delivering infrastructure, and specifically API infrastructure, in a consistent way that is easy to communicate with others. This example focuses on AWS usage of YAML, but it is something I&#39;m seeing from Google&amp;nbsp;and other tech giants. I think the readability of YAML (minus quotes and brackets) makes it accessible to a wider audience beyond developer groups, something that is going to be critical to doing APIs at scale.m even beginning to create API operational indexes using APIs.json&amp;nbsp;converted into YAML (there is a naming lesson in there). I also have YAML templates for each area of my API lifecycle research, providing me machine readable definitions for everything from news to patents, that I then use across my API research&amp;nbsp;and storytelling.<br />I feel the same way about YAML as I did about JSON a decade ago, and it is quickly becoming my preferred format for any structured data, no matter where it is used in my operations. YAML + Github is quickly becoming the engine for some interesting ways of delivering infrastructure, and specifically API infrastructure, in a consistent way that is easy to communicate with others. This example focuses on AWS usage of YAML, but it is something Im seeing from Google&amp;nbsp;and other tech giants. I think the readability of YAML (minus quotes and brackets) makes it accessible to a wider audience beyond developer groups, something that is going to be critical to doing APIs at scale.m seeing from Google&amp;nbsp;and other tech giants. I think the readability of YAML (minus quotes and brackets) makes it accessible to a wider audience beyond developer groups, something that is going to be critical to doing APIs at scale.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_04_16_at_5.38.15_pm.png"
  },
  {
  "title": "Tooling For Converting Your OpenAPI Definitions From 2.0 to 3.0",
  "date": "13 Apr 2017",
  "body": "<br />I wrote a post asking what it would take to migrate OpenAPI tooling from version 2.0 to 3.0 of the API specification, and Mike Ralphson (@PermittedSoc) commented about some of the projects hes been working on involving the latest specification version. Which I hope is a good sign of things to come, when it comes to moving from version 2.0 to 3.0 in 2017.<br />Mike has developed an OpenAPI converter and validator to help people migrate their OpenAPI definitions from 2.0 to 3.0. The open source tool also has an online version of the OpenAPI converter and validator for using in the browser, and of course, it also has an OpenAPI conversion and validation API, because ALL API tools and services should have an API--it is just good API craft.<br />It makes sense that some of the first tools to emerge are for conversion. Many API developers will need to convert their existing API definitions into version 3.0 of the specification to begin learning about what is new with OpenAPI 3.0. If you have examples of OpenAPI 3.0 definitions for your API, please publish them to Github and share with me, so I can help point folks to examples in the wild that they can learn from as we make this shift.s been working on involving the latest specification version. Which I hope is a good sign of things to come, when it comes to moving from version 2.0 to 3.0 in 2017.<br />Mike has developed an OpenAPI converter and validator to help people migrate their OpenAPI definitions from 2.0 to 3.0. The open source tool also has an online version of the OpenAPI converter and validator for using in the browser, and of course, it also has an OpenAPI conversion and validation API, because ALL API tools and services should have an API--it is just good API craft.<br />It makes sense that some of the first tools to emerge are for conversion. Many API developers will need to convert their existing API definitions into version 3.0 of the specification to begin learning about what is new with OpenAPI 3.0. If you have examples of OpenAPI 3.0 definitions for your API, please publish them to Github and share with me, so I can help point folks to examples in the wild that they can learn from as we make this shift.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/openapi_30_converter.png"
  },
  {
  "title": "Playing With Different Views For An OpenAPI Diff Tool",
  "date": "13 Apr 2017",
  "body": "<br />I am working on version 1.1 of the API definition&amp;nbsp;for the human services data specification (HSDS), and I needed some help articulating the differences between version 1.0 and 1.1, which are both defined using the OpenAPI 2.0 specification. I manage all of my OpenAPIs using Github, but I needed a friendlier way to show the diff between two JSON files, than what Github provides. I got to work on a version that would run using Liquid, that would work in Jekyll, which all my sites and tools run in.<br />I have a variety of API documentation tools that run on Github, so I wanted to develop an interface that showed two separate OpenAPI definitions side by side on a simple HTML page, so at this stage, Im playing with different ways of showing the differences between paths, and other elements of the API definition. I&#39;m not entirely happy with what I have, but I started applying a red DIFF label to any path that isn&#39;t represented in the previous API definition. It works well for helping me see which API endpoints have been added or changed in the latest version.<br />Currently, I am just looking to understand the differences in paths available, but I will be diff for headers, parameters, and other elements of the API definition. I&#39;m worried about things getting too cluttered with bigger API definitions. I&#39;m trying to keep things fast loading, and something I can work with non-developers on, so I want to be thoughtful about what I add, and how I add it to the layout. I&#39;m looking to get a group of business users up to speed on where things are going with the spec, and encourage them to get more involved with future versions--so not scaring them off is an important part of this conversation.<br />I am finding Jekyll, Liquid, and HTML, with a little JavaScript when necessary to be a perfect medium for developing OpenAPI tooling on top of. It provides a simple, static, and a flexible way to craft API tooling, that can be forked by anyone. As my proficiency with Liquid evolves, I&#39;m getting better at making it work with OpenAPI YAML which is mounted via Jekyll. With everything operating on Github, version control and API access to all my files are adding a valuable layer to my work. Now that I have several of these types of tools available, also I need to get more organized about how I&#39;m evolving the&amp;nbsp;code&amp;nbsp;and maintaining a catalog of these offerings so that others can put to use in their API operations.m playing with different ways of showing the differences between paths, and other elements of the API definition. Im not entirely happy with what I have, but I started applying a red DIFF label to any path that isn&#39;t represented in the previous API definition. It works well for helping me see which API endpoints have been added or changed in the latest version.<br />Currently, I am just looking to understand the differences in paths available, but I will be diff for headers, parameters, and other elements of the API definition. I&#39;m worried about things getting too cluttered with bigger API definitions. I&#39;m trying to keep things fast loading, and something I can work with non-developers on, so I want to be thoughtful about what I add, and how I add it to the layout. I&#39;m looking to get a group of business users up to speed on where things are going with the spec, and encourage them to get more involved with future versions--so not scaring them off is an important part of this conversation.<br />I am finding Jekyll, Liquid, and HTML, with a little JavaScript when necessary to be a perfect medium for developing OpenAPI tooling on top of. It provides a simple, static, and a flexible way to craft API tooling, that can be forked by anyone. As my proficiency with Liquid evolves, I&#39;m getting better at making it work with OpenAPI YAML which is mounted via Jekyll. With everything operating on Github, version control and API access to all my files are adding a valuable layer to my work. Now that I have several of these types of tools available, also I need to get more organized about how I&#39;m evolving the&amp;nbsp;code&amp;nbsp;and maintaining a catalog of these offerings so that others can put to use in their API operations.m not entirely happy with what I have, but I started applying a red DIFF label to any path that isnt represented in the previous API definition. It works well for helping me see which API endpoints have been added or changed in the latest version.<br />Currently, I am just looking to understand the differences in paths available, but I will be diff for headers, parameters, and other elements of the API definition. I&#39;m worried about things getting too cluttered with bigger API definitions. I&#39;m trying to keep things fast loading, and something I can work with non-developers on, so I want to be thoughtful about what I add, and how I add it to the layout. I&#39;m looking to get a group of business users up to speed on where things are going with the spec, and encourage them to get more involved with future versions--so not scaring them off is an important part of this conversation.<br />I am finding Jekyll, Liquid, and HTML, with a little JavaScript when necessary to be a perfect medium for developing OpenAPI tooling on top of. It provides a simple, static, and a flexible way to craft API tooling, that can be forked by anyone. As my proficiency with Liquid evolves, I&#39;m getting better at making it work with OpenAPI YAML which is mounted via Jekyll. With everything operating on Github, version control and API access to all my files are adding a valuable layer to my work. Now that I have several of these types of tools available, also I need to get more organized about how I&#39;m evolving the&amp;nbsp;code&amp;nbsp;and maintaining a catalog of these offerings so that others can put to use in their API operations.t represented in the previous API definition. It works well for helping me see which API endpoints have been added or changed in the latest version.<br />Currently, I am just looking to understand the differences in paths available, but I will be diff for headers, parameters, and other elements of the API definition. Im worried about things getting too cluttered with bigger API definitions. I&#39;m trying to keep things fast loading, and something I can work with non-developers on, so I want to be thoughtful about what I add, and how I add it to the layout. I&#39;m looking to get a group of business users up to speed on where things are going with the spec, and encourage them to get more involved with future versions--so not scaring them off is an important part of this conversation.<br />I am finding Jekyll, Liquid, and HTML, with a little JavaScript when necessary to be a perfect medium for developing OpenAPI tooling on top of. It provides a simple, static, and a flexible way to craft API tooling, that can be forked by anyone. As my proficiency with Liquid evolves, I&#39;m getting better at making it work with OpenAPI YAML which is mounted via Jekyll. With everything operating on Github, version control and API access to all my files are adding a valuable layer to my work. Now that I have several of these types of tools available, also I need to get more organized about how I&#39;m evolving the&amp;nbsp;code&amp;nbsp;and maintaining a catalog of these offerings so that others can put to use in their API operations.m worried about things getting too cluttered with bigger API definitions. Im trying to keep things fast loading, and something I can work with non-developers on, so I want to be thoughtful about what I add, and how I add it to the layout. I&#39;m looking to get a group of business users up to speed on where things are going with the spec, and encourage them to get more involved with future versions--so not scaring them off is an important part of this conversation.<br />I am finding Jekyll, Liquid, and HTML, with a little JavaScript when necessary to be a perfect medium for developing OpenAPI tooling on top of. It provides a simple, static, and a flexible way to craft API tooling, that can be forked by anyone. As my proficiency with Liquid evolves, I&#39;m getting better at making it work with OpenAPI YAML which is mounted via Jekyll. With everything operating on Github, version control and API access to all my files are adding a valuable layer to my work. Now that I have several of these types of tools available, also I need to get more organized about how I&#39;m evolving the&amp;nbsp;code&amp;nbsp;and maintaining a catalog of these offerings so that others can put to use in their API operations.m trying to keep things fast loading, and something I can work with non-developers on, so I want to be thoughtful about what I add, and how I add it to the layout. Im looking to get a group of business users up to speed on where things are going with the spec, and encourage them to get more involved with future versions--so not scaring them off is an important part of this conversation.<br />I am finding Jekyll, Liquid, and HTML, with a little JavaScript when necessary to be a perfect medium for developing OpenAPI tooling on top of. It provides a simple, static, and a flexible way to craft API tooling, that can be forked by anyone. As my proficiency with Liquid evolves, I&#39;m getting better at making it work with OpenAPI YAML which is mounted via Jekyll. With everything operating on Github, version control and API access to all my files are adding a valuable layer to my work. Now that I have several of these types of tools available, also I need to get more organized about how I&#39;m evolving the&amp;nbsp;code&amp;nbsp;and maintaining a catalog of these offerings so that others can put to use in their API operations.m looking to get a group of business users up to speed on where things are going with the spec, and encourage them to get more involved with future versions--so not scaring them off is an important part of this conversation.<br />I am finding Jekyll, Liquid, and HTML, with a little JavaScript when necessary to be a perfect medium for developing OpenAPI tooling on top of. It provides a simple, static, and a flexible way to craft API tooling, that can be forked by anyone. As my proficiency with Liquid evolves, Im getting better at making it work with OpenAPI YAML which is mounted via Jekyll. With everything operating on Github, version control and API access to all my files are adding a valuable layer to my work. Now that I have several of these types of tools available, also I need to get more organized about how I&#39;m evolving the&amp;nbsp;code&amp;nbsp;and maintaining a catalog of these offerings so that others can put to use in their API operations.m getting better at making it work with OpenAPI YAML which is mounted via Jekyll. With everything operating on Github, version control and API access to all my files are adding a valuable layer to my work. Now that I have several of these types of tools available, also I need to get more organized about how Im evolving the&amp;nbsp;code&amp;nbsp;and maintaining a catalog of these offerings so that others can put to use in their API operations.m evolving the&amp;nbsp;code&amp;nbsp;and maintaining a catalog of these offerings so that others can put to use in their API operations.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/openapi_diff.png"
  },
  {
  "title": "Open Source Drag And Drop API Lifecycle Design Tooling",
  "date": "12 Apr 2017",
  "body": "<br />Im always on the hunt for new ways to define, design, deploy, and manage API infrastructure, and thought the AWS Cloud Formation Designer provides a nice look at where things might be headed.&amp;nbsp;AWS CloudFormation Designer (Designer) is a graphic tool for creating, viewing, and modifying AWS CloudFormation templates, which translates pretty nicely to managing your API infrastructure as well.<br />While the AWS Cloud Formation Designer spans all AWS services, all the elements are there for managing all the core stops along the API life cycle liked definition, design, DNS, deployment, management, monitoring, and others. Each of the Amazon services is available with a listing of each element available for the service, complete with all the inputs and outputs as connectors on the icons. Since all the AWS services are APIs, it&#39;s basically a drag and drop interface for mapping out how you use these APIs to define, design, deploy and manage your API infrastructure.<br />Using the design tool you can create templates for governing the deployment and management of API infrastructure&amp;nbsp;by your team, partners, and other customers. This approach to defining the API life cycle is the closest I&#39;ve seen to what stimulated my API subway map work, which became&amp;nbsp;the subject of my keynotes at APIStrat in Austin, TX. It allows API architects and providers to templatize their approaches to delivering API infrastructure, in a way that is plug and play, and evolvable using the underlying JSON or YAML templates--right alongside the OpenAPI templates, we are crafting for each individual API.<br />The&amp;nbsp;AWS Cloud Formation Designer is a drag and drop UI for the entire AWS API stack. It is something that could easily be applied to Google&#39;s API stack, Microsoft, or any other stack you define--something that could easily be done using APIs.json, developing another layer of templating for which resource types are available in the designer, as well as the formation templates generated by the design tool itself. There should be an open source API formation designer available, that could span cloud providers, allowing architects to define which resources are available in their toolbox--that anyone could fork and run in their environment.<br />I like where AWS is headed with their&amp;nbsp;Cloud Formation Designer. It&#39;s another approach to providing full lifecycle tooling for use in the API space. It almost reminds me of Yahoo Pipes for the AWS Cloud, which triggers awkward feels for me. I&#39;m hoping it is a glimpse of what&#39;s to come, and someone steps up with an even more attractive drag and drop version, that helps folks work with API-driven&amp;nbsp;infrastructure no matter where it runs--maybe Google will get to work on something. They seem to be real big on supporting infrastructure that runs in any cloud environment. *wink wink*m always on the hunt for new ways to define, design, deploy, and manage API infrastructure, and thought the AWS Cloud Formation Designer provides a nice look at where things might be headed.&amp;nbsp;AWS CloudFormation Designer (Designer) is a graphic tool for creating, viewing, and modifying AWS CloudFormation templates, which translates pretty nicely to managing your API infrastructure as well.<br />While the AWS Cloud Formation Designer spans all AWS services, all the elements are there for managing all the core stops along the API life cycle liked definition, design, DNS, deployment, management, monitoring, and others. Each of the Amazon services is available with a listing of each element available for the service, complete with all the inputs and outputs as connectors on the icons. Since all the AWS services are APIs, its basically a drag and drop interface for mapping out how you use these APIs to define, design, deploy and manage your API infrastructure.<br />Using the design tool you can create templates for governing the deployment and management of API infrastructure&amp;nbsp;by your team, partners, and other customers. This approach to defining the API life cycle is the closest I&#39;ve seen to what stimulated my API subway map work, which became&amp;nbsp;the subject of my keynotes at APIStrat in Austin, TX. It allows API architects and providers to templatize their approaches to delivering API infrastructure, in a way that is plug and play, and evolvable using the underlying JSON or YAML templates--right alongside the OpenAPI templates, we are crafting for each individual API.<br />The&amp;nbsp;AWS Cloud Formation Designer is a drag and drop UI for the entire AWS API stack. It is something that could easily be applied to Google&#39;s API stack, Microsoft, or any other stack you define--something that could easily be done using APIs.json, developing another layer of templating for which resource types are available in the designer, as well as the formation templates generated by the design tool itself. There should be an open source API formation designer available, that could span cloud providers, allowing architects to define which resources are available in their toolbox--that anyone could fork and run in their environment.<br />I like where AWS is headed with their&amp;nbsp;Cloud Formation Designer. It&#39;s another approach to providing full lifecycle tooling for use in the API space. It almost reminds me of Yahoo Pipes for the AWS Cloud, which triggers awkward feels for me. I&#39;m hoping it is a glimpse of what&#39;s to come, and someone steps up with an even more attractive drag and drop version, that helps folks work with API-driven&amp;nbsp;infrastructure no matter where it runs--maybe Google will get to work on something. They seem to be real big on supporting infrastructure that runs in any cloud environment. *wink wink*s basically a drag and drop interface for mapping out how you use these APIs to define, design, deploy and manage your API infrastructure.<br />Using the design tool you can create templates for governing the deployment and management of API infrastructure&amp;nbsp;by your team, partners, and other customers. This approach to defining the API life cycle is the closest Ive seen to what stimulated my API subway map work, which became&amp;nbsp;the subject of my keynotes at APIStrat in Austin, TX. It allows API architects and providers to templatize their approaches to delivering API infrastructure, in a way that is plug and play, and evolvable using the underlying JSON or YAML templates--right alongside the OpenAPI templates, we are crafting for each individual API.<br />The&amp;nbsp;AWS Cloud Formation Designer is a drag and drop UI for the entire AWS API stack. It is something that could easily be applied to Google&#39;s API stack, Microsoft, or any other stack you define--something that could easily be done using APIs.json, developing another layer of templating for which resource types are available in the designer, as well as the formation templates generated by the design tool itself. There should be an open source API formation designer available, that could span cloud providers, allowing architects to define which resources are available in their toolbox--that anyone could fork and run in their environment.<br />I like where AWS is headed with their&amp;nbsp;Cloud Formation Designer. It&#39;s another approach to providing full lifecycle tooling for use in the API space. It almost reminds me of Yahoo Pipes for the AWS Cloud, which triggers awkward feels for me. I&#39;m hoping it is a glimpse of what&#39;s to come, and someone steps up with an even more attractive drag and drop version, that helps folks work with API-driven&amp;nbsp;infrastructure no matter where it runs--maybe Google will get to work on something. They seem to be real big on supporting infrastructure that runs in any cloud environment. *wink wink*ve seen to what stimulated my API subway map work, which became&amp;nbsp;the subject of my keynotes at APIStrat in Austin, TX. It allows API architects and providers to templatize their approaches to delivering API infrastructure, in a way that is plug and play, and evolvable using the underlying JSON or YAML templates--right alongside the OpenAPI templates, we are crafting for each individual API.<br />The&amp;nbsp;AWS Cloud Formation Designer is a drag and drop UI for the entire AWS API stack. It is something that could easily be applied to Googles API stack, Microsoft, or any other stack you define--something that could easily be done using APIs.json, developing another layer of templating for which resource types are available in the designer, as well as the formation templates generated by the design tool itself. There should be an open source API formation designer available, that could span cloud providers, allowing architects to define which resources are available in their toolbox--that anyone could fork and run in their environment.<br />I like where AWS is headed with their&amp;nbsp;Cloud Formation Designer. It&#39;s another approach to providing full lifecycle tooling for use in the API space. It almost reminds me of Yahoo Pipes for the AWS Cloud, which triggers awkward feels for me. I&#39;m hoping it is a glimpse of what&#39;s to come, and someone steps up with an even more attractive drag and drop version, that helps folks work with API-driven&amp;nbsp;infrastructure no matter where it runs--maybe Google will get to work on something. They seem to be real big on supporting infrastructure that runs in any cloud environment. *wink wink*s API stack, Microsoft, or any other stack you define--something that could easily be done using APIs.json, developing another layer of templating for which resource types are available in the designer, as well as the formation templates generated by the design tool itself. There should be an open source API formation designer available, that could span cloud providers, allowing architects to define which resources are available in their toolbox--that anyone could fork and run in their environment.<br />I like where AWS is headed with their&amp;nbsp;Cloud Formation Designer. Its another approach to providing full lifecycle tooling for use in the API space. It almost reminds me of Yahoo Pipes for the AWS Cloud, which triggers awkward feels for me. I&#39;m hoping it is a glimpse of what&#39;s to come, and someone steps up with an even more attractive drag and drop version, that helps folks work with API-driven&amp;nbsp;infrastructure no matter where it runs--maybe Google will get to work on something. They seem to be real big on supporting infrastructure that runs in any cloud environment. *wink wink*s another approach to providing full lifecycle tooling for use in the API space. It almost reminds me of Yahoo Pipes for the AWS Cloud, which triggers awkward feels for me. Im hoping it is a glimpse of what&#39;s to come, and someone steps up with an even more attractive drag and drop version, that helps folks work with API-driven&amp;nbsp;infrastructure no matter where it runs--maybe Google will get to work on something. They seem to be real big on supporting infrastructure that runs in any cloud environment. *wink wink*m hoping it is a glimpse of whats to come, and someone steps up with an even more attractive drag and drop version, that helps folks work with API-driven&amp;nbsp;infrastructure no matter where it runs--maybe Google will get to work on something. They seem to be real big on supporting infrastructure that runs in any cloud environment. *wink wink*s to come, and someone steps up with an even more attractive drag and drop version, that helps folks work with API-driven&amp;nbsp;infrastructure no matter where it runs--maybe Google will get to work on something. They seem to be real big on supporting infrastructure that runs in any cloud environment. *wink wink*",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/aws_cloud_formation_designer.png"
  },
  {
  "title": "What Questions Would You Ask Across 50K API Definitions?",
  "date": "11 Apr 2017",
  "body": "<br />Mike Ralphson&amp;rlm; (@PermittedSoc) asked me the other day, if you could run SQL / #GraphQL queries over nearly 50K #API definitions, what would you ask?. I told him I would respond via blog post, which is one way I help amplify the conversation I have with other API folks in the space. Mike is doing som important work when it comes to API discovery, something that needs amplification&amp;nbsp;if we are going to move this conversation forward.<br />Ok, so what would I ask of nearly 50K API definitions, if I had the opportunity to ask? Here are some of my answers:<br /><br />What are all the paths used? - Id like to see a list of all path folders, separated by the&amp;nbsp;forward slash, minus any parameters.<br />What paths folders&amp;nbsp;actually are words? - I&#39;d like to know how coherent API design patterns are, and how many are actually words in a dictionary.&amp;nbsp;<br />What are all the tags applied? - A listing of all tags applied to APIs, with counts for each time it is used.<br />What are all the parameters? - A listing of all the parameters applied to APIs, with counts for each used.<br />What are all the definitions - A listing of all definitions used as part of API requests and responses, with counts next to each.<br />How many don&#39;t have definitions? What percentage of the API definitions do not have definitions describing their responses<br />What businesses are involved?&amp;nbsp;- A listing of all companies involved with API definitions from contact information to domain ownership.<br />What is whois information behind each domain(s)? - Pull whois information for all the domains involved in API definitions.<br />Which definitions do not have path summary or description? - Which definitions have omitted the description for the path.<br />What&#39;s&amp;nbsp;the average length of path summary and descriptions? - Of the definitions with a description or summary, what is the average length?<br />How many APIs provide a link to terms of service? - Checking to see if a term of service is part of the definition.<br />How many APIs provide contact information for an API?&amp;nbsp;- Checking to see if contact information is part of the definition.<br />How many APIs describe their headers? - Looking for specific headers described as part of each path definition.<br />How many APIs use the body as part of their request? - Looking for heavy body use as part of the request surface area of an API.<br />How many APIs have a security definition? - Which of the APIs has provided a definition for how an API is secured?<br />How many APIs do not use response codes? - Which of the APIs do not provide response codes for their API responses?<br />Which API response HTTP status codes used? - Provide a list of API response HTTP status codes used, with counts for each.<br /><br />That is a starting list of what I&#39;d like to ask of 50K API definitions. It is something I&#39;d have to think and write about more to be able to come up with more creative questions. I recommend publishing them all to a Github repository and let people start asking questions via an interface. You might not be able to answer all of the questions, but it would be interesting to see what people want to know--I am sure you could develop a pretty interesting look at how folks see API discovery, and what they are looking for.<br />API discovery is one of the areas of the API life cycle that is pretty deficient due to how people view their APIs and how they often have their blinders on regarding the wider API community. Most folks are thinking about their APIs, and maybe a handful of other APIs they are familiar with but do not consider API usage across industries, or the entire space. We need more work like this to occur. We need more API definitions to be made available, as well as more dynamic ways for folks to discover, understand and learn about APIs that already exist.d like to see a list of all path folders, separated by the&amp;nbsp;forward slash, minus any parameters.<br />What paths folders&amp;nbsp;actually are words? - Id like to know how coherent API design patterns are, and how many are actually words in a dictionary.&amp;nbsp;<br />What are all the tags applied? - A listing of all tags applied to APIs, with counts for each time it is used.<br />What are all the parameters? - A listing of all the parameters applied to APIs, with counts for each used.<br />What are all the definitions - A listing of all definitions used as part of API requests and responses, with counts next to each.<br />How many don&#39;t have definitions? What percentage of the API definitions do not have definitions describing their responses<br />What businesses are involved?&amp;nbsp;- A listing of all companies involved with API definitions from contact information to domain ownership.<br />What is whois information behind each domain(s)? - Pull whois information for all the domains involved in API definitions.<br />Which definitions do not have path summary or description? - Which definitions have omitted the description for the path.<br />What&#39;s&amp;nbsp;the average length of path summary and descriptions? - Of the definitions with a description or summary, what is the average length?<br />How many APIs provide a link to terms of service? - Checking to see if a term of service is part of the definition.<br />How many APIs provide contact information for an API?&amp;nbsp;- Checking to see if contact information is part of the definition.<br />How many APIs describe their headers? - Looking for specific headers described as part of each path definition.<br />How many APIs use the body as part of their request? - Looking for heavy body use as part of the request surface area of an API.<br />How many APIs have a security definition? - Which of the APIs has provided a definition for how an API is secured?<br />How many APIs do not use response codes? - Which of the APIs do not provide response codes for their API responses?<br />Which API response HTTP status codes used? - Provide a list of API response HTTP status codes used, with counts for each.<br /><br />That is a starting list of what I&#39;d like to ask of 50K API definitions. It is something I&#39;d have to think and write about more to be able to come up with more creative questions. I recommend publishing them all to a Github repository and let people start asking questions via an interface. You might not be able to answer all of the questions, but it would be interesting to see what people want to know--I am sure you could develop a pretty interesting look at how folks see API discovery, and what they are looking for.<br />API discovery is one of the areas of the API life cycle that is pretty deficient due to how people view their APIs and how they often have their blinders on regarding the wider API community. Most folks are thinking about their APIs, and maybe a handful of other APIs they are familiar with but do not consider API usage across industries, or the entire space. We need more work like this to occur. We need more API definitions to be made available, as well as more dynamic ways for folks to discover, understand and learn about APIs that already exist.d like to know how coherent API design patterns are, and how many are actually words in a dictionary.&amp;nbsp;<br />What are all the tags applied? - A listing of all tags applied to APIs, with counts for each time it is used.<br />What are all the parameters? - A listing of all the parameters applied to APIs, with counts for each used.<br />What are all the definitions - A listing of all definitions used as part of API requests and responses, with counts next to each.<br />How many dont have definitions? What percentage of the API definitions do not have definitions describing their responses<br />What businesses are involved?&amp;nbsp;- A listing of all companies involved with API definitions from contact information to domain ownership.<br />What is whois information behind each domain(s)? - Pull whois information for all the domains involved in API definitions.<br />Which definitions do not have path summary or description? - Which definitions have omitted the description for the path.<br />What&#39;s&amp;nbsp;the average length of path summary and descriptions? - Of the definitions with a description or summary, what is the average length?<br />How many APIs provide a link to terms of service? - Checking to see if a term of service is part of the definition.<br />How many APIs provide contact information for an API?&amp;nbsp;- Checking to see if contact information is part of the definition.<br />How many APIs describe their headers? - Looking for specific headers described as part of each path definition.<br />How many APIs use the body as part of their request? - Looking for heavy body use as part of the request surface area of an API.<br />How many APIs have a security definition? - Which of the APIs has provided a definition for how an API is secured?<br />How many APIs do not use response codes? - Which of the APIs do not provide response codes for their API responses?<br />Which API response HTTP status codes used? - Provide a list of API response HTTP status codes used, with counts for each.<br /><br />That is a starting list of what I&#39;d like to ask of 50K API definitions. It is something I&#39;d have to think and write about more to be able to come up with more creative questions. I recommend publishing them all to a Github repository and let people start asking questions via an interface. You might not be able to answer all of the questions, but it would be interesting to see what people want to know--I am sure you could develop a pretty interesting look at how folks see API discovery, and what they are looking for.<br />API discovery is one of the areas of the API life cycle that is pretty deficient due to how people view their APIs and how they often have their blinders on regarding the wider API community. Most folks are thinking about their APIs, and maybe a handful of other APIs they are familiar with but do not consider API usage across industries, or the entire space. We need more work like this to occur. We need more API definitions to be made available, as well as more dynamic ways for folks to discover, understand and learn about APIs that already exist.t have definitions? What percentage of the API definitions do not have definitions describing their responses<br />What businesses are involved?&amp;nbsp;- A listing of all companies involved with API definitions from contact information to domain ownership.<br />What is whois information behind each domain(s)? - Pull whois information for all the domains involved in API definitions.<br />Which definitions do not have path summary or description? - Which definitions have omitted the description for the path.<br />Whats&amp;nbsp;the average length of path summary and descriptions? - Of the definitions with a description or summary, what is the average length?<br />How many APIs provide a link to terms of service? - Checking to see if a term of service is part of the definition.<br />How many APIs provide contact information for an API?&amp;nbsp;- Checking to see if contact information is part of the definition.<br />How many APIs describe their headers? - Looking for specific headers described as part of each path definition.<br />How many APIs use the body as part of their request? - Looking for heavy body use as part of the request surface area of an API.<br />How many APIs have a security definition? - Which of the APIs has provided a definition for how an API is secured?<br />How many APIs do not use response codes? - Which of the APIs do not provide response codes for their API responses?<br />Which API response HTTP status codes used? - Provide a list of API response HTTP status codes used, with counts for each.<br /><br />That is a starting list of what I&#39;d like to ask of 50K API definitions. It is something I&#39;d have to think and write about more to be able to come up with more creative questions. I recommend publishing them all to a Github repository and let people start asking questions via an interface. You might not be able to answer all of the questions, but it would be interesting to see what people want to know--I am sure you could develop a pretty interesting look at how folks see API discovery, and what they are looking for.<br />API discovery is one of the areas of the API life cycle that is pretty deficient due to how people view their APIs and how they often have their blinders on regarding the wider API community. Most folks are thinking about their APIs, and maybe a handful of other APIs they are familiar with but do not consider API usage across industries, or the entire space. We need more work like this to occur. We need more API definitions to be made available, as well as more dynamic ways for folks to discover, understand and learn about APIs that already exist.s&amp;nbsp;the average length of path summary and descriptions? - Of the definitions with a description or summary, what is the average length?<br />How many APIs provide a link to terms of service? - Checking to see if a term of service is part of the definition.<br />How many APIs provide contact information for an API?&amp;nbsp;- Checking to see if contact information is part of the definition.<br />How many APIs describe their headers? - Looking for specific headers described as part of each path definition.<br />How many APIs use the body as part of their request? - Looking for heavy body use as part of the request surface area of an API.<br />How many APIs have a security definition? - Which of the APIs has provided a definition for how an API is secured?<br />How many APIs do not use response codes? - Which of the APIs do not provide response codes for their API responses?<br />Which API response HTTP status codes used? - Provide a list of API response HTTP status codes used, with counts for each.<br /><br />That is a starting list of what Id like to ask of 50K API definitions. It is something I&#39;d have to think and write about more to be able to come up with more creative questions. I recommend publishing them all to a Github repository and let people start asking questions via an interface. You might not be able to answer all of the questions, but it would be interesting to see what people want to know--I am sure you could develop a pretty interesting look at how folks see API discovery, and what they are looking for.<br />API discovery is one of the areas of the API life cycle that is pretty deficient due to how people view their APIs and how they often have their blinders on regarding the wider API community. Most folks are thinking about their APIs, and maybe a handful of other APIs they are familiar with but do not consider API usage across industries, or the entire space. We need more work like this to occur. We need more API definitions to be made available, as well as more dynamic ways for folks to discover, understand and learn about APIs that already exist.d like to ask of 50K API definitions. It is something Id have to think and write about more to be able to come up with more creative questions. I recommend publishing them all to a Github repository and let people start asking questions via an interface. You might not be able to answer all of the questions, but it would be interesting to see what people want to know--I am sure you could develop a pretty interesting look at how folks see API discovery, and what they are looking for.<br />API discovery is one of the areas of the API life cycle that is pretty deficient due to how people view their APIs and how they often have their blinders on regarding the wider API community. Most folks are thinking about their APIs, and maybe a handful of other APIs they are familiar with but do not consider API usage across industries, or the entire space. We need more work like this to occur. We need more API definitions to be made available, as well as more dynamic ways for folks to discover, understand and learn about APIs that already exist.d have to think and write about more to be able to come up with more creative questions. I recommend publishing them all to a Github repository and let people start asking questions via an interface. You might not be able to answer all of the questions, but it would be interesting to see what people want to know--I am sure you could develop a pretty interesting look at how folks see API discovery, and what they are looking for.<br />API discovery is one of the areas of the API life cycle that is pretty deficient due to how people view their APIs and how they often have their blinders on regarding the wider API community. Most folks are thinking about their APIs, and maybe a handful of other APIs they are familiar with but do not consider API usage across industries, or the entire space. We need more work like this to occur. We need more API definitions to be made available, as well as more dynamic ways for folks to discover, understand and learn about APIs that already exist.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-question-mark.png"
  },
  {
  "title": "OpenAPI As An API Literacy Tool",
  "date": "11 Apr 2017",
  "body": "Ive been an advocate for OpenAPI since it&#39;s release, writing hundreds of stories about what is possible. I do not support OpenAPI because I think it is the perfect solution, I support it because I think it is the scaffolding for a bridge that will get us closer to a suitable solution for the world we have. I&#39;m always studying how people see OpenAPI, both positive and negative, in hopes of better crafting examples of it being used, and stories about what is possible with the specification.<br />When you ask people what OpenAPI is for, the most common answer is documentation. The second most common answer is for generating code and SDKs. People often associate documentation and code generation with OpenAPI because these were the first two tools that were developed on top of the API specification. I do not see much pushback from the folks who don&#39;t like OpenAPI when it comes to documentation, but when it comes to generating code, I regularly see folks criticizing the concept of generating code using OpenAPI definitions.<br />When I think about OpenAPI I think about a life cycle full of tools and services that can be delivered, with documentation and code generation being just two of them. I feel it is shortsighted to dismiss OpenAPI because it falls short in any single stop along the API lifecycle as I feel the most important role for OpenAPI is when it comes to API literacy--helping us craft, share, and teach API best practices.<br />OpenAPI, API Blueprint, and other API definition formats are the best way we currently have to define, share, and articulate APIs in a single document. Sure, a well-designed hypermedia API allows you to navigate, explore, and understand the surface area of an API, but how do you summarize that in a shareableÂ and collaborative document that can be also used for documentation, monitoring, testing, and other stops along the API life cycle.Â <br />I wish everybody could read the latest API design book and absorb the latest concepts for building the best API possible. Some folks learn this way, but in my experience, a significant segment of the community learn from seeing examples of API best practices in action. API definition formats allow us to describe the moving parts of an API request and response, which then provides an example that other API developers can follow when crafting their own APIs. I find that many people simply follow the API examples they are familiarÂ with, and OpenAPI allows us to easily craft and shares these examples for them to follow.<br />If we are going to do APIs at the scale we need to helpÂ folks craft RESTful web APIs, as well as hypermedia, GraphQL, and gRPC APIs. We need a way to define our APIs, and articulate this definition to our consumers, as well as to other API providers. This helps me remember to not get hung up on any single use of OpenAPI, and other API specification formats, because first and foremost, these formats help us with API literacy, which has wider implications than any single API implementation, or stops along the API life cycle.ve been an advocate for OpenAPI since its release, writing hundreds of stories about what is possible. I do not support OpenAPI because I think it is the perfect solution, I support it because I think it is the scaffolding for a bridge that will get us closer to a suitable solution for the world we have. I&#39;m always studying how people see OpenAPI, both positive and negative, in hopes of better crafting examples of it being used, and stories about what is possible with the specification.<br />When you ask people what OpenAPI is for, the most common answer is documentation. The second most common answer is for generating code and SDKs. People often associate documentation and code generation with OpenAPI because these were the first two tools that were developed on top of the API specification. I do not see much pushback from the folks who don&#39;t like OpenAPI when it comes to documentation, but when it comes to generating code, I regularly see folks criticizing the concept of generating code using OpenAPI definitions.<br />When I think about OpenAPI I think about a life cycle full of tools and services that can be delivered, with documentation and code generation being just two of them. I feel it is shortsighted to dismiss OpenAPI because it falls short in any single stop along the API lifecycle as I feel the most important role for OpenAPI is when it comes to API literacy--helping us craft, share, and teach API best practices.<br />OpenAPI, API Blueprint, and other API definition formats are the best way we currently have to define, share, and articulate APIs in a single document. Sure, a well-designed hypermedia API allows you to navigate, explore, and understand the surface area of an API, but how do you summarize that in a shareableÂ and collaborative document that can be also used for documentation, monitoring, testing, and other stops along the API life cycle.Â <br />I wish everybody could read the latest API design book and absorb the latest concepts for building the best API possible. Some folks learn this way, but in my experience, a significant segment of the community learn from seeing examples of API best practices in action. API definition formats allow us to describe the moving parts of an API request and response, which then provides an example that other API developers can follow when crafting their own APIs. I find that many people simply follow the API examples they are familiarÂ with, and OpenAPI allows us to easily craft and shares these examples for them to follow.<br />If we are going to do APIs at the scale we need to helpÂ folks craft RESTful web APIs, as well as hypermedia, GraphQL, and gRPC APIs. We need a way to define our APIs, and articulate this definition to our consumers, as well as to other API providers. This helps me remember to not get hung up on any single use of OpenAPI, and other API specification formats, because first and foremost, these formats help us with API literacy, which has wider implications than any single API implementation, or stops along the API life cycle.s release, writing hundreds of stories about what is possible. I do not support OpenAPI because I think it is the perfect solution, I support it because I think it is the scaffolding for a bridge that will get us closer to a suitable solution for the world we have. Im always studying how people see OpenAPI, both positive and negative, in hopes of better crafting examples of it being used, and stories about what is possible with the specification.<br />When you ask people what OpenAPI is for, the most common answer is documentation. The second most common answer is for generating code and SDKs. People often associate documentation and code generation with OpenAPI because these were the first two tools that were developed on top of the API specification. I do not see much pushback from the folks who don&#39;t like OpenAPI when it comes to documentation, but when it comes to generating code, I regularly see folks criticizing the concept of generating code using OpenAPI definitions.<br />When I think about OpenAPI I think about a life cycle full of tools and services that can be delivered, with documentation and code generation being just two of them. I feel it is shortsighted to dismiss OpenAPI because it falls short in any single stop along the API lifecycle as I feel the most important role for OpenAPI is when it comes to API literacy--helping us craft, share, and teach API best practices.<br />OpenAPI, API Blueprint, and other API definition formats are the best way we currently have to define, share, and articulate APIs in a single document. Sure, a well-designed hypermedia API allows you to navigate, explore, and understand the surface area of an API, but how do you summarize that in a shareableÂ and collaborative document that can be also used for documentation, monitoring, testing, and other stops along the API life cycle.Â <br />I wish everybody could read the latest API design book and absorb the latest concepts for building the best API possible. Some folks learn this way, but in my experience, a significant segment of the community learn from seeing examples of API best practices in action. API definition formats allow us to describe the moving parts of an API request and response, which then provides an example that other API developers can follow when crafting their own APIs. I find that many people simply follow the API examples they are familiarÂ with, and OpenAPI allows us to easily craft and shares these examples for them to follow.<br />If we are going to do APIs at the scale we need to helpÂ folks craft RESTful web APIs, as well as hypermedia, GraphQL, and gRPC APIs. We need a way to define our APIs, and articulate this definition to our consumers, as well as to other API providers. This helps me remember to not get hung up on any single use of OpenAPI, and other API specification formats, because first and foremost, these formats help us with API literacy, which has wider implications than any single API implementation, or stops along the API life cycle.m always studying how people see OpenAPI, both positive and negative, in hopes of better crafting examples of it being used, and stories about what is possible with the specification.<br />When you ask people what OpenAPI is for, the most common answer is documentation. The second most common answer is for generating code and SDKs. People often associate documentation and code generation with OpenAPI because these were the first two tools that were developed on top of the API specification. I do not see much pushback from the folks who dont like OpenAPI when it comes to documentation, but when it comes to generating code, I regularly see folks criticizing the concept of generating code using OpenAPI definitions.<br />When I think about OpenAPI I think about a life cycle full of tools and services that can be delivered, with documentation and code generation being just two of them. I feel it is shortsighted to dismiss OpenAPI because it falls short in any single stop along the API lifecycle as I feel the most important role for OpenAPI is when it comes to API literacy--helping us craft, share, and teach API best practices.<br />OpenAPI, API Blueprint, and other API definition formats are the best way we currently have to define, share, and articulate APIs in a single document. Sure, a well-designed hypermedia API allows you to navigate, explore, and understand the surface area of an API, but how do you summarize that in a shareableÂ and collaborative document that can be also used for documentation, monitoring, testing, and other stops along the API life cycle.Â <br />I wish everybody could read the latest API design book and absorb the latest concepts for building the best API possible. Some folks learn this way, but in my experience, a significant segment of the community learn from seeing examples of API best practices in action. API definition formats allow us to describe the moving parts of an API request and response, which then provides an example that other API developers can follow when crafting their own APIs. I find that many people simply follow the API examples they are familiarÂ with, and OpenAPI allows us to easily craft and shares these examples for them to follow.<br />If we are going to do APIs at the scale we need to helpÂ folks craft RESTful web APIs, as well as hypermedia, GraphQL, and gRPC APIs. We need a way to define our APIs, and articulate this definition to our consumers, as well as to other API providers. This helps me remember to not get hung up on any single use of OpenAPI, and other API specification formats, because first and foremost, these formats help us with API literacy, which has wider implications than any single API implementation, or stops along the API life cycle.t like OpenAPI when it comes to documentation, but when it comes to generating code, I regularly see folks criticizing the concept of generating code using OpenAPI definitions.<br />When I think about OpenAPI I think about a life cycle full of tools and services that can be delivered, with documentation and code generation being just two of them. I feel it is shortsighted to dismiss OpenAPI because it falls short in any single stop along the API lifecycle as I feel the most important role for OpenAPI is when it comes to API literacy--helping us craft, share, and teach API best practices.<br />OpenAPI, API Blueprint, and other API definition formats are the best way we currently have to define, share, and articulate APIs in a single document. Sure, a well-designed hypermedia API allows you to navigate, explore, and understand the surface area of an API, but how do you summarize that in a shareableÂ and collaborative document that can be also used for documentation, monitoring, testing, and other stops along the API life cycle.Â <br />I wish everybody could read the latest API design book and absorb the latest concepts for building the best API possible. Some folks learn this way, but in my experience, a significant segment of the community learn from seeing examples of API best practices in action. API definition formats allow us to describe the moving parts of an API request and response, which then provides an example that other API developers can follow when crafting their own APIs. I find that many people simply follow the API examples they are familiarÂ with, and OpenAPI allows us to easily craft and shares these examples for them to follow.<br />If we are going to do APIs at the scale we need to helpÂ folks craft RESTful web APIs, as well as hypermedia, GraphQL, and gRPC APIs. We need a way to define our APIs, and articulate this definition to our consumers, as well as to other API providers. This helps me remember to not get hung up on any single use of OpenAPI, and other API specification formats, because first and foremost, these formats help us with API literacy, which has wider implications than any single API implementation, or stops along the API life cycle.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/learning_tag_cloud.jpg"
  },
  {
  "title": "Taking A Look At The Stoplight API Spec Editor",
  "date": "31 Mar 2017",
  "body": "<br />Im keeping an eye on the different approaches by API service providers when it comes to providing API editors within their services and tooling. While I wish there was an open source GUI API editor out there, the closest thing we have is from these API service providers, and I am trying to track on what the best practices are so that when someone does step up and begin working on an open, embeddable solution, they can learn from my stories about what is working or not working across the space.<br />One example I think has characteristics that should be emulated is the API Spec Editor from Stoplight. The GUI editor lets you manage all the core elements of an OpenAPI like the general info, host, paths, and even the shared responses and parameters. They even provide what they call a CRUD builder where you paste the JSON schema, and they&#39;ll generate the common paths you will need to create, read, update, and delete your resources. Along the way you can also make calls to API endpoints using their interactive interface, helping ensure your API definition is actually in alignment with your API.<br />The Stoplight API Spec Editor bridges the process of defining your OpenAPI for your operations, with actually documenting and engaging with an API through an interactive client interface. I like this approach to coming at API design from multiple directions. Apiary first taught us that API definitions were about more than just documentation, and I think our API editors should keeping evolving on this concept, and allowing us to engage with any stops along the API life cycle&amp;nbsp;like we are seeing from API service providers like Restlet.<br />I&#39;m already keeping an eye on Restlet and APIMATIC&#39;s approach to providing a GUI API design editor within their solutions&amp;nbsp;and will keep an eye out on other providers as I have time. Like other areas of the API sector, I&#39;m hoping I can develop a list of best practices that any service provider can follow when developing their tools and services.m keeping an eye on the different approaches by API service providers when it comes to providing API editors within their services and tooling. While I wish there was an open source GUI API editor out there, the closest thing we have is from these API service providers, and I am trying to track on what the best practices are so that when someone does step up and begin working on an open, embeddable solution, they can learn from my stories about what is working or not working across the space.<br />One example I think has characteristics that should be emulated is the API Spec Editor from Stoplight. The GUI editor lets you manage all the core elements of an OpenAPI like the general info, host, paths, and even the shared responses and parameters. They even provide what they call a CRUD builder where you paste the JSON schema, and theyll generate the common paths you will need to create, read, update, and delete your resources. Along the way you can also make calls to API endpoints using their interactive interface, helping ensure your API definition is actually in alignment with your API.<br />The Stoplight API Spec Editor bridges the process of defining your OpenAPI for your operations, with actually documenting and engaging with an API through an interactive client interface. I like this approach to coming at API design from multiple directions. Apiary first taught us that API definitions were about more than just documentation, and I think our API editors should keeping evolving on this concept, and allowing us to engage with any stops along the API life cycle&amp;nbsp;like we are seeing from API service providers like Restlet.<br />I&#39;m already keeping an eye on Restlet and APIMATIC&#39;s approach to providing a GUI API design editor within their solutions&amp;nbsp;and will keep an eye out on other providers as I have time. Like other areas of the API sector, I&#39;m hoping I can develop a list of best practices that any service provider can follow when developing their tools and services.ll generate the common paths you will need to create, read, update, and delete your resources. Along the way you can also make calls to API endpoints using their interactive interface, helping ensure your API definition is actually in alignment with your API.<br />The Stoplight API Spec Editor bridges the process of defining your OpenAPI for your operations, with actually documenting and engaging with an API through an interactive client interface. I like this approach to coming at API design from multiple directions. Apiary first taught us that API definitions were about more than just documentation, and I think our API editors should keeping evolving on this concept, and allowing us to engage with any stops along the API life cycle&amp;nbsp;like we are seeing from API service providers like Restlet.<br />Im already keeping an eye on Restlet and APIMATIC&#39;s approach to providing a GUI API design editor within their solutions&amp;nbsp;and will keep an eye out on other providers as I have time. Like other areas of the API sector, I&#39;m hoping I can develop a list of best practices that any service provider can follow when developing their tools and services.m already keeping an eye on Restlet and APIMATICs approach to providing a GUI API design editor within their solutions&amp;nbsp;and will keep an eye out on other providers as I have time. Like other areas of the API sector, I&#39;m hoping I can develop a list of best practices that any service provider can follow when developing their tools and services.s approach to providing a GUI API design editor within their solutions&amp;nbsp;and will keep an eye out on other providers as I have time. Like other areas of the API sector, Im hoping I can develop a list of best practices that any service provider can follow when developing their tools and services.m hoping I can develop a list of best practices that any service provider can follow when developing their tools and services.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_31_at_2.40.15_pm.png"
  },
  {
  "title": "Learning To Use Our Words Better When Defining Our APIs",
  "date": "29 Mar 2017",
  "body": "<br />I am playing around with the Open API for the Oxford Dictionaries API, and Im struck by the importance of not just dictionaries like the Oxford Dictionaries, but also the importance of OpenAPI, and API providers defining their APIs like the Oxford folks have. While we aren&#39;t as far down the road as we are with the English dictionary, we are beginning to make progress when it comes to defining the paths, parameters, and other characteristics using OpenAPI, learning to speak and communicate in the digital world using APIs.<br />We use words to craft titles, paragraphs, outlines, and other ways that we communicatie in our personal and professional lives. We also use words to craft titles, paragraphs, outlines, collections, and other ways our systems our communicating in our personal and professional lives using the OpenAPI specification. In both these forms of communicating we are always trying to find just the right words, or series and orders of words to get across exactly the meaning we are looking for--we just have centuries of doing this when it comes writing and speaking, and only a decade or so of doing this with defining our digital resources using APIs.<br />Eventually, I&#39;d like to see entire dictionaries of JSON Schema, ALPS, or other machine readable specification, available by industry, and topic. The way we craft our API definitions and design our APIs often feels like we have barely learned to speak, let alone read or write. I&#39;d like to see more reuse of common dictionaries already in use by leading API providers, and I&#39;d like to see us get more thoughtful in how we express ourselves via our API definitions.  The most successful APIs I find out there don&#39;t just provide a machine readable interface, they provide an intuitive interface that makes sense to humans, while also being machine readable for use in other systems.<br />It feels like to me that we should integrating the Oxford Dictionaries API into our API design tooling, letting us suggest, autocomplete, and discover better ways to articulate the meaning behind our APIs. API design editors could use the Oxford Dictionaries API to help developers attach more precise meaning to the names of paths, parameters, and other aspects of defining our APIs, much like word processors have done for the last couple of decades. Most APIs I come across do not have any sort of coherent name, ordering, or structure, and the few that have deployed an OpenAPI or other machine readable format, often feel like cave writing, and lack any coherent structure, purpose, or meaning--we have a long, long way to go before our systems learn to communicate even at a 1st grade level.m struck by the importance of not just dictionaries like the Oxford Dictionaries, but also the importance of OpenAPI, and API providers defining their APIs like the Oxford folks have. While we arent as far down the road as we are with the English dictionary, we are beginning to make progress when it comes to defining the paths, parameters, and other characteristics using OpenAPI, learning to speak and communicate in the digital world using APIs.<br />We use words to craft titles, paragraphs, outlines, and other ways that we communicatie in our personal and professional lives. We also use words to craft titles, paragraphs, outlines, collections, and other ways our systems our communicating in our personal and professional lives using the OpenAPI specification. In both these forms of communicating we are always trying to find just the right words, or series and orders of words to get across exactly the meaning we are looking for--we just have centuries of doing this when it comes writing and speaking, and only a decade or so of doing this with defining our digital resources using APIs.<br />Eventually, I&#39;d like to see entire dictionaries of JSON Schema, ALPS, or other machine readable specification, available by industry, and topic. The way we craft our API definitions and design our APIs often feels like we have barely learned to speak, let alone read or write. I&#39;d like to see more reuse of common dictionaries already in use by leading API providers, and I&#39;d like to see us get more thoughtful in how we express ourselves via our API definitions.  The most successful APIs I find out there don&#39;t just provide a machine readable interface, they provide an intuitive interface that makes sense to humans, while also being machine readable for use in other systems.<br />It feels like to me that we should integrating the Oxford Dictionaries API into our API design tooling, letting us suggest, autocomplete, and discover better ways to articulate the meaning behind our APIs. API design editors could use the Oxford Dictionaries API to help developers attach more precise meaning to the names of paths, parameters, and other aspects of defining our APIs, much like word processors have done for the last couple of decades. Most APIs I come across do not have any sort of coherent name, ordering, or structure, and the few that have deployed an OpenAPI or other machine readable format, often feel like cave writing, and lack any coherent structure, purpose, or meaning--we have a long, long way to go before our systems learn to communicate even at a 1st grade level.t as far down the road as we are with the English dictionary, we are beginning to make progress when it comes to defining the paths, parameters, and other characteristics using OpenAPI, learning to speak and communicate in the digital world using APIs.<br />We use words to craft titles, paragraphs, outlines, and other ways that we communicatie in our personal and professional lives. We also use words to craft titles, paragraphs, outlines, collections, and other ways our systems our communicating in our personal and professional lives using the OpenAPI specification. In both these forms of communicating we are always trying to find just the right words, or series and orders of words to get across exactly the meaning we are looking for--we just have centuries of doing this when it comes writing and speaking, and only a decade or so of doing this with defining our digital resources using APIs.<br />Eventually, Id like to see entire dictionaries of JSON Schema, ALPS, or other machine readable specification, available by industry, and topic. The way we craft our API definitions and design our APIs often feels like we have barely learned to speak, let alone read or write. I&#39;d like to see more reuse of common dictionaries already in use by leading API providers, and I&#39;d like to see us get more thoughtful in how we express ourselves via our API definitions.  The most successful APIs I find out there don&#39;t just provide a machine readable interface, they provide an intuitive interface that makes sense to humans, while also being machine readable for use in other systems.<br />It feels like to me that we should integrating the Oxford Dictionaries API into our API design tooling, letting us suggest, autocomplete, and discover better ways to articulate the meaning behind our APIs. API design editors could use the Oxford Dictionaries API to help developers attach more precise meaning to the names of paths, parameters, and other aspects of defining our APIs, much like word processors have done for the last couple of decades. Most APIs I come across do not have any sort of coherent name, ordering, or structure, and the few that have deployed an OpenAPI or other machine readable format, often feel like cave writing, and lack any coherent structure, purpose, or meaning--we have a long, long way to go before our systems learn to communicate even at a 1st grade level.d like to see entire dictionaries of JSON Schema, ALPS, or other machine readable specification, available by industry, and topic. The way we craft our API definitions and design our APIs often feels like we have barely learned to speak, let alone read or write. Id like to see more reuse of common dictionaries already in use by leading API providers, and I&#39;d like to see us get more thoughtful in how we express ourselves via our API definitions.  The most successful APIs I find out there don&#39;t just provide a machine readable interface, they provide an intuitive interface that makes sense to humans, while also being machine readable for use in other systems.<br />It feels like to me that we should integrating the Oxford Dictionaries API into our API design tooling, letting us suggest, autocomplete, and discover better ways to articulate the meaning behind our APIs. API design editors could use the Oxford Dictionaries API to help developers attach more precise meaning to the names of paths, parameters, and other aspects of defining our APIs, much like word processors have done for the last couple of decades. Most APIs I come across do not have any sort of coherent name, ordering, or structure, and the few that have deployed an OpenAPI or other machine readable format, often feel like cave writing, and lack any coherent structure, purpose, or meaning--we have a long, long way to go before our systems learn to communicate even at a 1st grade level.d like to see more reuse of common dictionaries already in use by leading API providers, and Id like to see us get more thoughtful in how we express ourselves via our API definitions.  The most successful APIs I find out there don&#39;t just provide a machine readable interface, they provide an intuitive interface that makes sense to humans, while also being machine readable for use in other systems.<br />It feels like to me that we should integrating the Oxford Dictionaries API into our API design tooling, letting us suggest, autocomplete, and discover better ways to articulate the meaning behind our APIs. API design editors could use the Oxford Dictionaries API to help developers attach more precise meaning to the names of paths, parameters, and other aspects of defining our APIs, much like word processors have done for the last couple of decades. Most APIs I come across do not have any sort of coherent name, ordering, or structure, and the few that have deployed an OpenAPI or other machine readable format, often feel like cave writing, and lack any coherent structure, purpose, or meaning--we have a long, long way to go before our systems learn to communicate even at a 1st grade level.d like to see us get more thoughtful in how we express ourselves via our API definitions.  The most successful APIs I find out there dont just provide a machine readable interface, they provide an intuitive interface that makes sense to humans, while also being machine readable for use in other systems.<br />It feels like to me that we should integrating the Oxford Dictionaries API into our API design tooling, letting us suggest, autocomplete, and discover better ways to articulate the meaning behind our APIs. API design editors could use the Oxford Dictionaries API to help developers attach more precise meaning to the names of paths, parameters, and other aspects of defining our APIs, much like word processors have done for the last couple of decades. Most APIs I come across do not have any sort of coherent name, ordering, or structure, and the few that have deployed an OpenAPI or other machine readable format, often feel like cave writing, and lack any coherent structure, purpose, or meaning--we have a long, long way to go before our systems learn to communicate even at a 1st grade level.t just provide a machine readable interface, they provide an intuitive interface that makes sense to humans, while also being machine readable for use in other systems.<br />It feels like to me that we should integrating the Oxford Dictionaries API into our API design tooling, letting us suggest, autocomplete, and discover better ways to articulate the meaning behind our APIs. API design editors could use the Oxford Dictionaries API to help developers attach more precise meaning to the names of paths, parameters, and other aspects of defining our APIs, much like word processors have done for the last couple of decades. Most APIs I come across do not have any sort of coherent name, ordering, or structure, and the few that have deployed an OpenAPI or other machine readable format, often feel like cave writing, and lack any coherent structure, purpose, or meaning--we have a long, long way to go before our systems learn to communicate even at a 1st grade level.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/oxford_dictionaries_api_home_screenshot.png"
  },
  {
  "title": "Helping Your Customers Operate Throughout The API LIfe Cycle",
  "date": "29 Mar 2017",
  "body": "<br />When I started API Evangelist back in 2010 the only stop along the API life cycle that service providers were talking about was API management. In 2017, there are numerous stops along the API life cycle from design, to testing, all the way to deprecation. The leading API providers are expanding the number of stops they service, and the smart ones are making sure that if they only service on or two stops, they do so by providing via API definitions like OpenAPI, ensuring their customers are able to seamlessly weave multiple service providers together to address their full life cycle of needs.<br />Ive been working with my partner Restlet to advise them on expanding their platform to be what I consider to be an API life cycle provider. When I first was introduced to Restlet they were the original open source enterprise grade API deployment framework. Then Restlet became a cloud API deployment and management provider, and with their acquisition of DHC they also became an API client, and testing provider. Now with their latest update, they have worked hard to help their developer and business customers service almost every stop along a modern API life cycle, from design to deprecation.<br />While Restlet is developing tooling to help companies define what the API life cycle means to them, the heartbeat of what Restlet delivers centers around API definitions like OpenAPI and RAML. API definitions provide the framework when your designing, deploying, documenting, managing, and testing your APIs using Restlet. They also provide the ability for you to get your API definitions in and out of the platform, and load them into potentially other API services, allow API operators to get what they need done. In my opinion, making API definitions just as importan tas any other service or tooling you offer along the API life cycle.<br />Serving a single or handful of stops along the API life cycle can be today&#39;s version of vendor lockin. If your customers cannot easily load their API definitions in and out of your system you are locking them in, and while they may stay with you for a while, eventually they will need additional services, and the extra work it takes to keep in sync with your platform will increase, and eventually it won&#39;t be worth staying. I&#39;m a big fan of companies doing one thing and doing it well, servicing single stops along the API life cycle, but after watching companies come and go for the last seven years, the one&#39;s that don&#39;t support API definitions won&#39;t be around too long.ve been working with my partner Restlet to advise them on expanding their platform to be what I consider to be an API life cycle provider. When I first was introduced to Restlet they were the original open source enterprise grade API deployment framework. Then Restlet became a cloud API deployment and management provider, and with their acquisition of DHC they also became an API client, and testing provider. Now with their latest update, they have worked hard to help their developer and business customers service almost every stop along a modern API life cycle, from design to deprecation.<br />While Restlet is developing tooling to help companies define what the API life cycle means to them, the heartbeat of what Restlet delivers centers around API definitions like OpenAPI and RAML. API definitions provide the framework when your designing, deploying, documenting, managing, and testing your APIs using Restlet. They also provide the ability for you to get your API definitions in and out of the platform, and load them into potentially other API services, allow API operators to get what they need done. In my opinion, making API definitions just as importan tas any other service or tooling you offer along the API life cycle.<br />Serving a single or handful of stops along the API life cycle can be todays version of vendor lockin. If your customers cannot easily load their API definitions in and out of your system you are locking them in, and while they may stay with you for a while, eventually they will need additional services, and the extra work it takes to keep in sync with your platform will increase, and eventually it won&#39;t be worth staying. I&#39;m a big fan of companies doing one thing and doing it well, servicing single stops along the API life cycle, but after watching companies come and go for the last seven years, the one&#39;s that don&#39;t support API definitions won&#39;t be around too long.s version of vendor lockin. If your customers cannot easily load their API definitions in and out of your system you are locking them in, and while they may stay with you for a while, eventually they will need additional services, and the extra work it takes to keep in sync with your platform will increase, and eventually it wont be worth staying. I&#39;m a big fan of companies doing one thing and doing it well, servicing single stops along the API life cycle, but after watching companies come and go for the last seven years, the one&#39;s that don&#39;t support API definitions won&#39;t be around too long.t be worth staying. Im a big fan of companies doing one thing and doing it well, servicing single stops along the API life cycle, but after watching companies come and go for the last seven years, the one&#39;s that don&#39;t support API definitions won&#39;t be around too long.m a big fan of companies doing one thing and doing it well, servicing single stops along the API life cycle, but after watching companies come and go for the last seven years, the ones that don&#39;t support API definitions won&#39;t be around too long.s that dont support API definitions won&#39;t be around too long.t support API definitions wont be around too long.t be around too long.",
  "url": "http://localhost:4000",
  "image": "https://image.slidesharecdn.com/emnworkshop-restfullwebapisbuilddocumentmanage-slideshare-150206082129-conversion-gate02/95/restful-web-apis-build-document-manage-11-638.jpg?cb=1423211259"
  },
  {
  "title": "API Definition: API Transformer",
  "date": "28 Mar 2017",
  "body": "<br />This is an article from the current edition of the&amp;nbsp;API Evangelist industry guide to API definitions. The guide is designed to be a summary of the world of API definitions, providing the reader with a recent summary of the variety of specifications that are defining the technology behind almost every part of our digital world<br />OpenAPI Spec is currently the most used API definition format out there, with the number of implementations, and tooling, with API Blueprint, Postman Collections, and other formats trailing behind. It can make sense to support a single API definition when it comes to an individual platforms operations, but when it comes to interoperability with other systems it is important to be multi-lingual and support multiple of the top machine-readable formats out there today.<br />In my monitoring of the API sector, one service provider has stood out when it comes to being a truly multi-lingual API definition service provider--the SDK generation provider, APIMATIC. The company made API definitions the heart of its operations, generating what they call development experience (DX) kits, from a central API definition uploaded by users--supporting OpenAPI Spec, API Blueprint, Postman Collections, and other top formats. The approach has allowed the company to quickly expand into new areas like documentation, testing, continuous integration, as well as opening up their API definition translation as a separate service called API Transformer.<br />API Transformer allows anyone to input an API Blueprint, Swagger, WADL, WSDL, Google Discovery, RAML 0.8 - 1.0, I/O Docs - Mashery, HAR 1.2, Postman Collection 1.0 - 2.0, Mashape, or APIMATIC Format API definition and then translate and export in a&amp;nbsp; API Blueprint, Swagger 1.0 - 1.2, Swagger 2.0 JSON, Swagger 2.0 YAML, WADL - W3C 2009, RAML 0.8 - 1.0, Postman Collection 1.0 - 2.0, and their own APIMATIC Format. You can execute API definition translations through their interface or seamlessly integrate with the API Transformer API definition conversation API.<br />There is no reason that an API provider and API service providers shouldn&amp;rsquo;t be multi-lingual. It is fine to adopt a single API definition as part of your own API operations, but when it comes to working with external groups, there is no excuse for not being able to work with any of the top API definition formats. The translation of API definitions will increasingly be essential to doing business throughout the API life cycle, requiring each company to have an API definition translation engine baked into their continuous integration workflow, transforming how they do business and build software.<br /><br />&amp;nbsp;If you have a product, service, or story you think should be in the API Evangelist industry guide to API design you can&amp;nbsp;email&amp;nbsp;me&amp;nbsp;,&amp;nbsp;or&amp;nbsp;you can submit a Github issue for my API definition research, and I will consider adding your suggestion to the road map.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/api_definitions_apitransfomer_screenshot.png"
  },
  {
  "title": "API Definition: U.S. Data Federation",
  "date": "27 Mar 2017",
  "body": "<br />This is an article from the current edition of the&amp;nbsp;API Evangelist industry guide to API definitions. The guide is designed to be a summary of the world of API definitions, providing the reader with a recent summary of the variety of specifications that are defining the technology behind almost every part of our digital world.<br />The U.S. Data Federation is a federal government effort to facilitate data interoperability and harmonization across federal, state, and local government agencies by highlighting common data formats, API specifications, and metadata vocabularies. The project is focusing on being a coordinating interoperability across government agencies by showcasing and supporting use cases that demonstrate unified and coherent data architectures across disparate agencies, institutions, and organizations.<br />The project is designed to shine a light on &amp;ldquo;emerging data standards and API initiatives across all levels of government, convey the level of maturity for each effort, and facilitate greater participation by government agencies&amp;rdquo;--definitely in alignment with the goal of this guide. There are currently seven projects profiled as part of the U.S. Data Federation, including Building &amp;amp; Land Development Specification, National Information Exchange Model, Open Referral, Open311, Project Open Data, Schema.org, and the Voting Information Project.<br />By providing a single location for agencies to find common schema documentation tools, schema validation tools, and automated data aggregation and normalization capabilities, the project is hoping to incentivize and stimulate reusability and interoperability across public data and API implementations. Government agencies of all shapes and sizes can use the common blueprints available in the U.S. Data Federation to reduce costs, speed up the implementation of projects, while also opening them up for augmenting and extending using their APIs, and common schema.<br />It is unclear what resources the U.S. Data Federation will have available in the current administration, but it looks like the project is just getting going, and intends to add more specifications as they are identified. The model reflects an approach that should be federated and evangelized at all levels of government, but also provides a blueprint that could be applied in other sectors like healthcare, education, and beyond. Aggregating common data formats, API specifications, metadata vocabularies, and authentication scopes will prove to be critical to the success of the overall climate of almost any industry doing business on the web in 2017.<br /><br />&amp;nbsp;If you have a product, service, or story you think should be in the API Evangelist industry guide to API design you can&amp;nbsp;email&amp;nbsp;me&amp;nbsp;,&amp;nbsp;or&amp;nbsp;you can submit a Github issue for my API definition research, and I will consider adding your suggestion to the road map.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/api_definitions_us_data_federation_screenshot.png"
  },
  {
  "title": "API Definition: WebConcepts.info",
  "date": "24 Mar 2017",
  "body": "<br />This is an article from the current edition of the&amp;nbsp;API Evangelist industry guide to API definitions. The guide&amp;nbsp;is designed to be a summary of the world of API definitions, providing the reader with a recent summary of the variety of specifications that are defining the technology behind almost every part of our digital world.<br />Keeping up with the standards bodies like International Organization for Standardization (ISO) and Internet Engineering Task Force (IETF)&amp;nbsp; can be a full-time job. Thankfully,&amp;nbsp; Erik Wilde (@dret) has help simply and made the concepts and specifications that make the web work more accessible and easier to understand, with his WebConcepts.info project.<br />According to Erik, &amp;ldquo;the Web&amp;rsquo;s Uniform Interface is based on a large and growing set of specifications. These specifications establish the shared concepts that providers and consumers of Web services can rely on. Web Concepts is providing an overview of these concepts and of the specifications defining them.&amp;rdquo; His work is a natural fit for what I am trying to accomplish with my API definition industry guide, as well as supporting other areas of my research.<br />One of the areas that slows API adoption is a lack of awareness of the concepts and specifications that make the web work among developers who are providing and consuming APIs. The modern API leverages the same technology that drives the web--this is why it is working so well. The web is delivering HTML for humans, and APIs are using the same to deliver machine-readable data, content, and access to algorithms online. If a developer is not familiar with the fundamental building blocks of the web, the APIs they provide, and the applications they build on top of APIs will always be deficient.<br />This project provides an overview of 28 web concepts with 643 distinct implementations&amp;nbsp; aggregated across five separate organizations including the International Organization for Standardization (ISO), Internet Engineering Task Force (IETF), Java Community Process (JCP), Organization for the Advancement of Structured Information Standards (OASIS), and the World Wide Web Consortium (W3C)--who all contribute to what we know as the web.&amp;nbsp; An awareness and literacy around the 28 concepts aggregated by Web Concepts is essential for any API developer and architect looking to fully leverage the power of the web as part of their API work.<br />After aggregating the 28 web concepts from the five standards organization, Web Concepts additionally aggregates 218 actual specifications that API developers, architects, and consumers should be considering when putting APIs to work. Some of these specifications are included as part of this API Definition guide, and I will be working to add additional specifications in future editions of this guide, as it makes sense. The goal of this guide is to help bring awareness, literacy, and proficiency with common API and data patterns, making use of the work Web Concepts project, and building on the web literacy work already delivered by Erik, just makes sense.<br />Web Concepts is published as a Github repository, leveraging Github Pages for the website. He has worked hard to make the concepts and specification available as JSON feeds, providing a machine-readable feed that can be integrated into existing API design, deployment, and management applications--providing web literacy concepts and specifications throughout the API life cycle.&amp;nbsp; All JSON data is generated from the source data, which is managed as a set of XML descriptions of specifications, with the build process based upon XSLT and Jekyll, providing multiple ways to approach all concepts and specifications, while maintaining the relationship and structure of all the moving parts that make up the web.<br />When it comes to the startup space, the concepts that make up the web, and the specifications that make it all work, might seem a little boring, something only the older engineers pay attention to.&amp;nbsp; Web Concepts helps soften, and make these critical concepts and specifications accessible and digestible for a new generation of web and API developers--think of them as gummy versions of vitamins. If we are going to standardize how APIs are designed, deployed, and managed--making all of this much more usable, scalable, and interoperable, we are going to have to all get on the same page (aka the web).<br />Web Concepts is an open source project, and Erik encourages feedback on the concepts&amp;nbsp;and specifications. I encourage you to spend time on the site regularly&amp;nbsp;and see where you can integrate the JSON feeds into your systems, services, and tooling. We have a lot of work ahead of us to make sure the next generation of programmers have the base amount of web literacy necessary to keep the web strong and healthy. There are two main ways to contribute to the building blocks of the web: participate as a contributor to the standards body, or you can make sure you are implementing common concepts and specifications throughout your work, contributing to the web, and not just walled gardens and closed platforms.<br /><br />&amp;nbsp;If you have a product, service, or story you think should be in the API Evangelist industry guide to API design you can&amp;nbsp;email&amp;nbsp;me&amp;nbsp;,&amp;nbsp;or&amp;nbsp;you can submit a Github issue for my API definition research, and I will consider adding your suggestion to the road map.<br />",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/api_definitions_webconcepts_screenshot.png"
  },
  {
  "title": "API Definition: Open API Specification 3.0.0-RC0",
  "date": "23 Mar 2017",
  "body": "<br />This is an article from the current edition of the API Evangelist industry guide to API definitions. The guide is designed to be a summary of the world of API definitions, providing the reader with a recent summary of the variety of specifications that are defining the technology behind almost every part of our digital world.<br />The OpenAPI Specification, formerly known as Swagger is approaching an important milestone, version 3.0 of the specification, but it is also the first major release since the specification was entered into the Linux Foundation. Swagger was the creation of Tony Tam of Wordnik back in 2010, but after the project was acquired by SmartBear in 2015, the company donated the specification to the newly formed OpenAPI Initiative (OAI) which is part of the Linux Foundation. Swagger has now been reborn as the OpenAPI Specification, and in early 2017 is approaching its first major release under the guidance of a diverse group of governing members.<br />Version 3.0 of the API specification format has taken a much more modular, and reusable approach to defining the surface area of an API, enabling more power and versatility when it comes to describing the request and response models, as well as providing details on the common components that make up API usage like the underlying data schema and security definitions. There are numerous changes to the API specification, but there are just a handful that will have a significant impact across every stop along the API life cycle where API definitions are making an impact.<br />Hosts<br />When describing your API, you can now provide multiple hosts, allowing you to better deal with the complexity of how APIs might be located in a single location, or spread across multiple cloud location, and global infrastructure.<br />Content Negotiation<br />You can now provide content objects to define the relationship between response objects, media types, and schema, opening up the negotiation of exactly the type of content needed, encouraging the design of multiple rich dimensions for any single API resource.<br />Body<br />The latest version of the specification plays catch-up when it comes to allowing the body of a request and response to be defined separately from the request parameters, allowing for more control over the payload of any API calls.<br />Schema<br />There is an increased investment in JSON Schema, including the support of `oneOf`, `anyOf` and `not` functions, allowing for alternative schema, as well as the standard JSON schema definition included.<br />Components<br />The new components architecture really reflects APIs, making everything very modular, reusable, and much more coherent and functional. The new version encourages good schema and component reuse,  helping further bringing the definition into focus.<br />Linking<br />While not quite full hypermedia, version 3.0 of the OpenAPI Spec supports linking, allowing for the description of relationships between paths, giving a nod towards hypermedia design pattern, making this version the most resilient so far.<br />Webhooks<br />Like the nod towards hypermedia, the specification now allows for the inclusion of callbacks that can be attached to a subscription operation describing an outbound operation--providing much needed webhook descriptions as part of API operations, making it much more real time and event driven.<br />Examples<br />The new version enables API architects to better describe, and provide examples of APIs responses and requests, helping make API integration a learning experience, by providing examples for use beyond just documentation descriptions.<br />Cookies<br />Responding to a large number of API providers, and the reality on the ground for many implementations, the new version allows for the definition of cookies as part of API requests.<br />These nine areas represent the most significant changes to the OpenAPI Spec 3.0. The most notable shift is the componentized, modular, reusable aspect of the specification. After that, it is the content negotiation, linking, web hooks, and other changes that are moving the needle. It is clear that the 3.0 version of the specification has considered the design patterns across a large number of implementations, providing a pretty wide-reaching specification for defining what an API does, in a world where every API can be a special snowflake.<br />In 2017, the OpenAPI Spec is the clear leader of the API definition formats, with the largest adoption, as well as the amount of tooling developed. While documentation and SDK generation are still the top two reasons for crafting API definitions, there are numerous other reasons for using API definitions including mocking, testing, monitoring, IDE integration, and much, much more. In 2017, the OpenAPI Spec is the clear leader of the API definitions format. It has the highest usage rate, as well as the largest number of tooling (or tools?) available.<br /><br /> If you have a product, service, or story you think should be in the API Evangelist industry guide to API design you can email me , or you can submit a Github issue for my API definition research, and I will consider adding your suggestion to the road map.<br />",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/api_definitions_openapi_30_screenshot.png"
  },
  {
  "title": "API Icon Vocabulary",
  "date": "22 Mar 2017",
  "body": "<br />I am working on profiling 75 of the Google APIs, and one thing I struggle with at this scale is standardizing the images I use, or more specifically, icons that represent each service as well as the value they deliver under the hood--something Google seriously needs to get more organized in by the way. I have written before about having a set of icons for the API sector, for SDK related icons, and also about how Amazon is getting more organized when it comes to icons for the AWS platform, as I beat this drum about the need for common imagery.<br />While I am glad that Amazon is started to think about iconography when it comes to working with APIs at scale, a lead that Google and Microsoft should follow, Im hoping that API icons are something that someone will tackle at the same level as say a Schema.org. I would like to see API provider (company) level icons, building on the work of Devicon, but I&#39;d also like to see individual icons developed for common resources that are made available via APIs--like compute, storage, images, video, etc.<br />What Amazon is doing provides the best model we have so far, but I want to make sure icons are not vendor specific. I would like to see a universal icon to represent a compute API for instance, whether it was Amazon, Google, or Microsoft. Think about IFTTT or Zapier, but something that would universally represent the valuable bits and bytes we are putting to use via individual platforms, but are increasingly also moving around between platforms--I want a common visual iconography we can use to communicate about what is being done with APIs.<br />There is a ton of work involved with establishing a project of this scale. Ideally, it is something that would also involve API providers, and not just be an external thing. I&#39;d also like to see each icon be more than just a visual icon, I&#39;d like there to be semantics and vocabulary attached to each image. Imagine if we had a common set of icons describe machine learning APIs, that helped us quickly understand what they do, but would also help us more consistently articulate the reality of what they do, and do not do (ie. Facial Recognition, Sentiment Anlysis, etc.).<br />I am going to keep talking about this until someone either does it&amp;nbsp;or gives me the money to pay someone to do it. Sadly, I feel like it will end up being like the rest of common API definitions and tooling, we&#39;ll see each provider do it on their own, where all meaning and vocabulary becomes platform-driven, and not about actually finding a common language to communicate about what is possible with APIs.m hoping that API icons are something that someone will tackle at the same level as say a Schema.org. I would like to see API provider (company) level icons, building on the work of Devicon, but Id also like to see individual icons developed for common resources that are made available via APIs--like compute, storage, images, video, etc.<br />What Amazon is doing provides the best model we have so far, but I want to make sure icons are not vendor specific. I would like to see a universal icon to represent a compute API for instance, whether it was Amazon, Google, or Microsoft. Think about IFTTT or Zapier, but something that would universally represent the valuable bits and bytes we are putting to use via individual platforms, but are increasingly also moving around between platforms--I want a common visual iconography we can use to communicate about what is being done with APIs.<br />There is a ton of work involved with establishing a project of this scale. Ideally, it is something that would also involve API providers, and not just be an external thing. I&#39;d also like to see each icon be more than just a visual icon, I&#39;d like there to be semantics and vocabulary attached to each image. Imagine if we had a common set of icons describe machine learning APIs, that helped us quickly understand what they do, but would also help us more consistently articulate the reality of what they do, and do not do (ie. Facial Recognition, Sentiment Anlysis, etc.).<br />I am going to keep talking about this until someone either does it&amp;nbsp;or gives me the money to pay someone to do it. Sadly, I feel like it will end up being like the rest of common API definitions and tooling, we&#39;ll see each provider do it on their own, where all meaning and vocabulary becomes platform-driven, and not about actually finding a common language to communicate about what is possible with APIs.d also like to see individual icons developed for common resources that are made available via APIs--like compute, storage, images, video, etc.<br />What Amazon is doing provides the best model we have so far, but I want to make sure icons are not vendor specific. I would like to see a universal icon to represent a compute API for instance, whether it was Amazon, Google, or Microsoft. Think about IFTTT or Zapier, but something that would universally represent the valuable bits and bytes we are putting to use via individual platforms, but are increasingly also moving around between platforms--I want a common visual iconography we can use to communicate about what is being done with APIs.<br />There is a ton of work involved with establishing a project of this scale. Ideally, it is something that would also involve API providers, and not just be an external thing. Id also like to see each icon be more than just a visual icon, I&#39;d like there to be semantics and vocabulary attached to each image. Imagine if we had a common set of icons describe machine learning APIs, that helped us quickly understand what they do, but would also help us more consistently articulate the reality of what they do, and do not do (ie. Facial Recognition, Sentiment Anlysis, etc.).<br />I am going to keep talking about this until someone either does it&amp;nbsp;or gives me the money to pay someone to do it. Sadly, I feel like it will end up being like the rest of common API definitions and tooling, we&#39;ll see each provider do it on their own, where all meaning and vocabulary becomes platform-driven, and not about actually finding a common language to communicate about what is possible with APIs.d also like to see each icon be more than just a visual icon, Id like there to be semantics and vocabulary attached to each image. Imagine if we had a common set of icons describe machine learning APIs, that helped us quickly understand what they do, but would also help us more consistently articulate the reality of what they do, and do not do (ie. Facial Recognition, Sentiment Anlysis, etc.).<br />I am going to keep talking about this until someone either does it&amp;nbsp;or gives me the money to pay someone to do it. Sadly, I feel like it will end up being like the rest of common API definitions and tooling, we&#39;ll see each provider do it on their own, where all meaning and vocabulary becomes platform-driven, and not about actually finding a common language to communicate about what is possible with APIs.d like there to be semantics and vocabulary attached to each image. Imagine if we had a common set of icons describe machine learning APIs, that helped us quickly understand what they do, but would also help us more consistently articulate the reality of what they do, and do not do (ie. Facial Recognition, Sentiment Anlysis, etc.).<br />I am going to keep talking about this until someone either does it&amp;nbsp;or gives me the money to pay someone to do it. Sadly, I feel like it will end up being like the rest of common API definitions and tooling, well see each provider do it on their own, where all meaning and vocabulary becomes platform-driven, and not about actually finding a common language to communicate about what is possible with APIs.ll see each provider do it on their own, where all meaning and vocabulary becomes platform-driven, and not about actually finding a common language to communicate about what is possible with APIs.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/devicons_screenshot.png"
  },
  {
  "title": "API Definition: Human Services API Specification",
  "date": "22 Mar 2017",
  "body": "<br />This is an article from the current edition of the API Evangelist industry guide to API definitions. The guide&amp;nbsp;is designed to be a summary of the world of API definitions, providing the reader with a recent summary of the variety of specifications that are defining the technology behind almost every part of our digital world.<br />A lot of attention is given to APIs and the world of startups, but in 2017 this landscape is quickly shifting beyond just the heart of the tech space, with companies, organizations, institutions, and government agencies of all shapes and sizes are putting APIs to work. API definitions are being applied to the fundamental building blocks of the tech sector, quantifying the computational, storage, images, videos, and other essential resources powering web, mobile, and device based applications. This success is now spreading to other sectors, defining other vital resources that are making a real impact in our communities.<br />One API making an impact in communities is the Human Services Data Specification (HSDS), also known as the Open Referral Ohana API. The project began as a Code for America project, providing an API, website, and administrative system for managing the organizations, locations, and the human services that communities depend on. Open Referral, the governing organization for HSDS, and the Ohana API is working with API Evangelist and other partners to define the next generation of the human services data specification, API definition, as well as the next generation of API, website, admin, and developer portal implementations.<br />The HSDS Specification API isn&amp;rsquo;t about any single API, it is a suite of API-first definitions, schema, and open tooling that cities, counties, states&amp;nbsp;and federal government agencies can download or fork, and employ to help manage vital human services for their communities. Providing not just a website for finding vital services, but a complete API ecosystem that can be deployed incentivizing developers to build important web, mobile, and other applications on top of a central human services system. Better delivering on the mission of human services organizations, and meeting the demands of their constituents.<br />This approach to delivering APIs centers around a common data schema, extending it as an OpenAPI Spec definition, describing how that data is accessed&amp;nbsp;and put to use across a variety of applications, including a central website and administrative system. While server-side HSDS API implementations, website, mobile, administrative, developer portal, and other implementations are important, the key to the success of this model is a central OpenAPI definition of the HSDS API. This definition connects all the implementations within an API&amp;rsquo;s ecosystem, but it also provides the groundwork for a future where all human services implementations are open and interoperable with other implementations--establishing a federated network of services meeting the needs of the communities they serve.<br />Right now each city is managing one or multiple human service implementations. Even though some of these implementations operate in overlapping communities, few of them are providing 3rd party access, let alone providing integration between overlapping geographic regions. The HSDS API approach employs an API-first approach, focusing on the availability and access of the HSDS schema, then adding on a website, administrative and API developer portals to support. This model opens up human services to humans via the website, which is integrated with the central API, but then also opens up the human services for inclusion into other websites, mobile and device applications, as well as integration with other systems.<br />The HSDS OpenAPI spec and schema provide a reusable blueprint that can be used to standardize how we provide human services. The open source approach to delivering definitions, schema, and code reduces the cost of deployment and operation for cash-strapped public organizations and agencies. The API-first approach to delivering human services also opens up resources for inclusion in our applications and system, potentially outsourcing the heavy lifting to trusted partners, and 3rd party developers interested in helping augment and extend the mission of human service organizations and groups.<br />If you&amp;rsquo;d like to learn more about the HSDS API you can visit Open Referral. From there you can get involved in the discussion, and find existing open source definitions, schema, and code for putting HSDS to work. If you&amp;rsquo;d like to contribute to the project, there are numerous opportunities to join the discussion about next generation of the schema and OpenAPI Spec, as well as develop server-side&amp;nbsp;and client-side implementations.<br /><br />&amp;nbsp;If you have a product, service, or story you think should be in the API Evangelist industry guide to API design you can email me , or you can submit a Github issue for my API definition research, and I will consider adding your suggestion to the road map.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/api_definitions_human_services_screenshot.png"
  },
  {
  "title": "Considering Standards In Our API Design Over Being A Special Snowflake",
  "date": "21 Mar 2017",
  "body": "<br />Most of the APIs I look at are special snowflakes. The definition&amp;nbsp;and designs employed are usually custom-crafted without thinking other existing APIs, or standards that already in place. There are several contributing factors to why this is, ranging from the types of developers who are designing APIs, to incentive models put in place because of investment&amp;nbsp;and intellectual property constraints. So, whenever I find an API that is employing an existing standard, I feel compelled to showcase&amp;nbsp;and help plant the seeds in others minds that we should be speaking a common language instead of always being a special snowflake.<br />One of these APIs that I came across recently was the Google Spectrum Database API which has employed a standard&amp;nbsp;defined by the&amp;nbsp;IETF Protocol to Access White Space (PAWS). &amp;nbsp;I wouldnt say the API is the best-designed API, but it does follow a known standard, that is already in use by an industry, which in my experience can go further than having the best-designed API. The best product doesn&#39;t always win in this game, sometimes it is just about getting adoption with the widest possible audience.&amp;nbsp;I am guessing that the Google Spectrum Database API is targeting a different type of engineering audience than their more modern, machine learning and other APIs are, so following standards is probably more of a consideration.<br />I wish more APIs would share a little bit about the thoughts that went into the definition and design of their APIs, sharing their due diligence of existing APIs and standards, and other considerations that were included in the process of crafting an API. I&#39;d like to see some leadership in this area, as well as some folks admitting that they didn&#39;t have the time, budget, expertise, or whatever the other reasons why you are a special snowflake. It is a conversation we should be having, otherwise, we may never fully understand why we aren&#39;t seeing the adoption we&#39;d like to see with our APIs.t say the API is the best-designed API, but it does follow a known standard, that is already in use by an industry, which in my experience can go further than having the best-designed API. The best product doesnt always win in this game, sometimes it is just about getting adoption with the widest possible audience.&amp;nbsp;I am guessing that the Google Spectrum Database API is targeting a different type of engineering audience than their more modern, machine learning and other APIs are, so following standards is probably more of a consideration.<br />I wish more APIs would share a little bit about the thoughts that went into the definition and design of their APIs, sharing their due diligence of existing APIs and standards, and other considerations that were included in the process of crafting an API. I&#39;d like to see some leadership in this area, as well as some folks admitting that they didn&#39;t have the time, budget, expertise, or whatever the other reasons why you are a special snowflake. It is a conversation we should be having, otherwise, we may never fully understand why we aren&#39;t seeing the adoption we&#39;d like to see with our APIs.t always win in this game, sometimes it is just about getting adoption with the widest possible audience.&amp;nbsp;I am guessing that the Google Spectrum Database API is targeting a different type of engineering audience than their more modern, machine learning and other APIs are, so following standards is probably more of a consideration.<br />I wish more APIs would share a little bit about the thoughts that went into the definition and design of their APIs, sharing their due diligence of existing APIs and standards, and other considerations that were included in the process of crafting an API. Id like to see some leadership in this area, as well as some folks admitting that they didn&#39;t have the time, budget, expertise, or whatever the other reasons why you are a special snowflake. It is a conversation we should be having, otherwise, we may never fully understand why we aren&#39;t seeing the adoption we&#39;d like to see with our APIs.d like to see some leadership in this area, as well as some folks admitting that they didnt have the time, budget, expertise, or whatever the other reasons why you are a special snowflake. It is a conversation we should be having, otherwise, we may never fully understand why we aren&#39;t seeing the adoption we&#39;d like to see with our APIs.t have the time, budget, expertise, or whatever the other reasons why you are a special snowflake. It is a conversation we should be having, otherwise, we may never fully understand why we arent seeing the adoption we&#39;d like to see with our APIs.t seeing the adoption wed like to see with our APIs.d like to see with our APIs.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/google_spectrum_database.png"
  },
  {
  "title": "A Community Strategy For My API Definition Guide",
  "date": "20 Mar 2017",
  "body": "<br />I have tpublished the latest edition of my API definition guide. Ive rebooted my industry guides to be a more polished, summary version of my research instead of the rougher, more comprehensive version I&#39;ve bee publishing for the last couple of years. I&#39;m looking for my guides to better speak to the waves of new people entering the API space, and help them as they continue on their API journey.<br />In addition to being a little more polished, and having more curated content, my API guides are now going to also be more of a community thing. In the past I&#39;ve kept pretty tight control over the content I publish to API Evangelist, only opening up the four logos to my partners. Using my API industry guides I want to invite folks from the community to help edit the content, and provide editorial feedback--even suggesting what should be in future editions. I&#39;m also opening up the guides to include paid content that will help pay for the ongoing publication of the guides with the following opportunities available in the next edition:<br /><br />One Page Articles - Sponsored suggested topics, where I will craft the story and publish in the next edition of the guide--also published on API Evangelist blog after the guide is published.<br />Two Page Articles&amp;nbsp;- Sponsored suggested topics, where I will craft the story and publish in the next edition of the guide--also published on API Evangelist blog after the guide is published.Sponsor Slot -&amp;nbsp;<br />Sponsor Slot - On the service and tooling pages there are featured slots, some of which I will be giving to sponsors, who have related produces and services.<br />Private Distribution - Allow for private distribution of the industry guide, to partners, and behind lead generation forms, allowing you to use API Evangelist research to connect with customers.<br /><br />Even though I will be accepting paid content within these industry guides, and posts via the blog now, they will all be labeled as sponsored posts, and I will also still be adding my voice to each and every piece--if you know me, or read API Evangelist blog you know what this means. I&#39;m looking to keep the lights on, while also opening up the doors for companies in the space to join in the conversation, as well as the average reader--allowing anyone to provide feedback and suggestions via the Github issues for each area of research.<br />My API definition research is just the first to come off the assembly line. I will be applying this same model to my design, deployment, and management research in coming weeks, and eventually the rest of my research as it makes sense. If there is a specific research area you&#39;d like to see get attention&amp;nbsp;or would be willing to sponsor in one of the ways listed above, please let me know. Once I get the core set of my API industry research guides published in this way, I will be working on increasing the distribution beyond just my network of sites, and the API Evangelist digital presence--publishing them to Amazon, and other prominent ecosystems.<br />I also wanted to take a moment and thank everyone in the community who helped m last year&amp;nbsp;and for everyone who is helping make my research, and the publishing of these industry guides a reality. Your support is important to me, and it is also important to me that my research continues, and is as widely available as it possibly can.&amp;nbsp;ve rebooted my industry guides to be a more polished, summary version of my research instead of the rougher, more comprehensive version Ive bee publishing for the last couple of years. I&#39;m looking for my guides to better speak to the waves of new people entering the API space, and help them as they continue on their API journey.<br />In addition to being a little more polished, and having more curated content, my API guides are now going to also be more of a community thing. In the past I&#39;ve kept pretty tight control over the content I publish to API Evangelist, only opening up the four logos to my partners. Using my API industry guides I want to invite folks from the community to help edit the content, and provide editorial feedback--even suggesting what should be in future editions. I&#39;m also opening up the guides to include paid content that will help pay for the ongoing publication of the guides with the following opportunities available in the next edition:<br /><br />One Page Articles - Sponsored suggested topics, where I will craft the story and publish in the next edition of the guide--also published on API Evangelist blog after the guide is published.<br />Two Page Articles&amp;nbsp;- Sponsored suggested topics, where I will craft the story and publish in the next edition of the guide--also published on API Evangelist blog after the guide is published.Sponsor Slot -&amp;nbsp;<br />Sponsor Slot - On the service and tooling pages there are featured slots, some of which I will be giving to sponsors, who have related produces and services.<br />Private Distribution - Allow for private distribution of the industry guide, to partners, and behind lead generation forms, allowing you to use API Evangelist research to connect with customers.<br /><br />Even though I will be accepting paid content within these industry guides, and posts via the blog now, they will all be labeled as sponsored posts, and I will also still be adding my voice to each and every piece--if you know me, or read API Evangelist blog you know what this means. I&#39;m looking to keep the lights on, while also opening up the doors for companies in the space to join in the conversation, as well as the average reader--allowing anyone to provide feedback and suggestions via the Github issues for each area of research.<br />My API definition research is just the first to come off the assembly line. I will be applying this same model to my design, deployment, and management research in coming weeks, and eventually the rest of my research as it makes sense. If there is a specific research area you&#39;d like to see get attention&amp;nbsp;or would be willing to sponsor in one of the ways listed above, please let me know. Once I get the core set of my API industry research guides published in this way, I will be working on increasing the distribution beyond just my network of sites, and the API Evangelist digital presence--publishing them to Amazon, and other prominent ecosystems.<br />I also wanted to take a moment and thank everyone in the community who helped m last year&amp;nbsp;and for everyone who is helping make my research, and the publishing of these industry guides a reality. Your support is important to me, and it is also important to me that my research continues, and is as widely available as it possibly can.&amp;nbsp;ve bee publishing for the last couple of years. Im looking for my guides to better speak to the waves of new people entering the API space, and help them as they continue on their API journey.<br />In addition to being a little more polished, and having more curated content, my API guides are now going to also be more of a community thing. In the past I&#39;ve kept pretty tight control over the content I publish to API Evangelist, only opening up the four logos to my partners. Using my API industry guides I want to invite folks from the community to help edit the content, and provide editorial feedback--even suggesting what should be in future editions. I&#39;m also opening up the guides to include paid content that will help pay for the ongoing publication of the guides with the following opportunities available in the next edition:<br /><br />One Page Articles - Sponsored suggested topics, where I will craft the story and publish in the next edition of the guide--also published on API Evangelist blog after the guide is published.<br />Two Page Articles&amp;nbsp;- Sponsored suggested topics, where I will craft the story and publish in the next edition of the guide--also published on API Evangelist blog after the guide is published.Sponsor Slot -&amp;nbsp;<br />Sponsor Slot - On the service and tooling pages there are featured slots, some of which I will be giving to sponsors, who have related produces and services.<br />Private Distribution - Allow for private distribution of the industry guide, to partners, and behind lead generation forms, allowing you to use API Evangelist research to connect with customers.<br /><br />Even though I will be accepting paid content within these industry guides, and posts via the blog now, they will all be labeled as sponsored posts, and I will also still be adding my voice to each and every piece--if you know me, or read API Evangelist blog you know what this means. I&#39;m looking to keep the lights on, while also opening up the doors for companies in the space to join in the conversation, as well as the average reader--allowing anyone to provide feedback and suggestions via the Github issues for each area of research.<br />My API definition research is just the first to come off the assembly line. I will be applying this same model to my design, deployment, and management research in coming weeks, and eventually the rest of my research as it makes sense. If there is a specific research area you&#39;d like to see get attention&amp;nbsp;or would be willing to sponsor in one of the ways listed above, please let me know. Once I get the core set of my API industry research guides published in this way, I will be working on increasing the distribution beyond just my network of sites, and the API Evangelist digital presence--publishing them to Amazon, and other prominent ecosystems.<br />I also wanted to take a moment and thank everyone in the community who helped m last year&amp;nbsp;and for everyone who is helping make my research, and the publishing of these industry guides a reality. Your support is important to me, and it is also important to me that my research continues, and is as widely available as it possibly can.&amp;nbsp;m looking for my guides to better speak to the waves of new people entering the API space, and help them as they continue on their API journey.<br />In addition to being a little more polished, and having more curated content, my API guides are now going to also be more of a community thing. In the past Ive kept pretty tight control over the content I publish to API Evangelist, only opening up the four logos to my partners. Using my API industry guides I want to invite folks from the community to help edit the content, and provide editorial feedback--even suggesting what should be in future editions. I&#39;m also opening up the guides to include paid content that will help pay for the ongoing publication of the guides with the following opportunities available in the next edition:<br /><br />One Page Articles - Sponsored suggested topics, where I will craft the story and publish in the next edition of the guide--also published on API Evangelist blog after the guide is published.<br />Two Page Articles&amp;nbsp;- Sponsored suggested topics, where I will craft the story and publish in the next edition of the guide--also published on API Evangelist blog after the guide is published.Sponsor Slot -&amp;nbsp;<br />Sponsor Slot - On the service and tooling pages there are featured slots, some of which I will be giving to sponsors, who have related produces and services.<br />Private Distribution - Allow for private distribution of the industry guide, to partners, and behind lead generation forms, allowing you to use API Evangelist research to connect with customers.<br /><br />Even though I will be accepting paid content within these industry guides, and posts via the blog now, they will all be labeled as sponsored posts, and I will also still be adding my voice to each and every piece--if you know me, or read API Evangelist blog you know what this means. I&#39;m looking to keep the lights on, while also opening up the doors for companies in the space to join in the conversation, as well as the average reader--allowing anyone to provide feedback and suggestions via the Github issues for each area of research.<br />My API definition research is just the first to come off the assembly line. I will be applying this same model to my design, deployment, and management research in coming weeks, and eventually the rest of my research as it makes sense. If there is a specific research area you&#39;d like to see get attention&amp;nbsp;or would be willing to sponsor in one of the ways listed above, please let me know. Once I get the core set of my API industry research guides published in this way, I will be working on increasing the distribution beyond just my network of sites, and the API Evangelist digital presence--publishing them to Amazon, and other prominent ecosystems.<br />I also wanted to take a moment and thank everyone in the community who helped m last year&amp;nbsp;and for everyone who is helping make my research, and the publishing of these industry guides a reality. Your support is important to me, and it is also important to me that my research continues, and is as widely available as it possibly can.&amp;nbsp;ve kept pretty tight control over the content I publish to API Evangelist, only opening up the four logos to my partners. Using my API industry guides I want to invite folks from the community to help edit the content, and provide editorial feedback--even suggesting what should be in future editions. Im also opening up the guides to include paid content that will help pay for the ongoing publication of the guides with the following opportunities available in the next edition:<br /><br />One Page Articles - Sponsored suggested topics, where I will craft the story and publish in the next edition of the guide--also published on API Evangelist blog after the guide is published.<br />Two Page Articles&amp;nbsp;- Sponsored suggested topics, where I will craft the story and publish in the next edition of the guide--also published on API Evangelist blog after the guide is published.Sponsor Slot -&amp;nbsp;<br />Sponsor Slot - On the service and tooling pages there are featured slots, some of which I will be giving to sponsors, who have related produces and services.<br />Private Distribution - Allow for private distribution of the industry guide, to partners, and behind lead generation forms, allowing you to use API Evangelist research to connect with customers.<br /><br />Even though I will be accepting paid content within these industry guides, and posts via the blog now, they will all be labeled as sponsored posts, and I will also still be adding my voice to each and every piece--if you know me, or read API Evangelist blog you know what this means. I&#39;m looking to keep the lights on, while also opening up the doors for companies in the space to join in the conversation, as well as the average reader--allowing anyone to provide feedback and suggestions via the Github issues for each area of research.<br />My API definition research is just the first to come off the assembly line. I will be applying this same model to my design, deployment, and management research in coming weeks, and eventually the rest of my research as it makes sense. If there is a specific research area you&#39;d like to see get attention&amp;nbsp;or would be willing to sponsor in one of the ways listed above, please let me know. Once I get the core set of my API industry research guides published in this way, I will be working on increasing the distribution beyond just my network of sites, and the API Evangelist digital presence--publishing them to Amazon, and other prominent ecosystems.<br />I also wanted to take a moment and thank everyone in the community who helped m last year&amp;nbsp;and for everyone who is helping make my research, and the publishing of these industry guides a reality. Your support is important to me, and it is also important to me that my research continues, and is as widely available as it possibly can.&amp;nbsp;m also opening up the guides to include paid content that will help pay for the ongoing publication of the guides with the following opportunities available in the next edition:<br /><br />One Page Articles - Sponsored suggested topics, where I will craft the story and publish in the next edition of the guide--also published on API Evangelist blog after the guide is published.<br />Two Page Articles&amp;nbsp;- Sponsored suggested topics, where I will craft the story and publish in the next edition of the guide--also published on API Evangelist blog after the guide is published.Sponsor Slot -&amp;nbsp;<br />Sponsor Slot - On the service and tooling pages there are featured slots, some of which I will be giving to sponsors, who have related produces and services.<br />Private Distribution - Allow for private distribution of the industry guide, to partners, and behind lead generation forms, allowing you to use API Evangelist research to connect with customers.<br /><br />Even though I will be accepting paid content within these industry guides, and posts via the blog now, they will all be labeled as sponsored posts, and I will also still be adding my voice to each and every piece--if you know me, or read API Evangelist blog you know what this means. Im looking to keep the lights on, while also opening up the doors for companies in the space to join in the conversation, as well as the average reader--allowing anyone to provide feedback and suggestions via the Github issues for each area of research.<br />My API definition research is just the first to come off the assembly line. I will be applying this same model to my design, deployment, and management research in coming weeks, and eventually the rest of my research as it makes sense. If there is a specific research area you&#39;d like to see get attention&amp;nbsp;or would be willing to sponsor in one of the ways listed above, please let me know. Once I get the core set of my API industry research guides published in this way, I will be working on increasing the distribution beyond just my network of sites, and the API Evangelist digital presence--publishing them to Amazon, and other prominent ecosystems.<br />I also wanted to take a moment and thank everyone in the community who helped m last year&amp;nbsp;and for everyone who is helping make my research, and the publishing of these industry guides a reality. Your support is important to me, and it is also important to me that my research continues, and is as widely available as it possibly can.&amp;nbsp;m looking to keep the lights on, while also opening up the doors for companies in the space to join in the conversation, as well as the average reader--allowing anyone to provide feedback and suggestions via the Github issues for each area of research.<br />My API definition research is just the first to come off the assembly line. I will be applying this same model to my design, deployment, and management research in coming weeks, and eventually the rest of my research as it makes sense. If there is a specific research area youd like to see get attention&amp;nbsp;or would be willing to sponsor in one of the ways listed above, please let me know. Once I get the core set of my API industry research guides published in this way, I will be working on increasing the distribution beyond just my network of sites, and the API Evangelist digital presence--publishing them to Amazon, and other prominent ecosystems.<br />I also wanted to take a moment and thank everyone in the community who helped m last year&amp;nbsp;and for everyone who is helping make my research, and the publishing of these industry guides a reality. Your support is important to me, and it is also important to me that my research continues, and is as widely available as it possibly can.&amp;nbsp;d like to see get attention&amp;nbsp;or would be willing to sponsor in one of the ways listed above, please let me know. Once I get the core set of my API industry research guides published in this way, I will be working on increasing the distribution beyond just my network of sites, and the API Evangelist digital presence--publishing them to Amazon, and other prominent ecosystems.<br />I also wanted to take a moment and thank everyone in the community who helped m last year&amp;nbsp;and for everyone who is helping make my research, and the publishing of these industry guides a reality. Your support is important to me, and it is also important to me that my research continues, and is as widely available as it possibly can.&amp;nbsp;",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/api_definitions_2017_03.png"
  },
  {
  "title": "What Will It Take To Evolve OpenAPI Tooling to Version 3.0",
  "date": "16 Mar 2017",
  "body": "<br />I am spending some time adding more tools to my OpenAPI Toolbox, and Im looking to start evaluating what it will take for tooling providers to evolve their solution from version 2.0 of the OpenAPI Spec to version 3.0. I want to better understand what it will take to evolve the documentation, generators, servers, clients, editors, and other tools that I&#39;m tracking on as part of my toolbox research.<br />I&#39;m going to spend another couple of weeks populating the toolbox with OpenAPI solutions. Getting them entered with all the relevant metadata. Once I feel the list is good enough, I will begin reaching out to each tool owner, asking what their OpenAPI 3.0 plans are. It will give me a good reason to reach out and see if anyone is even home. I&#39;m assuming that a number of the projects are abandoned, and even that their owners do not have the resources necessary to go from 2.0 to 3.0. Regardless, this is something I want to track on as part of this OpenAPI toolbox research.<br />The overall architecture of OpenAPI shifted pretty significantly from 2.0 to 3.0. Things are way more modular, and reusable&amp;nbsp;in there, something that will take some work to bring out in most of the tooling areas. Personally, I&#39;m pretty excited for the opportunities when it comes to API documentation and API design editors with OpenAPI 3.0 as the core. I am also hoping that developers step up to make sure that the generators, as well as the server and client code generators become available in a variety of programming languages--we will need this to make sure we keep the momentum that we&#39;ve established with the specification so far.<br />If you are looking at developing any tooling using OpenAPI 3.0 I&#39;d love to hear from you. I&#39;d like to hear more about what it will take to either migrate your tool from version 2.0 to 3.0&amp;nbsp;or even hear what it will take to get up and running on 3.0 from scratch. I&#39;m going to get to work on crafting my first OpenAPI definition using version 3.0, then I&#39;m going to begin playing around with some new approaches to API documentation and possibly an API editor or notebook that takes advantage of the changes in the OpenAPI Specification.m looking to start evaluating what it will take for tooling providers to evolve their solution from version 2.0 of the OpenAPI Spec to version 3.0. I want to better understand what it will take to evolve the documentation, generators, servers, clients, editors, and other tools that Im tracking on as part of my toolbox research.<br />I&#39;m going to spend another couple of weeks populating the toolbox with OpenAPI solutions. Getting them entered with all the relevant metadata. Once I feel the list is good enough, I will begin reaching out to each tool owner, asking what their OpenAPI 3.0 plans are. It will give me a good reason to reach out and see if anyone is even home. I&#39;m assuming that a number of the projects are abandoned, and even that their owners do not have the resources necessary to go from 2.0 to 3.0. Regardless, this is something I want to track on as part of this OpenAPI toolbox research.<br />The overall architecture of OpenAPI shifted pretty significantly from 2.0 to 3.0. Things are way more modular, and reusable&amp;nbsp;in there, something that will take some work to bring out in most of the tooling areas. Personally, I&#39;m pretty excited for the opportunities when it comes to API documentation and API design editors with OpenAPI 3.0 as the core. I am also hoping that developers step up to make sure that the generators, as well as the server and client code generators become available in a variety of programming languages--we will need this to make sure we keep the momentum that we&#39;ve established with the specification so far.<br />If you are looking at developing any tooling using OpenAPI 3.0 I&#39;d love to hear from you. I&#39;d like to hear more about what it will take to either migrate your tool from version 2.0 to 3.0&amp;nbsp;or even hear what it will take to get up and running on 3.0 from scratch. I&#39;m going to get to work on crafting my first OpenAPI definition using version 3.0, then I&#39;m going to begin playing around with some new approaches to API documentation and possibly an API editor or notebook that takes advantage of the changes in the OpenAPI Specification.m tracking on as part of my toolbox research.<br />Im going to spend another couple of weeks populating the toolbox with OpenAPI solutions. Getting them entered with all the relevant metadata. Once I feel the list is good enough, I will begin reaching out to each tool owner, asking what their OpenAPI 3.0 plans are. It will give me a good reason to reach out and see if anyone is even home. I&#39;m assuming that a number of the projects are abandoned, and even that their owners do not have the resources necessary to go from 2.0 to 3.0. Regardless, this is something I want to track on as part of this OpenAPI toolbox research.<br />The overall architecture of OpenAPI shifted pretty significantly from 2.0 to 3.0. Things are way more modular, and reusable&amp;nbsp;in there, something that will take some work to bring out in most of the tooling areas. Personally, I&#39;m pretty excited for the opportunities when it comes to API documentation and API design editors with OpenAPI 3.0 as the core. I am also hoping that developers step up to make sure that the generators, as well as the server and client code generators become available in a variety of programming languages--we will need this to make sure we keep the momentum that we&#39;ve established with the specification so far.<br />If you are looking at developing any tooling using OpenAPI 3.0 I&#39;d love to hear from you. I&#39;d like to hear more about what it will take to either migrate your tool from version 2.0 to 3.0&amp;nbsp;or even hear what it will take to get up and running on 3.0 from scratch. I&#39;m going to get to work on crafting my first OpenAPI definition using version 3.0, then I&#39;m going to begin playing around with some new approaches to API documentation and possibly an API editor or notebook that takes advantage of the changes in the OpenAPI Specification.m going to spend another couple of weeks populating the toolbox with OpenAPI solutions. Getting them entered with all the relevant metadata. Once I feel the list is good enough, I will begin reaching out to each tool owner, asking what their OpenAPI 3.0 plans are. It will give me a good reason to reach out and see if anyone is even home. Im assuming that a number of the projects are abandoned, and even that their owners do not have the resources necessary to go from 2.0 to 3.0. Regardless, this is something I want to track on as part of this OpenAPI toolbox research.<br />The overall architecture of OpenAPI shifted pretty significantly from 2.0 to 3.0. Things are way more modular, and reusable&amp;nbsp;in there, something that will take some work to bring out in most of the tooling areas. Personally, I&#39;m pretty excited for the opportunities when it comes to API documentation and API design editors with OpenAPI 3.0 as the core. I am also hoping that developers step up to make sure that the generators, as well as the server and client code generators become available in a variety of programming languages--we will need this to make sure we keep the momentum that we&#39;ve established with the specification so far.<br />If you are looking at developing any tooling using OpenAPI 3.0 I&#39;d love to hear from you. I&#39;d like to hear more about what it will take to either migrate your tool from version 2.0 to 3.0&amp;nbsp;or even hear what it will take to get up and running on 3.0 from scratch. I&#39;m going to get to work on crafting my first OpenAPI definition using version 3.0, then I&#39;m going to begin playing around with some new approaches to API documentation and possibly an API editor or notebook that takes advantage of the changes in the OpenAPI Specification.m assuming that a number of the projects are abandoned, and even that their owners do not have the resources necessary to go from 2.0 to 3.0. Regardless, this is something I want to track on as part of this OpenAPI toolbox research.<br />The overall architecture of OpenAPI shifted pretty significantly from 2.0 to 3.0. Things are way more modular, and reusable&amp;nbsp;in there, something that will take some work to bring out in most of the tooling areas. Personally, Im pretty excited for the opportunities when it comes to API documentation and API design editors with OpenAPI 3.0 as the core. I am also hoping that developers step up to make sure that the generators, as well as the server and client code generators become available in a variety of programming languages--we will need this to make sure we keep the momentum that we&#39;ve established with the specification so far.<br />If you are looking at developing any tooling using OpenAPI 3.0 I&#39;d love to hear from you. I&#39;d like to hear more about what it will take to either migrate your tool from version 2.0 to 3.0&amp;nbsp;or even hear what it will take to get up and running on 3.0 from scratch. I&#39;m going to get to work on crafting my first OpenAPI definition using version 3.0, then I&#39;m going to begin playing around with some new approaches to API documentation and possibly an API editor or notebook that takes advantage of the changes in the OpenAPI Specification.m pretty excited for the opportunities when it comes to API documentation and API design editors with OpenAPI 3.0 as the core. I am also hoping that developers step up to make sure that the generators, as well as the server and client code generators become available in a variety of programming languages--we will need this to make sure we keep the momentum that weve established with the specification so far.<br />If you are looking at developing any tooling using OpenAPI 3.0 I&#39;d love to hear from you. I&#39;d like to hear more about what it will take to either migrate your tool from version 2.0 to 3.0&amp;nbsp;or even hear what it will take to get up and running on 3.0 from scratch. I&#39;m going to get to work on crafting my first OpenAPI definition using version 3.0, then I&#39;m going to begin playing around with some new approaches to API documentation and possibly an API editor or notebook that takes advantage of the changes in the OpenAPI Specification.ve established with the specification so far.<br />If you are looking at developing any tooling using OpenAPI 3.0 Id love to hear from you. I&#39;d like to hear more about what it will take to either migrate your tool from version 2.0 to 3.0&amp;nbsp;or even hear what it will take to get up and running on 3.0 from scratch. I&#39;m going to get to work on crafting my first OpenAPI definition using version 3.0, then I&#39;m going to begin playing around with some new approaches to API documentation and possibly an API editor or notebook that takes advantage of the changes in the OpenAPI Specification.d love to hear from you. Id like to hear more about what it will take to either migrate your tool from version 2.0 to 3.0&amp;nbsp;or even hear what it will take to get up and running on 3.0 from scratch. I&#39;m going to get to work on crafting my first OpenAPI definition using version 3.0, then I&#39;m going to begin playing around with some new approaches to API documentation and possibly an API editor or notebook that takes advantage of the changes in the OpenAPI Specification.d like to hear more about what it will take to either migrate your tool from version 2.0 to 3.0&amp;nbsp;or even hear what it will take to get up and running on 3.0 from scratch. Im going to get to work on crafting my first OpenAPI definition using version 3.0, then I&#39;m going to begin playing around with some new approaches to API documentation and possibly an API editor or notebook that takes advantage of the changes in the OpenAPI Specification.m going to get to work on crafting my first OpenAPI definition using version 3.0, then Im going to begin playing around with some new approaches to API documentation and possibly an API editor or notebook that takes advantage of the changes in the OpenAPI Specification.m going to begin playing around with some new approaches to API documentation and possibly an API editor or notebook that takes advantage of the changes in the OpenAPI Specification.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/openapi_spec_structural_improvements.png"
  },
  {
  "title": "API Environment Variable Autocomplete And Tooltips In Postman",
  "date": "16 Mar 2017",
  "body": "<br />The Postman team has been hard at work lately,&amp;nbsp;releasing their API data editor, as well as introducing variable highlighting and tooltips. The new&amp;nbsp;autocomplete menu contains a list of all the variables in the current environment, followed by global variables, making your API environment setups more accessible from the Postman interface. Introducing a pretty significant time saver, once you have your environments setup properly.<br />This is a pretty interesting feature, but what makes me most optimistic, is when this approach becomes available for parameters, headers, and some of the data management features we are seeing emerge with the new Portman data editor. It all feels like the UI equivalent of what weve seen emerge in the latest OpenAPI 3.0 release, helping us better manage and reuse the schema, data, and other bits we put to use across all of our APIs.&amp;nbsp;<br />Imagine when you can design and mock your API in Postman, crafting our API&amp;nbsp;using a common vocabulary. Reusing environment variables, API path resources, parameters, headers, and other common elements already in use across operations. Imagine when I get tooltip suggesting that I use Schema.org vocabulary, or possibly even RFCs for a date, currency, and other common definitions. Anyways, I&#39;m liking the features coming out of postman, and I&#39;m also liking that they are regularly blogging about this stuff, so I can keep up to speed on what is going on, and eventually cover here on the blog, and include in my research.ve seen emerge in the latest OpenAPI 3.0 release, helping us better manage and reuse the schema, data, and other bits we put to use across all of our APIs.&amp;nbsp;<br />Imagine when you can design and mock your API in Postman, crafting our API&amp;nbsp;using a common vocabulary. Reusing environment variables, API path resources, parameters, headers, and other common elements already in use across operations. Imagine when I get tooltip suggesting that I use Schema.org vocabulary, or possibly even RFCs for a date, currency, and other common definitions. Anyways, Im liking the features coming out of postman, and I&#39;m also liking that they are regularly blogging about this stuff, so I can keep up to speed on what is going on, and eventually cover here on the blog, and include in my research.m liking the features coming out of postman, and Im also liking that they are regularly blogging about this stuff, so I can keep up to speed on what is going on, and eventually cover here on the blog, and include in my research.m also liking that they are regularly blogging about this stuff, so I can keep up to speed on what is going on, and eventually cover here on the blog, and include in my research.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/autocomplete.gif,qx38712.pagespeed.ce.mdv9wuhtbw.gif"
  },
  {
  "title": "Tracking On Licensing For The Solutions In My OpenAPI Toolbox",
  "date": "15 Mar 2017",
  "body": "<br />I wanted to provide an easy way to publish and share some of the tools that Im tracking on in the OpenAPI ecosystem, so I launched my API toolbox. In addition to tracking on the name, description, logo, and URL for OpenAPI tooling, I also wanted to categorize them, helping me better understand the different types of tools that are emerging. As I do with all my research, I published the OpenAPI Toolbox as a Github repository, leveraging its YAML data core to store all the tools.&amp;nbsp;<br />It will be a never ending project for me to add, update, and archive abandoned projects, but before I got too far down the road I wanted to also begin tracking on the license for each of the tools. I&#39;m still deciding whether or not I want the toolbox to exclusively contain openly licensed tools, or look to provide a more comprehensive directory of tooling that includes unknown and proprietary solutions. I think for now I will just flag any tool I cannot find a license for, and follow up with the owner--it gives me a good excuse to reach out and see if there is anyone home.<br />Eventually, I want to also provide a search for the toolbox that allows users to search for tools&amp;nbsp;and filter by license. Most of the tools have been Apache 2.0 or MIT license, details that I will continue to keep tracking and reporting on. If you know of any tooling that employs the OpenAPI Specification that should be included feel free to submit a Github issue for the project, or submit a pull request on the repository and add it to the YAML data file that drives that OpenAPI Toolbox.m tracking on in the OpenAPI ecosystem, so I launched my API toolbox. In addition to tracking on the name, description, logo, and URL for OpenAPI tooling, I also wanted to categorize them, helping me better understand the different types of tools that are emerging. As I do with all my research, I published the OpenAPI Toolbox as a Github repository, leveraging its YAML data core to store all the tools.&amp;nbsp;<br />It will be a never ending project for me to add, update, and archive abandoned projects, but before I got too far down the road I wanted to also begin tracking on the license for each of the tools. Im still deciding whether or not I want the toolbox to exclusively contain openly licensed tools, or look to provide a more comprehensive directory of tooling that includes unknown and proprietary solutions. I think for now I will just flag any tool I cannot find a license for, and follow up with the owner--it gives me a good excuse to reach out and see if there is anyone home.<br />Eventually, I want to also provide a search for the toolbox that allows users to search for tools&amp;nbsp;and filter by license. Most of the tools have been Apache 2.0 or MIT license, details that I will continue to keep tracking and reporting on. If you know of any tooling that employs the OpenAPI Specification that should be included feel free to submit a Github issue for the project, or submit a pull request on the repository and add it to the YAML data file that drives that OpenAPI Toolbox.m still deciding whether or not I want the toolbox to exclusively contain openly licensed tools, or look to provide a more comprehensive directory of tooling that includes unknown and proprietary solutions. I think for now I will just flag any tool I cannot find a license for, and follow up with the owner--it gives me a good excuse to reach out and see if there is anyone home.<br />Eventually, I want to also provide a search for the toolbox that allows users to search for tools&amp;nbsp;and filter by license. Most of the tools have been Apache 2.0 or MIT license, details that I will continue to keep tracking and reporting on. If you know of any tooling that employs the OpenAPI Specification that should be included feel free to submit a Github issue for the project, or submit a pull request on the repository and add it to the YAML data file that drives that OpenAPI Toolbox.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_12_at_11.20.06_pm.png"
  },
  {
  "title": "Thinking About Schema.org&#039;s Relationship To API Discovery",
  "date": "15 Mar 2017",
  "body": "<br />I was following the discussion around adding a&amp;nbsp;WebAPI class to Schema.orgs core vocabulary, and it got me to think more about the role Schema.org has to play with not just our API definitions, but also significantly influencing API discovery. Meaning that we should be using Schema.org as part of our OpenAPI definitions, providing us with a common vocabulary for communicating around our APIs, but also empowering the discovery of APIs.&amp;nbsp;<br />When I describe the relationship between Schema.org to API discovery, I&#39;m talking about using the pending WebAPI class, but I&#39;m also talking about using common Schema.org org within API definitions--something that will open the definitions to discovery because it employs a common schema. I am also talking about how do we leverage this vocabulary in our HTML pages, helping search engines like Google understand there is an API service available:<br /><br />I&amp;nbsp;will also be exploring how I can better leverage Schema.org in my APIs.json&amp;nbsp;format, better leveraging a common vocabulary describing API operations, not just an individual API. I&#39;m looking to expand the opportunities for discovering, not limit them. I would love all APIs to take a page from the hypermedia playbook, and have a machine readable index for each API, with a set of links present with each response, but I also want folks to learn about APIs through Google, ensuring they are indexed in a way that search engines can comprehend.<br />When it comes to API discovery I am primarily invested in APIs.json (because it&#39;s my baby) describing API operations, and OpenAPI to describe the surface area of an API, but I also want this to map to the very SEO driven world we operate in right now. I will keep investing time in helping folks use Schema.org in their API definitions (APIs.json&amp;nbsp;&amp;amp; OpenAPI), but I will also start investing in folks employing JSON+LD and Schema.org as part of their search engine strategies (like above), making our APIs more discoverable to humans as well as other systems.s core vocabulary, and it got me to think more about the role Schema.org has to play with not just our API definitions, but also significantly influencing API discovery. Meaning that we should be using Schema.org as part of our OpenAPI definitions, providing us with a common vocabulary for communicating around our APIs, but also empowering the discovery of APIs.&amp;nbsp;<br />When I describe the relationship between Schema.org to API discovery, Im talking about using the pending WebAPI class, but I&#39;m also talking about using common Schema.org org within API definitions--something that will open the definitions to discovery because it employs a common schema. I am also talking about how do we leverage this vocabulary in our HTML pages, helping search engines like Google understand there is an API service available:<br /><br />I&amp;nbsp;will also be exploring how I can better leverage Schema.org in my APIs.json&amp;nbsp;format, better leveraging a common vocabulary describing API operations, not just an individual API. I&#39;m looking to expand the opportunities for discovering, not limit them. I would love all APIs to take a page from the hypermedia playbook, and have a machine readable index for each API, with a set of links present with each response, but I also want folks to learn about APIs through Google, ensuring they are indexed in a way that search engines can comprehend.<br />When it comes to API discovery I am primarily invested in APIs.json (because it&#39;s my baby) describing API operations, and OpenAPI to describe the surface area of an API, but I also want this to map to the very SEO driven world we operate in right now. I will keep investing time in helping folks use Schema.org in their API definitions (APIs.json&amp;nbsp;&amp;amp; OpenAPI), but I will also start investing in folks employing JSON+LD and Schema.org as part of their search engine strategies (like above), making our APIs more discoverable to humans as well as other systems.m talking about using the pending WebAPI class, but Im also talking about using common Schema.org org within API definitions--something that will open the definitions to discovery because it employs a common schema. I am also talking about how do we leverage this vocabulary in our HTML pages, helping search engines like Google understand there is an API service available:<br /><br />I&amp;nbsp;will also be exploring how I can better leverage Schema.org in my APIs.json&amp;nbsp;format, better leveraging a common vocabulary describing API operations, not just an individual API. I&#39;m looking to expand the opportunities for discovering, not limit them. I would love all APIs to take a page from the hypermedia playbook, and have a machine readable index for each API, with a set of links present with each response, but I also want folks to learn about APIs through Google, ensuring they are indexed in a way that search engines can comprehend.<br />When it comes to API discovery I am primarily invested in APIs.json (because it&#39;s my baby) describing API operations, and OpenAPI to describe the surface area of an API, but I also want this to map to the very SEO driven world we operate in right now. I will keep investing time in helping folks use Schema.org in their API definitions (APIs.json&amp;nbsp;&amp;amp; OpenAPI), but I will also start investing in folks employing JSON+LD and Schema.org as part of their search engine strategies (like above), making our APIs more discoverable to humans as well as other systems.m also talking about using common Schema.org org within API definitions--something that will open the definitions to discovery because it employs a common schema. I am also talking about how do we leverage this vocabulary in our HTML pages, helping search engines like Google understand there is an API service available:<br /><br />I&amp;nbsp;will also be exploring how I can better leverage Schema.org in my APIs.json&amp;nbsp;format, better leveraging a common vocabulary describing API operations, not just an individual API. Im looking to expand the opportunities for discovering, not limit them. I would love all APIs to take a page from the hypermedia playbook, and have a machine readable index for each API, with a set of links present with each response, but I also want folks to learn about APIs through Google, ensuring they are indexed in a way that search engines can comprehend.<br />When it comes to API discovery I am primarily invested in APIs.json (because it&#39;s my baby) describing API operations, and OpenAPI to describe the surface area of an API, but I also want this to map to the very SEO driven world we operate in right now. I will keep investing time in helping folks use Schema.org in their API definitions (APIs.json&amp;nbsp;&amp;amp; OpenAPI), but I will also start investing in folks employing JSON+LD and Schema.org as part of their search engine strategies (like above), making our APIs more discoverable to humans as well as other systems.m looking to expand the opportunities for discovering, not limit them. I would love all APIs to take a page from the hypermedia playbook, and have a machine readable index for each API, with a set of links present with each response, but I also want folks to learn about APIs through Google, ensuring they are indexed in a way that search engines can comprehend.<br />When it comes to API discovery I am primarily invested in APIs.json (because its my baby) describing API operations, and OpenAPI to describe the surface area of an API, but I also want this to map to the very SEO driven world we operate in right now. I will keep investing time in helping folks use Schema.org in their API definitions (APIs.json&amp;nbsp;&amp;amp; OpenAPI), but I will also start investing in folks employing JSON+LD and Schema.org as part of their search engine strategies (like above), making our APIs more discoverable to humans as well as other systems.s my baby) describing API operations, and OpenAPI to describe the surface area of an API, but I also want this to map to the very SEO driven world we operate in right now. I will keep investing time in helping folks use Schema.org in their API definitions (APIs.json&amp;nbsp;&amp;amp; OpenAPI), but I will also start investing in folks employing JSON+LD and Schema.org as part of their search engine strategies (like above), making our APIs more discoverable to humans as well as other systems.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/schema-org/schema-org.png"
  },
  {
  "title": "Getting Our Schema In Order With Postman&#039;s New Data Editor",
  "date": "15 Mar 2017",
  "body": "<br />In 2017 I think that getting our act together when it comes to our data&amp;nbsp;schema will prove to be just as important as getting it together when it comes to our API definitions and design. This is one reason Im such a big fan of using OpenAPI to define our APIs because it allows us to better organize the schema of the data included as part of the API request and response structure. So I am happy to see Postman announce their new data editor, something I&#39;m hoping will help us make sense of the schema we are using throughout our API operations.<br />The Postman data editor provides us with some pretty slick data management UI features including&amp;nbsp;drag and drop, a wealth of useful keyboard shortcuts, bulk actions, and other timesaving features. Postman has gone a long way to inject awareness into how we are using APIs over the last couple of years, and the data editor will only continue developing this awareness when it comes to the data we are passing back and forth. Lord knows&amp;nbsp;we need all the help we can get&amp;nbsp;when it comes to getting our data backends in order.<br />The Postman data editor makes me happy, but I&#39;m most optimistic about what it will enable, and what Postman has planned as part of their roadmap. They end their announcement with we&amp;nbsp;have a LOT of new feature releases planned to build on top of this editor, capabilities inspired by things you already do using&amp;nbsp;spreadsheets. For me, this points to some features that would directly map to the most ubiquitous data tools out there--the spreadsheet. With a significant&amp;nbsp;portion of business in the world is done via spreadsheets, it makes the concept of integration into the API toolchain a pretty compelling thing.m such a big fan of using OpenAPI to define our APIs because it allows us to better organize the schema of the data included as part of the API request and response structure. So I am happy to see Postman announce their new data editor, something Im hoping will help us make sense of the schema we are using throughout our API operations.<br />The Postman data editor provides us with some pretty slick data management UI features including&amp;nbsp;drag and drop, a wealth of useful keyboard shortcuts, bulk actions, and other timesaving features. Postman has gone a long way to inject awareness into how we are using APIs over the last couple of years, and the data editor will only continue developing this awareness when it comes to the data we are passing back and forth. Lord knows&amp;nbsp;we need all the help we can get&amp;nbsp;when it comes to getting our data backends in order.<br />The Postman data editor makes me happy, but I&#39;m most optimistic about what it will enable, and what Postman has planned as part of their roadmap. They end their announcement with we&amp;nbsp;have a LOT of new feature releases planned to build on top of this editor, capabilities inspired by things you already do using&amp;nbsp;spreadsheets. For me, this points to some features that would directly map to the most ubiquitous data tools out there--the spreadsheet. With a significant&amp;nbsp;portion of business in the world is done via spreadsheets, it makes the concept of integration into the API toolchain a pretty compelling thing.m hoping will help us make sense of the schema we are using throughout our API operations.<br />The Postman data editor provides us with some pretty slick data management UI features including&amp;nbsp;drag and drop, a wealth of useful keyboard shortcuts, bulk actions, and other timesaving features. Postman has gone a long way to inject awareness into how we are using APIs over the last couple of years, and the data editor will only continue developing this awareness when it comes to the data we are passing back and forth. Lord knows&amp;nbsp;we need all the help we can get&amp;nbsp;when it comes to getting our data backends in order.<br />The Postman data editor makes me happy, but Im most optimistic about what it will enable, and what Postman has planned as part of their roadmap. They end their announcement with we&amp;nbsp;have a LOT of new feature releases planned to build on top of this editor, capabilities inspired by things you already do using&amp;nbsp;spreadsheets. For me, this points to some features that would directly map to the most ubiquitous data tools out there--the spreadsheet. With a significant&amp;nbsp;portion of business in the world is done via spreadsheets, it makes the concept of integration into the API toolchain a pretty compelling thing.m most optimistic about what it will enable, and what Postman has planned as part of their roadmap. They end their announcement with we&amp;nbsp;have a LOT of new feature releases planned to build on top of this editor, capabilities inspired by things you already do using&amp;nbsp;spreadsheets. For me, this points to some features that would directly map to the most ubiquitous data tools out there--the spreadsheet. With a significant&amp;nbsp;portion of business in the world is done via spreadsheets, it makes the concept of integration into the API toolchain a pretty compelling thing.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/dataeditor.gif,qx38712.pagespeed.ce.jrrfqkxj5z.gif"
  },
  {
  "title": "A Tighter API Contract With gRPC",
  "date": "15 Mar 2017",
  "body": "<br />I was learning more about gRPC from the Google team last week, while at the Google Community Summit, as well as the API Craft SF Meetup. Im still learning about gRPC, and how it contributes to the API conversation, so I am trying to share what I learn as I go, keeping a record for others to learn from&amp;nbsp;along the way. One thing I wanted to better understand was something I kept hearing regarding gRPC delivering more of a tighter API contract between API provider and consumer.<br />In contrast to more RESTful APIs, a gRPC client has to be generated by the provider. First, you define a service in a .proto file (aka Protocol Buffer), then you generate client code using the protocol buffer compiler. Where client SDKs are up for debate in the world of RESTful APIs, and client generation might even be frowned upon in some circles, when it comes to gRPC APIs, client generation is a requirement--dictating a much&amp;nbsp;tighter coupling and contract, between API provider and consumer.&amp;nbsp;<br />I do not have the first-hand experience with this process yet, I am just learning from my discussions last week, and trying to understand how gRPC is different from the way we&#39;ve been doing APIs using a RESTful approach. So far it seems like you might want to consider gRPC if you are looking for significant levels of performance from your APIs, in situations where you have a tighter relationship with your consumers, such as internal, or partner scenarios. gRPC requires a tighter API contract between provider and consumer, something that might not always be possible, depending on the situation.&amp;nbsp;<br />While I&#39;m still getting up to speed, it seems to me that the .proto file, or the protocol buffer definition acts as the language for this API contract. Similar to how OpenAPI is quickly becoming a contract for more RESTful APIs, although it is often times much looser contract. I&#39;ll keep investing time into learning about gRP, but. I wanted to make sure and process what I&#39;ve learned leading up to, and while at Google this last week. I&#39;m not convinced yet that gRPC is the future of APIs, but I am getting more convinced that it is another important tool in our API toolbox.m still learning about gRPC, and how it contributes to the API conversation, so I am trying to share what I learn as I go, keeping a record for others to learn from&amp;nbsp;along the way. One thing I wanted to better understand was something I kept hearing regarding gRPC delivering more of a tighter API contract between API provider and consumer.<br />In contrast to more RESTful APIs, a gRPC client has to be generated by the provider. First, you define a service in a .proto file (aka Protocol Buffer), then you generate client code using the protocol buffer compiler. Where client SDKs are up for debate in the world of RESTful APIs, and client generation might even be frowned upon in some circles, when it comes to gRPC APIs, client generation is a requirement--dictating a much&amp;nbsp;tighter coupling and contract, between API provider and consumer.&amp;nbsp;<br />I do not have the first-hand experience with this process yet, I am just learning from my discussions last week, and trying to understand how gRPC is different from the way weve been doing APIs using a RESTful approach. So far it seems like you might want to consider gRPC if you are looking for significant levels of performance from your APIs, in situations where you have a tighter relationship with your consumers, such as internal, or partner scenarios. gRPC requires a tighter API contract between provider and consumer, something that might not always be possible, depending on the situation.&amp;nbsp;<br />While I&#39;m still getting up to speed, it seems to me that the .proto file, or the protocol buffer definition acts as the language for this API contract. Similar to how OpenAPI is quickly becoming a contract for more RESTful APIs, although it is often times much looser contract. I&#39;ll keep investing time into learning about gRP, but. I wanted to make sure and process what I&#39;ve learned leading up to, and while at Google this last week. I&#39;m not convinced yet that gRPC is the future of APIs, but I am getting more convinced that it is another important tool in our API toolbox.ve been doing APIs using a RESTful approach. So far it seems like you might want to consider gRPC if you are looking for significant levels of performance from your APIs, in situations where you have a tighter relationship with your consumers, such as internal, or partner scenarios. gRPC requires a tighter API contract between provider and consumer, something that might not always be possible, depending on the situation.&amp;nbsp;<br />While Im still getting up to speed, it seems to me that the .proto file, or the protocol buffer definition acts as the language for this API contract. Similar to how OpenAPI is quickly becoming a contract for more RESTful APIs, although it is often times much looser contract. I&#39;ll keep investing time into learning about gRP, but. I wanted to make sure and process what I&#39;ve learned leading up to, and while at Google this last week. I&#39;m not convinced yet that gRPC is the future of APIs, but I am getting more convinced that it is another important tool in our API toolbox.m still getting up to speed, it seems to me that the .proto file, or the protocol buffer definition acts as the language for this API contract. Similar to how OpenAPI is quickly becoming a contract for more RESTful APIs, although it is often times much looser contract. Ill keep investing time into learning about gRP, but. I wanted to make sure and process what I&#39;ve learned leading up to, and while at Google this last week. I&#39;m not convinced yet that gRPC is the future of APIs, but I am getting more convinced that it is another important tool in our API toolbox.ll keep investing time into learning about gRP, but. I wanted to make sure and process what Ive learned leading up to, and while at Google this last week. I&#39;m not convinced yet that gRPC is the future of APIs, but I am getting more convinced that it is another important tool in our API toolbox.ve learned leading up to, and while at Google this last week. Im not convinced yet that gRPC is the future of APIs, but I am getting more convinced that it is another important tool in our API toolbox.m not convinced yet that gRPC is the future of APIs, but I am getting more convinced that it is another important tool in our API toolbox.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_12_at_9.16.57_pm.png"
  },
  {
  "title": "Thinking About Schema.org&#039;s Relationship To API Discovery",
  "date": "14 Mar 2017",
  "body": "<br />I was following the discussion around adding a&amp;nbsp;WebAPI class to Schema.orgs core vocabulary, and it got me to think more about the role Schema.org has to play with not just our API definitions, but also significantly influencing API discovery. Meaning that we should be using Schema.org as part of our OpenAPI definitions, providing us with a common vocabulary for communicating around our APIs, but also empowering the discovery of APIs.&amp;nbsp;<br />When I describe the relationship between Schema.org to API discovery, I&#39;m talking about using the pending WebAPI class, but I&#39;m also talking about using common Schema.org org within API definitions--something that will open the definitions to discovery because it employs a common schema. I am also talking about how do we leverage this vocabulary in our HTML pages, helping search engines like Google understand there is an API service available:<br /><br />I&amp;nbsp;will also be exploring how I can better leverage Schema.org in my APIs.json&amp;nbsp;format, better leveraging a common vocabulary describing API operations, not just an individual API. I&#39;m looking to expand the opportunities for discovering, not limit them. I would love all APIs to take a page from the hypermedia playbook, and have a machine readable index for each API, with a set of links present with each response, but I also want folks to learn about APIs through Google, ensuring they are indexed in a way that search engines can comprehend.<br />When it comes to API discovery I am primarily invested in APIs.json (because it&#39;s my baby) describing API operations, and OpenAPI to describe the surface area of an API, but I also want this to map to the very SEO driven world we operate in right now. I will keep investing time in helping folks use Schema.org in their API definitions (APIs.json&amp;nbsp;&amp;amp; OpenAPI), but I will also start investing in folks employing JSON+LD and Schema.org as part of their search engine strategies (like above), making our APIs more discoverable to humans as well as other systems.s core vocabulary, and it got me to think more about the role Schema.org has to play with not just our API definitions, but also significantly influencing API discovery. Meaning that we should be using Schema.org as part of our OpenAPI definitions, providing us with a common vocabulary for communicating around our APIs, but also empowering the discovery of APIs.&amp;nbsp;<br />When I describe the relationship between Schema.org to API discovery, Im talking about using the pending WebAPI class, but I&#39;m also talking about using common Schema.org org within API definitions--something that will open the definitions to discovery because it employs a common schema. I am also talking about how do we leverage this vocabulary in our HTML pages, helping search engines like Google understand there is an API service available:<br /><br />I&amp;nbsp;will also be exploring how I can better leverage Schema.org in my APIs.json&amp;nbsp;format, better leveraging a common vocabulary describing API operations, not just an individual API. I&#39;m looking to expand the opportunities for discovering, not limit them. I would love all APIs to take a page from the hypermedia playbook, and have a machine readable index for each API, with a set of links present with each response, but I also want folks to learn about APIs through Google, ensuring they are indexed in a way that search engines can comprehend.<br />When it comes to API discovery I am primarily invested in APIs.json (because it&#39;s my baby) describing API operations, and OpenAPI to describe the surface area of an API, but I also want this to map to the very SEO driven world we operate in right now. I will keep investing time in helping folks use Schema.org in their API definitions (APIs.json&amp;nbsp;&amp;amp; OpenAPI), but I will also start investing in folks employing JSON+LD and Schema.org as part of their search engine strategies (like above), making our APIs more discoverable to humans as well as other systems.m talking about using the pending WebAPI class, but Im also talking about using common Schema.org org within API definitions--something that will open the definitions to discovery because it employs a common schema. I am also talking about how do we leverage this vocabulary in our HTML pages, helping search engines like Google understand there is an API service available:<br /><br />I&amp;nbsp;will also be exploring how I can better leverage Schema.org in my APIs.json&amp;nbsp;format, better leveraging a common vocabulary describing API operations, not just an individual API. I&#39;m looking to expand the opportunities for discovering, not limit them. I would love all APIs to take a page from the hypermedia playbook, and have a machine readable index for each API, with a set of links present with each response, but I also want folks to learn about APIs through Google, ensuring they are indexed in a way that search engines can comprehend.<br />When it comes to API discovery I am primarily invested in APIs.json (because it&#39;s my baby) describing API operations, and OpenAPI to describe the surface area of an API, but I also want this to map to the very SEO driven world we operate in right now. I will keep investing time in helping folks use Schema.org in their API definitions (APIs.json&amp;nbsp;&amp;amp; OpenAPI), but I will also start investing in folks employing JSON+LD and Schema.org as part of their search engine strategies (like above), making our APIs more discoverable to humans as well as other systems.m also talking about using common Schema.org org within API definitions--something that will open the definitions to discovery because it employs a common schema. I am also talking about how do we leverage this vocabulary in our HTML pages, helping search engines like Google understand there is an API service available:<br /><br />I&amp;nbsp;will also be exploring how I can better leverage Schema.org in my APIs.json&amp;nbsp;format, better leveraging a common vocabulary describing API operations, not just an individual API. Im looking to expand the opportunities for discovering, not limit them. I would love all APIs to take a page from the hypermedia playbook, and have a machine readable index for each API, with a set of links present with each response, but I also want folks to learn about APIs through Google, ensuring they are indexed in a way that search engines can comprehend.<br />When it comes to API discovery I am primarily invested in APIs.json (because it&#39;s my baby) describing API operations, and OpenAPI to describe the surface area of an API, but I also want this to map to the very SEO driven world we operate in right now. I will keep investing time in helping folks use Schema.org in their API definitions (APIs.json&amp;nbsp;&amp;amp; OpenAPI), but I will also start investing in folks employing JSON+LD and Schema.org as part of their search engine strategies (like above), making our APIs more discoverable to humans as well as other systems.m looking to expand the opportunities for discovering, not limit them. I would love all APIs to take a page from the hypermedia playbook, and have a machine readable index for each API, with a set of links present with each response, but I also want folks to learn about APIs through Google, ensuring they are indexed in a way that search engines can comprehend.<br />When it comes to API discovery I am primarily invested in APIs.json (because its my baby) describing API operations, and OpenAPI to describe the surface area of an API, but I also want this to map to the very SEO driven world we operate in right now. I will keep investing time in helping folks use Schema.org in their API definitions (APIs.json&amp;nbsp;&amp;amp; OpenAPI), but I will also start investing in folks employing JSON+LD and Schema.org as part of their search engine strategies (like above), making our APIs more discoverable to humans as well as other systems.s my baby) describing API operations, and OpenAPI to describe the surface area of an API, but I also want this to map to the very SEO driven world we operate in right now. I will keep investing time in helping folks use Schema.org in their API definitions (APIs.json&amp;nbsp;&amp;amp; OpenAPI), but I will also start investing in folks employing JSON+LD and Schema.org as part of their search engine strategies (like above), making our APIs more discoverable to humans as well as other systems.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/schema-org/schema-org.png"
  },
  {
  "title": "Getting Our Schema In Order With Postman&#039;s New Data Editor",
  "date": "14 Mar 2017",
  "body": "<br />In 2017 I think that getting our act together when it comes to our data&amp;nbsp;schema will prove to be just as important as getting it together when it comes to our API definitions and design. This is one reason Im such a big fan of using OpenAPI to define our APIs because it allows us to better organize the schema of the data included as part of the API request and response structure. So I am happy to see Postman announce their new data editor, something I&#39;m hoping will help us make sense of the schema we are using throughout our API operations.<br />The Postman data editor provides us with some pretty slick data management UI features including&amp;nbsp;drag and drop, a wealth of useful keyboard shortcuts, bulk actions, and other timesaving features. Postman has gone a long way to inject awareness into how we are using APIs over the last couple of years, and the data editor will only continue developing this awareness when it comes to the data we are passing back and forth. Lord knows&amp;nbsp;we need all the help we can get&amp;nbsp;when it comes to getting our data backends in order.<br />The Postman data editor makes me happy, but I&#39;m most optimistic about what it will enable, and what Postman has planned as part of their roadmap. They end their announcement with we&amp;nbsp;have a LOT of new feature releases planned to build on top of this editor, capabilities inspired by things you already do using&amp;nbsp;spreadsheets. For me, this points to some features that would directly map to the most ubiquitous data tools out there--the spreadsheet. With a significant&amp;nbsp;portion of business in the world is done via spreadsheets, it makes the concept of integration into the API toolchain a pretty compelling thing.m such a big fan of using OpenAPI to define our APIs because it allows us to better organize the schema of the data included as part of the API request and response structure. So I am happy to see Postman announce their new data editor, something Im hoping will help us make sense of the schema we are using throughout our API operations.<br />The Postman data editor provides us with some pretty slick data management UI features including&amp;nbsp;drag and drop, a wealth of useful keyboard shortcuts, bulk actions, and other timesaving features. Postman has gone a long way to inject awareness into how we are using APIs over the last couple of years, and the data editor will only continue developing this awareness when it comes to the data we are passing back and forth. Lord knows&amp;nbsp;we need all the help we can get&amp;nbsp;when it comes to getting our data backends in order.<br />The Postman data editor makes me happy, but I&#39;m most optimistic about what it will enable, and what Postman has planned as part of their roadmap. They end their announcement with we&amp;nbsp;have a LOT of new feature releases planned to build on top of this editor, capabilities inspired by things you already do using&amp;nbsp;spreadsheets. For me, this points to some features that would directly map to the most ubiquitous data tools out there--the spreadsheet. With a significant&amp;nbsp;portion of business in the world is done via spreadsheets, it makes the concept of integration into the API toolchain a pretty compelling thing.m hoping will help us make sense of the schema we are using throughout our API operations.<br />The Postman data editor provides us with some pretty slick data management UI features including&amp;nbsp;drag and drop, a wealth of useful keyboard shortcuts, bulk actions, and other timesaving features. Postman has gone a long way to inject awareness into how we are using APIs over the last couple of years, and the data editor will only continue developing this awareness when it comes to the data we are passing back and forth. Lord knows&amp;nbsp;we need all the help we can get&amp;nbsp;when it comes to getting our data backends in order.<br />The Postman data editor makes me happy, but Im most optimistic about what it will enable, and what Postman has planned as part of their roadmap. They end their announcement with we&amp;nbsp;have a LOT of new feature releases planned to build on top of this editor, capabilities inspired by things you already do using&amp;nbsp;spreadsheets. For me, this points to some features that would directly map to the most ubiquitous data tools out there--the spreadsheet. With a significant&amp;nbsp;portion of business in the world is done via spreadsheets, it makes the concept of integration into the API toolchain a pretty compelling thing.m most optimistic about what it will enable, and what Postman has planned as part of their roadmap. They end their announcement with we&amp;nbsp;have a LOT of new feature releases planned to build on top of this editor, capabilities inspired by things you already do using&amp;nbsp;spreadsheets. For me, this points to some features that would directly map to the most ubiquitous data tools out there--the spreadsheet. With a significant&amp;nbsp;portion of business in the world is done via spreadsheets, it makes the concept of integration into the API toolchain a pretty compelling thing.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/dataeditor.gif,qx38712.pagespeed.ce.jrrfqkxj5z.gif"
  },
  {
  "title": "A Tighter API Contract With gRPC",
  "date": "14 Mar 2017",
  "body": "<br />I was learning more about gRPC from the Google team last week, while at the Google Community Summit, as well as the API Craft SF Meetup. Im still learning about gRPC, and how it contributes to the API conversation, so I am trying to share what I learn as I go, keeping a record for others to learn from&amp;nbsp;along the way. One thing I wanted to better understand was something I kept hearing regarding gRPC delivering more of a tighter API contract between API provider and consumer.<br />In contrast to more RESTful APIs, a gRPC client has to be generated by the provider. First, you define a service in a .proto file (aka Protocol Buffer), then you generate client code using the protocol buffer compiler. Where client SDKs are up for debate in the world of RESTful APIs, and client generation might even be frowned upon in some circles, when it comes to gRPC APIs, client generation is a requirement--dictating a much&amp;nbsp;tighter coupling and contract, between API provider and consumer.&amp;nbsp;<br />I do not have the first-hand experience with this process yet, I am just learning from my discussions last week, and trying to understand how gRPC is different from the way we&#39;ve been doing APIs using a RESTful approach. So far it seems like you might want to consider gRPC if you are looking for significant levels of performance from your APIs, in situations where you have a tighter relationship with your consumers, such as internal, or partner scenarios. gRPC requires a tighter API contract between provider and consumer, something that might not always be possible, depending on the situation.&amp;nbsp;<br />While I&#39;m still getting up to speed, it seems to me that the .proto file, or the protocol buffer definition acts as the language for this API contract. Similar to how OpenAPI is quickly becoming a contract for more RESTful APIs, although it is often times much looser contract. I&#39;ll keep investing time into learning about gRP, but. I wanted to make sure and process what I&#39;ve learned leading up to, and while at Google this last week. I&#39;m not convinced yet that gRPC is the future of APIs, but I am getting more convinced that it is another important tool in our API toolbox.m still learning about gRPC, and how it contributes to the API conversation, so I am trying to share what I learn as I go, keeping a record for others to learn from&amp;nbsp;along the way. One thing I wanted to better understand was something I kept hearing regarding gRPC delivering more of a tighter API contract between API provider and consumer.<br />In contrast to more RESTful APIs, a gRPC client has to be generated by the provider. First, you define a service in a .proto file (aka Protocol Buffer), then you generate client code using the protocol buffer compiler. Where client SDKs are up for debate in the world of RESTful APIs, and client generation might even be frowned upon in some circles, when it comes to gRPC APIs, client generation is a requirement--dictating a much&amp;nbsp;tighter coupling and contract, between API provider and consumer.&amp;nbsp;<br />I do not have the first-hand experience with this process yet, I am just learning from my discussions last week, and trying to understand how gRPC is different from the way weve been doing APIs using a RESTful approach. So far it seems like you might want to consider gRPC if you are looking for significant levels of performance from your APIs, in situations where you have a tighter relationship with your consumers, such as internal, or partner scenarios. gRPC requires a tighter API contract between provider and consumer, something that might not always be possible, depending on the situation.&amp;nbsp;<br />While I&#39;m still getting up to speed, it seems to me that the .proto file, or the protocol buffer definition acts as the language for this API contract. Similar to how OpenAPI is quickly becoming a contract for more RESTful APIs, although it is often times much looser contract. I&#39;ll keep investing time into learning about gRP, but. I wanted to make sure and process what I&#39;ve learned leading up to, and while at Google this last week. I&#39;m not convinced yet that gRPC is the future of APIs, but I am getting more convinced that it is another important tool in our API toolbox.ve been doing APIs using a RESTful approach. So far it seems like you might want to consider gRPC if you are looking for significant levels of performance from your APIs, in situations where you have a tighter relationship with your consumers, such as internal, or partner scenarios. gRPC requires a tighter API contract between provider and consumer, something that might not always be possible, depending on the situation.&amp;nbsp;<br />While Im still getting up to speed, it seems to me that the .proto file, or the protocol buffer definition acts as the language for this API contract. Similar to how OpenAPI is quickly becoming a contract for more RESTful APIs, although it is often times much looser contract. I&#39;ll keep investing time into learning about gRP, but. I wanted to make sure and process what I&#39;ve learned leading up to, and while at Google this last week. I&#39;m not convinced yet that gRPC is the future of APIs, but I am getting more convinced that it is another important tool in our API toolbox.m still getting up to speed, it seems to me that the .proto file, or the protocol buffer definition acts as the language for this API contract. Similar to how OpenAPI is quickly becoming a contract for more RESTful APIs, although it is often times much looser contract. Ill keep investing time into learning about gRP, but. I wanted to make sure and process what I&#39;ve learned leading up to, and while at Google this last week. I&#39;m not convinced yet that gRPC is the future of APIs, but I am getting more convinced that it is another important tool in our API toolbox.ll keep investing time into learning about gRP, but. I wanted to make sure and process what Ive learned leading up to, and while at Google this last week. I&#39;m not convinced yet that gRPC is the future of APIs, but I am getting more convinced that it is another important tool in our API toolbox.ve learned leading up to, and while at Google this last week. Im not convinced yet that gRPC is the future of APIs, but I am getting more convinced that it is another important tool in our API toolbox.m not convinced yet that gRPC is the future of APIs, but I am getting more convinced that it is another important tool in our API toolbox.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_12_at_9.16.57_pm.png"
  },
  {
  "title": "API Definitions Covering Both REST and gRPC APIs",
  "date": "10 Mar 2017",
  "body": "<br />I have been learning more about the way Google designs and defines their APIs after their release of their API design guide. When I research a companys APIs I always spend time looking through their Github repositories for anything interesting, and while poking around in Google&#39;s I found a repository of interface definitions for a small (but growing) set of Google APIs. I keep track of any Github repo I find containing API definitions, but Google&#39;s repo stood out because it contained a set of API definitions that covered both APIs that support both REST and gRPC.<br />Straight from the Github repo, they support two ways of access APIs: Google APIs use&amp;nbsp;Protocol Buffers&amp;nbsp;version 3 (proto3) as their Interface Definition Language (IDL) to define the API interface and the structure of the payload messages. The same interface definition is used for both REST and RPC versions of the API, which can be accessed over different wire protocols.<br /><br /><br />JSON over HTTP: You can access Google APIs directly using JSON over HTTP, using&amp;nbsp;Google API client libraries&amp;nbsp;or third-party API client libraries.<br /><br /><br />Protocol Buffers over gRPC: You can access Google APIs published in this repository through&amp;nbsp;GRPC, which is a high-performance binary RPC protocol over HTTP/2. It offers many useful features, including request/response multiplex and full-duplex streaming.<br /><br /><br />This is the first example of this I&#39;ve seen in the wild, and it feels like we are shifting from an HTTP to an HTTP/2&amp;nbsp;API world. I don&#39;t think regular old REST or web APIs are going anywhere, I think they&#39;ll continue to be a staple, but it looks like Google is laying the groundwork for two-speed APIs, that are defined using a common API definition--you pick the speed you need. I&#39;ve been hearing tales of gRPC usage for a while and seeing more APIs defined using protocol buffers, but Google&#39;s approach signals a wider more significant shift for me.<br />I&#39;m still learning about gRPC, so I can&#39;t quite visualize the overlap between&amp;nbsp;gRPC and REST quite yet. I&#39;m going through their API definitions because they provide an interesting snapshot of the surface area of these hybrid APIs. As I spend my week in San Francisco for Google Next, I&#39;m eager to learn more about their evolving approach to designing and defining APIs--something that I think will be setting the tone for API design at scale in the near future.s APIs I always spend time looking through their Github repositories for anything interesting, and while poking around in Googles I found a repository of interface definitions for a small (but growing) set of Google APIs. I keep track of any Github repo I find containing API definitions, but Google&#39;s repo stood out because it contained a set of API definitions that covered both APIs that support both REST and gRPC.<br />Straight from the Github repo, they support two ways of access APIs: Google APIs use&amp;nbsp;Protocol Buffers&amp;nbsp;version 3 (proto3) as their Interface Definition Language (IDL) to define the API interface and the structure of the payload messages. The same interface definition is used for both REST and RPC versions of the API, which can be accessed over different wire protocols.<br /><br /><br />JSON over HTTP: You can access Google APIs directly using JSON over HTTP, using&amp;nbsp;Google API client libraries&amp;nbsp;or third-party API client libraries.<br /><br /><br />Protocol Buffers over gRPC: You can access Google APIs published in this repository through&amp;nbsp;GRPC, which is a high-performance binary RPC protocol over HTTP/2. It offers many useful features, including request/response multiplex and full-duplex streaming.<br /><br /><br />This is the first example of this I&#39;ve seen in the wild, and it feels like we are shifting from an HTTP to an HTTP/2&amp;nbsp;API world. I don&#39;t think regular old REST or web APIs are going anywhere, I think they&#39;ll continue to be a staple, but it looks like Google is laying the groundwork for two-speed APIs, that are defined using a common API definition--you pick the speed you need. I&#39;ve been hearing tales of gRPC usage for a while and seeing more APIs defined using protocol buffers, but Google&#39;s approach signals a wider more significant shift for me.<br />I&#39;m still learning about gRPC, so I can&#39;t quite visualize the overlap between&amp;nbsp;gRPC and REST quite yet. I&#39;m going through their API definitions because they provide an interesting snapshot of the surface area of these hybrid APIs. As I spend my week in San Francisco for Google Next, I&#39;m eager to learn more about their evolving approach to designing and defining APIs--something that I think will be setting the tone for API design at scale in the near future.s I found a repository of interface definitions for a small (but growing) set of Google APIs. I keep track of any Github repo I find containing API definitions, but Googles repo stood out because it contained a set of API definitions that covered both APIs that support both REST and gRPC.<br />Straight from the Github repo, they support two ways of access APIs: Google APIs use&amp;nbsp;Protocol Buffers&amp;nbsp;version 3 (proto3) as their Interface Definition Language (IDL) to define the API interface and the structure of the payload messages. The same interface definition is used for both REST and RPC versions of the API, which can be accessed over different wire protocols.<br /><br /><br />JSON over HTTP: You can access Google APIs directly using JSON over HTTP, using&amp;nbsp;Google API client libraries&amp;nbsp;or third-party API client libraries.<br /><br /><br />Protocol Buffers over gRPC: You can access Google APIs published in this repository through&amp;nbsp;GRPC, which is a high-performance binary RPC protocol over HTTP/2. It offers many useful features, including request/response multiplex and full-duplex streaming.<br /><br /><br />This is the first example of this I&#39;ve seen in the wild, and it feels like we are shifting from an HTTP to an HTTP/2&amp;nbsp;API world. I don&#39;t think regular old REST or web APIs are going anywhere, I think they&#39;ll continue to be a staple, but it looks like Google is laying the groundwork for two-speed APIs, that are defined using a common API definition--you pick the speed you need. I&#39;ve been hearing tales of gRPC usage for a while and seeing more APIs defined using protocol buffers, but Google&#39;s approach signals a wider more significant shift for me.<br />I&#39;m still learning about gRPC, so I can&#39;t quite visualize the overlap between&amp;nbsp;gRPC and REST quite yet. I&#39;m going through their API definitions because they provide an interesting snapshot of the surface area of these hybrid APIs. As I spend my week in San Francisco for Google Next, I&#39;m eager to learn more about their evolving approach to designing and defining APIs--something that I think will be setting the tone for API design at scale in the near future.s repo stood out because it contained a set of API definitions that covered both APIs that support both REST and gRPC.<br />Straight from the Github repo, they support two ways of access APIs: Google APIs use&amp;nbsp;Protocol Buffers&amp;nbsp;version 3 (proto3) as their Interface Definition Language (IDL) to define the API interface and the structure of the payload messages. The same interface definition is used for both REST and RPC versions of the API, which can be accessed over different wire protocols.<br /><br /><br />JSON over HTTP: You can access Google APIs directly using JSON over HTTP, using&amp;nbsp;Google API client libraries&amp;nbsp;or third-party API client libraries.<br /><br /><br />Protocol Buffers over gRPC: You can access Google APIs published in this repository through&amp;nbsp;GRPC, which is a high-performance binary RPC protocol over HTTP/2. It offers many useful features, including request/response multiplex and full-duplex streaming.<br /><br /><br />This is the first example of this Ive seen in the wild, and it feels like we are shifting from an HTTP to an HTTP/2&amp;nbsp;API world. I don&#39;t think regular old REST or web APIs are going anywhere, I think they&#39;ll continue to be a staple, but it looks like Google is laying the groundwork for two-speed APIs, that are defined using a common API definition--you pick the speed you need. I&#39;ve been hearing tales of gRPC usage for a while and seeing more APIs defined using protocol buffers, but Google&#39;s approach signals a wider more significant shift for me.<br />I&#39;m still learning about gRPC, so I can&#39;t quite visualize the overlap between&amp;nbsp;gRPC and REST quite yet. I&#39;m going through their API definitions because they provide an interesting snapshot of the surface area of these hybrid APIs. As I spend my week in San Francisco for Google Next, I&#39;m eager to learn more about their evolving approach to designing and defining APIs--something that I think will be setting the tone for API design at scale in the near future.ve seen in the wild, and it feels like we are shifting from an HTTP to an HTTP/2&amp;nbsp;API world. I dont think regular old REST or web APIs are going anywhere, I think they&#39;ll continue to be a staple, but it looks like Google is laying the groundwork for two-speed APIs, that are defined using a common API definition--you pick the speed you need. I&#39;ve been hearing tales of gRPC usage for a while and seeing more APIs defined using protocol buffers, but Google&#39;s approach signals a wider more significant shift for me.<br />I&#39;m still learning about gRPC, so I can&#39;t quite visualize the overlap between&amp;nbsp;gRPC and REST quite yet. I&#39;m going through their API definitions because they provide an interesting snapshot of the surface area of these hybrid APIs. As I spend my week in San Francisco for Google Next, I&#39;m eager to learn more about their evolving approach to designing and defining APIs--something that I think will be setting the tone for API design at scale in the near future.t think regular old REST or web APIs are going anywhere, I think theyll continue to be a staple, but it looks like Google is laying the groundwork for two-speed APIs, that are defined using a common API definition--you pick the speed you need. I&#39;ve been hearing tales of gRPC usage for a while and seeing more APIs defined using protocol buffers, but Google&#39;s approach signals a wider more significant shift for me.<br />I&#39;m still learning about gRPC, so I can&#39;t quite visualize the overlap between&amp;nbsp;gRPC and REST quite yet. I&#39;m going through their API definitions because they provide an interesting snapshot of the surface area of these hybrid APIs. As I spend my week in San Francisco for Google Next, I&#39;m eager to learn more about their evolving approach to designing and defining APIs--something that I think will be setting the tone for API design at scale in the near future.ll continue to be a staple, but it looks like Google is laying the groundwork for two-speed APIs, that are defined using a common API definition--you pick the speed you need. Ive been hearing tales of gRPC usage for a while and seeing more APIs defined using protocol buffers, but Google&#39;s approach signals a wider more significant shift for me.<br />I&#39;m still learning about gRPC, so I can&#39;t quite visualize the overlap between&amp;nbsp;gRPC and REST quite yet. I&#39;m going through their API definitions because they provide an interesting snapshot of the surface area of these hybrid APIs. As I spend my week in San Francisco for Google Next, I&#39;m eager to learn more about their evolving approach to designing and defining APIs--something that I think will be setting the tone for API design at scale in the near future.ve been hearing tales of gRPC usage for a while and seeing more APIs defined using protocol buffers, but Googles approach signals a wider more significant shift for me.<br />I&#39;m still learning about gRPC, so I can&#39;t quite visualize the overlap between&amp;nbsp;gRPC and REST quite yet. I&#39;m going through their API definitions because they provide an interesting snapshot of the surface area of these hybrid APIs. As I spend my week in San Francisco for Google Next, I&#39;m eager to learn more about their evolving approach to designing and defining APIs--something that I think will be setting the tone for API design at scale in the near future.s approach signals a wider more significant shift for me.<br />Im still learning about gRPC, so I can&#39;t quite visualize the overlap between&amp;nbsp;gRPC and REST quite yet. I&#39;m going through their API definitions because they provide an interesting snapshot of the surface area of these hybrid APIs. As I spend my week in San Francisco for Google Next, I&#39;m eager to learn more about their evolving approach to designing and defining APIs--something that I think will be setting the tone for API design at scale in the near future.m still learning about gRPC, so I cant quite visualize the overlap between&amp;nbsp;gRPC and REST quite yet. I&#39;m going through their API definitions because they provide an interesting snapshot of the surface area of these hybrid APIs. As I spend my week in San Francisco for Google Next, I&#39;m eager to learn more about their evolving approach to designing and defining APIs--something that I think will be setting the tone for API design at scale in the near future.t quite visualize the overlap between&amp;nbsp;gRPC and REST quite yet. Im going through their API definitions because they provide an interesting snapshot of the surface area of these hybrid APIs. As I spend my week in San Francisco for Google Next, I&#39;m eager to learn more about their evolving approach to designing and defining APIs--something that I think will be setting the tone for API design at scale in the near future.m going through their API definitions because they provide an interesting snapshot of the surface area of these hybrid APIs. As I spend my week in San Francisco for Google Next, Im eager to learn more about their evolving approach to designing and defining APIs--something that I think will be setting the tone for API design at scale in the near future.m eager to learn more about their evolving approach to designing and defining APIs--something that I think will be setting the tone for API design at scale in the near future.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/managing_grpc_apis_with_google_cloud_endpoints_3_638.jpg"
  },
  {
  "title": "People Doing Interesting Things With APIs",
  "date": "08 Mar 2017",
  "body": "I just wanted to take a moment and highlight some folks who are doing interesting things with APIs. I spend a lot of time focusing on the companies, products, and services from&amp;nbsp;the sector, but I dont talk a lot about individual people. So I wanted to pause for a moment and just highlight a couple of people doing really interesting things with APIs right now.<br />If have been paying attention to API definitions in the last year, then you probably have come across APIs.guru, the Wikipedia for APIs. They have 244 OpenAPI definitions available in their catalog, which&amp;nbsp;is the most comprehensive directory of machine readable API definitions out there. If you have an OpenAPI for your API you should be publishing it to APIs.guru. if you don&#39;t, you should be creating one, and then publishing it to APIs.guru.<br />Here are the hardworking, API-savvy folks behind APIs.guru:<br /><br /><br /><br /><br /><br />Ivan Goncharov<br /><br />Github:&amp;nbsp;https://github.com/IvanGoncharov<br />Twitter:&amp;nbsp;https://twitter.com/E1Goncharov<br /><br /><br /><br /><br /><br />Roman Hotsiy <br /><br />Twitter:&amp;nbsp;https://twitter.com/RomanHotsiy<br />Github:&amp;nbsp;https://github.com/RomanGotsiy<br /><br />&amp;nbsp;<br /><br /><br /><br /><br />I am in the middle of a project where I am building on the work these two have invested in with APIs.guru. I&#39;m hoping that with the next wave of this work, I&#39;ll have some complete API definitions I can contribute to APIs.guru. I encourage you to make sure your API definitions are published to the directory so that other people like me can include your APIs in our work.<br />Beyond the APIs.guru directory, I recommend checking out their Github repository, as they are doing some interesting things with GraphQL. If you need help crafting an API definition for your API platform, or in need of other API advice, I recommend messaging the APIs.guru team. I&#39;m sure they&#39;d be happy to talk to you, and see where they can help you with your API efforts.t talk a lot about individual people. So I wanted to pause for a moment and just highlight a couple of people doing really interesting things with APIs right now.<br />If have been paying attention to API definitions in the last year, then you probably have come across APIs.guru, the Wikipedia for APIs. They have 244 OpenAPI definitions available in their catalog, which&amp;nbsp;is the most comprehensive directory of machine readable API definitions out there. If you have an OpenAPI for your API you should be publishing it to APIs.guru. if you dont, you should be creating one, and then publishing it to APIs.guru.<br />Here are the hardworking, API-savvy folks behind APIs.guru:<br /><br /><br /><br /><br /><br />Ivan Goncharov<br /><br />Github:&amp;nbsp;https://github.com/IvanGoncharov<br />Twitter:&amp;nbsp;https://twitter.com/E1Goncharov<br /><br /><br /><br /><br /><br />Roman Hotsiy <br /><br />Twitter:&amp;nbsp;https://twitter.com/RomanHotsiy<br />Github:&amp;nbsp;https://github.com/RomanGotsiy<br /><br />&amp;nbsp;<br /><br /><br /><br /><br />I am in the middle of a project where I am building on the work these two have invested in with APIs.guru. I&#39;m hoping that with the next wave of this work, I&#39;ll have some complete API definitions I can contribute to APIs.guru. I encourage you to make sure your API definitions are published to the directory so that other people like me can include your APIs in our work.<br />Beyond the APIs.guru directory, I recommend checking out their Github repository, as they are doing some interesting things with GraphQL. If you need help crafting an API definition for your API platform, or in need of other API advice, I recommend messaging the APIs.guru team. I&#39;m sure they&#39;d be happy to talk to you, and see where they can help you with your API efforts.t, you should be creating one, and then publishing it to APIs.guru.<br />Here are the hardworking, API-savvy folks behind APIs.guru:<br /><br /><br /><br /><br /><br />Ivan Goncharov<br /><br />Github:&amp;nbsp;https://github.com/IvanGoncharov<br />Twitter:&amp;nbsp;https://twitter.com/E1Goncharov<br /><br /><br /><br /><br /><br />Roman Hotsiy <br /><br />Twitter:&amp;nbsp;https://twitter.com/RomanHotsiy<br />Github:&amp;nbsp;https://github.com/RomanGotsiy<br /><br />&amp;nbsp;<br /><br /><br /><br /><br />I am in the middle of a project where I am building on the work these two have invested in with APIs.guru. Im hoping that with the next wave of this work, I&#39;ll have some complete API definitions I can contribute to APIs.guru. I encourage you to make sure your API definitions are published to the directory so that other people like me can include your APIs in our work.<br />Beyond the APIs.guru directory, I recommend checking out their Github repository, as they are doing some interesting things with GraphQL. If you need help crafting an API definition for your API platform, or in need of other API advice, I recommend messaging the APIs.guru team. I&#39;m sure they&#39;d be happy to talk to you, and see where they can help you with your API efforts.m hoping that with the next wave of this work, Ill have some complete API definitions I can contribute to APIs.guru. I encourage you to make sure your API definitions are published to the directory so that other people like me can include your APIs in our work.<br />Beyond the APIs.guru directory, I recommend checking out their Github repository, as they are doing some interesting things with GraphQL. If you need help crafting an API definition for your API platform, or in need of other API advice, I recommend messaging the APIs.guru team. I&#39;m sure they&#39;d be happy to talk to you, and see where they can help you with your API efforts.ll have some complete API definitions I can contribute to APIs.guru. I encourage you to make sure your API definitions are published to the directory so that other people like me can include your APIs in our work.<br />Beyond the APIs.guru directory, I recommend checking out their Github repository, as they are doing some interesting things with GraphQL. If you need help crafting an API definition for your API platform, or in need of other API advice, I recommend messaging the APIs.guru team. Im sure they&#39;d be happy to talk to you, and see where they can help you with your API efforts.m sure theyd be happy to talk to you, and see where they can help you with your API efforts.d be happy to talk to you, and see where they can help you with your API efforts.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/ivan_goncharov.jpg"
  },
  {
  "title": "Getting Back To Work On My OpenAPI Toolbox",
  "date": "02 Mar 2017",
  "body": "I used to have a Github repository dedicated to Swagger tooling and implementations, but I took it down after Swagger was donated to the Linux Foundation. Ive rebooted it as my OpenAPI Toolbox, providing a single Github repository for managing an active list of open source tooling built on top of the OpenAPI specification.<br />Here is a snapshot of my toolbox of OpenAPI-driven solutions, as it stands today. This site is a Jekyll-driven website running on Github, using Github Pages. The tools in this toolbox are driven by a YAML file in the _data folder for this repository, with the HTML pages driven using Liquid.<br />Here are the tools organized by type of implementation (something that is evolving quickly):<br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br />Documentation<br /><br /><br />Generators<br /><br /><br />Servers<br /><br /><br /><br /><br /><br /><br /><br /><br /><br />&amp;nbsp;<br /><br /><br /><br />Clients<br /><br /><br />Editors<br /><br />&amp;nbsp;<br /><br /><br /><br />Here they are organized by programming language, providing another dimension to look at the tooling being developed on top of OpenAPI.<br /><br /><br /><br /><br /> <br /><br /><br /><br /><br /><br /><br />  <br /> <br />  <br /> <br />  <br /><br /><br /> <br /><br />  <br /> <br />  <br /> <br />  <br /><br /><br /><br />This project is forkable using the Github repository, and accessible as JSON. If you have a tool you think should be added, or there is something that needs fixing, you can submit an issue on the Github repository, or submit a pull request. It is meant to be a community project, designed to be forkable, shareable, and machine-readable.<br />I&#39;ve just started adding the tools I have in my database. I only have 37 so far, but will be adding more as I have time. Once I have it up to date, I will start thinking about other ways to slice and dice the tools, to better understand what is being built on the OpenAPI specification, what tools are being built on the upcoming 3.0 version, as well as working to identify where the gaps and opportunities are for developing tooling.ve rebooted it as my OpenAPI Toolbox, providing a single Github repository for managing an active list of open source tooling built on top of the OpenAPI specification.<br />Here is a snapshot of my toolbox of OpenAPI-driven solutions, as it stands today. This site is a Jekyll-driven website running on Github, using Github Pages. The tools in this toolbox are driven by a YAML file in the _data folder for this repository, with the HTML pages driven using Liquid.<br />Here are the tools organized by type of implementation (something that is evolving quickly):<br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br />Documentation<br /><br /><br />Generators<br /><br /><br />Servers<br /><br /><br /><br /><br /><br /><br /><br /><br /><br />&amp;nbsp;<br /><br /><br /><br />Clients<br /><br /><br />Editors<br /><br />&amp;nbsp;<br /><br /><br /><br />Here they are organized by programming language, providing another dimension to look at the tooling being developed on top of OpenAPI.<br /><br /><br /><br /><br /> <br /><br /><br /><br /><br /><br /><br />  <br /> <br />  <br /> <br />  <br /><br /><br /> <br /><br />  <br /> <br />  <br /> <br />  <br /><br /><br /><br />This project is forkable using the Github repository, and accessible as JSON. If you have a tool you think should be added, or there is something that needs fixing, you can submit an issue on the Github repository, or submit a pull request. It is meant to be a community project, designed to be forkable, shareable, and machine-readable.<br />Ive just started adding the tools I have in my database. I only have 37 so far, but will be adding more as I have time. Once I have it up to date, I will start thinking about other ways to slice and dice the tools, to better understand what is being built on the OpenAPI specification, what tools are being built on the upcoming 3.0 version, as well as working to identify where the gaps and opportunities are for developing tooling.ve just started adding the tools I have in my database. I only have 37 so far, but will be adding more as I have time. Once I have it up to date, I will start thinking about other ways to slice and dice the tools, to better understand what is being built on the OpenAPI specification, what tools are being built on the upcoming 3.0 version, as well as working to identify where the gaps and opportunities are for developing tooling.",
  "url": "http://localhost:4000",
  "image": ""
  },
  {
  "title": "New York Times Manages Their OpenAPI Using Github",
  "date": "01 Mar 2017",
  "body": "<br />I come across more companies managing their OpenAPI definition as a single Github repository. One example of this is from the New York Times, who as the API definitions for their platform available as its own Github repository. It demonstrates the importance of maintaining your API definitions separately from any particular implementation, such as just your documentation.<br />You can find Individual OpenAPIs for their&amp;nbsp;archive_api, updated description, article_search,books_api, community, geo_api, most_popular_api, movie_reviews, semantic_api, times_tags, timeswire, top_stories&amp;nbsp;broken down into separate folders within the Github repository. The NYT also provides markdown documentation, alongside the machine-readable OpenAPI definition in each folder, helping make sure things are human-readable.<br />It just makes sense to manage your API definitions this way. Its more than just documentation. When you do this, you are taking advantage of the repository and version control features of Github, but you also open things up for participation through forking and pull requests. The resulting definition and machine readable contract can then be injected anywhere into the integration&amp;nbsp;and API lifecycle, internally or externally.<br />I personally like it when companies manage their API definitions in this way. It gives me a central truth to work with when profiling their operations, something that will be used across my research and storytelling. The more you describe your APIs in this way, the more chance I will be writing about them&amp;nbsp;and including them across my work.s more than just documentation. When you do this, you are taking advantage of the repository and version control features of Github, but you also open things up for participation through forking and pull requests. The resulting definition and machine readable contract can then be injected anywhere into the integration&amp;nbsp;and API lifecycle, internally or externally.<br />I personally like it when companies manage their API definitions in this way. It gives me a central truth to work with when profiling their operations, something that will be used across my research and storytelling. The more you describe your APIs in this way, the more chance I will be writing about them&amp;nbsp;and including them across my work.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_02_26_at_3.44.42_pm.png"
  },
  {
  "title": "A Machine Readable Definition For Your AWS API Plan",
  "date": "01 Mar 2017",
  "body": "<br />I was learning about the AWS Serverless Developer Portal, and found their API plan layer to be an interesting evolution in how we define the access tiers of our APIs. There were a couple different layers of AWSs approach to deploying APIs that I found interesting, including the AWS marketplace integration, but I wanted to stop for a moment and focus in on their API plan approach.<br />Using the AWS API Gateway you can establish a variety of API plans, with the underlying mechanics of that plan configurable via the AWS API Gateway user interface or the AWS API Gateway API. In the documentation for the&amp;nbsp;AWS Serverless Developer&amp;nbsp;Portal, they include a JSON snippet of the configuration of the plan for each API being deployed.<br />This reminds me that I needed to take another look at my API plan research, and take the plan configuration, rate limit, and other&amp;nbsp;service composition API definitions I have, and aggregate their schema into a single snapshot. It has been a while since I worked on my machine-readable API plan definition, and there are now enough API management solutions with an API layer out there, I should be able to pull a wider sampling of the&amp;nbsp;schema in play. I&#39;m not in the business of defining what the definition should be, I am only looking to aggregate what others are doing.<br />I am happy to see more folks sharing machine-readable OpenAPI definitions describing the surface area of their APIs. As this work continues to grow we are going to have to also start sharing machine-readable definitions of the monetization, plan, and access layers of our API operations. After I identify the schema in play for some of the major API management providers I track on, I&#39;m going to invest more work into my standard API plan definition to make the access levels of APIs more discoverable using APIs.json.s approach to deploying APIs that I found interesting, including the AWS marketplace integration, but I wanted to stop for a moment and focus in on their API plan approach.<br />Using the AWS API Gateway you can establish a variety of API plans, with the underlying mechanics of that plan configurable via the AWS API Gateway user interface or the AWS API Gateway API. In the documentation for the&amp;nbsp;AWS Serverless Developer&amp;nbsp;Portal, they include a JSON snippet of the configuration of the plan for each API being deployed.<br />This reminds me that I needed to take another look at my API plan research, and take the plan configuration, rate limit, and other&amp;nbsp;service composition API definitions I have, and aggregate their schema into a single snapshot. It has been a while since I worked on my machine-readable API plan definition, and there are now enough API management solutions with an API layer out there, I should be able to pull a wider sampling of the&amp;nbsp;schema in play. Im not in the business of defining what the definition should be, I am only looking to aggregate what others are doing.<br />I am happy to see more folks sharing machine-readable OpenAPI definitions describing the surface area of their APIs. As this work continues to grow we are going to have to also start sharing machine-readable definitions of the monetization, plan, and access layers of our API operations. After I identify the schema in play for some of the major API management providers I track on, I&#39;m going to invest more work into my standard API plan definition to make the access levels of APIs more discoverable using APIs.json.m not in the business of defining what the definition should be, I am only looking to aggregate what others are doing.<br />I am happy to see more folks sharing machine-readable OpenAPI definitions describing the surface area of their APIs. As this work continues to grow we are going to have to also start sharing machine-readable definitions of the monetization, plan, and access layers of our API operations. After I identify the schema in play for some of the major API management providers I track on, Im going to invest more work into my standard API plan definition to make the access levels of APIs more discoverable using APIs.json.m going to invest more work into my standard API plan definition to make the access levels of APIs more discoverable using APIs.json.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_02_26_at_7.12.16_pm.png"
  },
  {
  "title": "The Potential Of The OpenAPI Spec Parameters Object",
  "date": "20 Oct 2016",
  "body": "<br />I enjoy learning from the OpenAPI Specs of the API providers I track on. Just having an OpenAPI Spec present tells a lot about an API provider in my book, but the level of detail some providers put into their API definitions adds another level to this for me. While reviewing the OpenAPI Spec for the Oxford Dictionaries API, I noticed their robust usage of the OpenAPI Spec parameters definitions collection, which provides an interesting overview of the surface area of the API, augmenting the benefits brought to the table by the definitions collection of an APIs underlying data schema.<br />When you are defining each path for an API you can either define the parameters using each paths parameters, or you can add them to the overall parameters definition object, allowing them to be reused across all paths. This object provided me with a centralized place to learn about the parameters used when making calls to the Oxford Dictionary API, and Im assuming it helped them be more organized in how they defined the surface area of their APIs.<br /><br />I can see how the processing of defining each path&#39;s parameters, and centrally organizing them for reuse can be a healthy thing. The more you lift yourself out of the individual&amp;nbsp;definition&amp;nbsp;of each path&amp;nbsp;and consider the parameter patterns that have been used for other paths, the chances you will have a better view of the landscape will increase. I am optimistic about this OpenAPI Spec object, and curious about how it can be evolved as part of other conversation around GraphQL--something I&#39;ll work to understand better in the future.m assuming it helped them be more organized in how they defined the surface area of their APIs.<br /><br />I can see how the processing of defining each paths parameters, and centrally organizing them for reuse can be a healthy thing. The more you lift yourself out of the individual&amp;nbsp;definition&amp;nbsp;of each path&amp;nbsp;and consider the parameter patterns that have been used for other paths, the chances you will have a better view of the landscape will increase. I am optimistic about this OpenAPI Spec object, and curious about how it can be evolved as part of other conversation around GraphQL--something I&#39;ll work to understand better in the future.s parameters, and centrally organizing them for reuse can be a healthy thing. The more you lift yourself out of the individual&amp;nbsp;definition&amp;nbsp;of each path&amp;nbsp;and consider the parameter patterns that have been used for other paths, the chances you will have a better view of the landscape will increase. I am optimistic about this OpenAPI Spec object, and curious about how it can be evolved as part of other conversation around GraphQL--something Ill work to understand better in the future.ll work to understand better in the future.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2016_10_19_at_9.04.05_pm.png"
  },
  {
  "title": "Reducing Friction For API Developers With Enums In API Definitions",
  "date": "20 Oct 2016",
  "body": "<br />I am going through the Oxford Dictionaries API, learning about this valuable resource. Their onboarding process for registration, and learning about what the API does using interactive documentation, is very smooth. One of the things that really cuts the rough edges off learning about each API are the enums that are available for each path.<br />The parameters required for making calls to many of the paths, like language and country, have their enum values populated as part of their API definition. I look at numerous OpenAPI Specs in the course of my work&amp;nbsp;and they rarely have values present for enum, providing critical default values for developers to use--eliminating some often serious frustration.<br />Not having the right values available when making even the simplest of API calls can be a significant point of friction when trying to get up and running using an API. While it may seem like a small thing, the work the Oxford Dictionaries API team has put into this level of detail for their API definitions will go a long way towards making their API resources more accessible and usable.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2016_10_19_at_7.24.09_pm.png"
  },
  {
  "title": "OpenAPI Spec Google Spreadsheet to Github Jekyll Hosted YAML ",
  "date": "19 Oct 2016",
  "body": "<br />I have been playing around with different ways of using Google Spreadsheet to drive YAML and JSON data to Jekyll data projects hosted as Github repositories. It is an approach I started playing around with in Washington DC, while I was helping data stewards publish government services as JSON-LD. It is something Ive been playing around with lately using to drive D3.js visualizations&amp;nbsp;and even a comic book.<br />There are couple of things going on here. First, you are managing machine-readable data using Google Spreadsheets, and publishing this data as two separate machine readable formats: JSON and YAML. When these formats are combined with the data capabilities of a Jekyll website hosted on Github Pages, it opens up some pretty interesting possibilities for using data to fuel some pretty fun things. Plus...no backend needed.<br />To push this approach forward I wanted to apply&amp;nbsp;to managing OpenAPI Specs that can be used across the API life cycle. I pulled together a spreadsheet template for managing the details I need for an OpenAPI Spec. Then I created a Github repository, forked my previous spreadsheet to YAML project, and modified it to pull data from a couple of worksheets in the Google Doc&amp;nbsp;and publish as both JSON and YAML OpenAPI Specs.&amp;nbsp;<br />My OpenAPI Spec Google Sheet to YAML for use in a Jekyll project hosted on Github is just a prototype. The results don&#39;t always validate, and I&#39;m playing with different ways to represent and manage the data in the Google Sheet. It is a fun start though! I am going to keep working on it, and probably start a similar project for managing an APIs.json&amp;nbsp;index using Google Sheets. When done right it might provide another way that non-developers can participate in the API design process, and apply OpenAPI Specs to other stops along the API life cycle like with API documentation, SDK generation, or testing and monitoring.ve been playing around with lately using to drive D3.js visualizations&amp;nbsp;and even a comic book.<br />There are couple of things going on here. First, you are managing machine-readable data using Google Spreadsheets, and publishing this data as two separate machine readable formats: JSON and YAML. When these formats are combined with the data capabilities of a Jekyll website hosted on Github Pages, it opens up some pretty interesting possibilities for using data to fuel some pretty fun things. Plus...no backend needed.<br />To push this approach forward I wanted to apply&amp;nbsp;to managing OpenAPI Specs that can be used across the API life cycle. I pulled together a spreadsheet template for managing the details I need for an OpenAPI Spec. Then I created a Github repository, forked my previous spreadsheet to YAML project, and modified it to pull data from a couple of worksheets in the Google Doc&amp;nbsp;and publish as both JSON and YAML OpenAPI Specs.&amp;nbsp;<br />My OpenAPI Spec Google Sheet to YAML for use in a Jekyll project hosted on Github is just a prototype. The results dont always validate, and I&#39;m playing with different ways to represent and manage the data in the Google Sheet. It is a fun start though! I am going to keep working on it, and probably start a similar project for managing an APIs.json&amp;nbsp;index using Google Sheets. When done right it might provide another way that non-developers can participate in the API design process, and apply OpenAPI Specs to other stops along the API life cycle like with API documentation, SDK generation, or testing and monitoring.t always validate, and Im playing with different ways to represent and manage the data in the Google Sheet. It is a fun start though! I am going to keep working on it, and probably start a similar project for managing an APIs.json&amp;nbsp;index using Google Sheets. When done right it might provide another way that non-developers can participate in the API design process, and apply OpenAPI Specs to other stops along the API life cycle like with API documentation, SDK generation, or testing and monitoring.m playing with different ways to represent and manage the data in the Google Sheet. It is a fun start though! I am going to keep working on it, and probably start a similar project for managing an APIs.json&amp;nbsp;index using Google Sheets. When done right it might provide another way that non-developers can participate in the API design process, and apply OpenAPI Specs to other stops along the API life cycle like with API documentation, SDK generation, or testing and monitoring.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2016_10_19_at_12.02.32_am.png"
  },
  {
  "title": "Please Share Your OpenAPI Specs So I Can Use Across The API Life Cycle",
  "date": "04 Oct 2016",
  "body": "I was profiling the New Relic API, and while I was pleased to find OpenAPI Specs behind their explorer, I was less than pleased to have to reverse engineer their docs to get at their API definitions. It is pretty easy to open up my Google Chrome Developer Tools and grab the URLs for each OpenAPI Spec, but you know what would be easier? If you just provided me a link to them in your documentation!<br /><br />Your API definitions arent just driving the API documentation on your website. They are being used across the API life cycle. I am using them fire up and playing with your API in Postman, generating SDKs using APIMATIC, or creating a development sandbox so I do not have to develop against your&amp;nbsp;live environment. Please do not hide your API definitions, bring them out of the shadow of your API documentation and give me a link I can click on--one click access to a machine-readable definition of the value your API delivers.<br />I&#39;m sure my regular readers are getting sick of hearing about this, but the reality of my readers is that they are a diverse, and busy group of folks and will most likely not read every post on this important subject. If you have read a previous post on this subject from me, and are reading this latest one, and still do not have API definitions&amp;nbsp;or prominent links--then shame on you for not making your API more accessible and usable...because isn&#39;t that what this is all about?t just driving the API documentation on your website. They are being used across the API life cycle. I am using them fire up and playing with your API in Postman, generating SDKs using APIMATIC, or creating a development sandbox so I do not have to develop against your&amp;nbsp;live environment. Please do not hide your API definitions, bring them out of the shadow of your API documentation and give me a link I can click on--one click access to a machine-readable definition of the value your API delivers.<br />Im sure my regular readers are getting sick of hearing about this, but the reality of my readers is that they are a diverse, and busy group of folks and will most likely not read every post on this important subject. If you have read a previous post on this subject from me, and are reading this latest one, and still do not have API definitions&amp;nbsp;or prominent links--then shame on you for not making your API more accessible and usable...because isn&#39;t that what this is all about?m sure my regular readers are getting sick of hearing about this, but the reality of my readers is that they are a diverse, and busy group of folks and will most likely not read every post on this important subject. If you have read a previous post on this subject from me, and are reading this latest one, and still do not have API definitions&amp;nbsp;or prominent links--then shame on you for not making your API more accessible and usable...because isnt that what this is all about?t that what this is all about?",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2016_10_01_at_12.43.12_pm.png"
  },
  {
  "title": "The Different Reasons Behind Why We Craft API Definitions",
  "date": "03 Oct 2016",
  "body": "<br />I wrote a post about the emails I get from folks telling me the API definitions contained within my API stack research, something that has helped me better see why it is I do API definitions. I go through APIs and craft OpenAPI Specs for them because it helps me understand the value each company offers, while also helping me discover interesting APIs&amp;nbsp;and the healthy practices behind them.<br />The reason I create API definitions and organize them into collections is all about discovery. While some of the APIs I will be putting to use, most of them just help me&amp;nbsp;better understand the world of APIs&amp;nbsp;and the value and the intent behind the companies who are doing the most interesting things in the space.<br />I would love it if all my API definitions were 100% certified, and included complete information about the request, response, and security models, but just having the surface area defined makes me happy. My intention is to try and provide as complete of a definition as possible, but the primary stop along the API lifecycle Im looking to serve is discovery, with other ones like design, mocking, deployment, testing, SDKs, and others following after that.<br />Maybe if we can all better understand the different reasons behind why&amp;nbsp;we all craft and maintain API definitions we can better leverage Github to help make more of them complete. For now, I&#39;ll keep working on my definitions, and if you want to contribute head over to the Github repo for my work, and share any of your own definitions, or submit an issue about which APIs you&#39;d like to see included.m looking to serve is discovery, with other ones like design, mocking, deployment, testing, SDKs, and others following after that.<br />Maybe if we can all better understand the different reasons behind why&amp;nbsp;we all craft and maintain API definitions we can better leverage Github to help make more of them complete. For now, Ill keep working on my definitions, and if you want to contribute head over to the Github repo for my work, and share any of your own definitions, or submit an issue about which APIs you&#39;d like to see included.ll keep working on my definitions, and if you want to contribute head over to the Github repo for my work, and share any of your own definitions, or submit an issue about which APIs youd like to see included.d like to see included.",
  "url": "http://localhost:4000",
  "image": ""
  },
  {
  "title": "APIs Can Give An Honest View Of What A Company Does",
  "date": "03 Oct 2016",
  "body": "<br />One of the reasons I enjoy profiling APIs is that they give an honest view of what a company does, absent of all the marketing fluff, and the promises that I see from each wave of startups. If designed right, APIs can provide a very functional, distilled down representation of data, content, and algorithmic resources of any company. Some APIs can be very fluffy and verbose, but the good ones are simple, concise, and straight to the point.<br />As Im profiling the APIs for the companies included in my API monitoring research, what&amp;nbsp;API Science, Apica, API Metrics, BMC Software, DataDog, New Relic, and Runscope offer quickly become pretty clear. A simple list of valuable resources you can put to use when monitoring your APIs. Crafting an OpenAPI Spec allows me to define each of these companies APIs, and easily articulate what it is that they do--minus all the bullshit that often comes with the businesses side of all of this.&amp;nbsp;<br />I feel like the detail I include for each company in an APIs.json&amp;nbsp;file provides a nice view of the intent behind an API, while the details I put into the OpenAPI Spec provide insight into whether or not a company actually has any value behind this intent. It can be frustrating to wade through the amount of information some providers feel they need to publish as API documentation, but it all becomes worth it once I have the distilled down OpenAPI Spec, giving an honest view of what each company does.m profiling the APIs for the companies included in my API monitoring research, what&amp;nbsp;API Science, Apica, API Metrics, BMC Software, DataDog, New Relic, and Runscope offer quickly become pretty clear. A simple list of valuable resources you can put to use when monitoring your APIs. Crafting an OpenAPI Spec allows me to define each of these companies APIs, and easily articulate what it is that they do--minus all the bullshit that often comes with the businesses side of all of this.&amp;nbsp;<br />I feel like the detail I include for each company in an APIs.json&amp;nbsp;file provides a nice view of the intent behind an API, while the details I put into the OpenAPI Spec provide insight into whether or not a company actually has any value behind this intent. It can be frustrating to wade through the amount of information some providers feel they need to publish as API documentation, but it all becomes worth it once I have the distilled down OpenAPI Spec, giving an honest view of what each company does.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2016_10_02_at_11.04.26_pm.png"
  },
  {
  "title": "SchemaHub&#039;s Usage Of Github To Launch Their API Service Is A Nice Approach",
  "date": "29 Sep 2016",
  "body": "Im looking through a new API definition focused service provider called SchemaHub today, and I found their approach to using Github as a base of operations was interesting and provided a nice blueprint for other API server providers to follow. I&#39;m continually amazed at the myriad of ways that Github can be put to use in the world of APIs, which is one of the things I love about it.<br />As a base for SchemaHub, they created a Github Org, and made their first repository the website for the service, hosted on Github Pages. In my opinion, this is how all API services should begin, as a repo, under an organization on Github--leveraging the social coding platform as a base for their operations.<br /><br />SchemaHub is taking advantage of Github for hosting their API definition focused project--free, version controlled, static website hosting for schemahub.io.&amp;nbsp;<br /><br />As I was looking through their site, learning about what they are doing I noticed a subscription button at the bottom of the page, asking me to subscribe, and they&#39;ll notify me when things are ready.<br /><br />Once I clicked on the button, I was taken for a Github OAuth dance, which now makes SchemaHub not just a Github repo for the site, it is an actual Github Application that I&#39;ve authenticated with using my Github account. They only have access to my profile and email, but is the types of provider to developer connection I like to see in the API world.<br /><br />Once I authorize and connect I am taken to a thank you page back on their website, letting me know I will be contacted shortly with any updates about the service. Oh, and I&#39;m offered a Twitter account as well, allowing me to stay in tune with what they are up to--providing a pretty complete picture for how new API services can operate.&amp;nbsp;<br /><br />SchemaHub&#39;s approach reflects what I&#39;m talking about when I say that Github should offer an Oauth service, something that would enable applications running on Github to establish a Github app as part of their organization and website. I like this model because it enables connections like Schema has established to occur, maximizing the social powers of the Github platform.<br />SchemaHub wins for making a great first impression on me with their API service. Github Org, simple static Github Pages hosted website, connectivity with my Github profile, and a Twitter account to follow. Now I know who they are, I&#39;m connected, and when they are ready with their API service, they have multiple channels to update me on. My only critique is that I would also like to have a blog with Atom feed, so I can hear stories about what they are trying to accomplish, but that is something that can come later. For now, they are off to a pretty good start.m looking through a new API definition focused service provider called SchemaHub today, and I found their approach to using Github as a base of operations was interesting and provided a nice blueprint for other API server providers to follow. Im continually amazed at the myriad of ways that Github can be put to use in the world of APIs, which is one of the things I love about it.<br />As a base for SchemaHub, they created a Github Org, and made their first repository the website for the service, hosted on Github Pages. In my opinion, this is how all API services should begin, as a repo, under an organization on Github--leveraging the social coding platform as a base for their operations.<br /><br />SchemaHub is taking advantage of Github for hosting their API definition focused project--free, version controlled, static website hosting for schemahub.io.&amp;nbsp;<br /><br />As I was looking through their site, learning about what they are doing I noticed a subscription button at the bottom of the page, asking me to subscribe, and they&#39;ll notify me when things are ready.<br /><br />Once I clicked on the button, I was taken for a Github OAuth dance, which now makes SchemaHub not just a Github repo for the site, it is an actual Github Application that I&#39;ve authenticated with using my Github account. They only have access to my profile and email, but is the types of provider to developer connection I like to see in the API world.<br /><br />Once I authorize and connect I am taken to a thank you page back on their website, letting me know I will be contacted shortly with any updates about the service. Oh, and I&#39;m offered a Twitter account as well, allowing me to stay in tune with what they are up to--providing a pretty complete picture for how new API services can operate.&amp;nbsp;<br /><br />SchemaHub&#39;s approach reflects what I&#39;m talking about when I say that Github should offer an Oauth service, something that would enable applications running on Github to establish a Github app as part of their organization and website. I like this model because it enables connections like Schema has established to occur, maximizing the social powers of the Github platform.<br />SchemaHub wins for making a great first impression on me with their API service. Github Org, simple static Github Pages hosted website, connectivity with my Github profile, and a Twitter account to follow. Now I know who they are, I&#39;m connected, and when they are ready with their API service, they have multiple channels to update me on. My only critique is that I would also like to have a blog with Atom feed, so I can hear stories about what they are trying to accomplish, but that is something that can come later. For now, they are off to a pretty good start.m continually amazed at the myriad of ways that Github can be put to use in the world of APIs, which is one of the things I love about it.<br />As a base for SchemaHub, they created a Github Org, and made their first repository the website for the service, hosted on Github Pages. In my opinion, this is how all API services should begin, as a repo, under an organization on Github--leveraging the social coding platform as a base for their operations.<br /><br />SchemaHub is taking advantage of Github for hosting their API definition focused project--free, version controlled, static website hosting for schemahub.io.&amp;nbsp;<br /><br />As I was looking through their site, learning about what they are doing I noticed a subscription button at the bottom of the page, asking me to subscribe, and theyll notify me when things are ready.<br /><br />Once I clicked on the button, I was taken for a Github OAuth dance, which now makes SchemaHub not just a Github repo for the site, it is an actual Github Application that I&#39;ve authenticated with using my Github account. They only have access to my profile and email, but is the types of provider to developer connection I like to see in the API world.<br /><br />Once I authorize and connect I am taken to a thank you page back on their website, letting me know I will be contacted shortly with any updates about the service. Oh, and I&#39;m offered a Twitter account as well, allowing me to stay in tune with what they are up to--providing a pretty complete picture for how new API services can operate.&amp;nbsp;<br /><br />SchemaHub&#39;s approach reflects what I&#39;m talking about when I say that Github should offer an Oauth service, something that would enable applications running on Github to establish a Github app as part of their organization and website. I like this model because it enables connections like Schema has established to occur, maximizing the social powers of the Github platform.<br />SchemaHub wins for making a great first impression on me with their API service. Github Org, simple static Github Pages hosted website, connectivity with my Github profile, and a Twitter account to follow. Now I know who they are, I&#39;m connected, and when they are ready with their API service, they have multiple channels to update me on. My only critique is that I would also like to have a blog with Atom feed, so I can hear stories about what they are trying to accomplish, but that is something that can come later. For now, they are off to a pretty good start.ll notify me when things are ready.<br /><br />Once I clicked on the button, I was taken for a Github OAuth dance, which now makes SchemaHub not just a Github repo for the site, it is an actual Github Application that Ive authenticated with using my Github account. They only have access to my profile and email, but is the types of provider to developer connection I like to see in the API world.<br /><br />Once I authorize and connect I am taken to a thank you page back on their website, letting me know I will be contacted shortly with any updates about the service. Oh, and I&#39;m offered a Twitter account as well, allowing me to stay in tune with what they are up to--providing a pretty complete picture for how new API services can operate.&amp;nbsp;<br /><br />SchemaHub&#39;s approach reflects what I&#39;m talking about when I say that Github should offer an Oauth service, something that would enable applications running on Github to establish a Github app as part of their organization and website. I like this model because it enables connections like Schema has established to occur, maximizing the social powers of the Github platform.<br />SchemaHub wins for making a great first impression on me with their API service. Github Org, simple static Github Pages hosted website, connectivity with my Github profile, and a Twitter account to follow. Now I know who they are, I&#39;m connected, and when they are ready with their API service, they have multiple channels to update me on. My only critique is that I would also like to have a blog with Atom feed, so I can hear stories about what they are trying to accomplish, but that is something that can come later. For now, they are off to a pretty good start.ve authenticated with using my Github account. They only have access to my profile and email, but is the types of provider to developer connection I like to see in the API world.<br /><br />Once I authorize and connect I am taken to a thank you page back on their website, letting me know I will be contacted shortly with any updates about the service. Oh, and Im offered a Twitter account as well, allowing me to stay in tune with what they are up to--providing a pretty complete picture for how new API services can operate.&amp;nbsp;<br /><br />SchemaHub&#39;s approach reflects what I&#39;m talking about when I say that Github should offer an Oauth service, something that would enable applications running on Github to establish a Github app as part of their organization and website. I like this model because it enables connections like Schema has established to occur, maximizing the social powers of the Github platform.<br />SchemaHub wins for making a great first impression on me with their API service. Github Org, simple static Github Pages hosted website, connectivity with my Github profile, and a Twitter account to follow. Now I know who they are, I&#39;m connected, and when they are ready with their API service, they have multiple channels to update me on. My only critique is that I would also like to have a blog with Atom feed, so I can hear stories about what they are trying to accomplish, but that is something that can come later. For now, they are off to a pretty good start.m offered a Twitter account as well, allowing me to stay in tune with what they are up to--providing a pretty complete picture for how new API services can operate.&amp;nbsp;<br /><br />SchemaHubs approach reflects what I&#39;m talking about when I say that Github should offer an Oauth service, something that would enable applications running on Github to establish a Github app as part of their organization and website. I like this model because it enables connections like Schema has established to occur, maximizing the social powers of the Github platform.<br />SchemaHub wins for making a great first impression on me with their API service. Github Org, simple static Github Pages hosted website, connectivity with my Github profile, and a Twitter account to follow. Now I know who they are, I&#39;m connected, and when they are ready with their API service, they have multiple channels to update me on. My only critique is that I would also like to have a blog with Atom feed, so I can hear stories about what they are trying to accomplish, but that is something that can come later. For now, they are off to a pretty good start.s approach reflects what Im talking about when I say that Github should offer an Oauth service, something that would enable applications running on Github to establish a Github app as part of their organization and website. I like this model because it enables connections like Schema has established to occur, maximizing the social powers of the Github platform.<br />SchemaHub wins for making a great first impression on me with their API service. Github Org, simple static Github Pages hosted website, connectivity with my Github profile, and a Twitter account to follow. Now I know who they are, I&#39;m connected, and when they are ready with their API service, they have multiple channels to update me on. My only critique is that I would also like to have a blog with Atom feed, so I can hear stories about what they are trying to accomplish, but that is something that can come later. For now, they are off to a pretty good start.m talking about when I say that Github should offer an Oauth service, something that would enable applications running on Github to establish a Github app as part of their organization and website. I like this model because it enables connections like Schema has established to occur, maximizing the social powers of the Github platform.<br />SchemaHub wins for making a great first impression on me with their API service. Github Org, simple static Github Pages hosted website, connectivity with my Github profile, and a Twitter account to follow. Now I know who they are, Im connected, and when they are ready with their API service, they have multiple channels to update me on. My only critique is that I would also like to have a blog with Atom feed, so I can hear stories about what they are trying to accomplish, but that is something that can come later. For now, they are off to a pretty good start.m connected, and when they are ready with their API service, they have multiple channels to update me on. My only critique is that I would also like to have a blog with Atom feed, so I can hear stories about what they are trying to accomplish, but that is something that can come later. For now, they are off to a pretty good start.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/schemahub_thanks.png"
  },
  {
  "title": "Defining API Surface Area By Converting HTML Forms To Open API Specs",
  "date": "08 Sep 2016",
  "body": "<br />Im investing some time learning about the USGS Water Services. They have some pretty interesting APIs, providing access to a wealth of data about water table levels, river flows, and other key points across all USGS sites. While their developer area has a wealth of information available, it is also pretty verbose and tough to absorb.<br />I wanted to help make the information more accessible, filterable, and remixable by turning it into an OpenAPI Spec. It is A LOT OF WORK to craft a complete OpenAPI Spec for a robust API like the six that are available from the USGS. One way I help alleviate this work is to scrape API documentation. As I was preparing to do this I noticed they also have testing tools for 5 out of the 6 APIs, which are just HTML forms containing a definition of the surface area for each API.&amp;nbsp;<br /><br />Instantaneous Values (IV) Web Service<br />Site Service<br />Daily Values (DV) Web Service<br />Groundwater Levels Web Service<br />Statistics Web Service<br /><br />The HTML forms provide me with a slightly more structured definition of each API so I will start here. Once I&#39;ve ingested these, I will write a scrape script for the HTML API documentation, and link the two up. Once I&#39;m done with this I will be able to generate an OpenAPI Spec that is halfway complete (with just the surface area). Once I have this I can load up in my Postman client, turn on Charles Proxy and my internal API monitoring system will fill in the remaining definitions for the Open API Spec--now I have the request and response model, in a machine readable format.&amp;nbsp;<br />As I write the code to tackle this, I&#39;m thinking about what a great approach HTML forms are to helping both technical, and semi-technical HTML craftspeople define the surface area of an API. Then I think about my friend Mike Amundsen (@mamund) and his work on ALPS, and I smile, and I&#39;m reminded of how much work we have ahead of us when it comes to both web literacy and establishing more meaningful, reusable design patterns across the API space(that repo should be full).<br />P.S. Is there a better tool out there for turning HTML Forms into OpenAPI Spec or at least JSON or YAML?P.S.S. If you wanna create an API that I can pass any web page with a form in it, and get back an OpenAPI Spec, you are a good person.m investing some time learning about the USGS Water Services. They have some pretty interesting APIs, providing access to a wealth of data about water table levels, river flows, and other key points across all USGS sites. While their developer area has a wealth of information available, it is also pretty verbose and tough to absorb.<br />I wanted to help make the information more accessible, filterable, and remixable by turning it into an OpenAPI Spec. It is A LOT OF WORK to craft a complete OpenAPI Spec for a robust API like the six that are available from the USGS. One way I help alleviate this work is to scrape API documentation. As I was preparing to do this I noticed they also have testing tools for 5 out of the 6 APIs, which are just HTML forms containing a definition of the surface area for each API.&amp;nbsp;<br /><br />Instantaneous Values (IV) Web Service<br />Site Service<br />Daily Values (DV) Web Service<br />Groundwater Levels Web Service<br />Statistics Web Service<br /><br />The HTML forms provide me with a slightly more structured definition of each API so I will start here. Once Ive ingested these, I will write a scrape script for the HTML API documentation, and link the two up. Once I&#39;m done with this I will be able to generate an OpenAPI Spec that is halfway complete (with just the surface area). Once I have this I can load up in my Postman client, turn on Charles Proxy and my internal API monitoring system will fill in the remaining definitions for the Open API Spec--now I have the request and response model, in a machine readable format.&amp;nbsp;<br />As I write the code to tackle this, I&#39;m thinking about what a great approach HTML forms are to helping both technical, and semi-technical HTML craftspeople define the surface area of an API. Then I think about my friend Mike Amundsen (@mamund) and his work on ALPS, and I smile, and I&#39;m reminded of how much work we have ahead of us when it comes to both web literacy and establishing more meaningful, reusable design patterns across the API space(that repo should be full).<br />P.S. Is there a better tool out there for turning HTML Forms into OpenAPI Spec or at least JSON or YAML?P.S.S. If you wanna create an API that I can pass any web page with a form in it, and get back an OpenAPI Spec, you are a good person.ve ingested these, I will write a scrape script for the HTML API documentation, and link the two up. Once Im done with this I will be able to generate an OpenAPI Spec that is halfway complete (with just the surface area). Once I have this I can load up in my Postman client, turn on Charles Proxy and my internal API monitoring system will fill in the remaining definitions for the Open API Spec--now I have the request and response model, in a machine readable format.&amp;nbsp;<br />As I write the code to tackle this, I&#39;m thinking about what a great approach HTML forms are to helping both technical, and semi-technical HTML craftspeople define the surface area of an API. Then I think about my friend Mike Amundsen (@mamund) and his work on ALPS, and I smile, and I&#39;m reminded of how much work we have ahead of us when it comes to both web literacy and establishing more meaningful, reusable design patterns across the API space(that repo should be full).<br />P.S. Is there a better tool out there for turning HTML Forms into OpenAPI Spec or at least JSON or YAML?P.S.S. If you wanna create an API that I can pass any web page with a form in it, and get back an OpenAPI Spec, you are a good person.m done with this I will be able to generate an OpenAPI Spec that is halfway complete (with just the surface area). Once I have this I can load up in my Postman client, turn on Charles Proxy and my internal API monitoring system will fill in the remaining definitions for the Open API Spec--now I have the request and response model, in a machine readable format.&amp;nbsp;<br />As I write the code to tackle this, Im thinking about what a great approach HTML forms are to helping both technical, and semi-technical HTML craftspeople define the surface area of an API. Then I think about my friend Mike Amundsen (@mamund) and his work on ALPS, and I smile, and I&#39;m reminded of how much work we have ahead of us when it comes to both web literacy and establishing more meaningful, reusable design patterns across the API space(that repo should be full).<br />P.S. Is there a better tool out there for turning HTML Forms into OpenAPI Spec or at least JSON or YAML?P.S.S. If you wanna create an API that I can pass any web page with a form in it, and get back an OpenAPI Spec, you are a good person.m thinking about what a great approach HTML forms are to helping both technical, and semi-technical HTML craftspeople define the surface area of an API. Then I think about my friend Mike Amundsen (@mamund) and his work on ALPS, and I smile, and Im reminded of how much work we have ahead of us when it comes to both web literacy and establishing more meaningful, reusable design patterns across the API space(that repo should be full).<br />P.S. Is there a better tool out there for turning HTML Forms into OpenAPI Spec or at least JSON or YAML?P.S.S. If you wanna create an API that I can pass any web page with a form in it, and get back an OpenAPI Spec, you are a good person.m reminded of how much work we have ahead of us when it comes to both web literacy and establishing more meaningful, reusable design patterns across the API space(that repo should be full).<br />P.S. Is there a better tool out there for turning HTML Forms into OpenAPI Spec or at least JSON or YAML?P.S.S. If you wanna create an API that I can pass any web page with a form in it, and get back an OpenAPI Spec, you are a good person.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/blog/USGS_Groundwater_Levels_REST_Web_Service_URL_Generation_Tool.png"
  },
  {
  "title": "Diff Tooling For JSON, YAML, And Markdown Versions Of API Definitions",
  "date": "05 Aug 2016",
  "body": "<br />As the number of available API definitions out there grows, I am increasingly coming across variations of APIs that I already have included in my API Stack. It can be tedious to try and sync these with existing copies, so I wanted to take a look and see if there was anything already available out there, that would help provide a diff for either OpenAPI Spec, RAML, or API Blueprint.<br />The most common one I found referenced was a Ruby one for OpenAPI Spec from&amp;nbsp;Civis Analytics. Next, I found a pretty interesting web tool, which provides its Node.js source code on Github, including a CLI edition. After these two solutions, I only found one more for RAML, but couldnt find anything for API Blueprint.<br />I wanted to think beyond just the common API definition formats&amp;nbsp;and look for diff tools that would work just for JSON. I found Diff which was pretty interesting, as well as DiffSync which provided a real-time&amp;nbsp;diff for JSON. I haven&#39;t tried any of them out, I am just trying to compile a list of what is out there&amp;nbsp;before I dive into what their capabilities are.<br />I have a master database of API definitions where I can just import API definitions that I find, and it will add any new paths, parameters, and schemas it comes across. I would much rather have the ability to just run each version through a diff tool, and be able to select which elements I want to have merged. For now, I will just implement a custom layer to my API monitoring system, but I would like to see API diff move forward similar to we saw the conversation evolve with the introduction of&amp;nbsp;API Transformer.t find anything for API Blueprint.<br />I wanted to think beyond just the common API definition formats&amp;nbsp;and look for diff tools that would work just for JSON. I found Diff which was pretty interesting, as well as DiffSync which provided a real-time&amp;nbsp;diff for JSON. I havent tried any of them out, I am just trying to compile a list of what is out there&amp;nbsp;before I dive into what their capabilities are.<br />I have a master database of API definitions where I can just import API definitions that I find, and it will add any new paths, parameters, and schemas it comes across. I would much rather have the ability to just run each version through a diff tool, and be able to select which elements I want to have merged. For now, I will just implement a custom layer to my API monitoring system, but I would like to see API diff move forward similar to we saw the conversation evolve with the introduction of&amp;nbsp;API Transformer.t tried any of them out, I am just trying to compile a list of what is out there&amp;nbsp;before I dive into what their capabilities are.<br />I have a master database of API definitions where I can just import API definitions that I find, and it will add any new paths, parameters, and schemas it comes across. I would much rather have the ability to just run each version through a diff tool, and be able to select which elements I want to have merged. For now, I will just implement a custom layer to my API monitoring system, but I would like to see API diff move forward similar to we saw the conversation evolve with the introduction of&amp;nbsp;API Transformer.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-diff.png"
  },
  {
  "title": "Cutting Through The Smoke &amp; MIrrors Of IT Discussions Using API Definitions",
  "date": "10 May 2016",
  "body": "<br />I get brought into a lot of API discussions with IT departments from companies, institutions, and government agencies, which are often coordinated by business groups who are interested in better meeting their goals using APIs. This is often an immediately charged conversation, with IT coming to their table with a whole array of baggage.&amp;nbsp;<br />In about 75% of the situations, IT, and developer representatives are nice, or rather they are tight-lipped, relying on a myriad of smoke &amp;amp; mirrors to defend their dark arts. Let me stop for a moment, and put out there that I was IT director from 1998 through 2010. Im not saying IT are bad people, but there are a wide variety of ways we slow, obfuscate, and distort the conversation to be in our favor -- takes one to know one. I wouldn&#39;t say that I was 100% honest in my approach to being an IT leader, but I tried my hardest to keep things as transparent as I possibly could.<br />Anyways, in a couple of the &amp;nbsp;IT discussions I&#39;ve had lately, there was an OpenAPI Spec available to define the resources that were on the table, and in a handful of other conversation there were not. Keep in mind that most of these scenarios are with a more traditional version of IT, not with startup technology groups (a whole different beast). As I step back, I am taking notice of the harmonizing effect that an API definition can have, in keeping conversations focused, productive, and moving forward toward a common goal.<br />In the conversations without an OpenAPI Spec, back-end systems and legacy processes dominated the discussion, even though we are all on a conference call to discuss an external, partner, and public facing API. In the discussions where an OpenAPI Spec was present, we focused on exactly which resources were needed (nothing more), and the details (params, responses, etc) that were needed by all consumers--essentially providing us with a scaffolding for the discussion, that kept things moving forward, and not bogged down in legacy sludge.&amp;nbsp;<br />Backend focused discussions&amp;nbsp;always seemed to get slowed down by what was, and what is. The API definition focused conversations seemed to focus on what was needed, using a common language that everyone at the table understood. The presence of an OpenAPI Spec seemed to cut through the smoke &amp;amp; mirrors, which I think often alienates many of the business users. I find having three versions of an OpenAPI Spec and APIs.json file present: 1) simple outline 2) YAML and 3) JSON, was also something that significantly improved discussions, keeping conversations focused while also making them as inclusive as possible.<br />I think people will always bring their baggage to these discussions, but I&#39;m liking the harmonization effects API definitions like OpenAPI Spec, API Blueprint, Postman, and APIs.json are having in&amp;nbsp;these conversations. I&#39;m hopeful that these API definitions can continue providing bridges between business and IT groups, helping close a canyon that has existed for decades.m not saying IT are bad people, but there are a wide variety of ways we slow, obfuscate, and distort the conversation to be in our favor -- takes one to know one. I wouldnt say that I was 100% honest in my approach to being an IT leader, but I tried my hardest to keep things as transparent as I possibly could.<br />Anyways, in a couple of the &amp;nbsp;IT discussions I&#39;ve had lately, there was an OpenAPI Spec available to define the resources that were on the table, and in a handful of other conversation there were not. Keep in mind that most of these scenarios are with a more traditional version of IT, not with startup technology groups (a whole different beast). As I step back, I am taking notice of the harmonizing effect that an API definition can have, in keeping conversations focused, productive, and moving forward toward a common goal.<br />In the conversations without an OpenAPI Spec, back-end systems and legacy processes dominated the discussion, even though we are all on a conference call to discuss an external, partner, and public facing API. In the discussions where an OpenAPI Spec was present, we focused on exactly which resources were needed (nothing more), and the details (params, responses, etc) that were needed by all consumers--essentially providing us with a scaffolding for the discussion, that kept things moving forward, and not bogged down in legacy sludge.&amp;nbsp;<br />Backend focused discussions&amp;nbsp;always seemed to get slowed down by what was, and what is. The API definition focused conversations seemed to focus on what was needed, using a common language that everyone at the table understood. The presence of an OpenAPI Spec seemed to cut through the smoke &amp;amp; mirrors, which I think often alienates many of the business users. I find having three versions of an OpenAPI Spec and APIs.json file present: 1) simple outline 2) YAML and 3) JSON, was also something that significantly improved discussions, keeping conversations focused while also making them as inclusive as possible.<br />I think people will always bring their baggage to these discussions, but I&#39;m liking the harmonization effects API definitions like OpenAPI Spec, API Blueprint, Postman, and APIs.json are having in&amp;nbsp;these conversations. I&#39;m hopeful that these API definitions can continue providing bridges between business and IT groups, helping close a canyon that has existed for decades.t say that I was 100% honest in my approach to being an IT leader, but I tried my hardest to keep things as transparent as I possibly could.<br />Anyways, in a couple of the &amp;nbsp;IT discussions Ive had lately, there was an OpenAPI Spec available to define the resources that were on the table, and in a handful of other conversation there were not. Keep in mind that most of these scenarios are with a more traditional version of IT, not with startup technology groups (a whole different beast). As I step back, I am taking notice of the harmonizing effect that an API definition can have, in keeping conversations focused, productive, and moving forward toward a common goal.<br />In the conversations without an OpenAPI Spec, back-end systems and legacy processes dominated the discussion, even though we are all on a conference call to discuss an external, partner, and public facing API. In the discussions where an OpenAPI Spec was present, we focused on exactly which resources were needed (nothing more), and the details (params, responses, etc) that were needed by all consumers--essentially providing us with a scaffolding for the discussion, that kept things moving forward, and not bogged down in legacy sludge.&amp;nbsp;<br />Backend focused discussions&amp;nbsp;always seemed to get slowed down by what was, and what is. The API definition focused conversations seemed to focus on what was needed, using a common language that everyone at the table understood. The presence of an OpenAPI Spec seemed to cut through the smoke &amp;amp; mirrors, which I think often alienates many of the business users. I find having three versions of an OpenAPI Spec and APIs.json file present: 1) simple outline 2) YAML and 3) JSON, was also something that significantly improved discussions, keeping conversations focused while also making them as inclusive as possible.<br />I think people will always bring their baggage to these discussions, but I&#39;m liking the harmonization effects API definitions like OpenAPI Spec, API Blueprint, Postman, and APIs.json are having in&amp;nbsp;these conversations. I&#39;m hopeful that these API definitions can continue providing bridges between business and IT groups, helping close a canyon that has existed for decades.ve had lately, there was an OpenAPI Spec available to define the resources that were on the table, and in a handful of other conversation there were not. Keep in mind that most of these scenarios are with a more traditional version of IT, not with startup technology groups (a whole different beast). As I step back, I am taking notice of the harmonizing effect that an API definition can have, in keeping conversations focused, productive, and moving forward toward a common goal.<br />In the conversations without an OpenAPI Spec, back-end systems and legacy processes dominated the discussion, even though we are all on a conference call to discuss an external, partner, and public facing API. In the discussions where an OpenAPI Spec was present, we focused on exactly which resources were needed (nothing more), and the details (params, responses, etc) that were needed by all consumers--essentially providing us with a scaffolding for the discussion, that kept things moving forward, and not bogged down in legacy sludge.&amp;nbsp;<br />Backend focused discussions&amp;nbsp;always seemed to get slowed down by what was, and what is. The API definition focused conversations seemed to focus on what was needed, using a common language that everyone at the table understood. The presence of an OpenAPI Spec seemed to cut through the smoke &amp;amp; mirrors, which I think often alienates many of the business users. I find having three versions of an OpenAPI Spec and APIs.json file present: 1) simple outline 2) YAML and 3) JSON, was also something that significantly improved discussions, keeping conversations focused while also making them as inclusive as possible.<br />I think people will always bring their baggage to these discussions, but Im liking the harmonization effects API definitions like OpenAPI Spec, API Blueprint, Postman, and APIs.json are having in&amp;nbsp;these conversations. I&#39;m hopeful that these API definitions can continue providing bridges between business and IT groups, helping close a canyon that has existed for decades.m liking the harmonization effects API definitions like OpenAPI Spec, API Blueprint, Postman, and APIs.json are having in&amp;nbsp;these conversations. Im hopeful that these API definitions can continue providing bridges between business and IT groups, helping close a canyon that has existed for decades.m hopeful that these API definitions can continue providing bridges between business and IT groups, helping close a canyon that has existed for decades.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-smoke-and-mirrors.png"
  },
  {
  "title": "I Am Seeing Significant Returns From Investing In Definitions Over Code When It Comes To My API Strategy",
  "date": "07 May 2016",
  "body": "<br />I am doing way more work on the creation of machine-readable OpenAPI Specs for APIs, indexed using machine-readable APIs.json&amp;nbsp;files than I am the actual creation of APIs lately. About half of the API definitions I create are for existing APIs, with the rest of them describing APIs that should exist. With the existing APIs, in some cases, I am creating client-side code, but mostly just focusing on a well crafted API definition. When it comes to the new API designs, I am focusing on a complete API definition, but also crafting both server-side, as well as client-side code around the definition--when needed.<br />Even when I do craft server or client code for an API definition, the value of the code is significantly lower than the definition(s). In my mind the code is disposable. I want to be able to throw it away, and start over with anything I am building, at any point. While I have made significant ideological investments into using Linux for my OS, AWS for my compute and storage hosting, MySQL for my database, and PHP + Slim for my API deployment framework, the code that operates within this framework has to be transient. Some code might end up having a long, long life, but if a piece of code isnt generating value, and in the way, I want to either get rid of it or rewrite it to better meet the requirements.<br />When it comes to delivering technology in my world, my investments are increasingly in the API definitions, underlying data schemas, and the data and content that is actually stored and transmitted within. The PHP, MySQL, JavaScript, CSS, and HTML is valuable, but a second class citizen to the JSON, and YAML representations of my APIs, schemas, and the valuable data and content stored. For me personally, having made significant investments in a variety of tech solutions historically, this provides me with the flexibility I need to live in the current online climate. This is something that only has been coming into focus in the last year, so I assume it will also continue to evolve in focus over the next couple of years, but I am already seeing significant returns from my investing in definitions over the code when it comes to my API strategy.t generating value, and in the way, I want to either get rid of it or rewrite it to better meet the requirements.<br />When it comes to delivering technology in my world, my investments are increasingly in the API definitions, underlying data schemas, and the data and content that is actually stored and transmitted within. The PHP, MySQL, JavaScript, CSS, and HTML is valuable, but a second class citizen to the JSON, and YAML representations of my APIs, schemas, and the valuable data and content stored. For me personally, having made significant investments in a variety of tech solutions historically, this provides me with the flexibility I need to live in the current online climate. This is something that only has been coming into focus in the last year, so I assume it will also continue to evolve in focus over the next couple of years, but I am already seeing significant returns from my investing in definitions over the code when it comes to my API strategy.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-invest-api.png"
  },
  {
  "title": "Example Of API Service Providers Making Onboarding With Services Easier Using API Definitions",
  "date": "08 Apr 2016",
  "body": "API definitions like OpenAPI Spec, API Blueprint, and Postman, have been gaining in popularity over the last couple of years, mostly because of the their ability to deploy interactive documentation like Swagger UI. However, the API providers who have been using them the longest, have also realized these machine readable definitions can be applied effectively at almost every step along a modern API life cycle, from design to deprecation.<br />Im always encouraging companies, who are selling software services to the API space (aka API service providers), to make sure and have APIs for their entire stack, as well as speak in as many of the leading API definition formats as you possibly can. To help in this effort, I try to regularly showcase the API service providers who are doing it right--this round, its the folks over at APImetrics.<br />The screen that comes up, when you go to add new API calls to the monitoring service is exactly what I am talking about, allowing me to get up and running using the API definition format of my choosing.<br /><br />I am given the option to manually add an API, or do a bulk import of the APIs I wish to monitor using the service. I&#39;m given the option of importing WSDL, OpenAPI Spec, RAML, Blueprint, and Postman, which reflects the leading API definition formats, any API service provider should be speaking by default. If you need help enabling this in your services, I recommend talking to the APIMATIC folks about using their API Transformer.<br />API definitions are quickly becoming the central contract that gets passed around among technical folks, and increasingly with business units as well. No matter where you exist on the API life cycle, between API design, all the way to deprecation, your customers should be able to onboard, and offboard using all of the modern API definition formats--enabling your users get up and running in seconds, rather than minutes, hours, or even not at all.&amp;nbsp;m always encouraging companies, who are selling software services to the API space (aka API service providers), to make sure and have APIs for their entire stack, as well as speak in as many of the leading API definition formats as you possibly can. To help in this effort, I try to regularly showcase the API service providers who are doing it right--this round, its the folks over at APImetrics.<br />The screen that comes up, when you go to add new API calls to the monitoring service is exactly what I am talking about, allowing me to get up and running using the API definition format of my choosing.<br /><br />I am given the option to manually add an API, or do a bulk import of the APIs I wish to monitor using the service. Im given the option of importing WSDL, OpenAPI Spec, RAML, Blueprint, and Postman, which reflects the leading API definition formats, any API service provider should be speaking by default. If you need help enabling this in your services, I recommend talking to the APIMATIC folks about using their API Transformer.<br />API definitions are quickly becoming the central contract that gets passed around among technical folks, and increasingly with business units as well. No matter where you exist on the API life cycle, between API design, all the way to deprecation, your customers should be able to onboard, and offboard using all of the modern API definition formats--enabling your users get up and running in seconds, rather than minutes, hours, or even not at all.&amp;nbsp;m given the option of importing WSDL, OpenAPI Spec, RAML, Blueprint, and Postman, which reflects the leading API definition formats, any API service provider should be speaking by default. If you need help enabling this in your services, I recommend talking to the APIMATIC folks about using their API Transformer.<br />API definitions are quickly becoming the central contract that gets passed around among technical folks, and increasingly with business units as well. No matter where you exist on the API life cycle, between API design, all the way to deprecation, your customers should be able to onboard, and offboard using all of the modern API definition formats--enabling your users get up and running in seconds, rather than minutes, hours, or even not at all.&amp;nbsp;",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/blog/Fullscreen_4_8_16__1_09_PM.png"
  },
  {
  "title": "Scraping Static Docs Is Often Better Than Proxy For Generating Machine Readable API Definitions",
  "date": "04 Mar 2016",
  "body": "<br />I was looking to create an APIs.json plus OpenAPI Spec(s) for the WordPress.org API, and the Instructure Canvas Learning Management System (LMS) API. I am pulling together a toolkit to support a workshop at Davidson College in North Carolina this month, and I&amp;nbsp;wanted a handful of APIs that would be relevant to students, and faculty on campus.&amp;nbsp;<br />In my experience, when it comes to documenting large APIs using OpenAPI Spec, you dont want to be hand rolling things, making auto generation essential. There are two options for accomplishing this, 1) I can use a proxy like Charles or Stoplight.io, or 2) I can write a script to scrape the publicly available HTML documentation for each API. While I do enjoy playing with mapping out APIs in Stoplight.io, allowing it do the heavy lifting of crafting each API definition, sometimes there is more relevant meta data for the API available in the API documentation.<br />The OpenAPI Spec, plus APIs.json files for both the WordPress and Instructure Canvas APIs took me about an hour a each, to write the script, and round off the OpenAPI Spec, making sure it was as complete as possible. Through scraping, I get description for endpoints, parameters, and sometimes I also get other detail including sample responses, enum, and response codes.<br />One downside of obtaining an API definition by scraping, is that I only get the surface area of an API, not the responses, and underlying data model. Sometimes this is included in documentation, but I do not always harvest this--waiting until I can get a often more correct schema, when I map out using a proxy or via HAR file. This is OK. I find the trade-off worth it. I&#39;d rather have the more human-centered descriptions, and names of each endpoints, than the response definitions--that will come with time, and more usage of the actual APIs.<br />In the end, it really depends to the size of an API, and the quality of the API documentation. If it is a big API, and the documentation is well crafted, it is preferable to scrape and auto generate the definition. Once I have this, I can load it into Postman or Stoplight.io, start making API calls, and use either Stoplight&#39;s proxy, or my own solution that uses Charles Proxy, to provide the remaining schema of the responses, as well as the resulting HTTP status code(s).<br />I think the human touch on all APIs.json, OpenAPI Spec, and API Blueprint files will prove to be essential in streamlining interactions at every stop along the API life cycle. If you can&#39;t easily understand what an API does, and what the moving parts are, the rest won&#39;t matter, so having simple, well written titles, and descriptions for APIs that are described in each machine readable definition is well worth any extra work. Even with auto generation via scraping, or Stoplight.io, I find I still have have to give each API definitions a little extra love to make sure they are as polished as possible.<br />I&#39;m thinking I will start keeping a journal of the work goes into crafting each API&#39;s definition(s). It might be something I can use down the road to further streamline the creation, and maintenance of my API definitions, and the API services I develop to support all of this.<br />Here is the APIs.json for the Wordpress.org API by the way:<br /><br />Here is the APIs.json for the Instructure Canvas API as well:<br /><br />You can see these, and some other API definitions for my workshop over at the Github repo for the project. I created a new Liquid template, that allows me to display APIs.json and OpenAPI Specs within the Jekyll site for this project. Something that I will be using to better deliver API driven content, visualizations, and other resources that help us learn about, and put APIs to work.t want to be hand rolling things, making auto generation essential. There are two options for accomplishing this, 1) I can use a proxy like Charles or Stoplight.io, or 2) I can write a script to scrape the publicly available HTML documentation for each API. While I do enjoy playing with mapping out APIs in Stoplight.io, allowing it do the heavy lifting of crafting each API definition, sometimes there is more relevant meta data for the API available in the API documentation.<br />The OpenAPI Spec, plus APIs.json files for both the WordPress and Instructure Canvas APIs took me about an hour a each, to write the script, and round off the OpenAPI Spec, making sure it was as complete as possible. Through scraping, I get description for endpoints, parameters, and sometimes I also get other detail including sample responses, enum, and response codes.<br />One downside of obtaining an API definition by scraping, is that I only get the surface area of an API, not the responses, and underlying data model. Sometimes this is included in documentation, but I do not always harvest this--waiting until I can get a often more correct schema, when I map out using a proxy or via HAR file. This is OK. I find the trade-off worth it. Id rather have the more human-centered descriptions, and names of each endpoints, than the response definitions--that will come with time, and more usage of the actual APIs.<br />In the end, it really depends to the size of an API, and the quality of the API documentation. If it is a big API, and the documentation is well crafted, it is preferable to scrape and auto generate the definition. Once I have this, I can load it into Postman or Stoplight.io, start making API calls, and use either Stoplight&#39;s proxy, or my own solution that uses Charles Proxy, to provide the remaining schema of the responses, as well as the resulting HTTP status code(s).<br />I think the human touch on all APIs.json, OpenAPI Spec, and API Blueprint files will prove to be essential in streamlining interactions at every stop along the API life cycle. If you can&#39;t easily understand what an API does, and what the moving parts are, the rest won&#39;t matter, so having simple, well written titles, and descriptions for APIs that are described in each machine readable definition is well worth any extra work. Even with auto generation via scraping, or Stoplight.io, I find I still have have to give each API definitions a little extra love to make sure they are as polished as possible.<br />I&#39;m thinking I will start keeping a journal of the work goes into crafting each API&#39;s definition(s). It might be something I can use down the road to further streamline the creation, and maintenance of my API definitions, and the API services I develop to support all of this.<br />Here is the APIs.json for the Wordpress.org API by the way:<br /><br />Here is the APIs.json for the Instructure Canvas API as well:<br /><br />You can see these, and some other API definitions for my workshop over at the Github repo for the project. I created a new Liquid template, that allows me to display APIs.json and OpenAPI Specs within the Jekyll site for this project. Something that I will be using to better deliver API driven content, visualizations, and other resources that help us learn about, and put APIs to work.d rather have the more human-centered descriptions, and names of each endpoints, than the response definitions--that will come with time, and more usage of the actual APIs.<br />In the end, it really depends to the size of an API, and the quality of the API documentation. If it is a big API, and the documentation is well crafted, it is preferable to scrape and auto generate the definition. Once I have this, I can load it into Postman or Stoplight.io, start making API calls, and use either Stoplights proxy, or my own solution that uses Charles Proxy, to provide the remaining schema of the responses, as well as the resulting HTTP status code(s).<br />I think the human touch on all APIs.json, OpenAPI Spec, and API Blueprint files will prove to be essential in streamlining interactions at every stop along the API life cycle. If you can&#39;t easily understand what an API does, and what the moving parts are, the rest won&#39;t matter, so having simple, well written titles, and descriptions for APIs that are described in each machine readable definition is well worth any extra work. Even with auto generation via scraping, or Stoplight.io, I find I still have have to give each API definitions a little extra love to make sure they are as polished as possible.<br />I&#39;m thinking I will start keeping a journal of the work goes into crafting each API&#39;s definition(s). It might be something I can use down the road to further streamline the creation, and maintenance of my API definitions, and the API services I develop to support all of this.<br />Here is the APIs.json for the Wordpress.org API by the way:<br /><br />Here is the APIs.json for the Instructure Canvas API as well:<br /><br />You can see these, and some other API definitions for my workshop over at the Github repo for the project. I created a new Liquid template, that allows me to display APIs.json and OpenAPI Specs within the Jekyll site for this project. Something that I will be using to better deliver API driven content, visualizations, and other resources that help us learn about, and put APIs to work.s proxy, or my own solution that uses Charles Proxy, to provide the remaining schema of the responses, as well as the resulting HTTP status code(s).<br />I think the human touch on all APIs.json, OpenAPI Spec, and API Blueprint files will prove to be essential in streamlining interactions at every stop along the API life cycle. If you cant easily understand what an API does, and what the moving parts are, the rest won&#39;t matter, so having simple, well written titles, and descriptions for APIs that are described in each machine readable definition is well worth any extra work. Even with auto generation via scraping, or Stoplight.io, I find I still have have to give each API definitions a little extra love to make sure they are as polished as possible.<br />I&#39;m thinking I will start keeping a journal of the work goes into crafting each API&#39;s definition(s). It might be something I can use down the road to further streamline the creation, and maintenance of my API definitions, and the API services I develop to support all of this.<br />Here is the APIs.json for the Wordpress.org API by the way:<br /><br />Here is the APIs.json for the Instructure Canvas API as well:<br /><br />You can see these, and some other API definitions for my workshop over at the Github repo for the project. I created a new Liquid template, that allows me to display APIs.json and OpenAPI Specs within the Jekyll site for this project. Something that I will be using to better deliver API driven content, visualizations, and other resources that help us learn about, and put APIs to work.t easily understand what an API does, and what the moving parts are, the rest wont matter, so having simple, well written titles, and descriptions for APIs that are described in each machine readable definition is well worth any extra work. Even with auto generation via scraping, or Stoplight.io, I find I still have have to give each API definitions a little extra love to make sure they are as polished as possible.<br />I&#39;m thinking I will start keeping a journal of the work goes into crafting each API&#39;s definition(s). It might be something I can use down the road to further streamline the creation, and maintenance of my API definitions, and the API services I develop to support all of this.<br />Here is the APIs.json for the Wordpress.org API by the way:<br /><br />Here is the APIs.json for the Instructure Canvas API as well:<br /><br />You can see these, and some other API definitions for my workshop over at the Github repo for the project. I created a new Liquid template, that allows me to display APIs.json and OpenAPI Specs within the Jekyll site for this project. Something that I will be using to better deliver API driven content, visualizations, and other resources that help us learn about, and put APIs to work.t matter, so having simple, well written titles, and descriptions for APIs that are described in each machine readable definition is well worth any extra work. Even with auto generation via scraping, or Stoplight.io, I find I still have have to give each API definitions a little extra love to make sure they are as polished as possible.<br />Im thinking I will start keeping a journal of the work goes into crafting each API&#39;s definition(s). It might be something I can use down the road to further streamline the creation, and maintenance of my API definitions, and the API services I develop to support all of this.<br />Here is the APIs.json for the Wordpress.org API by the way:<br /><br />Here is the APIs.json for the Instructure Canvas API as well:<br /><br />You can see these, and some other API definitions for my workshop over at the Github repo for the project. I created a new Liquid template, that allows me to display APIs.json and OpenAPI Specs within the Jekyll site for this project. Something that I will be using to better deliver API driven content, visualizations, and other resources that help us learn about, and put APIs to work.m thinking I will start keeping a journal of the work goes into crafting each APIs definition(s). It might be something I can use down the road to further streamline the creation, and maintenance of my API definitions, and the API services I develop to support all of this.<br />Here is the APIs.json for the Wordpress.org API by the way:<br /><br />Here is the APIs.json for the Instructure Canvas API as well:<br /><br />You can see these, and some other API definitions for my workshop over at the Github repo for the project. I created a new Liquid template, that allows me to display APIs.json and OpenAPI Specs within the Jekyll site for this project. Something that I will be using to better deliver API driven content, visualizations, and other resources that help us learn about, and put APIs to work.s definition(s). It might be something I can use down the road to further streamline the creation, and maintenance of my API definitions, and the API services I develop to support all of this.<br />Here is the APIs.json for the Wordpress.org API by the way:<br /><br />Here is the APIs.json for the Instructure Canvas API as well:<br /><br />You can see these, and some other API definitions for my workshop over at the Github repo for the project. I created a new Liquid template, that allows me to display APIs.json and OpenAPI Specs within the Jekyll site for this project. Something that I will be using to better deliver API driven content, visualizations, and other resources that help us learn about, and put APIs to work.",
  "url": "http://localhost:4000",
  "image": ""
  },
  {
  "title": "API Definitions Are The Contract For Doing Business With APIs",
  "date": "27 Jan 2016",
  "body": "I held a hangout with API Evangelist this morning, with Steve Willmot (@njyx) of @3scale, &amp;amp; Jakub Nesetril (@jakubnesetril) of @apiaryio&amp;nbsp;today, where we discussed API definitions. Both Steve and Jakub are CEOs of leading tech companies, who are taking frontline positions when it comes to the whole API definition conversation.<br />My role in this hangout, was just bringing together these two API leaders, to discuss the most important topic facing us in the world of APIs. API definitions are touching on every aspect of the API life cycle, and as Steve and Jakub discuss, playing a central role in their businesses, and their customers businesses. We published the hour and half conversation on Youtube, so you can join in, even if you couldn&#39;t make the hangout.<br />&amp;nbsp;<br /><br />&amp;nbsp;<br />The focus on API definitions being the contract, was the most important part of today&#39;s hangout for me. This wasn&#39;t a conversation about just Swagger, or API Blueprint, it was a discussion about the role API definitions play in the API life cycle, from the latest wave of API description formats like Swagger and Blueprint, to API discovery formats like APIs.json, and even media types, and schemas. These are the contracts we are using to communicate our ideas, generate code, setup tests, drive documentation, and make the API economy go roudn.<br />This hangout was scheduled to be an hour, but there was so much to cover, we took it an extra 30 minutes. The conversation left me feeling like I need to do this more often, expanding on the API definition discussion, but also push into other important areas like API deployment, virtualization, discovery, monitoring, and the other almost 40 areas of the API lifecycle I track on. We&#39;ll see how much time i have to do these, but more importantly my ability to bring smart people like Steve and Jakub together--something I hope I can make it work.<br />Thanks to Jakub and Steve for participating today!s businesses. We published the hour and half conversation on Youtube, so you can join in, even if you couldnt make the hangout.<br />&amp;nbsp;<br /><br />&amp;nbsp;<br />The focus on API definitions being the contract, was the most important part of today&#39;s hangout for me. This wasn&#39;t a conversation about just Swagger, or API Blueprint, it was a discussion about the role API definitions play in the API life cycle, from the latest wave of API description formats like Swagger and Blueprint, to API discovery formats like APIs.json, and even media types, and schemas. These are the contracts we are using to communicate our ideas, generate code, setup tests, drive documentation, and make the API economy go roudn.<br />This hangout was scheduled to be an hour, but there was so much to cover, we took it an extra 30 minutes. The conversation left me feeling like I need to do this more often, expanding on the API definition discussion, but also push into other important areas like API deployment, virtualization, discovery, monitoring, and the other almost 40 areas of the API lifecycle I track on. We&#39;ll see how much time i have to do these, but more importantly my ability to bring smart people like Steve and Jakub together--something I hope I can make it work.<br />Thanks to Jakub and Steve for participating today!t make the hangout.<br />&amp;nbsp;<br /><br />&amp;nbsp;<br />The focus on API definitions being the contract, was the most important part of todays hangout for me. This wasn&#39;t a conversation about just Swagger, or API Blueprint, it was a discussion about the role API definitions play in the API life cycle, from the latest wave of API description formats like Swagger and Blueprint, to API discovery formats like APIs.json, and even media types, and schemas. These are the contracts we are using to communicate our ideas, generate code, setup tests, drive documentation, and make the API economy go roudn.<br />This hangout was scheduled to be an hour, but there was so much to cover, we took it an extra 30 minutes. The conversation left me feeling like I need to do this more often, expanding on the API definition discussion, but also push into other important areas like API deployment, virtualization, discovery, monitoring, and the other almost 40 areas of the API lifecycle I track on. We&#39;ll see how much time i have to do these, but more importantly my ability to bring smart people like Steve and Jakub together--something I hope I can make it work.<br />Thanks to Jakub and Steve for participating today!s hangout for me. This wasnt a conversation about just Swagger, or API Blueprint, it was a discussion about the role API definitions play in the API life cycle, from the latest wave of API description formats like Swagger and Blueprint, to API discovery formats like APIs.json, and even media types, and schemas. These are the contracts we are using to communicate our ideas, generate code, setup tests, drive documentation, and make the API economy go roudn.<br />This hangout was scheduled to be an hour, but there was so much to cover, we took it an extra 30 minutes. The conversation left me feeling like I need to do this more often, expanding on the API definition discussion, but also push into other important areas like API deployment, virtualization, discovery, monitoring, and the other almost 40 areas of the API lifecycle I track on. We&#39;ll see how much time i have to do these, but more importantly my ability to bring smart people like Steve and Jakub together--something I hope I can make it work.<br />Thanks to Jakub and Steve for participating today!t a conversation about just Swagger, or API Blueprint, it was a discussion about the role API definitions play in the API life cycle, from the latest wave of API description formats like Swagger and Blueprint, to API discovery formats like APIs.json, and even media types, and schemas. These are the contracts we are using to communicate our ideas, generate code, setup tests, drive documentation, and make the API economy go roudn.<br />This hangout was scheduled to be an hour, but there was so much to cover, we took it an extra 30 minutes. The conversation left me feeling like I need to do this more often, expanding on the API definition discussion, but also push into other important areas like API deployment, virtualization, discovery, monitoring, and the other almost 40 areas of the API lifecycle I track on. Well see how much time i have to do these, but more importantly my ability to bring smart people like Steve and Jakub together--something I hope I can make it work.<br />Thanks to Jakub and Steve for participating today!ll see how much time i have to do these, but more importantly my ability to bring smart people like Steve and Jakub together--something I hope I can make it work.<br />Thanks to Jakub and Steve for participating today!",
  "url": "http://localhost:4000",
  "image": ""
  },
  {
  "title": "Join @3Scale, @Apiary, And I For A Hangout On API Definitions This Wednesday",
  "date": "25 Jan 2016",
  "body": "<br />Join me, Steve Willmott(@njyx) of 3Scale, and Jakub Nesetril(@jakubnesetril) of Apiary, for a hangout on API definitions this week. I wanted to explore&amp;nbsp; doing more hangouts under the APIStrat, as well as API Evangelist brand(s)--for this one I wanted to bring together some experts to talk about the fast moving world of API definitions, as a Hangout with API Evangelist.<br />This Wednesday, January 27th, at 11:00 AM PST, the three of us will jump on a Google Hangout, and you are welcome to join in the conversation. We will be doing the gathering as a Hangout on Air, so that you can ask questions if you want, joining in the live conversation, or you can wait until after we are done, I will make sure and publish the video to Youtube.<br /><br />Its a pretty important time for API definitions with the Swagger specification reborn as the OpenAPISpec, and Apiary, the creator of API Blueprint and MSON, also adopting OpenAPI Spec this last week, allowing you to design and mock your API in both formats. 3Scale was an earlier adopter of Swagger, and has taken a leadership position in shepherding it to into the Linux Foundation, and is a member of the governance working group.<br />I figured that it is a pretty good time to check-in with Steve and Jakub, on the current state of API definitions, and how they see them impacting their own platforms, as well as the overall API space. If you have any specific questions youd like me to ask, or have any specific topics you&#39;d like to see discussed, feel free to tweet at me. I&#39;ll tweet out the link for the event, but all you need to do is visit hangoutwith.apievangelist.com, this Wednesday at 11:00 PST, and join in the conversation.d like me to ask, or have any specific topics youd like to see discussed, feel free to tweet at me. I&#39;ll tweet out the link for the event, but all you need to do is visit hangoutwith.apievangelist.com, this Wednesday at 11:00 PST, and join in the conversation.d like to see discussed, feel free to tweet at me. Ill tweet out the link for the event, but all you need to do is visit hangoutwith.apievangelist.com, this Wednesday at 11:00 PST, and join in the conversation.ll tweet out the link for the event, but all you need to do is visit hangoutwith.apievangelist.com, this Wednesday at 11:00 PST, and join in the conversation.",
  "url": "http://localhost:4000",
  "image": ""
  },
  {
  "title": "Join Me For A Hangout With @3Scale @Apiary To Discuss Current State of API Definitions",
  "date": "18 Jan 2016",
  "body": "It is an important time for API definitions. Ive seen a significant uptick in the usage across the leading API definition formats, and we experienced the evolution of Swagger into the Linux Foundation, being reborn as the OpenAPI Spec. In 2016,&amp;nbsp;ve seen a significant uptick in the usage across the leading API definition formats, and we experienced the evolution of Swagger into the Linux Foundation, being reborn as the OpenAPI Spec. In 2016,&amp;nbsp;",
  "url": "http://localhost:4000",
  "image": ""
  },
  {
  "title": "An APIStrat Hangout On API Definitions With @3Scale and @Apiary",
  "date": "13 Jan 2016",
  "body": "",
  "url": "http://localhost:4000",
  "image": ""
  },
  {
  "title": "API Stack, APIs.io, And APIs.Guru Need You To Create And Share Your API Definitions",
  "date": "09 Jan 2016",
  "body": "<br />I feel pretty strongly that for the next wave of growth in the API sector, we need the majority of public APIs in use today, to have well crafted, as complete as possible, API definitions in either OpenAPI Spec or API Blueprint. Yes I know, we actually need all of these APIs to be crafted using hypermedia approaches, but until then we need them all to possess machine readable API definitions, making them discoverable, learnable, and consumable.<br />It is easy to get hung up on this being about API discovery, but API definitions are enabling almost every step along the 35 areas of the API life cycle I am mapping out. Historically API definitions have bee used for interactive API documentation, but more recently are additionally being used to light up other aspects of API integration, such as setting up your API monitoring, loading into the API client of your choosing, or lighting up a mock server for use in development.&amp;nbsp;<br />In addition enabling services and tooling throughout the life cycle, well crafted, complete API definitions is driving API design literacy. Many API developers and architects learn by reverse engineering the APIs they know, and a well crafted OpenAPI Spec or API Blueprint provides a detail blueprint for enabling this experience. API definitions make it easier to learn about good, and bad API design, in terms of the APIs you actually care about--equaling a much more open mind.<br />Ive been working to define API definitions as part of my API Stack work, for over a year now. You can access all the APIs.json + OpenAPI Specs + API Blueprint + Postman collections under the /data folder for the project repository. Additionally, this repo is one of the sources of APIs.io which is an APIs.json driven open source API search engine, which provides an API for you to register and search for API definitions.<br />In 2015, I saw another strong player emerge, that I&#39;m big on supporting--APIs.guru. The open source API definitions repository is looking to be the Wikipedia of API definitions, providing a single place we can find, robust, complete, API definitions in a variety of formats. They have done a lot of work to seed the repository with 196 APIs, possessing over 4000 endpoints, but they are looking to take things to the next level, and will need our help to this Wikipedia of APIs become a reality.<br />The API Stack, APIs.io, and APIs.guru all need you to help contribute, and refine the API definitions in their indexes. Developers around the world are using these definitions in their work, and modern API tooling and service providers are using them to define the value they bring to the table. To help the API sector reach the next level, we need you to step up and share the API definitions you have with API Stack, APIs.io, or APIs.guru, and if you have the time and skills, we could use your help crafting other new API definitions for popular services available today.&amp;nbsp;<br />If you need help getting in touch with APIs.io or APIs.guru, there is contact information on both their sites. Alternatively, feel free to just ping me with the URL of your own Github repository, and I&#39;ll make sure your API definition index gets in sync with all of this new wave of open API repositories.ve been working to define API definitions as part of my API Stack work, for over a year now. You can access all the APIs.json + OpenAPI Specs + API Blueprint + Postman collections under the /data folder for the project repository. Additionally, this repo is one of the sources of APIs.io which is an APIs.json driven open source API search engine, which provides an API for you to register and search for API definitions.<br />In 2015, I saw another strong player emerge, that Im big on supporting--APIs.guru. The open source API definitions repository is looking to be the Wikipedia of API definitions, providing a single place we can find, robust, complete, API definitions in a variety of formats. They have done a lot of work to seed the repository with 196 APIs, possessing over 4000 endpoints, but they are looking to take things to the next level, and will need our help to this Wikipedia of APIs become a reality.<br />The API Stack, APIs.io, and APIs.guru all need you to help contribute, and refine the API definitions in their indexes. Developers around the world are using these definitions in their work, and modern API tooling and service providers are using them to define the value they bring to the table. To help the API sector reach the next level, we need you to step up and share the API definitions you have with API Stack, APIs.io, or APIs.guru, and if you have the time and skills, we could use your help crafting other new API definitions for popular services available today.&amp;nbsp;<br />If you need help getting in touch with APIs.io or APIs.guru, there is contact information on both their sites. Alternatively, feel free to just ping me with the URL of your own Github repository, and I&#39;ll make sure your API definition index gets in sync with all of this new wave of open API repositories.m big on supporting--APIs.guru. The open source API definitions repository is looking to be the Wikipedia of API definitions, providing a single place we can find, robust, complete, API definitions in a variety of formats. They have done a lot of work to seed the repository with 196 APIs, possessing over 4000 endpoints, but they are looking to take things to the next level, and will need our help to this Wikipedia of APIs become a reality.<br />The API Stack, APIs.io, and APIs.guru all need you to help contribute, and refine the API definitions in their indexes. Developers around the world are using these definitions in their work, and modern API tooling and service providers are using them to define the value they bring to the table. To help the API sector reach the next level, we need you to step up and share the API definitions you have with API Stack, APIs.io, or APIs.guru, and if you have the time and skills, we could use your help crafting other new API definitions for popular services available today.&amp;nbsp;<br />If you need help getting in touch with APIs.io or APIs.guru, there is contact information on both their sites. Alternatively, feel free to just ping me with the URL of your own Github repository, and Ill make sure your API definition index gets in sync with all of this new wave of open API repositories.ll make sure your API definition index gets in sync with all of this new wave of open API repositories.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/api-commons/api-commons-icon.png"
  },
  {
  "title": "Sharing 235K API Definitions With The English Language API Recipe Book",
  "date": "23 Nov 2015",
  "body": "<br />I needed a side project to reboot my mind after @APIStrat this last weekend, so I opened up my notebook and picked a project that Ive been meaning to give some attention to, one that would help me clean my slate, and let me get back to my regular work levels. The project I picked is one that I came up with a little over a year ago, but recently had flushed out my vision further, as I hung out at my favorite watering whole drinking an IPA.<br />It took me several iterations before I landed on a name for this project, but my working title is the English Language API Recipe Book. I find myself in an awkward position these days, when it comes to the concept of API copyright, which is something I have taken a firm stance on with my work around the Oracle v Google ava API copyright case, and the release of the API licensing format API Commons, but is something, in the end, I just do not believe in.<br />You see, in my opinion, API definitions should NOT fall under copyright. Like recipes and menus, API definitions should not be open for anyone to use. To help me make my point, I wanted to craft the English Language API Recipe Book, publishing an open API definition for almost every word in the English dictionary. I found a reasonably complete list of every English word, and auto-generated an Open API Definition Format (OADF) specification for each of the 235K+ words.&amp;nbsp;<br />For each API definition, I cover the base GET, POST, PUT, and DELETE verbs for each word, providing a basic query via a parameter, and return a name, and description as the basic underlying data model. I am already playing with other variations of database models, and have also generated another dimension for each word, by again iterating through each word, and adding it as a secondary level resource. I am also playing with other relationships, and ideas for expanding the dimensions of this recipe book, but wanted to get this first version out the door.<br /><br />Overall, I just want to show how easy it is to programmatically generate API definitions, and add this English Language API Recipe Book to my already growing number of API definitions, from popular APIs that I include in the API Stack. Through this work, I wanted to emphasize, that no matter how much work you put into the naming, ordering, and design of your API definitions, they are not creative works that you should lock up and defend--your API definitions should be open, easily accessible, shared, and designed for reuse.<br />While I do not think any of the 235K+ API definitions should have copyright applied, I will putting all of these into public domain, using a Creative Commons license, as act two of this production. This is more theater than anything, but using API Commons, I will make sure every word in the English dictionary, crafted as a basic web API, is available for anyone to use, anytime, anywhere (as it should be, DUH). I recently stated in a keynote, after launching API Commons, that I was going to be the Johnny Fucking Appleseed of publishing openly licensed API definitions, out in front of slower moving corporations like Oracle--the English Language API Recipe Book is just the beginning of this.<br />Next up, I will be crafting a series of OADF API definitions for Schema.org and use APIs.json to bundles as a more meaningful collection. I will be using these data models to further automate the English Language API Recipe Book, and establish additional dimensions to this collection. You can find the English Language API Recipe Book on Github. I have published as a Github organization, with a separate sharded repository for each letter of the alphabet, containing a separate OADF definition for each word in the dictionary, and indexed using APIs.json to index each letter, as well as for the overall recipe book collection--making it all machine readable by default.ve been meaning to give some attention to, one that would help me clean my slate, and let me get back to my regular work levels. The project I picked is one that I came up with a little over a year ago, but recently had flushed out my vision further, as I hung out at my favorite watering whole drinking an IPA.<br />It took me several iterations before I landed on a name for this project, but my working title is the English Language API Recipe Book. I find myself in an awkward position these days, when it comes to the concept of API copyright, which is something I have taken a firm stance on with my work around the Oracle v Google ava API copyright case, and the release of the API licensing format API Commons, but is something, in the end, I just do not believe in.<br />You see, in my opinion, API definitions should NOT fall under copyright. Like recipes and menus, API definitions should not be open for anyone to use. To help me make my point, I wanted to craft the English Language API Recipe Book, publishing an open API definition for almost every word in the English dictionary. I found a reasonably complete list of every English word, and auto-generated an Open API Definition Format (OADF) specification for each of the 235K+ words.&amp;nbsp;<br />For each API definition, I cover the base GET, POST, PUT, and DELETE verbs for each word, providing a basic query via a parameter, and return a name, and description as the basic underlying data model. I am already playing with other variations of database models, and have also generated another dimension for each word, by again iterating through each word, and adding it as a secondary level resource. I am also playing with other relationships, and ideas for expanding the dimensions of this recipe book, but wanted to get this first version out the door.<br /><br />Overall, I just want to show how easy it is to programmatically generate API definitions, and add this English Language API Recipe Book to my already growing number of API definitions, from popular APIs that I include in the API Stack. Through this work, I wanted to emphasize, that no matter how much work you put into the naming, ordering, and design of your API definitions, they are not creative works that you should lock up and defend--your API definitions should be open, easily accessible, shared, and designed for reuse.<br />While I do not think any of the 235K+ API definitions should have copyright applied, I will putting all of these into public domain, using a Creative Commons license, as act two of this production. This is more theater than anything, but using API Commons, I will make sure every word in the English dictionary, crafted as a basic web API, is available for anyone to use, anytime, anywhere (as it should be, DUH). I recently stated in a keynote, after launching API Commons, that I was going to be the Johnny Fucking Appleseed of publishing openly licensed API definitions, out in front of slower moving corporations like Oracle--the English Language API Recipe Book is just the beginning of this.<br />Next up, I will be crafting a series of OADF API definitions for Schema.org and use APIs.json to bundles as a more meaningful collection. I will be using these data models to further automate the English Language API Recipe Book, and establish additional dimensions to this collection. You can find the English Language API Recipe Book on Github. I have published as a Github organization, with a separate sharded repository for each letter of the alphabet, containing a separate OADF definition for each word in the dictionary, and indexed using APIs.json to index each letter, as well as for the overall recipe book collection--making it all machine readable by default.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-api-copyright.png"
  },
  {
  "title": "API Visualization Exploration Using API Definitions",
  "date": "29 Oct 2015",
  "body": "<br />There are number of areas across the API life-cycle that are being expanded upon in the current space, thanks to the evolution of API definition formats like Swagger, API Blueprint, and RAML. One area I havent seen as much growth as I&#39;d like, is in the area of visualizations driven by API definitions.&amp;nbsp;<br />There are two distinct pools of API definition driven visualization: 1) Letting you visualize the surface area of an API 2) Letting you visualize the resource made available via an API. One area my friend the @APIHandyman has been exploring is around the surface area of API.<br />@APIHandyman has a nice prototype created that he is calling Swagger Specification Visual Documentation. The API Definition driven visualization uses A D3.js visualization to help you explore the surface area of any API that is defined using Swagger. I have written about API definition driven visualizations before, so I am happy to see the concept being pushed forward, as we have a lot of iterations to cycle through before we find a visualization format(s) that works for different API designers, architects, and developers.<br />The visual documentation that @APIHandyman created runs on Github, and he is looking for feedback on the micro tool, and where he should take it next. He recently added a bigger information display area, but could use the communities ideas on how to make it more useful. This type of work is a time drain. Every time I started playing with Swagger + D3.js I would lose an entire evening, and have very little to show for work, so I know how valuable feedback can be.<br />I strongly feel that API definition driven D3.js visualizations will be the future of API design, management, and orchestration. APIs are going to continue to grow in number, and scope, and we will need simple, visual ways we can quickly traverse the landscape, and makes sense of things. If you are working on an API definition driven visualization tool, either for the surface area of an API, or helping visualize the actual resources being served up, please let me know so I can showcase.t seen as much growth as Id like, is in the area of visualizations driven by API definitions.&amp;nbsp;<br />There are two distinct pools of API definition driven visualization: 1) Letting you visualize the surface area of an API 2) Letting you visualize the resource made available via an API. One area my friend the @APIHandyman has been exploring is around the surface area of API.<br />@APIHandyman has a nice prototype created that he is calling Swagger Specification Visual Documentation. The API Definition driven visualization uses A D3.js visualization to help you explore the surface area of any API that is defined using Swagger. I have written about API definition driven visualizations before, so I am happy to see the concept being pushed forward, as we have a lot of iterations to cycle through before we find a visualization format(s) that works for different API designers, architects, and developers.<br />The visual documentation that @APIHandyman created runs on Github, and he is looking for feedback on the micro tool, and where he should take it next. He recently added a bigger information display area, but could use the communities ideas on how to make it more useful. This type of work is a time drain. Every time I started playing with Swagger + D3.js I would lose an entire evening, and have very little to show for work, so I know how valuable feedback can be.<br />I strongly feel that API definition driven D3.js visualizations will be the future of API design, management, and orchestration. APIs are going to continue to grow in number, and scope, and we will need simple, visual ways we can quickly traverse the landscape, and makes sense of things. If you are working on an API definition driven visualization tool, either for the surface area of an API, or helping visualize the actual resources being served up, please let me know so I can showcase.d like, is in the area of visualizations driven by API definitions.&amp;nbsp;<br />There are two distinct pools of API definition driven visualization: 1) Letting you visualize the surface area of an API 2) Letting you visualize the resource made available via an API. One area my friend the @APIHandyman has been exploring is around the surface area of API.<br />@APIHandyman has a nice prototype created that he is calling Swagger Specification Visual Documentation. The API Definition driven visualization uses A D3.js visualization to help you explore the surface area of any API that is defined using Swagger. I have written about API definition driven visualizations before, so I am happy to see the concept being pushed forward, as we have a lot of iterations to cycle through before we find a visualization format(s) that works for different API designers, architects, and developers.<br />The visual documentation that @APIHandyman created runs on Github, and he is looking for feedback on the micro tool, and where he should take it next. He recently added a bigger information display area, but could use the communities ideas on how to make it more useful. This type of work is a time drain. Every time I started playing with Swagger + D3.js I would lose an entire evening, and have very little to show for work, so I know how valuable feedback can be.<br />I strongly feel that API definition driven D3.js visualizations will be the future of API design, management, and orchestration. APIs are going to continue to grow in number, and scope, and we will need simple, visual ways we can quickly traverse the landscape, and makes sense of things. If you are working on an API definition driven visualization tool, either for the surface area of an API, or helping visualize the actual resources being served up, please let me know so I can showcase.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/blog/swagger-specification-visual-documentation.png"
  },
  {
  "title": "API Definitions Broker Critical Conversations Between Business And Developers Who Are Building NextGen Web, Mobile, and Device Apps",
  "date": "15 Sep 2015",
  "body": "<br />If  you are in an industry being impacted by technology, you have probably  become very aware of the term Application Programming Interfaces, more  widely known as APIs, and how they are driving web applications, mobile  applications, and increasingly everyday  objects in our homes, cars, businesses, and across the public  landscape. If you are finding yourself part of this growing  conversations, you have most likely have also heard talk of a new breed  of API definition formats that are becoming ubiquitous like Swagger  and API Blueprint.<br />API definitions are a way to describe what an API does, providing a  machine readable blueprint of how to put the digital resource to work.  API definitions are not new, but this latest round of available formats  are taking the API conversation out of just  IT and developer groups, and enabling business units, and other key  stakeholders to participate throughout the API life-cycle. Much like the  latest wave of web APIs has made data, content, and other digital  resources like video and images more accessible,  API definitions are making APIs more accessible across the rapidly  expanding digital business landscape.<br />The first widely available API definition format was the  Web Services Description Language (WSDL), which is an XML format  established in 2001 that described web services. Much like web services  (an API predecessor), WSDL was a very technical vision of APIs,  something dictated by IT, and developer groups, with  heavy top down governance from business and industry leadership. While  web services, and WSDL are still ubiquitous across the enterprise, they  are rapidly being replaced with much lighter weight, simpler web APIs  that use the Internet as a way of delivering  the digital data, content, and resources web, mobile, and devices are  demanding in 2015.<br /><br />Along the way, newer, more web friendly API definition formats emerged, such as  Web Application Description Language (WADL), but ultimately WADL was  something that never took root, suffering from many of the same illness  of its predecessor WSDL. It wasnt until a new format called  Swagger was born, that we started to see the conversation around how  we define, communicate and develop standardized tooling around APIs  evolve, providing an open specification for defining all the details  that go into an API.&amp;nbsp;<br />Swagger provided developers a way to describe an API that was more in  sync with everything else modern API developers were used to, including  using JSON, rather than the XML of previous web services, WSDL and  WADL. Swagger gave us something more than just  way to define APIs, it gave us swagger UI, which is a interactive  version of API documentation that made learning about what an API does,  and how to integrate with it, a hands on, interactive experience. This  new approach to documentation gave us a solution  to the number one problem plaguing API providers, which was out of date  documentation that confused consumers.<br />Shortly after Swagger began seeing wide adoption because of the  interactive documentation it provided for APIs, a new API definition  format also emerged called API Blueprint, which provided interactive  documentation, but rather than using JSON, it used Markdown,  making the process of defining APIs a little less intimidating for  non-developers. Apiary, the makers of API Blueprint did another thing  that would move the conversation forward again, making the reasons for  defining APIs in these formats, more about API design,  than just about delivering up-to-date documentation.<br /><br />Using API Blueprint, API designers could define an API, before any  code was actually written. Developers could craft an API using Apiary&#39;s  tooling, then a mock version of an API could be generated, which could  be shared with other project stakeholders, from  business users, to potential web or mobile developers. This process  saves considerable time, money, and other resources in ensuring than API  would be something web, mobile, and device developers could actually  put to use. With two new API definition formats  Swagger, and now API Blueprint, the processing of defining, designing  APIs in a machine readable way, was accessible to everyone, across a  rapidly expanding API life-cycle.<br />This evolution has all occurred over the last 4 years, a period which  has also produced other API definition formats like RSDL, RADL, RAML,  I/O Docs, and MSON--just to name a few. All of these API definition  formats are quickly becoming the preferred format  for not just defining, and designing APIs, as well as delivering  documentation. Another positive by-product has been that a new breed of  API service providers are also using it as the central definition for  quickly putting their services to work on any API,  for documentation, mocking and virtualizing APIs, generating server  code, producing software development kits (SDK), and setting up  essential testing and monitoring to keep APIs stable and reliable for  consumers--the API definition driven life-cycle continues  to expand.<br />In 15 years, like APIs, the API definition formats have moved out of  the real of the technical, and are providing vital business interactions  that ensure APIs meet critical internal, partner, and public needs.  They are also being applied to bring much needed  balance to the political side of API operations, from making sure APIs  are stable, and available, to defining pricing, rate limits, terms of  service, and even helping secure APIs that operate on the open Internet.<br />API definitions have become a machine readable contract that defines  the boundaries of a relationship between API provider, and its  consumers. Acting as a central truth, that is crafted by developers and  API architects to govern how an API operates, from  mocking to client integration, but in a way that is also setting the  technical, business, and legal expectations of consumers. This API  definition-driven contact is transcending the often proprietary, black  box algorithms that make an API function behind the  scenes, providing a portable, shareable, machine readable contract that  can be shared internally, and externally with partners or the general  public.<br />The importance of this new layer, and its role in the future of software development can be seen playing out in the  Oracle v Google API copyright case, where Oracle (using the courts)  has set the precedent that the naming, and ordering of your interface is  separate from the code, and falls under copyright protection. Beyond  the core legal case, the questions, and understanding  of exactly what is code has been even more interesting. Many API  architects do not see APIs as anything but code, having not seen impacts  of the modern API definition movement within their architecture yet.<br />API definitions aren&#39;t just about defining the URLs, parameters,  headers, and other aspects of API operations that developers need to  know, it is also bringing much needed clarity and awareness of value  generated by APIs among business users, and the end-users  of the applications that APIs are powering. API definitions provide a  common format in markdown, YAML, or JSON, that describe the technical  surface of an API, but then also take this technical specification, and  allow it to be applied across every stop along  the API life-cycle, from idea to deployment, to resulting integration  with web, mobile, and device applications.<br />As APIs make their way into almost every aspect of our business and  personal lives, driving our social relationships with family and  friends, meter our connections to our utility companies, connect us to  educational and healthcare opportunities, this touch-point  between platform, and the web, mobile, and device applications it  powers, is becoming increasingly critical. To businesses this layer  represents critical supply chains, but to each individual this touch  point is where all of our life bits flow--further emphasizing  the importance of, but also the sensitivity required in defining APIs  in a meaningful way, that makes sense to EVERYONE involved.<br />In 2001, a WSDL definition was very much about communicating what a  service did between platform and an the system that was integrated,  something that only involved IT, and developers. In 2015, a modern API  definition format provides the same benefits that  WSDL has historically delivered, but it is also addressing the  business, and political elements of how Internet enabled software works.  &amp;nbsp;A modern API definition provides:<br /><br />a medium for API designs, architects, and business stakeholders to  craft exactly the API that is needed, before any production code is  written. <br />a necessary set of instructions needed for a quality assurance (QA) team to make sure an API meets business requirements <br />a definition of sandbox, mocking, simulation, and virtualization environments that developers may need to be successful <br />what a developer needs to integrate with another system, or  build an application through interactive documentation, and even  complete Software Development Kits (SDK) <br />what the API testing, monitoring, and performance groups will need to ensure service level agreements are met or exceeded <br />the known surface area that security auditor will need to  properly secure the infrastructure web, mobile, devices, and ultimately  users will depend on <br />a map that government regulators can use to understand the  industry landscape, and help keep all players in alignment with the  nations priorities <br /><br />This is just a sampling of how API definitions are being used as a  driver for what is widely being called the API economy, which is the  heart of cloud, mobile, big data, Internet of Things (IoT), and almost  every other technical trend of the last ten years.  While API definitions provide the much needed machine readable  instructions for computers to understand what occurs at these vital API  touch-points, they also provide the much needed human readable  instructions, that people can use to interpret business agreements,  individual relationships, that are playing out across our increasingly  digital lives.t until a new format called  Swagger was born, that we started to see the conversation around how  we define, communicate and develop standardized tooling around APIs  evolve, providing an open specification for defining all the details  that go into an API.&amp;nbsp;<br />Swagger provided developers a way to describe an API that was more in  sync with everything else modern API developers were used to, including  using JSON, rather than the XML of previous web services, WSDL and  WADL. Swagger gave us something more than just  way to define APIs, it gave us swagger UI, which is a interactive  version of API documentation that made learning about what an API does,  and how to integrate with it, a hands on, interactive experience. This  new approach to documentation gave us a solution  to the number one problem plaguing API providers, which was out of date  documentation that confused consumers.<br />Shortly after Swagger began seeing wide adoption because of the  interactive documentation it provided for APIs, a new API definition  format also emerged called API Blueprint, which provided interactive  documentation, but rather than using JSON, it used Markdown,  making the process of defining APIs a little less intimidating for  non-developers. Apiary, the makers of API Blueprint did another thing  that would move the conversation forward again, making the reasons for  defining APIs in these formats, more about API design,  than just about delivering up-to-date documentation.<br /><br />Using API Blueprint, API designers could define an API, before any  code was actually written. Developers could craft an API using Apiarys  tooling, then a mock version of an API could be generated, which could  be shared with other project stakeholders, from  business users, to potential web or mobile developers. This process  saves considerable time, money, and other resources in ensuring than API  would be something web, mobile, and device developers could actually  put to use. With two new API definition formats  Swagger, and now API Blueprint, the processing of defining, designing  APIs in a machine readable way, was accessible to everyone, across a  rapidly expanding API life-cycle.<br />This evolution has all occurred over the last 4 years, a period which  has also produced other API definition formats like RSDL, RADL, RAML,  I/O Docs, and MSON--just to name a few. All of these API definition  formats are quickly becoming the preferred format  for not just defining, and designing APIs, as well as delivering  documentation. Another positive by-product has been that a new breed of  API service providers are also using it as the central definition for  quickly putting their services to work on any API,  for documentation, mocking and virtualizing APIs, generating server  code, producing software development kits (SDK), and setting up  essential testing and monitoring to keep APIs stable and reliable for  consumers--the API definition driven life-cycle continues  to expand.<br />In 15 years, like APIs, the API definition formats have moved out of  the real of the technical, and are providing vital business interactions  that ensure APIs meet critical internal, partner, and public needs.  They are also being applied to bring much needed  balance to the political side of API operations, from making sure APIs  are stable, and available, to defining pricing, rate limits, terms of  service, and even helping secure APIs that operate on the open Internet.<br />API definitions have become a machine readable contract that defines  the boundaries of a relationship between API provider, and its  consumers. Acting as a central truth, that is crafted by developers and  API architects to govern how an API operates, from  mocking to client integration, but in a way that is also setting the  technical, business, and legal expectations of consumers. This API  definition-driven contact is transcending the often proprietary, black  box algorithms that make an API function behind the  scenes, providing a portable, shareable, machine readable contract that  can be shared internally, and externally with partners or the general  public.<br />The importance of this new layer, and its role in the future of software development can be seen playing out in the  Oracle v Google API copyright case, where Oracle (using the courts)  has set the precedent that the naming, and ordering of your interface is  separate from the code, and falls under copyright protection. Beyond  the core legal case, the questions, and understanding  of exactly what is code has been even more interesting. Many API  architects do not see APIs as anything but code, having not seen impacts  of the modern API definition movement within their architecture yet.<br />API definitions aren&#39;t just about defining the URLs, parameters,  headers, and other aspects of API operations that developers need to  know, it is also bringing much needed clarity and awareness of value  generated by APIs among business users, and the end-users  of the applications that APIs are powering. API definitions provide a  common format in markdown, YAML, or JSON, that describe the technical  surface of an API, but then also take this technical specification, and  allow it to be applied across every stop along  the API life-cycle, from idea to deployment, to resulting integration  with web, mobile, and device applications.<br />As APIs make their way into almost every aspect of our business and  personal lives, driving our social relationships with family and  friends, meter our connections to our utility companies, connect us to  educational and healthcare opportunities, this touch-point  between platform, and the web, mobile, and device applications it  powers, is becoming increasingly critical. To businesses this layer  represents critical supply chains, but to each individual this touch  point is where all of our life bits flow--further emphasizing  the importance of, but also the sensitivity required in defining APIs  in a meaningful way, that makes sense to EVERYONE involved.<br />In 2001, a WSDL definition was very much about communicating what a  service did between platform and an the system that was integrated,  something that only involved IT, and developers. In 2015, a modern API  definition format provides the same benefits that  WSDL has historically delivered, but it is also addressing the  business, and political elements of how Internet enabled software works.  &amp;nbsp;A modern API definition provides:<br /><br />a medium for API designs, architects, and business stakeholders to  craft exactly the API that is needed, before any production code is  written. <br />a necessary set of instructions needed for a quality assurance (QA) team to make sure an API meets business requirements <br />a definition of sandbox, mocking, simulation, and virtualization environments that developers may need to be successful <br />what a developer needs to integrate with another system, or  build an application through interactive documentation, and even  complete Software Development Kits (SDK) <br />what the API testing, monitoring, and performance groups will need to ensure service level agreements are met or exceeded <br />the known surface area that security auditor will need to  properly secure the infrastructure web, mobile, devices, and ultimately  users will depend on <br />a map that government regulators can use to understand the  industry landscape, and help keep all players in alignment with the  nations priorities <br /><br />This is just a sampling of how API definitions are being used as a  driver for what is widely being called the API economy, which is the  heart of cloud, mobile, big data, Internet of Things (IoT), and almost  every other technical trend of the last ten years.  While API definitions provide the much needed machine readable  instructions for computers to understand what occurs at these vital API  touch-points, they also provide the much needed human readable  instructions, that people can use to interpret business agreements,  individual relationships, that are playing out across our increasingly  digital lives.s  tooling, then a mock version of an API could be generated, which could  be shared with other project stakeholders, from  business users, to potential web or mobile developers. This process  saves considerable time, money, and other resources in ensuring than API  would be something web, mobile, and device developers could actually  put to use. With two new API definition formats  Swagger, and now API Blueprint, the processing of defining, designing  APIs in a machine readable way, was accessible to everyone, across a  rapidly expanding API life-cycle.<br />This evolution has all occurred over the last 4 years, a period which  has also produced other API definition formats like RSDL, RADL, RAML,  I/O Docs, and MSON--just to name a few. All of these API definition  formats are quickly becoming the preferred format  for not just defining, and designing APIs, as well as delivering  documentation. Another positive by-product has been that a new breed of  API service providers are also using it as the central definition for  quickly putting their services to work on any API,  for documentation, mocking and virtualizing APIs, generating server  code, producing software development kits (SDK), and setting up  essential testing and monitoring to keep APIs stable and reliable for  consumers--the API definition driven life-cycle continues  to expand.<br />In 15 years, like APIs, the API definition formats have moved out of  the real of the technical, and are providing vital business interactions  that ensure APIs meet critical internal, partner, and public needs.  They are also being applied to bring much needed  balance to the political side of API operations, from making sure APIs  are stable, and available, to defining pricing, rate limits, terms of  service, and even helping secure APIs that operate on the open Internet.<br />API definitions have become a machine readable contract that defines  the boundaries of a relationship between API provider, and its  consumers. Acting as a central truth, that is crafted by developers and  API architects to govern how an API operates, from  mocking to client integration, but in a way that is also setting the  technical, business, and legal expectations of consumers. This API  definition-driven contact is transcending the often proprietary, black  box algorithms that make an API function behind the  scenes, providing a portable, shareable, machine readable contract that  can be shared internally, and externally with partners or the general  public.<br />The importance of this new layer, and its role in the future of software development can be seen playing out in the  Oracle v Google API copyright case, where Oracle (using the courts)  has set the precedent that the naming, and ordering of your interface is  separate from the code, and falls under copyright protection. Beyond  the core legal case, the questions, and understanding  of exactly what is code has been even more interesting. Many API  architects do not see APIs as anything but code, having not seen impacts  of the modern API definition movement within their architecture yet.<br />API definitions arent just about defining the URLs, parameters,  headers, and other aspects of API operations that developers need to  know, it is also bringing much needed clarity and awareness of value  generated by APIs among business users, and the end-users  of the applications that APIs are powering. API definitions provide a  common format in markdown, YAML, or JSON, that describe the technical  surface of an API, but then also take this technical specification, and  allow it to be applied across every stop along  the API life-cycle, from idea to deployment, to resulting integration  with web, mobile, and device applications.<br />As APIs make their way into almost every aspect of our business and  personal lives, driving our social relationships with family and  friends, meter our connections to our utility companies, connect us to  educational and healthcare opportunities, this touch-point  between platform, and the web, mobile, and device applications it  powers, is becoming increasingly critical. To businesses this layer  represents critical supply chains, but to each individual this touch  point is where all of our life bits flow--further emphasizing  the importance of, but also the sensitivity required in defining APIs  in a meaningful way, that makes sense to EVERYONE involved.<br />In 2001, a WSDL definition was very much about communicating what a  service did between platform and an the system that was integrated,  something that only involved IT, and developers. In 2015, a modern API  definition format provides the same benefits that  WSDL has historically delivered, but it is also addressing the  business, and political elements of how Internet enabled software works.  &amp;nbsp;A modern API definition provides:<br /><br />a medium for API designs, architects, and business stakeholders to  craft exactly the API that is needed, before any production code is  written. <br />a necessary set of instructions needed for a quality assurance (QA) team to make sure an API meets business requirements <br />a definition of sandbox, mocking, simulation, and virtualization environments that developers may need to be successful <br />what a developer needs to integrate with another system, or  build an application through interactive documentation, and even  complete Software Development Kits (SDK) <br />what the API testing, monitoring, and performance groups will need to ensure service level agreements are met or exceeded <br />the known surface area that security auditor will need to  properly secure the infrastructure web, mobile, devices, and ultimately  users will depend on <br />a map that government regulators can use to understand the  industry landscape, and help keep all players in alignment with the  nations priorities <br /><br />This is just a sampling of how API definitions are being used as a  driver for what is widely being called the API economy, which is the  heart of cloud, mobile, big data, Internet of Things (IoT), and almost  every other technical trend of the last ten years.  While API definitions provide the much needed machine readable  instructions for computers to understand what occurs at these vital API  touch-points, they also provide the much needed human readable  instructions, that people can use to interpret business agreements,  individual relationships, that are playing out across our increasingly  digital lives.t just about defining the URLs, parameters,  headers, and other aspects of API operations that developers need to  know, it is also bringing much needed clarity and awareness of value  generated by APIs among business users, and the end-users  of the applications that APIs are powering. API definitions provide a  common format in markdown, YAML, or JSON, that describe the technical  surface of an API, but then also take this technical specification, and  allow it to be applied across every stop along  the API life-cycle, from idea to deployment, to resulting integration  with web, mobile, and device applications.<br />As APIs make their way into almost every aspect of our business and  personal lives, driving our social relationships with family and  friends, meter our connections to our utility companies, connect us to  educational and healthcare opportunities, this touch-point  between platform, and the web, mobile, and device applications it  powers, is becoming increasingly critical. To businesses this layer  represents critical supply chains, but to each individual this touch  point is where all of our life bits flow--further emphasizing  the importance of, but also the sensitivity required in defining APIs  in a meaningful way, that makes sense to EVERYONE involved.<br />In 2001, a WSDL definition was very much about communicating what a  service did between platform and an the system that was integrated,  something that only involved IT, and developers. In 2015, a modern API  definition format provides the same benefits that  WSDL has historically delivered, but it is also addressing the  business, and political elements of how Internet enabled software works.  &amp;nbsp;A modern API definition provides:<br /><br />a medium for API designs, architects, and business stakeholders to  craft exactly the API that is needed, before any production code is  written. <br />a necessary set of instructions needed for a quality assurance (QA) team to make sure an API meets business requirements <br />a definition of sandbox, mocking, simulation, and virtualization environments that developers may need to be successful <br />what a developer needs to integrate with another system, or  build an application through interactive documentation, and even  complete Software Development Kits (SDK) <br />what the API testing, monitoring, and performance groups will need to ensure service level agreements are met or exceeded <br />the known surface area that security auditor will need to  properly secure the infrastructure web, mobile, devices, and ultimately  users will depend on <br />a map that government regulators can use to understand the  industry landscape, and help keep all players in alignment with the  nations priorities <br /><br />This is just a sampling of how API definitions are being used as a  driver for what is widely being called the API economy, which is the  heart of cloud, mobile, big data, Internet of Things (IoT), and almost  every other technical trend of the last ten years.  While API definitions provide the much needed machine readable  instructions for computers to understand what occurs at these vital API  touch-points, they also provide the much needed human readable  instructions, that people can use to interpret business agreements,  individual relationships, that are playing out across our increasingly  digital lives.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-business-dev-code.png"
  },
  {
  "title": "InfoWorld - API Definitions",
  "date": "07 Sep 2015",
  "body": "If you are in an industry being impacted by technology, you have probably become very aware of the term Application Programming Interfaces, more widely known as APIs, and how they are driving web applications, mobile applications, and increasingly everyday objects in our homes, cars, businesses, and across the public landscape. If you are finding yourself part of this growing conversations, you have most likely have also heard talk of a new breed of API definition formats that are becoming ubiquitous like Swagger and API Blueprint.<br />API definitions are a way to describe what an API does, providing a machine readable blueprint of how to put the digital resource to work. API definitions are not new, but this latest round of available formats are taking the API conversation out of just IT and developer groups, and enabling business units, and other key stakeholders to participate throughout the API life-cycle. Much like the latest wave of web APIs has made data, content, and other digital resources like video and images more accessible, API definitions are making APIs more accessible across the rapidly expanding digital business landscape.<br />The first widely available API definition format was the Web Services Description Language (WSDL), which is an XML format established in 2001 that described web services. Much like web services (an API predecessor), WSDL was a very technical vision of APIs, something dictated by IT, and developer groups, with heavy top down governance from business and industry leadership. While web services, and WSDL are still ubiquitous across the enterprise, they are rapidly being replaced with much lighter weight, simpler web APIs that use the Internet as a way of delivering the digital data, content, and resources web, mobile, and devices are demanding in 2015.<br />Along the way, newer, more web friendly API definition formats emerged, such as Web Application Description Language (WADL), but ultimately WADL was something that never took root, suffering from many of the same illness of its predecessor WSDL. It wasnt until a new format called Swagger was born, that we started to see the conversation around how we define, communicate and develop standardized tooling around APIs evolve, providing an open specification for defining all the details that go into an API.&amp;nbsp;<br />Swagger provided developers a way to describe an API that was more in sync with everything else modern API developers were used to, including using JSON, rather than the XML of previous web services, WSDL and WADL. Swagger gave us something more than just way to define APIs, it gave us swagger UI, which is a interactive version of API documentation that made learning about what an API does, and how to integrate with it, a hands on, interactive experience. This new approach to documentation gave us a solution to the number one problem plaguing API providers, which was out of date documentation that confused consumers.<br />Shortly after Swagger began seeing wide adoption because of the interactive documentation it provided for APIs, a new API definition format also emerged called API Blueprint, which provided interactive documentation, but rather than using JSON, it used Markdown, making the process of defining APIs a little less intimidating for non-developers. Apiary, the makers of API Blueprint did another thing that would move the conversation forward again, making the reasons for defining APIs in these formats, more about API design, than just about delivering up-to-date documentation.<br />Using API Blueprint, API designers could define an API, before any code was actually written. Developers could craft an API using Apiary&#39;s tooling, then a mock version of an API could be generated, which could be shared with other project stakeholders, from business users, to potential web or mobile developers. This process saves considerable time, money, and other resources in ensuring than API would be something web, mobile, and device developers could actually put to use. With two new API definition formats Swagger, and now API Blueprint, the processing of defining, designing APIs in a machine readable way, was accessible to everyone, across a rapidly expanding API life-cycle.<br />This evolution has all occurred over the last 4 years, a period which has also produced other API definition formats like RSDL, RADL, RAML, I/O Docs, and MSON--just to name a few. All of these API definition formats are quickly becoming the preferred format for not just defining, and designing APIs, as well as delivering documentation. Another positive by-product has been that a new breed of API service providers are also using it as the central definition for quickly putting their services to work on any API, for documentation, mocking and virtualizing APIs, generating server code, producing software development kits (SDK), and setting up essential testing and monitoring to keep APIs stable and reliable for consumers--the API definition driven life-cycle continues to expand.<br />In 15 years, like APIs, the API definition formats have moved out of the real of the technical, and are providing vital business interactions that ensure APIs meet critical internal, partner, and public needs. They are also being applied to bring much needed balance to the political side of API operations, from making sure APIs are stable, and available, to defining pricing, rate limits, terms of service, and even helping secure APIs that operate on the open Internet.<br />API definitions have become a machine readable contract that defines the boundaries of a relationship between API provider, and its consumers. Acting as a central truth, that is crafted by developers and API architects to govern how an API operates, from mocking to client integration, but in a way that is also setting the technical, business, and legal expectations of consumers. This API definition-driven contact is transcending the often proprietary, black box algorithms that make an API function behind the scenes, providing a portable, shareable, machine readable contract that can be shared internally, and externally with partners or the general public.<br />The importance of this new layer, and its role in the future of software development can be seen playing out in the Oracle v Google API copyright case, where Oracle (using the courts) has set the precedent that the naming, and ordering of your interface is separate from the code, and falls under copyright protection. Beyond the core legal case, the questions, and understanding of exactly what is code has been even more interesting. Many API architects do not see APIs as anything but code, having not seen impacts of the modern API definition movement within their architecture yet.<br />API definitions aren&#39;t just about defining the URLs, parameters, headers, and other aspects of API operations that developers need to know, it is also bringing much needed clarity and awareness of value generated by APIs among business users, and the end-users of the applications that APIs are powering. API definitions provide a common format in markdown, YAML, or JSON, that describe the technical surface of an API, but then also take this technical specification, and allow it to be applied across every stop along the API life-cycle, from idea to deployment, to resulting integration with web, mobile, and device applications.<br />As APIs make their way into almost every aspect of our business and personal lives, driving our social relationships with family and friends, meter our connections to our utility companies, connect us to educational and healthcare opportunities, this touch-point between platform, and the web, mobile, and device applications it powers, is becoming increasingly critical. To businesses this layer represents critical supply chains, but to each individual this touch point is where all of our life bits flow--further emphasizing the importance of, but also the sensitivity required in defining APIs in a meaningful way, that makes sense to EVERYONE involved.<br />In 2001, a WSDL definition was very much about communicating what a service did between platform and an the system that was integrated, something that only involved IT, and developers. In 2015, a modern API definition format provides the same benefits that WSDL has historically delivered, but it is also addressing the business, and political elements of how Internet enabled software works. &amp;nbsp;A modern API definition provides:<br /><br />a medium for API designs, architects, and business stakeholders to craft exactly the API that is needed, before any production code is written.<br />a necessary set of instructions needed for a quality assurance (QA) team to make sure an API meets business requirements<br />a definition of sandbox, mocking, simulation, and virtualization environments that developers may need to be successful<br />what a developer needs to integrate with another system, or build an application through interactive documentation, and even complete Software Development Kits (SDK)<br />what the API testing, monitoring, and performance groups will need to ensure service level agreements are met or exceeded<br />the known surface area that security auditor will need to properly secure the infrastructure web, mobile, devices, and ultimately users will depend on<br />a map that government regulators can use to understand the industry landscape, and help keep all players in alignment with the nations priorities<br /><br />This is just a sampling of how API definitions are being used as a driver for what is widely being called the API economy, which is the heart of cloud, mobile, big data, Internet of Things (IoT), and almost every other technical trend of the last ten years. While API definitions provide the much needed machine readable instructions for computers to understand what occurs at these vital API touch-points, they also provide the much needed human readable instructions, that people can use to interpret business agreements, individual relationships, that are playing out across our increasingly digital lives.t until a new format called Swagger was born, that we started to see the conversation around how we define, communicate and develop standardized tooling around APIs evolve, providing an open specification for defining all the details that go into an API.&amp;nbsp;<br />Swagger provided developers a way to describe an API that was more in sync with everything else modern API developers were used to, including using JSON, rather than the XML of previous web services, WSDL and WADL. Swagger gave us something more than just way to define APIs, it gave us swagger UI, which is a interactive version of API documentation that made learning about what an API does, and how to integrate with it, a hands on, interactive experience. This new approach to documentation gave us a solution to the number one problem plaguing API providers, which was out of date documentation that confused consumers.<br />Shortly after Swagger began seeing wide adoption because of the interactive documentation it provided for APIs, a new API definition format also emerged called API Blueprint, which provided interactive documentation, but rather than using JSON, it used Markdown, making the process of defining APIs a little less intimidating for non-developers. Apiary, the makers of API Blueprint did another thing that would move the conversation forward again, making the reasons for defining APIs in these formats, more about API design, than just about delivering up-to-date documentation.<br />Using API Blueprint, API designers could define an API, before any code was actually written. Developers could craft an API using Apiarys tooling, then a mock version of an API could be generated, which could be shared with other project stakeholders, from business users, to potential web or mobile developers. This process saves considerable time, money, and other resources in ensuring than API would be something web, mobile, and device developers could actually put to use. With two new API definition formats Swagger, and now API Blueprint, the processing of defining, designing APIs in a machine readable way, was accessible to everyone, across a rapidly expanding API life-cycle.<br />This evolution has all occurred over the last 4 years, a period which has also produced other API definition formats like RSDL, RADL, RAML, I/O Docs, and MSON--just to name a few. All of these API definition formats are quickly becoming the preferred format for not just defining, and designing APIs, as well as delivering documentation. Another positive by-product has been that a new breed of API service providers are also using it as the central definition for quickly putting their services to work on any API, for documentation, mocking and virtualizing APIs, generating server code, producing software development kits (SDK), and setting up essential testing and monitoring to keep APIs stable and reliable for consumers--the API definition driven life-cycle continues to expand.<br />In 15 years, like APIs, the API definition formats have moved out of the real of the technical, and are providing vital business interactions that ensure APIs meet critical internal, partner, and public needs. They are also being applied to bring much needed balance to the political side of API operations, from making sure APIs are stable, and available, to defining pricing, rate limits, terms of service, and even helping secure APIs that operate on the open Internet.<br />API definitions have become a machine readable contract that defines the boundaries of a relationship between API provider, and its consumers. Acting as a central truth, that is crafted by developers and API architects to govern how an API operates, from mocking to client integration, but in a way that is also setting the technical, business, and legal expectations of consumers. This API definition-driven contact is transcending the often proprietary, black box algorithms that make an API function behind the scenes, providing a portable, shareable, machine readable contract that can be shared internally, and externally with partners or the general public.<br />The importance of this new layer, and its role in the future of software development can be seen playing out in the Oracle v Google API copyright case, where Oracle (using the courts) has set the precedent that the naming, and ordering of your interface is separate from the code, and falls under copyright protection. Beyond the core legal case, the questions, and understanding of exactly what is code has been even more interesting. Many API architects do not see APIs as anything but code, having not seen impacts of the modern API definition movement within their architecture yet.<br />API definitions aren&#39;t just about defining the URLs, parameters, headers, and other aspects of API operations that developers need to know, it is also bringing much needed clarity and awareness of value generated by APIs among business users, and the end-users of the applications that APIs are powering. API definitions provide a common format in markdown, YAML, or JSON, that describe the technical surface of an API, but then also take this technical specification, and allow it to be applied across every stop along the API life-cycle, from idea to deployment, to resulting integration with web, mobile, and device applications.<br />As APIs make their way into almost every aspect of our business and personal lives, driving our social relationships with family and friends, meter our connections to our utility companies, connect us to educational and healthcare opportunities, this touch-point between platform, and the web, mobile, and device applications it powers, is becoming increasingly critical. To businesses this layer represents critical supply chains, but to each individual this touch point is where all of our life bits flow--further emphasizing the importance of, but also the sensitivity required in defining APIs in a meaningful way, that makes sense to EVERYONE involved.<br />In 2001, a WSDL definition was very much about communicating what a service did between platform and an the system that was integrated, something that only involved IT, and developers. In 2015, a modern API definition format provides the same benefits that WSDL has historically delivered, but it is also addressing the business, and political elements of how Internet enabled software works. &amp;nbsp;A modern API definition provides:<br /><br />a medium for API designs, architects, and business stakeholders to craft exactly the API that is needed, before any production code is written.<br />a necessary set of instructions needed for a quality assurance (QA) team to make sure an API meets business requirements<br />a definition of sandbox, mocking, simulation, and virtualization environments that developers may need to be successful<br />what a developer needs to integrate with another system, or build an application through interactive documentation, and even complete Software Development Kits (SDK)<br />what the API testing, monitoring, and performance groups will need to ensure service level agreements are met or exceeded<br />the known surface area that security auditor will need to properly secure the infrastructure web, mobile, devices, and ultimately users will depend on<br />a map that government regulators can use to understand the industry landscape, and help keep all players in alignment with the nations priorities<br /><br />This is just a sampling of how API definitions are being used as a driver for what is widely being called the API economy, which is the heart of cloud, mobile, big data, Internet of Things (IoT), and almost every other technical trend of the last ten years. While API definitions provide the much needed machine readable instructions for computers to understand what occurs at these vital API touch-points, they also provide the much needed human readable instructions, that people can use to interpret business agreements, individual relationships, that are playing out across our increasingly digital lives.s tooling, then a mock version of an API could be generated, which could be shared with other project stakeholders, from business users, to potential web or mobile developers. This process saves considerable time, money, and other resources in ensuring than API would be something web, mobile, and device developers could actually put to use. With two new API definition formats Swagger, and now API Blueprint, the processing of defining, designing APIs in a machine readable way, was accessible to everyone, across a rapidly expanding API life-cycle.<br />This evolution has all occurred over the last 4 years, a period which has also produced other API definition formats like RSDL, RADL, RAML, I/O Docs, and MSON--just to name a few. All of these API definition formats are quickly becoming the preferred format for not just defining, and designing APIs, as well as delivering documentation. Another positive by-product has been that a new breed of API service providers are also using it as the central definition for quickly putting their services to work on any API, for documentation, mocking and virtualizing APIs, generating server code, producing software development kits (SDK), and setting up essential testing and monitoring to keep APIs stable and reliable for consumers--the API definition driven life-cycle continues to expand.<br />In 15 years, like APIs, the API definition formats have moved out of the real of the technical, and are providing vital business interactions that ensure APIs meet critical internal, partner, and public needs. They are also being applied to bring much needed balance to the political side of API operations, from making sure APIs are stable, and available, to defining pricing, rate limits, terms of service, and even helping secure APIs that operate on the open Internet.<br />API definitions have become a machine readable contract that defines the boundaries of a relationship between API provider, and its consumers. Acting as a central truth, that is crafted by developers and API architects to govern how an API operates, from mocking to client integration, but in a way that is also setting the technical, business, and legal expectations of consumers. This API definition-driven contact is transcending the often proprietary, black box algorithms that make an API function behind the scenes, providing a portable, shareable, machine readable contract that can be shared internally, and externally with partners or the general public.<br />The importance of this new layer, and its role in the future of software development can be seen playing out in the Oracle v Google API copyright case, where Oracle (using the courts) has set the precedent that the naming, and ordering of your interface is separate from the code, and falls under copyright protection. Beyond the core legal case, the questions, and understanding of exactly what is code has been even more interesting. Many API architects do not see APIs as anything but code, having not seen impacts of the modern API definition movement within their architecture yet.<br />API definitions arent just about defining the URLs, parameters, headers, and other aspects of API operations that developers need to know, it is also bringing much needed clarity and awareness of value generated by APIs among business users, and the end-users of the applications that APIs are powering. API definitions provide a common format in markdown, YAML, or JSON, that describe the technical surface of an API, but then also take this technical specification, and allow it to be applied across every stop along the API life-cycle, from idea to deployment, to resulting integration with web, mobile, and device applications.<br />As APIs make their way into almost every aspect of our business and personal lives, driving our social relationships with family and friends, meter our connections to our utility companies, connect us to educational and healthcare opportunities, this touch-point between platform, and the web, mobile, and device applications it powers, is becoming increasingly critical. To businesses this layer represents critical supply chains, but to each individual this touch point is where all of our life bits flow--further emphasizing the importance of, but also the sensitivity required in defining APIs in a meaningful way, that makes sense to EVERYONE involved.<br />In 2001, a WSDL definition was very much about communicating what a service did between platform and an the system that was integrated, something that only involved IT, and developers. In 2015, a modern API definition format provides the same benefits that WSDL has historically delivered, but it is also addressing the business, and political elements of how Internet enabled software works. &amp;nbsp;A modern API definition provides:<br /><br />a medium for API designs, architects, and business stakeholders to craft exactly the API that is needed, before any production code is written.<br />a necessary set of instructions needed for a quality assurance (QA) team to make sure an API meets business requirements<br />a definition of sandbox, mocking, simulation, and virtualization environments that developers may need to be successful<br />what a developer needs to integrate with another system, or build an application through interactive documentation, and even complete Software Development Kits (SDK)<br />what the API testing, monitoring, and performance groups will need to ensure service level agreements are met or exceeded<br />the known surface area that security auditor will need to properly secure the infrastructure web, mobile, devices, and ultimately users will depend on<br />a map that government regulators can use to understand the industry landscape, and help keep all players in alignment with the nations priorities<br /><br />This is just a sampling of how API definitions are being used as a driver for what is widely being called the API economy, which is the heart of cloud, mobile, big data, Internet of Things (IoT), and almost every other technical trend of the last ten years. While API definitions provide the much needed machine readable instructions for computers to understand what occurs at these vital API touch-points, they also provide the much needed human readable instructions, that people can use to interpret business agreements, individual relationships, that are playing out across our increasingly digital lives.t just about defining the URLs, parameters, headers, and other aspects of API operations that developers need to know, it is also bringing much needed clarity and awareness of value generated by APIs among business users, and the end-users of the applications that APIs are powering. API definitions provide a common format in markdown, YAML, or JSON, that describe the technical surface of an API, but then also take this technical specification, and allow it to be applied across every stop along the API life-cycle, from idea to deployment, to resulting integration with web, mobile, and device applications.<br />As APIs make their way into almost every aspect of our business and personal lives, driving our social relationships with family and friends, meter our connections to our utility companies, connect us to educational and healthcare opportunities, this touch-point between platform, and the web, mobile, and device applications it powers, is becoming increasingly critical. To businesses this layer represents critical supply chains, but to each individual this touch point is where all of our life bits flow--further emphasizing the importance of, but also the sensitivity required in defining APIs in a meaningful way, that makes sense to EVERYONE involved.<br />In 2001, a WSDL definition was very much about communicating what a service did between platform and an the system that was integrated, something that only involved IT, and developers. In 2015, a modern API definition format provides the same benefits that WSDL has historically delivered, but it is also addressing the business, and political elements of how Internet enabled software works. &amp;nbsp;A modern API definition provides:<br /><br />a medium for API designs, architects, and business stakeholders to craft exactly the API that is needed, before any production code is written.<br />a necessary set of instructions needed for a quality assurance (QA) team to make sure an API meets business requirements<br />a definition of sandbox, mocking, simulation, and virtualization environments that developers may need to be successful<br />what a developer needs to integrate with another system, or build an application through interactive documentation, and even complete Software Development Kits (SDK)<br />what the API testing, monitoring, and performance groups will need to ensure service level agreements are met or exceeded<br />the known surface area that security auditor will need to properly secure the infrastructure web, mobile, devices, and ultimately users will depend on<br />a map that government regulators can use to understand the industry landscape, and help keep all players in alignment with the nations priorities<br /><br />This is just a sampling of how API definitions are being used as a driver for what is widely being called the API economy, which is the heart of cloud, mobile, big data, Internet of Things (IoT), and almost every other technical trend of the last ten years. While API definitions provide the much needed machine readable instructions for computers to understand what occurs at these vital API touch-points, they also provide the much needed human readable instructions, that people can use to interpret business agreements, individual relationships, that are playing out across our increasingly digital lives.",
  "url": "http://localhost:4000",
  "image": ""
  },
  {
  "title": "Please Do Not Hide Your API Definitions From Consumers",
  "date": "31 Aug 2015",
  "body": "<br />I am always pleased to see API providers publishing Swagger definitions, and using them to drive their interactive documentation. Projects like the&amp;nbsp;Global Change Information System API, are getting on the API definition bandwagon, and this is a good thing. I have been pushing API definition formats like Swagger and API Blueprint since 2012, but in 2015, while I want to keep on-boarding folks to the concept of using API definitions for interactive documentation, but I also want them to also understand that their APIs definition will be used in other areas of API operations as well.<br />Most people think Swagger is the documentation, and have not been able able to separate the specification from the interactive documentation. I think Apiary has done a better job of this separation with the separation of API Blueprint from Apiary. As an API provider, you may not have evolved to a full API-first level of operation, which is ok, but I encourage you to make your Swagger or API Blueprint definition as accessible as possible, so your API consumers can put to use in other ways--even if you dont have the time.<br />As soon as I saw that the&amp;nbsp;Global Change Information System API&amp;nbsp;employed Swagger for their documentation, the next thing I wanted to do was also use in my Postman client. While the Swagger UI provides me with a hands-on way of getting to know the GCIS API, I have to come back to the site to play with more, and it doesn&#39;t give me as much detail about how the API works, as my Postman client does. All GCIS API team has to do, is publish a text or image link to their Swagger definition in a prominent location, so it is obvious to us consumers.<br />I get easily reverse engineer the Swagger UI, using my Google Developer tools, but it is a couple of extra steps for me, that stands in between me, and making calls to the GCIS API in my local Postman Client. Interactive API documentation via Swagger and Apiary has significantly moved the API definition conversation forward, but just like we should be thinking beyond just language specific clients, we also need to be enabling our API consumers to speak the formats popular HTTP clients like Postman speak.t have the time.<br />As soon as I saw that the&amp;nbsp;Global Change Information System API&amp;nbsp;employed Swagger for their documentation, the next thing I wanted to do was also use in my Postman client. While the Swagger UI provides me with a hands-on way of getting to know the GCIS API, I have to come back to the site to play with more, and it doesnt give me as much detail about how the API works, as my Postman client does. All GCIS API team has to do, is publish a text or image link to their Swagger definition in a prominent location, so it is obvious to us consumers.<br />I get easily reverse engineer the Swagger UI, using my Google Developer tools, but it is a couple of extra steps for me, that stands in between me, and making calls to the GCIS API in my local Postman Client. Interactive API documentation via Swagger and Apiary has significantly moved the API definition conversation forward, but just like we should be thinking beyond just language specific clients, we also need to be enabling our API consumers to speak the formats popular HTTP clients like Postman speak.t give me as much detail about how the API works, as my Postman client does. All GCIS API team has to do, is publish a text or image link to their Swagger definition in a prominent location, so it is obvious to us consumers.<br />I get easily reverse engineer the Swagger UI, using my Google Developer tools, but it is a couple of extra steps for me, that stands in between me, and making calls to the GCIS API in my local Postman Client. Interactive API documentation via Swagger and Apiary has significantly moved the API definition conversation forward, but just like we should be thinking beyond just language specific clients, we also need to be enabling our API consumers to speak the formats popular HTTP clients like Postman speak.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-nose-disguise.png"
  },
  {
  "title": "The Swagger Definitions Collection Is The Cherry On Top Of Each API That I Profile",
  "date": "21 Jun 2015",
  "body": "<br />I create a lot of machine readable API definitions for the 1000 companies I monitor as part of my API Stack. I am using Swagger to define all of my APIs, providing me with a simple, yet powerful way to profile each of the APIs Im working to understand better. If you aren&#39;t familiar with Swagger, it provides a handful of fields you can use to fill out the metadata profile for APIs, like title, description, etc., but where it really gets powerful is when you put the paths collection to work, outline the details of each endpoint.<br />Most of the APIs I come across that are defined using Swagger, focuses on providing details on each path, including verbs, headers, parameters, and sometimes response status codes. When looking for the benefits of Swagger, many stop here. With basic metadata, and details about the paths, you can launch interactive documentation using Swagger UI--which is how about 80% of folks are using the API specification format.<br />When it comes to Swagger, my own motivations are all about API discovery, so when crafting Swagger files for the APIs I track on, I can easily call it quits after defining the basic meta information, and path details, but all of this ignores some of the exremely valuable aspect of using Swagger--with the definitions collection.<br />Using the Swagger definitions collection you can quantify the underlying data model across API operations, providing a machine readable profile of the XML and JSON that will be part of each API request and response. Once you have the underlying data model defined, including each parameter, description, and type, you can then link to each path and / or parameter, where the data model is being put to use as part of the request or response.&amp;nbsp;<br />Swagger definition collections are not a requirement for Swagger UI, or for API discovery currently, but if you want to generate high quality server side code, or client SDKs, you will need a complete set of definitions present. The problem is, this is a shitload of work, and as I face the Swagger definition for Twitter, I&#39;m looking at many hours of work if I want to ensure that Twitter&#39;s Swagger file has all of its underlying data model present, understanding why many people stop short of a complete Swagger spec.<br />In the end, the Swagger definition collections is really the cherry on top of each API I am profiling, highlighting the maturity of a particular API definition, demonstrating that you can do more with a machine readable definition, than just discovery, and documentation.m working to understand better. If you arent familiar with Swagger, it provides a handful of fields you can use to fill out the metadata profile for APIs, like title, description, etc., but where it really gets powerful is when you put the paths collection to work, outline the details of each endpoint.<br />Most of the APIs I come across that are defined using Swagger, focuses on providing details on each path, including verbs, headers, parameters, and sometimes response status codes. When looking for the benefits of Swagger, many stop here. With basic metadata, and details about the paths, you can launch interactive documentation using Swagger UI--which is how about 80% of folks are using the API specification format.<br />When it comes to Swagger, my own motivations are all about API discovery, so when crafting Swagger files for the APIs I track on, I can easily call it quits after defining the basic meta information, and path details, but all of this ignores some of the exremely valuable aspect of using Swagger--with the definitions collection.<br />Using the Swagger definitions collection you can quantify the underlying data model across API operations, providing a machine readable profile of the XML and JSON that will be part of each API request and response. Once you have the underlying data model defined, including each parameter, description, and type, you can then link to each path and / or parameter, where the data model is being put to use as part of the request or response.&amp;nbsp;<br />Swagger definition collections are not a requirement for Swagger UI, or for API discovery currently, but if you want to generate high quality server side code, or client SDKs, you will need a complete set of definitions present. The problem is, this is a shitload of work, and as I face the Swagger definition for Twitter, I&#39;m looking at many hours of work if I want to ensure that Twitter&#39;s Swagger file has all of its underlying data model present, understanding why many people stop short of a complete Swagger spec.<br />In the end, the Swagger definition collections is really the cherry on top of each API I am profiling, highlighting the maturity of a particular API definition, demonstrating that you can do more with a machine readable definition, than just discovery, and documentation.t familiar with Swagger, it provides a handful of fields you can use to fill out the metadata profile for APIs, like title, description, etc., but where it really gets powerful is when you put the paths collection to work, outline the details of each endpoint.<br />Most of the APIs I come across that are defined using Swagger, focuses on providing details on each path, including verbs, headers, parameters, and sometimes response status codes. When looking for the benefits of Swagger, many stop here. With basic metadata, and details about the paths, you can launch interactive documentation using Swagger UI--which is how about 80% of folks are using the API specification format.<br />When it comes to Swagger, my own motivations are all about API discovery, so when crafting Swagger files for the APIs I track on, I can easily call it quits after defining the basic meta information, and path details, but all of this ignores some of the exremely valuable aspect of using Swagger--with the definitions collection.<br />Using the Swagger definitions collection you can quantify the underlying data model across API operations, providing a machine readable profile of the XML and JSON that will be part of each API request and response. Once you have the underlying data model defined, including each parameter, description, and type, you can then link to each path and / or parameter, where the data model is being put to use as part of the request or response.&amp;nbsp;<br />Swagger definition collections are not a requirement for Swagger UI, or for API discovery currently, but if you want to generate high quality server side code, or client SDKs, you will need a complete set of definitions present. The problem is, this is a shitload of work, and as I face the Swagger definition for Twitter, Im looking at many hours of work if I want to ensure that Twitter&#39;s Swagger file has all of its underlying data model present, understanding why many people stop short of a complete Swagger spec.<br />In the end, the Swagger definition collections is really the cherry on top of each API I am profiling, highlighting the maturity of a particular API definition, demonstrating that you can do more with a machine readable definition, than just discovery, and documentation.m looking at many hours of work if I want to ensure that Twitters Swagger file has all of its underlying data model present, understanding why many people stop short of a complete Swagger spec.<br />In the end, the Swagger definition collections is really the cherry on top of each API I am profiling, highlighting the maturity of a particular API definition, demonstrating that you can do more with a machine readable definition, than just discovery, and documentation.s Swagger file has all of its underlying data model present, understanding why many people stop short of a complete Swagger spec.<br />In the end, the Swagger definition collections is really the cherry on top of each API I am profiling, highlighting the maturity of a particular API definition, demonstrating that you can do more with a machine readable definition, than just discovery, and documentation.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-cherry.png"
  },
  {
  "title": "Parsing Charles Proxy Exports To Generate Swagger Definitions, While Also Linking Them To Each Path",
  "date": "21 Jun 2015",
  "body": "<br />Making sure the Swagger files I craft possess a complete definition for its underlying data model, one that is linked to each API path, and parameters where it is put to use, is important to me, but damn it is a lot of work. As I mentioned in my last piece Im looking at the Twitter Swagger file, and my head starts spinning thinking about how much work it will be to hand-define all of the data models that used across the almost 100 Twitter endpoints.<br />I quickly got to work finding a better solution--I landed on Charles Proxy. I had downloaded and installed Charles Proxy to better understand how we could map out the dark layer of the API universe, that the popular mobile applications we use depend on. When running, Charles proxies all the requests and responses my desktop apps, and browsers make on my local Macbook. I can also route my iPhone and iPad through the proxy, when I want to also record my mobile app usage. This is perfect for helping me map out the public APIs in my API Stack work!<br />When the Charles Proxy is running, it saves an XML summary export to my local Dropbox folder, which then gets synced to the cloud via the Dropbox API. I am now working on a script that will keep an eye on my Dropbox folder, and process any new Charles export files it finds. As I process each file, I&#39;m cherry picking from the domains of specific companies that I&#39;m tracking on, pulling out the request and response information I need to craft a Swagger definition.&amp;nbsp;<br />To generate the traffic I need, I just load up any API I&#39;m looking to profile in Postman, and started working my way through the list of endpoints, until I&#39;ve covered the entire surface area of any API. I find it is easy to generate a beginning Swagger definition, which includes the host, base uRL, endpoints, and parameters, then load it into Postman, and let Charles proxy complete the rest of the Swagger definition collection, and link each one to any path or parameter it is referenced by. I will be running checks on request details, to make sure I haven&#39;t forgotten about any endpoints, and parameters, but my goal is primarily around polishing the definition collection, with an endpoint linkage.<br />I will not rely on these Swagger definitions generated from the Charles proxy. I will be queuing them up in a Github repo(s), and syncing them existing, often hand-crafted Swagger definitions I&#39;m already evolving. Hopefully this process will help me automate the profiling of popular public APIs, and enable me to crank through more APIs this summer, as part of my API Stack research.<br />All of this is working out well. My need to automate the defining of underlying data models, reminded me of the dark API work I was already doing with Charles Proxy--something I will spend more time on this summer. I am looking to generate a Swagger definition for each of the desktop apps I use on my MacBook, and the mobile apps I use on my iDevices--stay tuned!m looking at the Twitter Swagger file, and my head starts spinning thinking about how much work it will be to hand-define all of the data models that used across the almost 100 Twitter endpoints.<br />I quickly got to work finding a better solution--I landed on Charles Proxy. I had downloaded and installed Charles Proxy to better understand how we could map out the dark layer of the API universe, that the popular mobile applications we use depend on. When running, Charles proxies all the requests and responses my desktop apps, and browsers make on my local Macbook. I can also route my iPhone and iPad through the proxy, when I want to also record my mobile app usage. This is perfect for helping me map out the public APIs in my API Stack work!<br />When the Charles Proxy is running, it saves an XML summary export to my local Dropbox folder, which then gets synced to the cloud via the Dropbox API. I am now working on a script that will keep an eye on my Dropbox folder, and process any new Charles export files it finds. As I process each file, Im cherry picking from the domains of specific companies that I&#39;m tracking on, pulling out the request and response information I need to craft a Swagger definition.&amp;nbsp;<br />To generate the traffic I need, I just load up any API I&#39;m looking to profile in Postman, and started working my way through the list of endpoints, until I&#39;ve covered the entire surface area of any API. I find it is easy to generate a beginning Swagger definition, which includes the host, base uRL, endpoints, and parameters, then load it into Postman, and let Charles proxy complete the rest of the Swagger definition collection, and link each one to any path or parameter it is referenced by. I will be running checks on request details, to make sure I haven&#39;t forgotten about any endpoints, and parameters, but my goal is primarily around polishing the definition collection, with an endpoint linkage.<br />I will not rely on these Swagger definitions generated from the Charles proxy. I will be queuing them up in a Github repo(s), and syncing them existing, often hand-crafted Swagger definitions I&#39;m already evolving. Hopefully this process will help me automate the profiling of popular public APIs, and enable me to crank through more APIs this summer, as part of my API Stack research.<br />All of this is working out well. My need to automate the defining of underlying data models, reminded me of the dark API work I was already doing with Charles Proxy--something I will spend more time on this summer. I am looking to generate a Swagger definition for each of the desktop apps I use on my MacBook, and the mobile apps I use on my iDevices--stay tuned!m cherry picking from the domains of specific companies that Im tracking on, pulling out the request and response information I need to craft a Swagger definition.&amp;nbsp;<br />To generate the traffic I need, I just load up any API I&#39;m looking to profile in Postman, and started working my way through the list of endpoints, until I&#39;ve covered the entire surface area of any API. I find it is easy to generate a beginning Swagger definition, which includes the host, base uRL, endpoints, and parameters, then load it into Postman, and let Charles proxy complete the rest of the Swagger definition collection, and link each one to any path or parameter it is referenced by. I will be running checks on request details, to make sure I haven&#39;t forgotten about any endpoints, and parameters, but my goal is primarily around polishing the definition collection, with an endpoint linkage.<br />I will not rely on these Swagger definitions generated from the Charles proxy. I will be queuing them up in a Github repo(s), and syncing them existing, often hand-crafted Swagger definitions I&#39;m already evolving. Hopefully this process will help me automate the profiling of popular public APIs, and enable me to crank through more APIs this summer, as part of my API Stack research.<br />All of this is working out well. My need to automate the defining of underlying data models, reminded me of the dark API work I was already doing with Charles Proxy--something I will spend more time on this summer. I am looking to generate a Swagger definition for each of the desktop apps I use on my MacBook, and the mobile apps I use on my iDevices--stay tuned!m tracking on, pulling out the request and response information I need to craft a Swagger definition.&amp;nbsp;<br />To generate the traffic I need, I just load up any API Im looking to profile in Postman, and started working my way through the list of endpoints, until I&#39;ve covered the entire surface area of any API. I find it is easy to generate a beginning Swagger definition, which includes the host, base uRL, endpoints, and parameters, then load it into Postman, and let Charles proxy complete the rest of the Swagger definition collection, and link each one to any path or parameter it is referenced by. I will be running checks on request details, to make sure I haven&#39;t forgotten about any endpoints, and parameters, but my goal is primarily around polishing the definition collection, with an endpoint linkage.<br />I will not rely on these Swagger definitions generated from the Charles proxy. I will be queuing them up in a Github repo(s), and syncing them existing, often hand-crafted Swagger definitions I&#39;m already evolving. Hopefully this process will help me automate the profiling of popular public APIs, and enable me to crank through more APIs this summer, as part of my API Stack research.<br />All of this is working out well. My need to automate the defining of underlying data models, reminded me of the dark API work I was already doing with Charles Proxy--something I will spend more time on this summer. I am looking to generate a Swagger definition for each of the desktop apps I use on my MacBook, and the mobile apps I use on my iDevices--stay tuned!m looking to profile in Postman, and started working my way through the list of endpoints, until Ive covered the entire surface area of any API. I find it is easy to generate a beginning Swagger definition, which includes the host, base uRL, endpoints, and parameters, then load it into Postman, and let Charles proxy complete the rest of the Swagger definition collection, and link each one to any path or parameter it is referenced by. I will be running checks on request details, to make sure I haven&#39;t forgotten about any endpoints, and parameters, but my goal is primarily around polishing the definition collection, with an endpoint linkage.<br />I will not rely on these Swagger definitions generated from the Charles proxy. I will be queuing them up in a Github repo(s), and syncing them existing, often hand-crafted Swagger definitions I&#39;m already evolving. Hopefully this process will help me automate the profiling of popular public APIs, and enable me to crank through more APIs this summer, as part of my API Stack research.<br />All of this is working out well. My need to automate the defining of underlying data models, reminded me of the dark API work I was already doing with Charles Proxy--something I will spend more time on this summer. I am looking to generate a Swagger definition for each of the desktop apps I use on my MacBook, and the mobile apps I use on my iDevices--stay tuned!ve covered the entire surface area of any API. I find it is easy to generate a beginning Swagger definition, which includes the host, base uRL, endpoints, and parameters, then load it into Postman, and let Charles proxy complete the rest of the Swagger definition collection, and link each one to any path or parameter it is referenced by. I will be running checks on request details, to make sure I havent forgotten about any endpoints, and parameters, but my goal is primarily around polishing the definition collection, with an endpoint linkage.<br />I will not rely on these Swagger definitions generated from the Charles proxy. I will be queuing them up in a Github repo(s), and syncing them existing, often hand-crafted Swagger definitions I&#39;m already evolving. Hopefully this process will help me automate the profiling of popular public APIs, and enable me to crank through more APIs this summer, as part of my API Stack research.<br />All of this is working out well. My need to automate the defining of underlying data models, reminded me of the dark API work I was already doing with Charles Proxy--something I will spend more time on this summer. I am looking to generate a Swagger definition for each of the desktop apps I use on my MacBook, and the mobile apps I use on my iDevices--stay tuned!t forgotten about any endpoints, and parameters, but my goal is primarily around polishing the definition collection, with an endpoint linkage.<br />I will not rely on these Swagger definitions generated from the Charles proxy. I will be queuing them up in a Github repo(s), and syncing them existing, often hand-crafted Swagger definitions Im already evolving. Hopefully this process will help me automate the profiling of popular public APIs, and enable me to crank through more APIs this summer, as part of my API Stack research.<br />All of this is working out well. My need to automate the defining of underlying data models, reminded me of the dark API work I was already doing with Charles Proxy--something I will spend more time on this summer. I am looking to generate a Swagger definition for each of the desktop apps I use on my MacBook, and the mobile apps I use on my iDevices--stay tuned!m already evolving. Hopefully this process will help me automate the profiling of popular public APIs, and enable me to crank through more APIs this summer, as part of my API Stack research.<br />All of this is working out well. My need to automate the defining of underlying data models, reminded me of the dark API work I was already doing with Charles Proxy--something I will spend more time on this summer. I am looking to generate a Swagger definition for each of the desktop apps I use on my MacBook, and the mobile apps I use on my iDevices--stay tuned!",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/blog/charles-proxy-to-swagger.png"
  },
  {
  "title": "Using API Definitions To Help API Providers With Their API Design Roadmap",
  "date": "10 Jun 2015",
  "body": "<br />As I work to create Swagger API definitions for the almost 1000 companies in my API stack, Im chasing an elusive definition of a complete Swagger definition for any API. Only a small portion of APIs I am defining using Swagger will reach an 80-90% completions status, in reality most will never be complete for reasons that are totally out of my control.<br />When it comes to crafting API definitions for public APIs, I may be able to get the API definition complete in the sense that it has all the paths, parameters, responses, definitions, and security configurations, but if the API itself is missing pieces--the API definition will always be incomplete (in perpetuity).<br />As I work to automate the questions I ask of Swagger definitions, helping me get to a more coherent definition of what is a complete Swagger definition, I can&#39;t help feel the need to offer API design tips to the API providers I am profiling. Honestly I have never considered myself a high quality API designer, I&#39;ve been more business than tech, but I can&#39;t help pointing out the obvious stuff.&amp;nbsp;<br />I am still using my API definition tooling for my own goals around defining the API Stack, but because I&#39;m building it all as APIs, I intend to open it up to others for analyzing their own API definitions, determining how complete they are, and potentially offering up tips on what could be done to improve them. A kind of self-service, API design tip API, that helps with some of the most common elements that are missing from API designs.<br />In 2015, API definitions are opening up a buffet of services that are courting API providers ranging from mocking and deployment, to monitoring and security. I don&#39;t see why API definitions couldn&#39;t also allow for professional API designers to help API providers evolve their APIs in a more constructive ways, from the outside-in. Using Swagger or API Blueprint, professional designers could easily provide suggestions for existing API providers and their designs, then give them potential suggestions that they could use in their API design road-map.<br />Anyhoo, food for thought!m chasing an elusive definition of a complete Swagger definition for any API. Only a small portion of APIs I am defining using Swagger will reach an 80-90% completions status, in reality most will never be complete for reasons that are totally out of my control.<br />When it comes to crafting API definitions for public APIs, I may be able to get the API definition complete in the sense that it has all the paths, parameters, responses, definitions, and security configurations, but if the API itself is missing pieces--the API definition will always be incomplete (in perpetuity).<br />As I work to automate the questions I ask of Swagger definitions, helping me get to a more coherent definition of what is a complete Swagger definition, I cant help feel the need to offer API design tips to the API providers I am profiling. Honestly I have never considered myself a high quality API designer, I&#39;ve been more business than tech, but I can&#39;t help pointing out the obvious stuff.&amp;nbsp;<br />I am still using my API definition tooling for my own goals around defining the API Stack, but because I&#39;m building it all as APIs, I intend to open it up to others for analyzing their own API definitions, determining how complete they are, and potentially offering up tips on what could be done to improve them. A kind of self-service, API design tip API, that helps with some of the most common elements that are missing from API designs.<br />In 2015, API definitions are opening up a buffet of services that are courting API providers ranging from mocking and deployment, to monitoring and security. I don&#39;t see why API definitions couldn&#39;t also allow for professional API designers to help API providers evolve their APIs in a more constructive ways, from the outside-in. Using Swagger or API Blueprint, professional designers could easily provide suggestions for existing API providers and their designs, then give them potential suggestions that they could use in their API design road-map.<br />Anyhoo, food for thought!t help feel the need to offer API design tips to the API providers I am profiling. Honestly I have never considered myself a high quality API designer, Ive been more business than tech, but I can&#39;t help pointing out the obvious stuff.&amp;nbsp;<br />I am still using my API definition tooling for my own goals around defining the API Stack, but because I&#39;m building it all as APIs, I intend to open it up to others for analyzing their own API definitions, determining how complete they are, and potentially offering up tips on what could be done to improve them. A kind of self-service, API design tip API, that helps with some of the most common elements that are missing from API designs.<br />In 2015, API definitions are opening up a buffet of services that are courting API providers ranging from mocking and deployment, to monitoring and security. I don&#39;t see why API definitions couldn&#39;t also allow for professional API designers to help API providers evolve their APIs in a more constructive ways, from the outside-in. Using Swagger or API Blueprint, professional designers could easily provide suggestions for existing API providers and their designs, then give them potential suggestions that they could use in their API design road-map.<br />Anyhoo, food for thought!ve been more business than tech, but I cant help pointing out the obvious stuff.&amp;nbsp;<br />I am still using my API definition tooling for my own goals around defining the API Stack, but because I&#39;m building it all as APIs, I intend to open it up to others for analyzing their own API definitions, determining how complete they are, and potentially offering up tips on what could be done to improve them. A kind of self-service, API design tip API, that helps with some of the most common elements that are missing from API designs.<br />In 2015, API definitions are opening up a buffet of services that are courting API providers ranging from mocking and deployment, to monitoring and security. I don&#39;t see why API definitions couldn&#39;t also allow for professional API designers to help API providers evolve their APIs in a more constructive ways, from the outside-in. Using Swagger or API Blueprint, professional designers could easily provide suggestions for existing API providers and their designs, then give them potential suggestions that they could use in their API design road-map.<br />Anyhoo, food for thought!t help pointing out the obvious stuff.&amp;nbsp;<br />I am still using my API definition tooling for my own goals around defining the API Stack, but because Im building it all as APIs, I intend to open it up to others for analyzing their own API definitions, determining how complete they are, and potentially offering up tips on what could be done to improve them. A kind of self-service, API design tip API, that helps with some of the most common elements that are missing from API designs.<br />In 2015, API definitions are opening up a buffet of services that are courting API providers ranging from mocking and deployment, to monitoring and security. I don&#39;t see why API definitions couldn&#39;t also allow for professional API designers to help API providers evolve their APIs in a more constructive ways, from the outside-in. Using Swagger or API Blueprint, professional designers could easily provide suggestions for existing API providers and their designs, then give them potential suggestions that they could use in their API design road-map.<br />Anyhoo, food for thought!m building it all as APIs, I intend to open it up to others for analyzing their own API definitions, determining how complete they are, and potentially offering up tips on what could be done to improve them. A kind of self-service, API design tip API, that helps with some of the most common elements that are missing from API designs.<br />In 2015, API definitions are opening up a buffet of services that are courting API providers ranging from mocking and deployment, to monitoring and security. I dont see why API definitions couldn&#39;t also allow for professional API designers to help API providers evolve their APIs in a more constructive ways, from the outside-in. Using Swagger or API Blueprint, professional designers could easily provide suggestions for existing API providers and their designs, then give them potential suggestions that they could use in their API design road-map.<br />Anyhoo, food for thought!t see why API definitions couldnt also allow for professional API designers to help API providers evolve their APIs in a more constructive ways, from the outside-in. Using Swagger or API Blueprint, professional designers could easily provide suggestions for existing API providers and their designs, then give them potential suggestions that they could use in their API design road-map.<br />Anyhoo, food for thought!t also allow for professional API designers to help API providers evolve their APIs in a more constructive ways, from the outside-in. Using Swagger or API Blueprint, professional designers could easily provide suggestions for existing API providers and their designs, then give them potential suggestions that they could use in their API design road-map.<br />Anyhoo, food for thought!",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-journey.png"
  },
  {
  "title": "Join @apimatic, @blockspring, and @apievangelist In Completing API Definitions For 1000 Companies In The API Stack",
  "date": "05 Jun 2015",
  "body": "<br />3Scale and I have been working hard to craft APIs.json files for the top public APIs out there, including machine readable Swagger definitions, ever since we launched the open source API search engine APIs.io. We will keep working to define, and index the API space, but it is a lot of work ahead, and we could use some help.<br />Over the last couple months Ive had several conversations with folks about the need for Swagger and API Blueprints for popular APIs, so that the community can build valuable tooling and services on top of commonly used APIs. Two companies who I&#39;ve been talking to are&amp;nbsp;SDK generation service APIMATIC, and API spreadsheet integration provider BlockSpring.<br />APIMATC wants see better quality Swagger definitions emerge, so they can build client SDKs that work, and make available via SKDs.io. BlockSpring wants to be able to integrate popular API content, data, and functionality into Google Spreadsheets, using their slick plugin. These are just two examples of services that are emerging to deliver much needed functionality on top of APIs -- if we can establish a rich, open, machine readable repository of API definitions, it will open up the flood gates for even more API tooling and services. #win<br />I&#39;ve added some new information to the API Stack to support this effort. So far I have&amp;nbsp;917 companies, in 223 areas, with 882 APIs cataloged, and 407 Swagger definitions. I want all 917 companies to have all their APIs fully defined using APIs.json, Swagger, and API Blueprint by the end of the summer, as well as any important companies that are not listed. It is a lofty goal, but I think with some help, we can do it.<br />As a working group, we have several challenges, that we are hoping to work out in real-time via the API Stack Github repository. First we have to actually do the heavy lifting of generating APIs.json, Swagger, and API Blueprints, but we also have to also define a process for what is considered a complete API definition--I&#39;ll be working through these thoughts separately.<br />Now that I am done traveling, I will be dedicating a considerable amount of time to this work in June. If you want to get involved, please participate via the API Stack site and Github repository, or feel free to ping me directly. We need all the help we can get, and are looking to have a robust repository of high quality API definitions for 1000+ of the top APIs available today.ve had several conversations with folks about the need for Swagger and API Blueprints for popular APIs, so that the community can build valuable tooling and services on top of commonly used APIs. Two companies who Ive been talking to are&amp;nbsp;SDK generation service APIMATIC, and API spreadsheet integration provider BlockSpring.<br />APIMATC wants see better quality Swagger definitions emerge, so they can build client SDKs that work, and make available via SKDs.io. BlockSpring wants to be able to integrate popular API content, data, and functionality into Google Spreadsheets, using their slick plugin. These are just two examples of services that are emerging to deliver much needed functionality on top of APIs -- if we can establish a rich, open, machine readable repository of API definitions, it will open up the flood gates for even more API tooling and services. #win<br />I&#39;ve added some new information to the API Stack to support this effort. So far I have&amp;nbsp;917 companies, in 223 areas, with 882 APIs cataloged, and 407 Swagger definitions. I want all 917 companies to have all their APIs fully defined using APIs.json, Swagger, and API Blueprint by the end of the summer, as well as any important companies that are not listed. It is a lofty goal, but I think with some help, we can do it.<br />As a working group, we have several challenges, that we are hoping to work out in real-time via the API Stack Github repository. First we have to actually do the heavy lifting of generating APIs.json, Swagger, and API Blueprints, but we also have to also define a process for what is considered a complete API definition--I&#39;ll be working through these thoughts separately.<br />Now that I am done traveling, I will be dedicating a considerable amount of time to this work in June. If you want to get involved, please participate via the API Stack site and Github repository, or feel free to ping me directly. We need all the help we can get, and are looking to have a robust repository of high quality API definitions for 1000+ of the top APIs available today.ve been talking to are&amp;nbsp;SDK generation service APIMATIC, and API spreadsheet integration provider BlockSpring.<br />APIMATC wants see better quality Swagger definitions emerge, so they can build client SDKs that work, and make available via SKDs.io. BlockSpring wants to be able to integrate popular API content, data, and functionality into Google Spreadsheets, using their slick plugin. These are just two examples of services that are emerging to deliver much needed functionality on top of APIs -- if we can establish a rich, open, machine readable repository of API definitions, it will open up the flood gates for even more API tooling and services. #win<br />Ive added some new information to the API Stack to support this effort. So far I have&amp;nbsp;917 companies, in 223 areas, with 882 APIs cataloged, and 407 Swagger definitions. I want all 917 companies to have all their APIs fully defined using APIs.json, Swagger, and API Blueprint by the end of the summer, as well as any important companies that are not listed. It is a lofty goal, but I think with some help, we can do it.<br />As a working group, we have several challenges, that we are hoping to work out in real-time via the API Stack Github repository. First we have to actually do the heavy lifting of generating APIs.json, Swagger, and API Blueprints, but we also have to also define a process for what is considered a complete API definition--I&#39;ll be working through these thoughts separately.<br />Now that I am done traveling, I will be dedicating a considerable amount of time to this work in June. If you want to get involved, please participate via the API Stack site and Github repository, or feel free to ping me directly. We need all the help we can get, and are looking to have a robust repository of high quality API definitions for 1000+ of the top APIs available today.ve added some new information to the API Stack to support this effort. So far I have&amp;nbsp;917 companies, in 223 areas, with 882 APIs cataloged, and 407 Swagger definitions. I want all 917 companies to have all their APIs fully defined using APIs.json, Swagger, and API Blueprint by the end of the summer, as well as any important companies that are not listed. It is a lofty goal, but I think with some help, we can do it.<br />As a working group, we have several challenges, that we are hoping to work out in real-time via the API Stack Github repository. First we have to actually do the heavy lifting of generating APIs.json, Swagger, and API Blueprints, but we also have to also define a process for what is considered a complete API definition--Ill be working through these thoughts separately.<br />Now that I am done traveling, I will be dedicating a considerable amount of time to this work in June. If you want to get involved, please participate via the API Stack site and Github repository, or feel free to ping me directly. We need all the help we can get, and are looking to have a robust repository of high quality API definitions for 1000+ of the top APIs available today.ll be working through these thoughts separately.<br />Now that I am done traveling, I will be dedicating a considerable amount of time to this work in June. If you want to get involved, please participate via the API Stack site and Github repository, or feel free to ping me directly. We need all the help we can get, and are looking to have a robust repository of high quality API definitions for 1000+ of the top APIs available today.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/api-stack/api-stack-logo.png"
  },
  {
  "title": "Using Machine Readable API Definitions To Solve A Persistent Question: Are There Any Write APIs In Federal Government?",
  "date": "02 Mar 2015",
  "body": "<br />A topic Ive written about before, and one that I answer regularly on forums, via email, and on Twitter is, &amp;ldquo;Are there any write APIs in the federal government?&amp;rdquo; It is a valid question, and as I said in my strategy suggestions for the federal government, write APIs are a critical aspect of all of this moving forward in a healthy way.<br />Rebecca Williams (@internetrebecca) pointed me to a recent discussion on this topic earlier today, to which I added a couple of suggestions, but ultimately it is something I would like to see a more progressive solution emerge, something that can answer it real-time, and change as the API inventory in the federal government changes and evolves. Keeping a list, like 18F is doing, is a start, but we need more.<br />One of the side projects that I work on a couple of hours each week, is the profiling of federal government APIs using APIs.json, and Swagger, for use in my federal API stack. I only have a handful of the 120+ APIs that I&amp;rsquo;m profiling completed, but once done, you will be able to search for APIs based upon whether or not an API uses the verbs GET, POST, PUT, and DELETE&amp;mdash;giving you a much more detailed picture of how government APIs function.<br />Generating machine readable API definitions in Swagger and API Blueprint are time consuming, but once you tie it together using a discovery format like APIs.json, it opens up a lot more opportunity to answer questions about government APIs. I&amp;rsquo;m doing a lot of the heavy lifting currently, to establish a critical mass of API definitions in federal government, then I am hoping that each agency will take ownership over maintaining their own definitions--if not, I think it can just as easily be done from the outside-in, by the community.<br />I&amp;rsquo;m excited for the potential, when all of the meta-layer of APIs and open data in government is rich, well defined, and machine readable by default. The continuing data.json work out of the government, and our own APIs.json format is looking to help with this over time. There is a lot of work ahead, as well as education to occur, before the meta data layer for government APIs is machine readable by default, but once it is, we&amp;rsquo;ll be able to answer questions like this in a much more efficient way.ve written about before, and one that I answer regularly on forums, via email, and on Twitter is, &amp;ldquo;Are there any write APIs in the federal government?&amp;rdquo; It is a valid question, and as I said in my strategy suggestions for the federal government, write APIs are a critical aspect of all of this moving forward in a healthy way.<br />Rebecca Williams (@internetrebecca) pointed me to a recent discussion on this topic earlier today, to which I added a couple of suggestions, but ultimately it is something I would like to see a more progressive solution emerge, something that can answer it real-time, and change as the API inventory in the federal government changes and evolves. Keeping a list, like 18F is doing, is a start, but we need more.<br />One of the side projects that I work on a couple of hours each week, is the profiling of federal government APIs using APIs.json, and Swagger, for use in my federal API stack. I only have a handful of the 120+ APIs that I&amp;rsquo;m profiling completed, but once done, you will be able to search for APIs based upon whether or not an API uses the verbs GET, POST, PUT, and DELETE&amp;mdash;giving you a much more detailed picture of how government APIs function.<br />Generating machine readable API definitions in Swagger and API Blueprint are time consuming, but once you tie it together using a discovery format like APIs.json, it opens up a lot more opportunity to answer questions about government APIs. I&amp;rsquo;m doing a lot of the heavy lifting currently, to establish a critical mass of API definitions in federal government, then I am hoping that each agency will take ownership over maintaining their own definitions--if not, I think it can just as easily be done from the outside-in, by the community.<br />I&amp;rsquo;m excited for the potential, when all of the meta-layer of APIs and open data in government is rich, well defined, and machine readable by default. The continuing data.json work out of the government, and our own APIs.json format is looking to help with this over time. There is a lot of work ahead, as well as education to occur, before the meta data layer for government APIs is machine readable by default, but once it is, we&amp;rsquo;ll be able to answer questions like this in a much more efficient way.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-question-mark.png"
  },
  {
  "title": "Generating Client Side Code From Machine Readable API Definitions",
  "date": "26 Feb 2015",
  "body": "<br />This post has been open for almost two weeks now in Evernote. It began as a simple story about the possibility for generating code samples and libraries using Swagger. The longer it stays open, the wider the definition becomes, so I have to post something, just to draw a line in the sand. I&amp;rsquo;m not talking about generating code that runs on the server, this post is all about everything on the API consumption side of things.<br />Shortly after Wordnik launched the machine readable API definition format&amp;nbsp;Swagger, they launched a library for generating client side code samples in a variety of languages. This was something that was evolved upon by Apiary, with the launch of their API design platform, and introduction of API Blueprint. Even with these advances forward, there were still many shortcomings, and debate around what you could actually auto-generate on the client-side using a machine readable API definition continued. I can&amp;rsquo;t tell you how many random Tweets I get from people saying, &amp;ldquo;Oh is auto-generation of code cool again?&amp;rdquo; or &amp;ldquo;I thought you couldn&amp;rsquo;t auto-generate client code or SDKs ;-)<br />Amidst the debate about what is really possible, and the jokes about our SOA past, new players have emerged like Apimatic that are looking to raise the bar when it comes to generation of not just simple code samples, libraries or stubs, but sophisticated API SDKs. I am sure the jokes about automating client code will still occurs, but there is no denying that the overall conversation is moving forward.<br />As I&amp;rsquo;m exploring my own limitations of what is possible when generating client-side code with Swagger, I also come across new players like Lucybot, who are moving the conversation forward with API cookbooks, and Single Page App (SPA) generated from Swagger definitions. I&amp;rsquo;m not in denial that there is a lot of work ahead, but in the two weeks that I&amp;rsquo;ve been crafting this post, I&amp;rsquo;d say I have gotten a glimpse of what is next. When you bundle the latest movements in virtualization and containerization, and using API definitions like Swagger and API Blueprint to auto-generate client side code, I feel like the current potential is unlimited, and things are just heating up.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-gears.png"
  },
  {
  "title": "Static HTML Documentation Generated From Machine Readable API Blueprint Definitions Using Aglio",
  "date": "03 Feb 2015",
  "body": "<br />Im on the hunt for new ways to deploy attractive, interactive API documentation, from machine readable API definition formats like Swagger and API Blueprint. I am advocating for the development of new approaches to deploy UI documentation, and part of this showcasing what I find along the way.<br />In the spotlight today is Aglio, which they describe as:<br />An API Blueprint renderer that supports multiple themes and outputs static HTML that can be served by any web host. API Blueprint is a Markdown-based document format that lets you write API descriptions and documentation in a simple and straightforward way.<br /><br />Aglio is significant because it is driven from the machine readable format API Blueprint, and produces static HTML that can be served up anywhere, specifically on Github or Amazon S3 deployed using Jekyll. Additionally it just makes your document simple, easy to follow, and just damn sexy.<br />I&amp;rsquo;d love to see a Swagger generated version of Aglio, allowing you to deploy the attractive API documentation from both Swagger or API Blueprint. If more API documentation looked like Aglio, I would be a seriously happy camper.m on the hunt for new ways to deploy attractive, interactive API documentation, from machine readable API definition formats like Swagger and API Blueprint. I am advocating for the development of new approaches to deploy UI documentation, and part of this showcasing what I find along the way.<br />In the spotlight today is Aglio, which they describe as:<br />An API Blueprint renderer that supports multiple themes and outputs static HTML that can be served by any web host. API Blueprint is a Markdown-based document format that lets you write API descriptions and documentation in a simple and straightforward way.<br /><br />Aglio is significant because it is driven from the machine readable format API Blueprint, and produces static HTML that can be served up anywhere, specifically on Github or Amazon S3 deployed using Jekyll. Additionally it just makes your document simple, easy to follow, and just damn sexy.<br />I&amp;rsquo;d love to see a Swagger generated version of Aglio, allowing you to deploy the attractive API documentation from both Swagger or API Blueprint. If more API documentation looked like Aglio, I would be a seriously happy camper.",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/blog/aglio-logo.png"
  },
  {
  "title": "A Common Place To Manage All The API Definitions In My World",
  "date": "21 Dec 2014",
  "body": "<br />I&amp;rsquo;m profiling all the 700+ companies I monitor across the space, going through each one and defining their API program, evaluating the tech, business and politics of their operations. Part of this process is creating a Swagger definition for each API. I&amp;rsquo;m not deeply concerned with getting each API definition 100%, unless Im directly integrating with the aPI. For this round I&amp;rsquo;m looking at defining just the surface area of the API, including each endpoint, headers, parameters, and body format, and leaving the underlying data model for another time.<br />I&amp;rsquo;m publishing all of my API definitions to the API Stack Github repository. I&amp;rsquo;m using this as a staging area before I publish them to APIs.io. Last month I create an APIs.son for 690 APIs, and I&amp;rsquo;m looking to generate as many Swagger definitions for these high value APIs as I can over the holidays. It would be much better if API providers generated, and maintained their own API definitions, but until that happens I&amp;rsquo;m happy doing a little extra work to get us to a critical mass.<br /><br />Feel free to use any of my Swagger specifications, all that I ask is if you update, or add to them, please commit back to the repository so everyone can benefit. Additionally if you have any Swagger definitions for your own APIs, or other public APIs that I do not have in my listings, please share. It is extremely important that all public API endpoints are defined in a machine readable format. I don&amp;rsquo;t care if you use Swagger, API Blueprint or RAML, just make sure your APIs have a definition, and it is shared publicly. If it is one of your designs, make sure and also add to API Commons.<br />When I reach a critical mass of API definitions in the API Stack Github repo, I will publish a story on apievangelist.com announcing they are there, and do incremental pushes to APIs.io, so that these value APIs are part of its open index, allowing you to build API collections, and even your open API search engine. Its important that we all work to define this layer of the API space, and work to keep it as open, and machine readable as possible.m directly integrating with the aPI. For this round I&amp;rsquo;m looking at defining just the surface area of the API, including each endpoint, headers, parameters, and body format, and leaving the underlying data model for another time.<br />I&amp;rsquo;m publishing all of my API definitions to the API Stack Github repository. I&amp;rsquo;m using this as a staging area before I publish them to APIs.io. Last month I create an APIs.son for 690 APIs, and I&amp;rsquo;m looking to generate as many Swagger definitions for these high value APIs as I can over the holidays. It would be much better if API providers generated, and maintained their own API definitions, but until that happens I&amp;rsquo;m happy doing a little extra work to get us to a critical mass.<br /><br />Feel free to use any of my Swagger specifications, all that I ask is if you update, or add to them, please commit back to the repository so everyone can benefit. Additionally if you have any Swagger definitions for your own APIs, or other public APIs that I do not have in my listings, please share. It is extremely important that all public API endpoints are defined in a machine readable format. I don&amp;rsquo;t care if you use Swagger, API Blueprint or RAML, just make sure your APIs have a definition, and it is shared publicly. If it is one of your designs, make sure and also add to API Commons.<br />When I reach a critical mass of API definitions in the API Stack Github repo, I will publish a story on apievangelist.com announcing they are there, and do incremental pushes to APIs.io, so that these value APIs are part of its open index, allowing you to build API collections, and even your open API search engine. Its important that we all work to define this layer of the API space, and work to keep it as open, and machine readable as possible.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/api-commons/api-commons-icon.png"
  },
  {
  "title": "What Are The Incentives For Creating Machine Readable API Definitions?",
  "date": "05 Jun 2014",
  "body": "<br />After #Gluecon in Colorado the other week, I have API design on the brain. A portion of the #APIStrat un-workshops were dedicated to API design related discussion, and API Design is also the most trafficked portion of API Evangelist this year, according to my Google Analytics.<br />At #Gluecon, 3Scale and API Evangelist announced our new API discovery project APIs.json, and associated tooling, API search engine APIs.io. For APIs.json, APIs.io, and API Commons to work, we are counting API providers, and API consumers creating machine readable API definitions.<br />With this in mind, I wanted to do some exploration--what would be possible incentives for creating machine readable API definitions?<br /><br /><br /><br />JSON API Definition<br /> <br /><br /><br />Interactive Documentation<br /> <br /><br /><br />Server Side Code Deployment<br /> <br /><br /><br />Client Side Code generation<br /> <br /><br /><br />Design, Mocking, and Collaboration<br /> <br /><br /><br />Markdown Based API Definition<br /> <br /><br /><br />YAML Based API Definition<br /> <br /><br /><br />Reusability, Interoperability and Copyright<br /> <br /><br /><br />Testing &amp;amp; Monitoring<br /> <br /><br /><br />Discovery<br /> <br /><br /><br />Search<br /> <br /><br /><br /><br />The importance of having an API definition of available resources, is increasing. It was hard to realize the value of defining APIs with the heavy, top down defined WSDL, and even its web counterpart WADL, but with these new approaches, other incentives are emerging&amp;mdash;incentives that live throughout the API lifecycle.<br />The first tangible shift in this area was when Swagger released the Swagger UI, providing interactive documentation that was generated from a Swagger API definition. Apiary quickly moved the incentives to an earlier stage in the API design lifecycle with design, mocking and collaboration opportunities.<br />As the API design world continues to explode, I&amp;rsquo;m seeing a number of other incentives emerge for API providers to generate machine readable API definitions, and looking to find any incentives that I&amp;rsquo;m missing, as well as identify any opportunities in how I can encourage API designers to generate machine readable API definitions in whatever format they desire.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-carrot.png"
  },
  {
  "title": "Swagger Levels The API Design Playing Field With New Editor And YAML Definitions",
  "date": "05 Jun 2014",
  "body": "<br />In January I started taking a closer look at the world of API design, by reviewing the top movers in the space, Swagger from Wordnik, API Blueprint from Apiary, and RAML from Mulesoft. My goal was to quantity the world of API design, and help me understand where it might be going, or where there are opportunities for new tools and services.<br />My intention is to write a white paper on API Design, but haven&amp;rsquo;t reached this point, with the crazy amount of events and travel I&amp;rsquo;ve had in the last couple months. Looking back, at where I left off in my research, the major difference between providers was that Swagger was JSON, and didnt have all the tooling that was available with API Blueprint and RAML.<br />Fast forward 60 days, and I find myself at Gluecon, hanging out with Tony Tam of Reverb, creator of Swagger. On the last day of the conference,Tony shows me the new Swagger editor, with a new focus on YAML, as well as JSON Swagger definitions.  With one release Tony addresses any gap in the space, leveling the API design playing field between API Blueprint, Swagger, and RAML.<br />While there are many differences between each providers, which you can see in my reposting of  Ole Lensmar of SmartBear explored in his talk at #APIStrat Amsterdam with how they model REST, and what is behind the name, each of these top API design solutions will get you there, it just depends on your preferences.<br />60 days ago I would say that RAML and API Blueprint had a leg up on Swagger because of markdown / YAML focus, and with the amount of tooling they had. With one release Swagger has closed the gap, and with the traction they have amongst developers with a first mover advantage, this could put them squarely in the lead for adoption.<br />I&amp;rsquo;m predicting I&amp;rsquo;ll have more time this month to finish up my API design research, and produce the first draft of the white paper. API design is proving to one of the most talked about areas of the API sector in 2014, and one I&amp;rsquo;m enjoying tracking on.t have all the tooling that was available with API Blueprint and RAML.<br />Fast forward 60 days, and I find myself at Gluecon, hanging out with Tony Tam of Reverb, creator of Swagger. On the last day of the conference,Tony shows me the new Swagger editor, with a new focus on YAML, as well as JSON Swagger definitions.  With one release Tony addresses any gap in the space, leveling the API design playing field between API Blueprint, Swagger, and RAML.<br />While there are many differences between each providers, which you can see in my reposting of  Ole Lensmar of SmartBear explored in his talk at #APIStrat Amsterdam with how they model REST, and what is behind the name, each of these top API design solutions will get you there, it just depends on your preferences.<br />60 days ago I would say that RAML and API Blueprint had a leg up on Swagger because of markdown / YAML focus, and with the amount of tooling they had. With one release Swagger has closed the gap, and with the traction they have amongst developers with a first mover advantage, this could put them squarely in the lead for adoption.<br />I&amp;rsquo;m predicting I&amp;rsquo;ll have more time this month to finish up my API design research, and produce the first draft of the white paper. API design is proving to one of the most talked about areas of the API sector in 2014, and one I&amp;rsquo;m enjoying tracking on.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/api-evangelist/swagger/swagger-editor.png"
  },
  {
  "title": "API Definitions: What Is Behind The Name?",
  "date": "03 Apr 2014",
  "body": "<br />Last week at #APIStrat Amsterdam, I moderated, and presented in a session that was called API service descriptions. I gave the talk for the first 15 minutes, then Sumit Sharma (@sumitcan), Ole Lensmar (@olensmar), and Ruben Verborgh (@RubenVerborgh) followed me-- the full video is on Youtube if you are interested.<br />Over the last couple months Ive been doing a deeper dive into the area of API design, with a specific look at API definition formats from API Blueprint, RAML and Swagger, so the session was intended to help me continue the conversation, in person, on the stage at #APIStrat Amsterdam. I&#39;m happy I did, because Ole came to the table with some valuable data on API definitions, that save me some valuable research hours.<br />I&#39;m breaking up his work into several smaller posts, you can find his full deck on slideshare, first up is a comparison overview of each API Blueprint, RAML and Swagger:<br /><br /> <br /><br /><br />&amp;nbsp;<br /><br />API-Blueprint<br /><br /><br />RAML<br /><br /><br />Swagger<br /><br /><br /><br /><br />Format<br /><br /><br />Markdown<br /><br /><br />YAML<br /><br /><br />JSON<br /><br /><br /><br /><br />Spec License<br /><br /><br />MIT<br /><br /><br />ASL 2.0 / TM<br /><br /><br />ASL 2.0<br /><br /><br /><br /><br />Available at<br /><br /><br />GitHub<br /><br /><br />GitHub<br /><br /><br />GitHub<br /><br /><br /><br /><br />Sponsored by<br /><br /><br />Apiary<br /><br /><br />Mulesoft<br /><br /><br />Reverb<br /><br /><br /><br /><br />Current Version<br /><br /><br />1A3<br /><br /><br />0.8<br /><br /><br />1.2<br /><br /><br /><br /><br />Initial commit<br /><br /><br />April, 2013<br /><br /><br />Sep, 2013<br /><br /><br />July, 2011 <br /><br /><br /><br /><br />Commercial Offering<br /><br /><br />Yes<br /><br /><br />Yes<br /><br /><br />No<br /><br /><br /><br /><br />API Design Approach<br /><br /><br />Top-down<br /><br /><br />Top-down<br /><br /><br />Bottom-up<br /><br /><br /><br /><br /> <br />Ole provides a nice overview of the three leading API definition formats, giving API providers a good side-by-side summary that can be used when deciding which format to support. I will work with Ole to help keep the numbers up to date, and include in my final research white paper for API design when finished.<br />Thank you too&amp;nbsp;Ole Lensmar (@olensmar) and Smartbear Software for doing this research, and allowing me to share it with you.<br /><br />ve been doing a deeper dive into the area of API design, with a specific look at API definition formats from API Blueprint, RAML and Swagger, so the session was intended to help me continue the conversation, in person, on the stage at #APIStrat Amsterdam. Im happy I did, because Ole came to the table with some valuable data on API definitions, that save me some valuable research hours.<br />I&#39;m breaking up his work into several smaller posts, you can find his full deck on slideshare, first up is a comparison overview of each API Blueprint, RAML and Swagger:<br /><br /> <br /><br /><br />&amp;nbsp;<br /><br />API-Blueprint<br /><br /><br />RAML<br /><br /><br />Swagger<br /><br /><br /><br /><br />Format<br /><br /><br />Markdown<br /><br /><br />YAML<br /><br /><br />JSON<br /><br /><br /><br /><br />Spec License<br /><br /><br />MIT<br /><br /><br />ASL 2.0 / TM<br /><br /><br />ASL 2.0<br /><br /><br /><br /><br />Available at<br /><br /><br />GitHub<br /><br /><br />GitHub<br /><br /><br />GitHub<br /><br /><br /><br /><br />Sponsored by<br /><br /><br />Apiary<br /><br /><br />Mulesoft<br /><br /><br />Reverb<br /><br /><br /><br /><br />Current Version<br /><br /><br />1A3<br /><br /><br />0.8<br /><br /><br />1.2<br /><br /><br /><br /><br />Initial commit<br /><br /><br />April, 2013<br /><br /><br />Sep, 2013<br /><br /><br />July, 2011 <br /><br /><br /><br /><br />Commercial Offering<br /><br /><br />Yes<br /><br /><br />Yes<br /><br /><br />No<br /><br /><br /><br /><br />API Design Approach<br /><br /><br />Top-down<br /><br /><br />Top-down<br /><br /><br />Bottom-up<br /><br /><br /><br /><br /> <br />Ole provides a nice overview of the three leading API definition formats, giving API providers a good side-by-side summary that can be used when deciding which format to support. I will work with Ole to help keep the numbers up to date, and include in my final research white paper for API design when finished.<br />Thank you too&amp;nbsp;Ole Lensmar (@olensmar) and Smartbear Software for doing this research, and allowing me to share it with you.<br /><br />m happy I did, because Ole came to the table with some valuable data on API definitions, that save me some valuable research hours.<br />Im breaking up his work into several smaller posts, you can find his full deck on slideshare, first up is a comparison overview of each API Blueprint, RAML and Swagger:<br /><br /> <br /><br /><br />&amp;nbsp;<br /><br />API-Blueprint<br /><br /><br />RAML<br /><br /><br />Swagger<br /><br /><br /><br /><br />Format<br /><br /><br />Markdown<br /><br /><br />YAML<br /><br /><br />JSON<br /><br /><br /><br /><br />Spec License<br /><br /><br />MIT<br /><br /><br />ASL 2.0 / TM<br /><br /><br />ASL 2.0<br /><br /><br /><br /><br />Available at<br /><br /><br />GitHub<br /><br /><br />GitHub<br /><br /><br />GitHub<br /><br /><br /><br /><br />Sponsored by<br /><br /><br />Apiary<br /><br /><br />Mulesoft<br /><br /><br />Reverb<br /><br /><br /><br /><br />Current Version<br /><br /><br />1A3<br /><br /><br />0.8<br /><br /><br />1.2<br /><br /><br /><br /><br />Initial commit<br /><br /><br />April, 2013<br /><br /><br />Sep, 2013<br /><br /><br />July, 2011 <br /><br /><br /><br /><br />Commercial Offering<br /><br /><br />Yes<br /><br /><br />Yes<br /><br /><br />No<br /><br /><br /><br /><br />API Design Approach<br /><br /><br />Top-down<br /><br /><br />Top-down<br /><br /><br />Bottom-up<br /><br /><br /><br /><br /> <br />Ole provides a nice overview of the three leading API definition formats, giving API providers a good side-by-side summary that can be used when deciding which format to support. I will work with Ole to help keep the numbers up to date, and include in my final research white paper for API design when finished.<br />Thank you too&amp;nbsp;Ole Lensmar (@olensmar) and Smartbear Software for doing this research, and allowing me to share it with you.<br /><br />m breaking up his work into several smaller posts, you can find his full deck on slideshare, first up is a comparison overview of each API Blueprint, RAML and Swagger:<br /><br /> <br /><br /><br />&amp;nbsp;<br /><br />API-Blueprint<br /><br /><br />RAML<br /><br /><br />Swagger<br /><br /><br /><br /><br />Format<br /><br /><br />Markdown<br /><br /><br />YAML<br /><br /><br />JSON<br /><br /><br /><br /><br />Spec License<br /><br /><br />MIT<br /><br /><br />ASL 2.0 / TM<br /><br /><br />ASL 2.0<br /><br /><br /><br /><br />Available at<br /><br /><br />GitHub<br /><br /><br />GitHub<br /><br /><br />GitHub<br /><br /><br /><br /><br />Sponsored by<br /><br /><br />Apiary<br /><br /><br />Mulesoft<br /><br /><br />Reverb<br /><br /><br /><br /><br />Current Version<br /><br /><br />1A3<br /><br /><br />0.8<br /><br /><br />1.2<br /><br /><br /><br /><br />Initial commit<br /><br /><br />April, 2013<br /><br /><br />Sep, 2013<br /><br /><br />July, 2011 <br /><br /><br /><br /><br />Commercial Offering<br /><br /><br />Yes<br /><br /><br />Yes<br /><br /><br />No<br /><br /><br /><br /><br />API Design Approach<br /><br /><br />Top-down<br /><br /><br />Top-down<br /><br /><br />Bottom-up<br /><br /><br /><br /><br /> <br />Ole provides a nice overview of the three leading API definition formats, giving API providers a good side-by-side summary that can be used when deciding which format to support. I will work with Ole to help keep the numbers up to date, and include in my final research white paper for API design when finished.<br />Thank you too&amp;nbsp;Ole Lensmar (@olensmar) and Smartbear Software for doing this research, and allowing me to share it with you.<br /><br />",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/blog/apistrat-logo.png"
  },
  {
  "title": "Added API For Searching And Adding API Definitions To API Commons",
  "date": "03 Mar 2014",
  "body": "<br />I think the title of this blog post has the most occurrence of API, I&amp;rsquo;ve ever used.  We have had requests to provide an API for the API commons, so now you can add API definitions using a Github manifest, the API Commons Manifest generator, or via the API Commons API.<br />I added the ability to search API definitions, as well as POST an API through the new interface. I deployed a simple registration form for the API using 3Scale API infrastructure, and will add more account management features as the API matures&amp;mdash;right now can just signup, login, get your keys and logout.<br />If you&amp;rsquo;d like to integrate the publishing of API definitions directly to the commons from your API management system let us know, we are happy to help you with the integration, and keeping the latest version of your API definitions published to the commons automatically.<br />If you run into any issues or have comments you can submit via the issue management for the Github repository that the API Commons site runs in.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/api-commons/api-commons-icon.png"
  },
  {
  "title": "Will API Definitions Be Big in 2014?",
  "date": "31 Jan 2014",
  "body": "Im a big fan of Traffic and Weather, where in a recent episode John Sheehan (@johnsheehan) definitively answers the questions of weather or not API definitions will be a big thing 2014?<br /><br /><br /><br /><br /><br /><br /><br /><br /><br />We can always count on John and Steve to clear things up!  Make sure and head over to Traffic and Weather and tune in for the latest in commentary from the API space.m a big fan of Traffic and Weather, where in a recent episode John Sheehan (@johnsheehan) definitively answers the questions of weather or not API definitions will be a big thing 2014?<br /><br /><br /><br /><br /><br /><br /><br /><br /><br />We can always count on John and Steve to clear things up!  Make sure and head over to Traffic and Weather and tune in for the latest in commentary from the API space.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/events/api-strategy-practice-conference/apistrat-john-sheehan.jpg"
  },
  {
  "title": "The Evolving Motivations Behind API Definitions",
  "date": "22 Jan 2014",
  "body": "<br />I&amp;rsquo;m spending more time diving into the evolving world of API design over the next couple of weeks. There is a rapidly emerging community of companies, tooling and approaches to designing and developing APIs, that is centered around API definition languages.<br />Languages for defining web services have been around for a while, with Web Application Description Language (WADL), which was born out of the SOAP WSDL era, representing very technical approach to describing this new world of web APIs. While WADL is still in use, it hasn&amp;rsquo;t seen the adoption many envisioned.<br />It wasn&amp;rsquo;t until recently that we&amp;rsquo;ve seen new approaches emerge, and get traction, with JSON based API definitions like Swagger from Wordnik, and I/O Docs from Mashery. The primary motivation behind defining your API using Swagger or I/O Docs has historicaly been to deploy interactive documentation for developers, with discovery, client-side code generation, server-side code generation and other tooling as secondary motivator, if at all.<br />In the last year we&amp;rsquo;ve also seen even newer approaches to designing and defining APIs emerge, with the introduction of markdown based API definitions like API Blueprint from Apiary, and RAML from Mulesoft. This new markdown approach is&amp;nbsp;providing languages for describing and defining APIs that holds the promise of even being accessible to non-developers.<br />I have time scheduled to talk with each of the providers listed above in the coming weeks, but after a talk with the API Blueprint team from Apiary, I&amp;rsquo;m reminded of how the motivations for API definitions is continuing its rapid expansion. When you are motivated to use API definitions for just generating API documentation, you miss so much opportunity for communicating, collaborating and iterating during the planning and design of your API.<br />API Blueprint was born out of Apiary, so it is rooted in the desire to design and mockup APIs, all while collaborating with other key players and the actual consumers of the API. If you wait to generate an API definition when you reach the point where you are ready for documentation, you are throwing away valuable design time, and burning costly development hours. Apiary needed a way to articulate, share and communicate around the design of an API from start to finish, pushing the motivation for developers to generate an API definition, from producing interactive docs, to devliering on the entire API planning, design, development, deployment and management lifecycle.<br />We need these new languages to describe and communicate around APIs. Without them we can&amp;rsquo;t mockup, iterate and collaborate to find the best possible API design. Without these new languages we can&amp;rsquo;t quantify APIs to key business, marketing, and sales players, as well as the lawyers, providing a contract for not just machine to machine interaction, but B2B and B2C. Without these new languages we can&amp;rsquo;t generate standardized tooling and API deployments based upon the best API patterns available today.<br />I think that the fact that there are now 4 major API design approaches, represents not just an evolution in the motivation for developers to use common definitions for APIs, but also a shift that will make API design accessible to everyone, motivating even non-developers to communicate and interact with APIs, in a simple, but powerful way that can align IT and development, with overall business goals.",
  "url": "http://localhost:4000",
  "image": "https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-evolving.png"
  },
  {
  "title": "Startups Need To Work Together on API Definitions",
  "date": "02 May 2013",
  "body": "<br />I am tracking on 2000 APIs that I have deemed worthy enough to pay attention, out of the 9000 on ProgrammableWeb, 13,000 in APIHub and numerous APIs in Mashapes marketplace.  In addition to these APIs, I&#39;m also closely watching 30+ backend as a service providers, 20+ reciprocity providers and emerging big data, analysis, visualization and other emerging platforms who are using APIs in new ways.<br />I was reading some of the great research coming out of OPENi, which is a Open-Source, Web-Based, Framework for Integrating Applications with Cloud-based Services and Personal Cloudlets--specifically the post on OpenI API Framework: Studying the Landscape of Cloud-Based Services.<br />What is great about OPENi, is they are doing all this research and planning, and sharing the process with everyone publicly.  Which is great for everyone, but will take some time to play out, as they study, plan and execute in the space.<br />As I watch aggregate API providers like Singly plow forward and reciprocity providers like Zapier deliver some amazing integrations, using APIs, and bridging some of the most meaningful cloud platforms in our world--I can&#39;t help but think about how much redundant work is going on amongst startups.<br /><br />When it comes to the definitions of specific APIs, the nuances of their interface and authentication, each of these service providers is doing their own work, in a silo. In a perfect world, API providers would provide Swagger definitions, standard oAuth implementations, etc.  API owners would do a lot of the legwork for these providers. &amp;nbsp;As we know, this isn&#39;t the reality, and each of these aggegrators, reciprocity providers, analytics tools are all mapping these API connections on their own.<br />I can&#39;t help but think about, how if providers stepped up, communicated with each other, they could establish some sort of commons for all of these API definitions to reside. &amp;nbsp;They could colloaborately develop a way they could identify the meaningful APIs, hang Swagger definitions and code for connecting and authenticating in a multitude of programming languages.<br />Each provider could still maintain their secret sauce, what happens before and after each API connection, allowing them to have their own unique approach to API aggregation, reciprocity, analysis, visualization or real-time tools. But by sharing the API definitions and working together on the connections, they could spend more time on what makes their companies unique, rather than hand-rolling each API connection in isolation.<br />Just some random thoughts, as I navigate the world of APIs, from within my own silo!s marketplace.  In addition to these APIs, Im also closely watching 30+ backend as a service providers, 20+ reciprocity providers and emerging big data, analysis, visualization and other emerging platforms who are using APIs in new ways.<br />I was reading some of the great research coming out of OPENi, which is a Open-Source, Web-Based, Framework for Integrating Applications with Cloud-based Services and Personal Cloudlets--specifically the post on OpenI API Framework: Studying the Landscape of Cloud-Based Services.<br />What is great about OPENi, is they are doing all this research and planning, and sharing the process with everyone publicly.  Which is great for everyone, but will take some time to play out, as they study, plan and execute in the space.<br />As I watch aggregate API providers like Singly plow forward and reciprocity providers like Zapier deliver some amazing integrations, using APIs, and bridging some of the most meaningful cloud platforms in our world--I can&#39;t help but think about how much redundant work is going on amongst startups.<br /><br />When it comes to the definitions of specific APIs, the nuances of their interface and authentication, each of these service providers is doing their own work, in a silo. In a perfect world, API providers would provide Swagger definitions, standard oAuth implementations, etc.  API owners would do a lot of the legwork for these providers. &amp;nbsp;As we know, this isn&#39;t the reality, and each of these aggegrators, reciprocity providers, analytics tools are all mapping these API connections on their own.<br />I can&#39;t help but think about, how if providers stepped up, communicated with each other, they could establish some sort of commons for all of these API definitions to reside. &amp;nbsp;They could colloaborately develop a way they could identify the meaningful APIs, hang Swagger definitions and code for connecting and authenticating in a multitude of programming languages.<br />Each provider could still maintain their secret sauce, what happens before and after each API connection, allowing them to have their own unique approach to API aggregation, reciprocity, analysis, visualization or real-time tools. But by sharing the API definitions and working together on the connections, they could spend more time on what makes their companies unique, rather than hand-rolling each API connection in isolation.<br />Just some random thoughts, as I navigate the world of APIs, from within my own silo!m also closely watching 30+ backend as a service providers, 20+ reciprocity providers and emerging big data, analysis, visualization and other emerging platforms who are using APIs in new ways.<br />I was reading some of the great research coming out of OPENi, which is a Open-Source, Web-Based, Framework for Integrating Applications with Cloud-based Services and Personal Cloudlets--specifically the post on OpenI API Framework: Studying the Landscape of Cloud-Based Services.<br />What is great about OPENi, is they are doing all this research and planning, and sharing the process with everyone publicly.  Which is great for everyone, but will take some time to play out, as they study, plan and execute in the space.<br />As I watch aggregate API providers like Singly plow forward and reciprocity providers like Zapier deliver some amazing integrations, using APIs, and bridging some of the most meaningful cloud platforms in our world--I cant help but think about how much redundant work is going on amongst startups.<br /><br />When it comes to the definitions of specific APIs, the nuances of their interface and authentication, each of these service providers is doing their own work, in a silo. In a perfect world, API providers would provide Swagger definitions, standard oAuth implementations, etc.  API owners would do a lot of the legwork for these providers. &amp;nbsp;As we know, this isn&#39;t the reality, and each of these aggegrators, reciprocity providers, analytics tools are all mapping these API connections on their own.<br />I can&#39;t help but think about, how if providers stepped up, communicated with each other, they could establish some sort of commons for all of these API definitions to reside. &amp;nbsp;They could colloaborately develop a way they could identify the meaningful APIs, hang Swagger definitions and code for connecting and authenticating in a multitude of programming languages.<br />Each provider could still maintain their secret sauce, what happens before and after each API connection, allowing them to have their own unique approach to API aggregation, reciprocity, analysis, visualization or real-time tools. But by sharing the API definitions and working together on the connections, they could spend more time on what makes their companies unique, rather than hand-rolling each API connection in isolation.<br />Just some random thoughts, as I navigate the world of APIs, from within my own silo!t help but think about how much redundant work is going on amongst startups.<br /><br />When it comes to the definitions of specific APIs, the nuances of their interface and authentication, each of these service providers is doing their own work, in a silo. In a perfect world, API providers would provide Swagger definitions, standard oAuth implementations, etc.  API owners would do a lot of the legwork for these providers. &amp;nbsp;As we know, this isnt the reality, and each of these aggegrators, reciprocity providers, analytics tools are all mapping these API connections on their own.<br />I can&#39;t help but think about, how if providers stepped up, communicated with each other, they could establish some sort of commons for all of these API definitions to reside. &amp;nbsp;They could colloaborately develop a way they could identify the meaningful APIs, hang Swagger definitions and code for connecting and authenticating in a multitude of programming languages.<br />Each provider could still maintain their secret sauce, what happens before and after each API connection, allowing them to have their own unique approach to API aggregation, reciprocity, analysis, visualization or real-time tools. But by sharing the API definitions and working together on the connections, they could spend more time on what makes their companies unique, rather than hand-rolling each API connection in isolation.<br />Just some random thoughts, as I navigate the world of APIs, from within my own silo!t the reality, and each of these aggegrators, reciprocity providers, analytics tools are all mapping these API connections on their own.<br />I cant help but think about, how if providers stepped up, communicated with each other, they could establish some sort of commons for all of these API definitions to reside. &amp;nbsp;They could colloaborately develop a way they could identify the meaningful APIs, hang Swagger definitions and code for connecting and authenticating in a multitude of programming languages.<br />Each provider could still maintain their secret sauce, what happens before and after each API connection, allowing them to have their own unique approach to API aggregation, reciprocity, analysis, visualization or real-time tools. But by sharing the API definitions and working together on the connections, they could spend more time on what makes their companies unique, rather than hand-rolling each API connection in isolation.<br />Just some random thoughts, as I navigate the world of APIs, from within my own silo!t help but think about, how if providers stepped up, communicated with each other, they could establish some sort of commons for all of these API definitions to reside. &amp;nbsp;They could colloaborately develop a way they could identify the meaningful APIs, hang Swagger definitions and code for connecting and authenticating in a multitude of programming languages.<br />Each provider could still maintain their secret sauce, what happens before and after each API connection, allowing them to have their own unique approach to API aggregation, reciprocity, analysis, visualization or real-time tools. But by sharing the API definitions and working together on the connections, they could spend more time on what makes their companies unique, rather than hand-rolling each API connection in isolation.<br />Just some random thoughts, as I navigate the world of APIs, from within my own silo!",
  "url": "http://localhost:4000",
  "image": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/blog/openi-logo.png"
  }
]
