---
swagger: "2.0"
info: !php/object "O:8:\"stdClass\":11:{s:11:\"description\";s:507:\"The Computer
  Vision API provides state-of-the-art algorithms to process images and return information.
  For example, it can be used to determine if an image contains mature content, or
  it can be used to find all the faces in an image.  It also has other features like
  estimating dominant and accent colors, categorizing the content of images, and describing
  an image with complete English sentences.  Additionally, it can also intelligently
  generate images thumbnails for displaying large images effectively.\";s:5:\"title\";s:15:\"Computer
  Vision\";s:7:\"version\";s:3:\"1.0\";s:21:\"x-apisguru-categories\";a:1:{i:0;s:5:\"cloud\";}s:6:\"x-logo\";O:8:\"stdClass\":1:{s:3:\"url\";s:131:\"https://api.apis.guru/v2/cache/logo/https_assets.onestore.ms_cdnfiles_onestorerolling-1606-01000_shell_v3_images_logo_microsoft.png\";}s:8:\"x-origin\";a:1:{i:0;O:8:\"stdClass\":3:{s:6:\"format\";s:7:\"swagger\";s:3:\"url\";s:157:\"https://raw.githubusercontent.com/Azure/azure-rest-api-specs/master/specification/cognitiveservices/data-plane/ComputerVision/stable/v1.0/ComputerVision.json\";s:7:\"version\";s:3:\"2.0\";}}s:11:\"x-preferred\";b:1;s:14:\"x-providerName\";s:9:\"azure.com\";s:13:\"x-serviceName\";s:32:\"cognitiveservices-ComputerVision\";s:6:\"x-tags\";a:2:{i:0;s:5:\"Azure\";i:1;s:9:\"Microsoft\";}s:10:\"x-datafire\";O:8:\"stdClass\":2:{s:4:\"name\";s:38:\"azure_cognitiveservices_computervision\";s:4:\"type\";s:7:\"openapi\";}}"
host: azure.local
basePath: /vision/v1.0
paths:
  /analyze:
    post:
      consumes:
      - application/json
      description: This operation extracts a rich set of visual features based on
        the image content. Two input methods are supported -- (1) Uploading an image
        or (2) specifying an image URL.  Within your request, there is an optional
        parameter to allow you to choose which features to return.  By default, image
        categories are returned in the response.
      operationId: AnalyzeImage
      parameters:
      - $ref: '#/parameters/VisualFeatures'
      - collectionFormat: csv
        description: A string indicating which domain-specific details to return.
          Multiple values should be comma-separated. Valid visual feature types include:Celebrities
          - identifies celebrities if detected in the image.
        in: query
        items:
          enum:
          - Celebrities
          - Landmarks
          type: string
          x-ms-enum:
            modelAsString: false
            name: Details
          x-nullable: false
        name: details
        required: false
        type: array
      - $ref: '#/parameters/ServiceLanguage'
      - description: A JSON document with a URL pointing to the image that is to be
          analyzed.
        in: body
        name: ImageUrl
        required: true
        schema:
          properties:
            url:
              description: Publicly reachable URL of an image
              type: string
          required:
          - url
          type: object
        x-ms-client-flatten: true
        x-ms-parameter-location: method
      produces:
      - application/json
      responses:
        200:
          description: The response include the extracted features in JSON format.Here
            is the definitions for enumeration typesClipartTypeNon-clipart = 0,  ambiguous
            = 1, normal-clipart = 2, good-clipart = 3.LineDrawingTypeNon-LineDrawing
            = 0,LineDrawing = 1.
          schema:
            $ref: '#/definitions/ImageAnalysis'
        default:
          description: Error response.
          schema:
            $ref: '#/definitions/ComputerVisionError'
      x-ms-examples:
        Successful Analyze with Url request:
          parameters:
            Content-Type: application/json
            Ocp-Apim-Subscription-Key: '{API key}'
            body:
              url: '{Image Url here}'
            details: Celebrities
            language: en
            visualFeatures: Categories,Adult,Tags,Description,Faces,Color,ImageType
          responses:
            200:
              body:
                adult:
                  adultScore: 0.093435
                  isAdultContent: false
                  isRacyContent: false
                  racyScore: 0.068613
                categories:
                - name: abstract_
                  score: 0.003906
                - detail:
                    celebrities:
                    - confidence: 0.999028
                      faceRectangle:
                        height: 248
                        left: 597
                        top: 162
                        width: 248
                      name: Satya Nadella
                    landmarks:
                    - confidence: 0.997835
                      name: Forbidden City
                  name: people_
                  score: 0.839844
                color:
                  accentColor: 873B59
                  dominantColorBackground: Brown
                  dominantColorForeground: Brown
                  dominantColors:
                  - Brown
                  - Black
                  isBWImg: false
                description:
                  captions:
                  - confidence: 0.482936
                    text: Satya Nadella sitting on a bench
                  tags:
                  - person
                  - man
                  - outdoor
                  - window
                  - glasses
                faces:
                - age: 44
                  faceRectangle:
                    height: 250
                    left: 593
                    top: 160
                    width: 250
                  gender: Male
                imageType:
                  clipArtType: 0
                  lineDrawingType: 0
                metadata:
                  format: Jpeg
                  height: 1000
                  width: 1500
                requestId: 0dbec5ad-a3d3-4f7e-96b4-dfd57efe967d
                tags:
                - confidence: 0.989791
                  name: person
                - confidence: 0.944939
                  name: man
                - confidence: 0.938492
                  name: outdoor
                - confidence: 0.895139
                  name: window
              headers: []
  /describe:
    post:
      consumes:
      - application/json
      description: This operation generates a description of an image in human readable
        language with complete sentences.  The description is based on a collection
        of content tags, which are also returned by the operation. More than one description
        can be generated for each image.  Descriptions are ordered by their confidence
        score. All descriptions are in English. Two input methods are supported --
        (1) Uploading an image or (2) specifying an image URL.A successful response
        will be returned in JSON.  If the request failed, the response will contain
        an error code and a message to help understand what went wrong.
      operationId: DescribeImage
      parameters:
      - default: "1"
        description: Maximum number of candidate descriptions to be returned.  The
          default is 1.
        in: query
        name: maxCandidates
        required: false
        type: string
      - $ref: '#/parameters/ServiceLanguage'
      - description: A JSON document with a URL pointing to the image that is to be
          analyzed.
        in: body
        name: ImageUrl
        required: true
        schema:
          properties:
            url:
              description: Publicly reachable URL of an image
              type: string
          required:
          - url
          type: object
        x-ms-client-flatten: true
        x-ms-parameter-location: method
      produces:
      - application/json
      responses:
        200:
          description: Image description object.
          schema:
            $ref: '#/definitions/ImageDescription'
        default:
          description: Error response.
          schema:
            $ref: '#/definitions/ComputerVisionError'
      x-ms-examples:
        Successful Describe request:
          parameters:
            Content-Type: application/json
            Ocp-Apim-Subscription-Key: '{API key}'
            body:
              url: '{Image Url here}'
            maxCandidates: "1"
          responses:
            200:
              body:
                description:
                  captions:
                  - confidence: 0.482936
                    text: Satya Nadella sitting on a bench
                  - confidence: 0.400370
                    text: Satya Nadella is sitting on a bench
                  - confidence: 0.380352
                    text: Satya Nadella sitting in front of a building
                  tags:
                  - person
                  - man
                  - outdoor
                  - window
                  - glasses
                metadata:
                  format: Jpeg
                  height: 1000
                  width: 1500
                requestId: ed2de1c6-fb55-4686-b0da-4da6e05d283f
  /generateThumbnail:
    post:
      consumes:
      - application/json
      description: This operation generates a thumbnail image with the user-specified
        width and height. By default, the service analyzes the image, identifies the
        region of interest (ROI), and generates smart cropping coordinates based on
        the ROI. Smart cropping helps when you specify an aspect ratio that differs
        from that of the input image. A successful response contains the thumbnail
        image binary. If the request failed, the response contains an error code and
        a message to help determine what went wrong.
      operationId: GenerateThumbnail
      parameters:
      - description: Width of the thumbnail. It must be between 1 and 1024. Recommended
          minimum of 50.
        in: query
        maximum: 1023
        minimum: 1
        name: width
        required: true
        type: integer
      - description: Height of the thumbnail. It must be between 1 and 1024. Recommended
          minimum of 50.
        in: query
        maximum: 1023
        minimum: 1
        name: height
        required: true
        type: integer
      - description: A JSON document with a URL pointing to the image that is to be
          analyzed.
        in: body
        name: ImageUrl
        required: true
        schema:
          properties:
            url:
              description: Publicly reachable URL of an image
              type: string
          required:
          - url
          type: object
        x-ms-client-flatten: true
        x-ms-parameter-location: method
      - default: false
        description: Boolean flag for enabling smart cropping.
        in: query
        name: smartCropping
        required: false
        type: boolean
      produces:
      - application/octet-stream
      responses:
        200:
          description: The generated thumbnail in binary format.
          schema:
            type: file
        default:
          description: Error response.
          schema:
            $ref: '#/definitions/ComputerVisionError'
      x-ms-examples:
        Successful Generate Thumbnail request:
          parameters:
            Content-Type: application/json
            Ocp-Apim-Subscription-Key: '{API key}'
            body:
              url: '{Image Url here}'
            height: "500"
            smartCropping: true
            width: "500"
          responses:
            200:
              body: '{Binary}'
              headers: []
  /models:
    get:
      description: 'This operation returns the list of domain-specific models that
        are supported by the Computer Vision API.  Currently, the API only supports
        one domain-specific model: a celebrity recognizer. A successful response will
        be returned in JSON.  If the request failed, the response will contain an
        error code and a message to help understand what went wrong.'
      operationId: ListModels
      produces:
      - application/json
      responses:
        200:
          description: List of available domain models.
          schema:
            $ref: '#/definitions/ListModelsResult'
        default:
          description: Error response.
          schema:
            $ref: '#/definitions/ComputerVisionError'
      x-ms-examples:
        Successful List Domains request:
          parameters:
            Ocp-Apim-Subscription-Key: '{API key}'
            body: []
          responses:
            200:
              body:
                models:
                - categories:
                  - people_
                  name: celebrities
                - categories:
                  - building_
                  name: landmarks
              headers: []
  /models/{model}/analyze:
    post:
      consumes:
      - application/json
      description: 'This operation recognizes content within an image by applying
        a domain-specific model.  The list of domain-specific models that are supported
        by the Computer Vision API can be retrieved using the /models GET request.  Currently,
        the API only provides a single domain-specific model: celebrities. Two input
        methods are supported -- (1) Uploading an image or (2) specifying an image
        URL. A successful response will be returned in JSON.  If the request failed,
        the response will contain an error code and a message to help understand what
        went wrong.'
      operationId: AnalyzeImageByDomain
      parameters:
      - description: The domain-specific content to recognize.
        enum:
        - Celebrities
        - Landmarks
        in: path
        name: model
        required: true
        type: string
        x-ms-enum:
          modelAsString: false
          name: DomainModels
        x-nullable: false
      - description: A JSON document with a URL pointing to the image that is to be
          analyzed.
        in: body
        name: ImageUrl
        required: true
        schema:
          properties:
            url:
              description: Publicly reachable URL of an image
              type: string
          required:
          - url
          type: object
        x-ms-client-flatten: true
        x-ms-parameter-location: method
      produces:
      - application/json
      responses:
        200:
          description: Analysis result based on the domain model
          schema:
            $ref: '#/definitions/DomainModelResults'
        default:
          description: Error response.
          schema:
            $ref: '#/definitions/ComputerVisionError'
      x-ms-examples:
        Successful Domain Model analysis request:
          parameters:
            Content-Type: application/json
            Model: Celebrities
            Ocp-Apim-Subscription-Key: '{API key}'
            body:
              url: '{Image Url here}'
          responses:
            200:
              body:
                metadata:
                  format: Jpeg
                  height: 1000
                  width: 1500
                requestId: f0027b4b-dc0d-4082-9228-1545ed246b03
                result:
                  celebrities:
                  - confidence: 0.999028
                    faceRectangle:
                      height: 248
                      left: 597
                      top: 162
                      width: 248
                    name: Satya Nadella
  /ocr:
    post:
      consumes:
      - application/json
      description: Optical Character Recognition (OCR) detects printed text in an
        image and extracts the recognized characters into a machine-usable character
        stream.   Upon success, the OCR results will be returned. Upon failure, the
        error code together with an error message will be returned. The error code
        can be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage,  NotSupportedLanguage,
        or InternalServerError.
      operationId: RecognizePrintedText
      parameters:
      - $ref: '#/parameters/DetectOrientation'
      - description: A JSON document with a URL pointing to the image that is to be
          analyzed.
        in: body
        name: ImageUrl
        required: true
        schema:
          properties:
            url:
              description: Publicly reachable URL of an image
              type: string
          required:
          - url
          type: object
        x-ms-client-flatten: true
        x-ms-parameter-location: method
      - $ref: '#/parameters/OcrLanguage'
      produces:
      - application/json
      responses:
        200:
          description: The OCR results in the hierarchy of region/line/word. The results
            include text, bounding box for regions, lines and words.textAngleThe angle,
            in degrees, of the detected text with respect to the closest horizontal
            or vertical direction. After rotating the input image clockwise by this
            angle, the recognized text lines become horizontal or vertical. In combination
            with the orientation property it can be used to overlay recognition results
            correctly on the original image, by rotating either the original image
            or recognition results by a suitable angle around the center of the original
            image. If the angle cannot be confidently detected, this property is not
            present. If the image contains text at different angles, only part of
            the text will be recognized correctly.
          schema:
            $ref: '#/definitions/OcrResult'
        default:
          description: Error response.
          schema:
            $ref: '#/definitions/ComputerVisionError'
      x-ms-examples:
        Successful Ocr request:
          parameters:
            Content-Type: application/json
            Ocp-Apim-Subscription-Key: '{API key}'
            body:
              url: '{Image Url here}'
            detectOrientation: "true"
            language: en
          responses:
            200:
              body:
                language: en
                orientation: Up
                regions:
                - boundingBox: "462,379,497,258"
                  lines:
                  - boundingBox: "462,379,497,74"
                    words:
                    - boundingBox: "462,379,41,73"
                      text: A
                    - boundingBox: "523,379,153,73"
                      text: GOAL
                    - boundingBox: "694,379,265,74"
                      text: WITHOUT
                  - boundingBox: "565,471,289,74"
                    words:
                    - boundingBox: "565,471,41,73"
                      text: A
                    - boundingBox: "626,471,150,73"
                      text: PLAN
                    - boundingBox: "801,472,53,73"
                      text: IS
                  - boundingBox: "519,563,375,74"
                    words:
                    - boundingBox: "519,563,149,74"
                      text: JUST
                    - boundingBox: "683,564,41,72"
                      text: A
                    - boundingBox: "741,564,153,73"
                      text: WISH
                textAngle: -2
              headers: []
  /recognizeText:
    post:
      consumes:
      - application/json
      description: Recognize Text operation. When you use the Recognize Text interface,
        the response contains a field called 'Operation-Location'. The 'Operation-Location'
        field contains the URL that you must use for your Get Handwritten Text Operation
        Result operation.
      operationId: RecognizeText
      parameters:
      - description: A JSON document with a URL pointing to the image that is to be
          analyzed.
        in: body
        name: ImageUrl
        required: true
        schema:
          properties:
            url:
              description: Publicly reachable URL of an image
              type: string
          required:
          - url
          type: object
        x-ms-client-flatten: true
        x-ms-parameter-location: method
      - $ref: '#/parameters/HandwritingBoolean'
      produces:
      - application/json
      responses:
        202:
          description: The service has accepted the request and will start processing
            later. It will return Accepted immediately and include an Operation-Location
            header. Client side should further query the operation status using the
            URL specified in this header. The operation ID will expire in 48 hours.
          headers:
            Operation-Location:
              description: 'URL to query for status of the operation. The operation
                ID will expire in 48 hours. '
              type: string
        default:
          description: Error response.
          schema:
            $ref: '#/definitions/ComputerVisionError'
      x-ms-examples:
        Successful Domain Model analysis request:
          parameters:
            Content-Type: application/json
            Handwriting: "true"
            Ocp-Apim-Subscription-Key: '{API key}'
            body:
              url: '{Image Url here}'
          responses:
            202:
              header:
                Operation-Location: https://{domain}/vision/v1.0/textOperations/49a36324-fc4b-4387-aa06-090cfbf0064f
  /tag:
    post:
      consumes:
      - application/json
      description: This operation generates a list of words, or tags, that are relevant
        to the content of the supplied image. The Computer Vision API can return tags
        based on objects, living beings, scenery or actions found in images. Unlike
        categories, tags are not organized according to a hierarchical classification
        system, but correspond to image content. Tags may contain hints to avoid ambiguity
        or provide context, for example the tag 'cello' may be accompanied by the
        hint 'musical instrument'. All tags are in English.
      operationId: TagImage
      parameters:
      - $ref: '#/parameters/ServiceLanguage'
      - description: A JSON document with a URL pointing to the image that is to be
          analyzed.
        in: body
        name: ImageUrl
        required: true
        schema:
          properties:
            url:
              description: Publicly reachable URL of an image
              type: string
          required:
          - url
          type: object
        x-ms-client-flatten: true
        x-ms-parameter-location: method
      produces:
      - application/json
      responses:
        200:
          description: Image tags object.
          schema:
            $ref: '#/definitions/TagResult'
        default:
          description: Error response.
          schema:
            $ref: '#/definitions/ComputerVisionError'
      x-ms-examples:
        Successful Tag request:
          parameters:
            Content-Type: application/json
            Ocp-Apim-Subscription-Key: '{API key}'
            body:
              url: '{Image Url here}'
          responses:
            200:
              body:
                metadata:
                  format: Jpeg
                  height: 400
                  width: 400
                requestId: 1ad0e45e-b7b4-4be3-8042-53be96103337
                tags:
                - confidence: 1.000000
                  name: grass
                - confidence: 0.999971
                  name: outdoor
                - confidence: 0.999290
                  name: sky
                - confidence: 0.996463
                  name: building
                - confidence: 0.992798
                  name: house
                - confidence: 0.822680
                  name: lawn
                - confidence: 0.641223
                  name: green
                - confidence: 0.314032
                  name: residential
  /textOperations/{operationId}:
    get:
      description: This interface is used for getting text operation result. The URL
        to this interface should be retrieved from 'Operation-Location' field returned
        from Recognize Text interface.
      operationId: GetTextOperationResult
      parameters:
      - description: Id of the text operation returned in the response of the 'Recognize
          Handwritten Text'
        in: path
        name: operationId
        required: true
        type: string
      produces:
      - application/json
      responses:
        200:
          description: Returns the operation status.
          schema:
            $ref: '#/definitions/TextOperationResult'
        default:
          description: Error response.
          schema:
            $ref: '#/definitions/ComputerVisionError'
      x-ms-examples:
        Successful Domain Model analysis request:
          parameters:
            Ocp-Apim-Subscription-Key: '{API key}'
            operationId: 49a36324-fc4b-4387-aa06-090cfbf0064f
          responses:
            200:
              body:
                recognitionResult:
                  lines:
                  - boundingBox:
                    - 202
                    - 618
                    - 2047
                    - 643
                    - 2046
                    - 840
                    - 200
                    - 813
                    text: Our greatest glory is not
                    words:
                    - boundingBox:
                      - 204
                      - 627
                      - 481
                      - 628
                      - 481
                      - 830
                      - 204
                      - 829
                      text: Our
                    - boundingBox:
                      - 519
                      - 628
                      - 1057
                      - 630
                      - 1057
                      - 832
                      - 518
                      - 830
                      text: greatest
                    - boundingBox:
                      - 1114
                      - 630
                      - 1549
                      - 631
                      - 1548
                      - 833
                      - 1114
                      - 832
                      text: glory
                    - boundingBox:
                      - 1586
                      - 631
                      - 1785
                      - 632
                      - 1784
                      - 834
                      - 1586
                      - 833
                      text: is
                    - boundingBox:
                      - 1822
                      - 632
                      - 2115
                      - 633
                      - 2115
                      - 835
                      - 1822
                      - 834
                      text: not
                  - boundingBox:
                    - 420
                    - 1273
                    - 2954
                    - 1250
                    - 2958
                    - 1488
                    - 422
                    - 1511
                    text: but in rising every time we fall
                    words:
                    - boundingBox:
                      - 423
                      - 1269
                      - 634
                      - 1268
                      - 635
                      - 1507
                      - 424
                      - 1508
                      text: but
                    - boundingBox:
                      - 667
                      - 1268
                      - 808
                      - 1268
                      - 809
                      - 1506
                      - 668
                      - 1507
                      text: in
                    - boundingBox:
                      - 874
                      - 1267
                      - 1289
                      - 1265
                      - 1290
                      - 1504
                      - 875
                      - 1506
                      text: rising
                    - boundingBox:
                      - 1331
                      - 1265
                      - 1771
                      - 1263
                      - 1772
                      - 1502
                      - 1332
                      - 1504
                      text: every
                    - boundingBox:
                      - 1812
                      - 1263
                      - 2178
                      - 1261
                      - 2179
                      - 1500
                      - 1813
                      - 1502
                      text: time
                    - boundingBox:
                      - 2219
                      - 1261
                      - 2510
                      - 1260
                      - 2511
                      - 1498
                      - 2220
                      - 1500
                      text: we
                    - boundingBox:
                      - 2551
                      - 1260
                      - 3016
                      - 1258
                      - 3017
                      - 1496
                      - 2552
                      - 1498
                      text: fall
                  - boundingBox:
                    - 1612
                    - 903
                    - 2744
                    - 935
                    - 2738
                    - 1139
                    - 1607
                    - 1107
                    text: in never failing ,
                    words:
                    - boundingBox:
                      - 1611
                      - 934
                      - 1707
                      - 933
                      - 1708
                      - 1147
                      - 1613
                      - 1147
                      text: in
                    - boundingBox:
                      - 1753
                      - 933
                      - 2132
                      - 930
                      - 2133
                      - 1144
                      - 1754
                      - 1146
                      text: never
                    - boundingBox:
                      - 2162
                      - 930
                      - 2673
                      - 927
                      - 2674
                      - 1140
                      - 2164
                      - 1144
                      text: failing
                    - boundingBox:
                      - 2703
                      - 926
                      - 2788
                      - 926
                      - 2790
                      - 1139
                      - 2705
                      - 1140
                      text: ','
                status: Succeeded
              header: []
schemes:
- https
definitions: !php/object "O:8:\"stdClass\":30:{s:9:\"AdultInfo\";O:8:\"stdClass\":3:{s:11:\"description\";s:86:\"An
  object describing whether the image contains adult-oriented content and/or is racy.\";s:10:\"properties\";O:8:\"stdClass\":4:{s:10:\"adultScore\";O:8:\"stdClass\":4:{s:11:\"description\";s:79:\"Score
  from 0 to 1 that indicates how much of adult content is within the image.\";s:6:\"format\";s:6:\"double\";s:4:\"type\";s:6:\"number\";s:10:\"x-nullable\";b:0;}s:14:\"isAdultContent\";O:8:\"stdClass\":3:{s:11:\"description\";s:64:\"A
  value indicating if the image contains adult-oriented content.\";s:4:\"type\";s:7:\"boolean\";s:10:\"x-nullable\";b:0;}s:13:\"isRacyContent\";O:8:\"stdClass\":3:{s:11:\"description\";s:40:\"A
  value indicating if the image is race.\";s:4:\"type\";s:7:\"boolean\";s:10:\"x-nullable\";b:0;}s:9:\"racyScore\";O:8:\"stdClass\":4:{s:11:\"description\";s:61:\"Score
  from 0 to 1 that indicates how suggestive is the image.\";s:6:\"format\";s:6:\"double\";s:4:\"type\";s:6:\"number\";s:10:\"x-nullable\";b:0;}}s:4:\"type\";s:6:\"object\";}s:11:\"BoundingBox\";O:8:\"stdClass\":2:{s:5:\"items\";O:8:\"stdClass\":2:{s:4:\"type\";s:7:\"integer\";s:10:\"x-nullable\";b:0;}s:4:\"type\";s:5:\"array\";}s:8:\"Category\";O:8:\"stdClass\":3:{s:11:\"description\";s:41:\"An
  object describing identified category.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:6:\"detail\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:28:\"#/definitions/CategoryDetail\";}s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:21:\"Name
  of the category.\";s:4:\"type\";s:6:\"string\";}s:5:\"score\";O:8:\"stdClass\":3:{s:11:\"description\";s:24:\"Scoring
  of the category.\";s:6:\"format\";s:6:\"double\";s:4:\"type\";s:6:\"number\";}}s:4:\"type\";s:6:\"object\";}s:14:\"CategoryDetail\";O:8:\"stdClass\":3:{s:11:\"description\";s:49:\"An
  object describing additional category details.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:11:\"celebrities\";O:8:\"stdClass\":3:{s:11:\"description\";s:42:\"An
  array of celebrities if any identified.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:30:\"#/definitions/CelebritiesModel\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:16:\"CelebritiesModel\";O:8:\"stdClass\":3:{s:11:\"description\";s:55:\"An
  object describing possible celebrity identification.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:10:\"confidence\";O:8:\"stdClass\":3:{s:11:\"description\";s:40:\"Level
  of confidence ranging from 0 to 1.\";s:6:\"format\";s:6:\"double\";s:4:\"type\";s:6:\"number\";}s:13:\"faceRectangle\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:27:\"#/definitions/FaceRectangle\";}s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:22:\"Name
  of the celebrity.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:9:\"ColorInfo\";O:8:\"stdClass\":3:{s:11:\"description\";s:68:\"An
  object providing additional metadata describing color attributes.\";s:10:\"properties\";O:8:\"stdClass\":5:{s:11:\"accentColor\";O:8:\"stdClass\":2:{s:11:\"description\";s:22:\"Possible
  accent color.\";s:4:\"type\";s:6:\"string\";}s:23:\"dominantColorBackground\";O:8:\"stdClass\":2:{s:11:\"description\";s:35:\"Possible
  dominant background color.\";s:4:\"type\";s:6:\"string\";}s:23:\"dominantColorForeground\";O:8:\"stdClass\":2:{s:11:\"description\";s:35:\"Possible
  dominant foreground color.\";s:4:\"type\";s:6:\"string\";}s:14:\"dominantColors\";O:8:\"stdClass\":3:{s:11:\"description\";s:37:\"An
  array of possible dominant colors.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:4:\"type\";s:5:\"array\";}s:7:\"isBWImg\";O:8:\"stdClass\":2:{s:11:\"description\";s:51:\"A
  value indicating if the image is black and white.\";s:4:\"type\";s:7:\"boolean\";}}s:4:\"type\";s:6:\"object\";}s:19:\"ComputerVisionError\";O:8:\"stdClass\":3:{s:10:\"properties\";O:8:\"stdClass\":3:{s:4:\"code\";O:8:\"stdClass\":4:{s:11:\"description\";s:15:\"The
  error code.\";s:4:\"enum\";a:13:{i:0;s:15:\"InvalidImageUrl\";i:1;s:18:\"InvalidImageFormat\";i:2;s:16:\"InvalidImageSize\";i:3;s:25:\"NotSupportedVisualFeature\";i:4;s:17:\"NotSupportedImage\";i:5;s:14:\"InvalidDetails\";i:6;s:20:\"NotSupportedLanguage\";i:7;s:11:\"BadArgument\";i:8;s:15:\"FailedToProcess\";i:9;s:7:\"Timeout\";i:10;s:19:\"InternalServerError\";i:11;s:11:\"Unspecified\";i:12;s:16:\"StorageException\";}s:4:\"type\";s:6:\"string\";s:9:\"x-ms-enum\";O:8:\"stdClass\":2:{s:13:\"modelAsString\";b:0;s:4:\"name\";s:24:\"ComputerVisionErrorCodes\";}}s:7:\"message\";O:8:\"stdClass\":2:{s:11:\"description\";s:55:\"A
  message explaining the error reported by the service.\";s:4:\"type\";s:6:\"string\";}s:9:\"requestId\";O:8:\"stdClass\":2:{s:11:\"description\";s:28:\"A
  unique request identifier.\";s:4:\"type\";s:6:\"string\";}}s:8:\"required\";a:2:{i:0;s:4:\"code\";i:1;s:7:\"message\";}s:4:\"type\";s:6:\"object\";}s:17:\"DomainModelResult\";O:8:\"stdClass\":2:{s:10:\"properties\";O:8:\"stdClass\":1:{s:11:\"celebrities\";O:8:\"stdClass\":3:{s:11:\"description\";s:57:\"An
  array of possible celebritied identified in the image.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:30:\"#/definitions/CelebritiesModel\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:18:\"DomainModelResults\";O:8:\"stdClass\":3:{s:11:\"description\";s:85:\"Result
  of image analysis using a specific domain model including additional metadata.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:8:\"metadata\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:27:\"#/definitions/ImageMetadata\";}s:9:\"requestId\";O:8:\"stdClass\":2:{s:11:\"description\";s:27:\"Id
  of the REST API request.\";s:4:\"type\";s:6:\"string\";}s:6:\"result\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/DomainModelResult\";s:19:\"x-ms-client-flatten\";b:1;}}s:4:\"type\";s:6:\"object\";}s:15:\"FaceDescription\";O:8:\"stdClass\":3:{s:11:\"description\";s:52:\"An
  object describing a face identified in the image.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:3:\"age\";O:8:\"stdClass\":2:{s:11:\"description\";s:25:\"Possible
  age of the face.\";s:4:\"type\";s:7:\"integer\";}s:13:\"faceRectangle\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:27:\"#/definitions/FaceRectangle\";}s:6:\"gender\";O:8:\"stdClass\":4:{s:11:\"description\";s:28:\"Possible
  gender of the face.\";s:4:\"enum\";a:2:{i:0;s:4:\"Male\";i:1;s:6:\"Female\";}s:4:\"type\";s:6:\"string\";s:9:\"x-ms-enum\";O:8:\"stdClass\":2:{s:13:\"modelAsString\";b:0;s:4:\"name\";s:7:\"Gender-\";}}}s:4:\"type\";s:6:\"object\";}s:13:\"FaceRectangle\";O:8:\"stdClass\":3:{s:11:\"description\";s:36:\"An
  object describing face rectangle.\";s:10:\"properties\";O:8:\"stdClass\":4:{s:6:\"height\";O:8:\"stdClass\":2:{s:11:\"description\";s:52:\"Height
  measured from the top-left point of the face.\";s:4:\"type\";s:7:\"integer\";}s:4:\"left\";O:8:\"stdClass\":2:{s:11:\"description\";s:47:\"X-coordinate
  of the top left point of the face.\";s:4:\"type\";s:7:\"integer\";}s:3:\"top\";O:8:\"stdClass\":2:{s:11:\"description\";s:47:\"Y-coordinate
  of the top left point of the face.\";s:4:\"type\";s:7:\"integer\";}s:5:\"width\";O:8:\"stdClass\":2:{s:11:\"description\";s:51:\"Width
  measured from the top-left point of the face.\";s:4:\"type\";s:7:\"integer\";}}s:4:\"type\";s:6:\"object\";}s:13:\"ImageAnalysis\";O:8:\"stdClass\":3:{s:11:\"description\";s:33:\"Result
  of AnalyzeImage operation.\";s:10:\"properties\";O:8:\"stdClass\":9:{s:5:\"adult\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:23:\"#/definitions/AdultInfo\";}s:10:\"categories\";O:8:\"stdClass\":3:{s:11:\"description\";s:42:\"An
  array indicating identified categories.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:22:\"#/definitions/Category\";}s:4:\"type\";s:5:\"array\";}s:5:\"color\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:23:\"#/definitions/ColorInfo\";}s:11:\"description\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:37:\"#/definitions/ImageDescriptionDetails\";}s:5:\"faces\";O:8:\"stdClass\":3:{s:11:\"description\";s:44:\"An
  array of possible faces within the image.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:29:\"#/definitions/FaceDescription\";}s:4:\"type\";s:5:\"array\";}s:9:\"imageType\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:23:\"#/definitions/ImageType\";}s:8:\"metadata\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:27:\"#/definitions/ImageMetadata\";}s:9:\"requestId\";O:8:\"stdClass\":2:{s:11:\"description\";s:40:\"Id
  of the request for tracking purposes.\";s:4:\"type\";s:6:\"string\";}s:4:\"tags\";O:8:\"stdClass\":3:{s:11:\"description\";s:37:\"A
  list of tags with confidence level.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:22:\"#/definitions/ImageTag\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:12:\"ImageCaption\";O:8:\"stdClass\":3:{s:11:\"description\";s:69:\"An
  image caption, i.e. a brief description of what the image depicts.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:10:\"confidence\";O:8:\"stdClass\":3:{s:11:\"description\";s:54:\"The
  level of confidence the service has in the caption\";s:6:\"format\";s:6:\"double\";s:4:\"type\";s:6:\"number\";}s:4:\"text\";O:8:\"stdClass\":2:{s:11:\"description\";s:23:\"The
  text of the caption\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:16:\"ImageDescription\";O:8:\"stdClass\":3:{s:11:\"description\";s:107:\"A
  collection of content tags, along with a list of captions sorted by confidence level,
  and image metadata.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:11:\"description\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/ImageDescriptionDetails\";s:19:\"x-ms-client-flatten\";b:1;}}s:4:\"type\";s:6:\"object\";}s:23:\"ImageDescriptionDetails\";O:8:\"stdClass\":3:{s:11:\"description\";s:107:\"A
  collection of content tags, along with a list of captions sorted by confidence level,
  and image metadata.\";s:10:\"properties\";O:8:\"stdClass\":4:{s:8:\"captions\";O:8:\"stdClass\":3:{s:11:\"description\";s:47:\"A
  list of captions, sorted by confidence level.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:26:\"#/definitions/ImageCaption\";}s:4:\"type\";s:5:\"array\";}s:8:\"metadata\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:27:\"#/definitions/ImageMetadata\";}s:9:\"requestId\";O:8:\"stdClass\":2:{s:11:\"description\";s:27:\"Id
  of the REST API request.\";s:4:\"type\";s:6:\"string\";}s:4:\"tags\";O:8:\"stdClass\":3:{s:11:\"description\";s:27:\"A
  collection of image tags.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:13:\"ImageMetadata\";O:8:\"stdClass\":3:{s:11:\"description\";s:14:\"Image
  metadata\";s:10:\"properties\";O:8:\"stdClass\":3:{s:6:\"format\";O:8:\"stdClass\":2:{s:11:\"description\";s:12:\"Image
  format\";s:4:\"type\";s:6:\"string\";}s:6:\"height\";O:8:\"stdClass\":3:{s:11:\"description\";s:12:\"Image
  height\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}s:5:\"width\";O:8:\"stdClass\":3:{s:11:\"description\";s:11:\"Image
  width\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}}s:4:\"type\";s:6:\"object\";}s:8:\"ImageTag\";O:8:\"stdClass\":3:{s:11:\"description\";s:69:\"An
  image caption, i.e. a brief description of what the image depicts.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:10:\"confidence\";O:8:\"stdClass\":3:{s:11:\"description\";s:54:\"The
  level of confidence the service has in the caption\";s:6:\"format\";s:6:\"double\";s:4:\"type\";s:6:\"number\";}s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:13:\"The
  tag value\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:9:\"ImageType\";O:8:\"stdClass\":3:{s:11:\"description\";s:72:\"An
  object providing possible image types and matching confidence levels.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:11:\"clipArtType\";O:8:\"stdClass\":2:{s:11:\"description\";s:46:\"Confidence
  level that the image is a clip art.\";s:4:\"type\";s:6:\"number\";}s:15:\"lineDrawingType\";O:8:\"stdClass\":2:{s:11:\"description\";s:50:\"Confidence
  level that the image is a line drawing.\";s:4:\"type\";s:6:\"number\";}}s:4:\"type\";s:6:\"object\";}s:4:\"Line\";O:8:\"stdClass\":2:{s:10:\"properties\";O:8:\"stdClass\":3:{s:11:\"boundingBox\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:25:\"#/definitions/BoundingBox\";}s:4:\"text\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:5:\"words\";O:8:\"stdClass\":2:{s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:18:\"#/definitions/Word\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:16:\"ListModelsResult\";O:8:\"stdClass\":3:{s:11:\"description\";s:43:\"Result
  of the List Domain Models operation.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:6:\"models\";O:8:\"stdClass\":4:{s:11:\"description\";s:29:\"An
  array of supported models.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:30:\"#/definitions/ModelDescription\";}s:8:\"readOnly\";b:1;s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:16:\"ModelDescription\";O:8:\"stdClass\":3:{s:11:\"description\";s:60:\"An
  object describing supported model by name and categories.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:10:\"categories\";O:8:\"stdClass\":2:{s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:4:\"type\";s:5:\"array\";}s:4:\"name\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:7:\"OcrLine\";O:8:\"stdClass\":3:{s:11:\"description\";s:54:\"An
  object describing a single recognized line of text.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:11:\"boundingBox\";O:8:\"stdClass\":2:{s:11:\"description\";s:392:\"Bounding
  box of a recognized line. The four integers represent the x-coordinate of the left
  edge, the y-coordinate of the top edge, width, and height of the bounding box, in
  the coordinate system of the input image, after it has been rotated around its center
  according to the detected text angle (see textAngle property), with the origin at
  the top-left corner, and the y-axis pointing down.\";s:4:\"type\";s:6:\"string\";}s:5:\"words\";O:8:\"stdClass\":3:{s:11:\"description\";s:68:\"An
  array of objects, where each object represents a recognized word.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:21:\"#/definitions/OcrWord\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:9:\"OcrRegion\";O:8:\"stdClass\":3:{s:11:\"description\";s:87:\"A
  region consists of multiple lines (e.g. a column of text in a multi-column document).\";s:10:\"properties\";O:8:\"stdClass\":2:{s:11:\"boundingBox\";O:8:\"stdClass\":2:{s:11:\"description\";s:394:\"Bounding
  box of a recognized region. The four integers represent the x-coordinate of the
  left edge, the y-coordinate of the top edge, width, and height of the bounding box,
  in the coordinate system of the input image, after it has been rotated around its
  center according to the detected text angle (see textAngle property), with the origin
  at the top-left corner, and the y-axis pointing down.\";s:4:\"type\";s:6:\"string\";}s:5:\"lines\";O:8:\"stdClass\":2:{s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:21:\"#/definitions/OcrLine\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:9:\"OcrResult\";O:8:\"stdClass\":2:{s:10:\"properties\";O:8:\"stdClass\":4:{s:8:\"language\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:23:\"#/definitions/OcrResult\";}s:11:\"orientation\";O:8:\"stdClass\":2:{s:11:\"description\";s:268:\"Orientation
  of the text recognized in the image. The value (up,down,left, or right) refers to
  the direction that the top of the recognized text is facing, after the image has
  been rotated around its center according to the detected text angle (see textAngle
  property).\";s:4:\"type\";s:6:\"string\";}s:7:\"regions\";O:8:\"stdClass\":3:{s:11:\"description\";s:78:\"An
  array of objects, where each object represents a region of recognized text.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:23:\"#/definitions/OcrRegion\";}s:4:\"type\";s:5:\"array\";}s:9:\"textAngle\";O:8:\"stdClass\":3:{s:11:\"description\";s:639:\"The
  angle, in degrees, of the detected text with respect to the closest horizontal or
  vertical direction. After rotating the input image clockwise by this angle, the
  recognized text lines become horizontal or vertical. In combination with the orientation
  property it can be used to overlay recognition results correctly on the original
  image, by rotating either the original image or recognition results by a suitable
  angle around the center of the original image. If the angle cannot be confidently
  detected, this property is not present. If the image contains text at different
  angles, only part of the text will be recognized correctly.\";s:6:\"format\";s:6:\"double\";s:4:\"type\";s:6:\"number\";}}s:4:\"type\";s:6:\"object\";}s:7:\"OcrWord\";O:8:\"stdClass\":3:{s:11:\"description\";s:33:\"Information
  on a recognized word.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:11:\"boundingBox\";O:8:\"stdClass\":2:{s:11:\"description\";s:392:\"Bounding
  box of a recognized word. The four integers represent the x-coordinate of the left
  edge, the y-coordinate of the top edge, width, and height of the bounding box, in
  the coordinate system of the input image, after it has been rotated around its center
  according to the detected text angle (see textAngle property), with the origin at
  the top-left corner, and the y-axis pointing down.\";s:4:\"type\";s:6:\"string\";}s:4:\"text\";O:8:\"stdClass\":2:{s:11:\"description\";s:34:\"String
  value of a recognized word.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:17:\"RecognitionResult\";O:8:\"stdClass\":2:{s:10:\"properties\";O:8:\"stdClass\":1:{s:5:\"lines\";O:8:\"stdClass\":2:{s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:18:\"#/definitions/Line\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:15:\"ServiceLanguage\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:9:\"TagResult\";O:8:\"stdClass\":3:{s:11:\"description\";s:76:\"The
  results of a image tag operation, including any tags and image metadata.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:8:\"metadata\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:27:\"#/definitions/ImageMetadata\";}s:9:\"requestId\";O:8:\"stdClass\":2:{s:11:\"description\";s:27:\"Id
  of the REST API request.\";s:4:\"type\";s:6:\"string\";}s:4:\"tags\";O:8:\"stdClass\":3:{s:11:\"description\";s:37:\"A
  list of tags with confidence level.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:22:\"#/definitions/ImageTag\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:19:\"TextOperationResult\";O:8:\"stdClass\":2:{s:10:\"properties\";O:8:\"stdClass\":2:{s:17:\"recognitionResult\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:31:\"#/definitions/RecognitionResult\";}s:6:\"status\";O:8:\"stdClass\":5:{s:11:\"description\";s:29:\"Status
  of the text operation.\";s:4:\"enum\";a:4:{i:0;s:11:\"Not Started\";i:1;s:7:\"Running\";i:2;s:6:\"Failed\";i:3;s:9:\"Succeeded\";}s:4:\"type\";s:6:\"string\";s:9:\"x-ms-enum\";O:8:\"stdClass\":2:{s:13:\"modelAsString\";b:0;s:4:\"name\";s:24:\"TextOperationStatusCodes\";}s:10:\"x-nullable\";b:0;}}s:4:\"type\";s:6:\"object\";}s:4:\"Word\";O:8:\"stdClass\":2:{s:10:\"properties\";O:8:\"stdClass\":2:{s:11:\"boundingBox\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:25:\"#/definitions/BoundingBox\";}s:4:\"text\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}}"
...
