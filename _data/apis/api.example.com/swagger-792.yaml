---
swagger: "2.0"
info: !php/object "O:8:\"stdClass\":2:{s:5:\"title\";s:13:\"tensor-bridge\";s:7:\"version\";s:5:\"0.0.1\";}"
paths:
  /tensor-bridge/v1/classification:
    post:
      summary: Classify.
      operationId: Classify
      responses:
        200:
          description: ""
          schema:
            $ref: '#/definitions/servingClassificationResponse'
      parameters:
      - name: body
        in: body
        required: true
        schema:
          $ref: '#/definitions/servingClassificationRequest'
      tags:
      - PredictionService
  /tensor-bridge/v1/modelmetadata:
    post:
      summary: GetModelMetadata - provides access to metadata for loaded models.
      operationId: GetModelMetadata
      responses:
        200:
          description: ""
          schema:
            $ref: '#/definitions/servingGetModelMetadataResponse'
      parameters:
      - name: body
        in: body
        required: true
        schema:
          $ref: '#/definitions/servingGetModelMetadataRequest'
      tags:
      - PredictionService
  /tensor-bridge/v1/multi-inference:
    post:
      summary: MultiInference API for multi-headed models.
      operationId: MultiInference
      responses:
        200:
          description: ""
          schema:
            $ref: '#/definitions/servingMultiInferenceResponse'
      parameters:
      - name: body
        in: body
        required: true
        schema:
          $ref: '#/definitions/servingMultiInferenceRequest'
      tags:
      - PredictionService
  /tensor-bridge/v1/prediction:
    post:
      summary: Predict -- provides access to loaded TensorFlow model.
      operationId: Predict
      responses:
        200:
          description: ""
          schema:
            $ref: '#/definitions/servingPredictResponse'
      parameters:
      - name: body
        in: body
        required: true
        schema:
          $ref: '#/definitions/servingPredictRequest'
      tags:
      - PredictionService
  /tensor-bridge/v1/regression:
    post:
      summary: Regress.
      operationId: Regress
      responses:
        200:
          description: ""
          schema:
            $ref: '#/definitions/servingRegressionResponse'
      parameters:
      - name: body
        in: body
        required: true
        schema:
          $ref: '#/definitions/servingRegressionRequest'
      tags:
      - PredictionService
produces:
- application/json
schemes:
- http
- https
definitions: !php/object "O:8:\"stdClass\":34:{s:19:\"TensorShapeProtoDim\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":2:{s:4:\"size\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"string\";s:6:\"format\";s:5:\"int64\";s:11:\"description\";s:293:\"Size
  of the tensor in that dimension.\nThis value must be >= -1, but values of -1 are
  reserved for \"unknown\"\nshapes (values of -1 mean \"unknown\" dimension).  Certain
  wrappers\nthat work with TensorShapeProto may fail at runtime when deserializing\na
  TensorShapeProto containing a dim value of -1.\";}s:4:\"name\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"string\";s:11:\"description\";s:38:\"Optional
  name of the tensor dimension.\";}}s:11:\"description\";s:28:\"One dimension of the
  tensor.\";}s:11:\"protobufAny\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":2:{s:8:\"type_url\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"string\";s:11:\"description\";s:961:\"A
  URL/resource name whose content describes the type of the\nserialized protocol buffer
  message.\n\nFor URLs which use the scheme `http`, `https`, or no scheme, the\nfollowing
  restrictions and interpretations apply:\n\n* If no scheme is provided, `https` is
  assumed.\n* The last segment of the URL's path must represent the fully\n  qualified
  name of the type (as in `path/google.protobuf.Duration`).\n  The name should be
  in a canonical form (e.g., leading \".\" is\n  not accepted).\n* An HTTP GET on
  the URL must yield a [google.protobuf.Type][]\n  value in binary format, or produce
  an error.\n* Applications are allowed to cache lookup results based on the\n  URL,
  or have them precompiled into a binary to avoid any\n  lookup. Therefore, binary
  compatibility needs to be preserved\n  on changes to types. (Use versioned type
  names to manage\n  breaking changes.)\n\nSchemes other than `http`, `https` (or
  the empty scheme) might be\nused with implementation specific semantics.\";}s:5:\"value\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"string\";s:6:\"format\";s:4:\"byte\";s:11:\"description\";s:71:\"Must
  be a valid serialized protocol buffer of the above specified type.\";}}s:11:\"description\";s:1850:\"`Any`
  contains an arbitrary serialized protocol buffer message along with a\nURL that
  describes the type of the serialized message.\n\nProtobuf library provides support
  to pack/unpack Any values in the form\nof utility functions or additional generated
  methods of the Any type.\n\nExample 1: Pack and unpack a message in C++.\n\n    Foo
  foo = ...;\n    Any any;\n    any.PackFrom(foo);\n    ...\n    if (any.UnpackTo(&foo))
  {\n      ...\n    }\n\nExample 2: Pack and unpack a message in Java.\n\n    Foo
  foo = ...;\n    Any any = Any.pack(foo);\n    ...\n    if (any.is(Foo.class)) {\n
  \     foo = any.unpack(Foo.class);\n    }\n\n Example 3: Pack and unpack a message
  in Python.\n\n    foo = Foo(...)\n    any = Any()\n    any.Pack(foo)\n    ...\n
  \   if any.Is(Foo.DESCRIPTOR):\n      any.Unpack(foo)\n      ...\n\nThe pack methods
  provided by protobuf library will by default use\n'type.googleapis.com/full.type.name'
  as the type URL and the unpack\nmethods only use the fully qualified type name after
  the last '/'\nin the type URL, for example \"foo.bar.com/x/y.z\" will yield type\nname
  \"y.z\".\n\n\nJSON\n====\nThe JSON representation of an `Any` value uses the regular\nrepresentation
  of the deserialized, embedded message, with an\nadditional field `@type` which contains
  the type URL. Example:\n\n    package google.profile;\n    message Person {\n      string
  first_name = 1;\n      string last_name = 2;\n    }\n\n    {\n      \"@type\": \"type.googleapis.com/google.profile.Person\",\n
  \     \"firstName\": <string>,\n      \"lastName\": <string>\n    }\n\nIf the embedded
  message type is well-known and has a custom JSON\nrepresentation, that representation
  will be embedded adding a field\n`value` which holds the custom JSON in addition
  to the `@type`\nfield. Example (for message [google.protobuf.Duration][]):\n\n    {\n
  \     \"@type\": \"type.googleapis.com/google.protobuf.Duration\",\n      \"value\":
  \"1.212s\"\n    }\";}s:18:\"protobufInt64Value\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":1:{s:5:\"value\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"string\";s:6:\"format\";s:5:\"int64\";s:11:\"description\";s:16:\"The
  int64 value.\";}}s:11:\"description\";s:86:\"Wrapper message for `int64`.\n\nThe
  JSON representation for `Int64Value` is JSON string.\";}s:12:\"servingClass\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":2:{s:5:\"label\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"string\";s:11:\"description\";s:27:\"Label
  or name of the class.\";}s:5:\"score\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"number\";s:6:\"format\";s:5:\"float\";s:11:\"description\";s:76:\"Score
  for this class (e.g., the probability the item belongs to this\nclass).\";}}s:11:\"description\";s:15:\"A
  single class.\";}s:28:\"servingClassificationRequest\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":2:{s:10:\"model_spec\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:30:\"#/definitions/servingModelSpec\";s:11:\"description\";s:20:\"Model
  Specification.\";}s:5:\"input\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:26:\"#/definitions/servingInput\";s:11:\"description\";s:11:\"Input
  data.\";}}}s:29:\"servingClassificationResponse\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":1:{s:6:\"result\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:41:\"#/definitions/servingClassificationResult\";s:11:\"description\";s:29:\"Result
  of the classification.\";}}}s:27:\"servingClassificationResult\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":1:{s:15:\"classifications\";O:8:\"stdClass\":2:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:36:\"#/definitions/servingClassifications\";}}}s:11:\"description\";s:95:\"Contains
  one result per input example, in the same order as the input in\nClassificationRequest.\";}s:22:\"servingClassifications\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":1:{s:7:\"classes\";O:8:\"stdClass\":2:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:26:\"#/definitions/servingClass\";}}}s:11:\"description\";s:55:\"List
  of classes for a single item (tensorflow.Example).\";}s:18:\"servingExampleList\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":1:{s:8:\"examples\";O:8:\"stdClass\":2:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:31:\"#/definitions/tensorflowExample\";}}}s:5:\"title\";s:167:\"Specifies
  one or more fully independent input Examples.\nSee examples at:\n    https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/example.proto\";}s:29:\"servingExampleListWithContext\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":2:{s:8:\"examples\";O:8:\"stdClass\":2:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:31:\"#/definitions/tensorflowExample\";}}s:7:\"context\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:31:\"#/definitions/tensorflowExample\";}}s:11:\"description\";s:1031:\"Specifies
  one or more independent input Examples, with a common context\nExample.\n\nThe common
  use case for context is to cleanly and optimally specify some\nfeatures that are
  common across multiple examples.\n\nSee example below with a search query as the
  context and multiple restaurants\nto perform some inference on.\n\ncontext: {\n
  \ feature: {\n    key  : \"query\"\n    value: {\n      bytes_list: {\n        value:
  [ \"pizza\" ]\n      }\n    }\n  }\n}\nexamples: {\n  feature: {\n    key  : \"cuisine\"\n
  \   value: {\n      bytes_list: {\n        value: [ \"Pizzeria\" ]\n      }\n    }\n
  \ }\n}\nexamples: {\n  feature: {\n    key  : \"cuisine\"\n    value: {\n      bytes_list:
  {\n        value: [ \"Taqueria\" ]\n      }\n    }\n  }\n}\n\nImplementations of
  ExampleListWithContext merge the context Example into each\nof the Examples. Note
  that feature keys must not be duplicated between the\nExamples and context Example,
  or the behavior is undefined.\n\nSee also:\n    tensorflow/core/example/example.proto\n
  \   https://developers.google.com/protocol-buffers/docs/proto3#maps\";}s:30:\"servingGetModelMetadataRequest\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":2:{s:10:\"model_spec\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:30:\"#/definitions/servingModelSpec\";s:11:\"description\";s:72:\"Model
  Specification indicating which model we are querying for metadata.\";}s:14:\"metadata_field\";O:8:\"stdClass\":3:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:11:\"description\";s:61:\"Metadata
  fields to get. Currently supported: \"signature_def\".\";}}}s:31:\"servingGetModelMetadataResponse\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":2:{s:10:\"model_spec\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:30:\"#/definitions/servingModelSpec\";s:11:\"description\";s:68:\"Model
  Specification indicating which model this metadata belongs to.\";}s:8:\"metadata\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:25:\"#/definitions/protobufAny\";}s:11:\"description\";s:158:\"Map
  of metadata field name to metadata field. The options for metadata\nfield name are
  listed in GetModelMetadataRequest. Currently supported:\n\"signature_def\".\";}}}s:22:\"servingInferenceResult\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":3:{s:10:\"model_spec\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:30:\"#/definitions/servingModelSpec\";}s:21:\"classification_result\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:41:\"#/definitions/servingClassificationResult\";}s:17:\"regression_result\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:37:\"#/definitions/servingRegressionResult\";}}s:11:\"description\";s:61:\"Inference
  result, matches the type of request or is an error.\";}s:20:\"servingInferenceTask\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":2:{s:10:\"model_spec\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:30:\"#/definitions/servingModelSpec\";}s:11:\"method_name\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"string\";s:11:\"description\";s:171:\"Signature's
  method_name. Should be one of the method names defined in\nthird_party/tensorflow/python/saved_model/signature_constants.py.\ne.g.
  \"tensorflow/serving/classify\".\";}}s:11:\"description\";s:60:\"Inference request
  such as classification, regression, etc...\";}s:12:\"servingInput\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":2:{s:12:\"example_list\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:32:\"#/definitions/servingExampleList\";}s:25:\"example_list_with_context\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:43:\"#/definitions/servingExampleListWithContext\";}}}s:16:\"servingModelSpec\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":3:{s:4:\"name\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"string\";s:11:\"description\";s:23:\"Required
  servable name.\";}s:7:\"version\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/protobufInt64Value\";s:11:\"description\";s:230:\"Optional
  version. If unspecified, will use the latest (numerical) version.\nTypically not
  needed unless coordinating across multiple models that were\nco-trained and/or have
  inter-dependencies on the versions used at inference\ntime.\";}s:14:\"signature_name\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"string\";s:11:\"description\";s:141:\"A
  named signature to evaluate. If unspecified, the default signature will\nbe used.
  Note that only MultiInference will initially support this.\";}}s:11:\"description\";s:69:\"Metadata
  for an inference request such as the model name and version.\";}s:28:\"servingMultiInferenceRequest\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":2:{s:5:\"tasks\";O:8:\"stdClass\":3:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:34:\"#/definitions/servingInferenceTask\";}s:11:\"description\";s:16:\"Inference
  tasks.\";}s:5:\"input\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:26:\"#/definitions/servingInput\";s:11:\"description\";s:11:\"Input
  data.\";}}s:11:\"description\";s:50:\"Inference request containing one or more requests.\";}s:29:\"servingMultiInferenceResponse\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":1:{s:7:\"results\";O:8:\"stdClass\":3:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:36:\"#/definitions/servingInferenceResult\";}s:11:\"description\";s:102:\"List
  of results; one for each InferenceTask in the request, returned in the\nsame order
  as the request.\";}}s:11:\"description\";s:51:\"Inference request containing one
  or more responses.\";}s:21:\"servingPredictRequest\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":3:{s:10:\"model_spec\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:30:\"#/definitions/servingModelSpec\";s:11:\"description\";s:20:\"Model
  Specification.\";}s:6:\"inputs\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:35:\"#/definitions/tensorflowTensorProto\";}s:11:\"description\";s:321:\"Input
  tensors.\nNames of input tensor are alias names. The mapping from aliases to real\ninput
  tensor names is expected to be stored as named generic signature\nunder the key
  \"inputs\" in the model export.\nEach alias listed in a generic signature named
  \"inputs\" should be provided\nexactly once in order to run the prediction.\";}s:13:\"output_filter\";O:8:\"stdClass\":3:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:11:\"description\";s:386:\"Output
  filter.\nNames specified are alias names. The mapping from aliases to real output\ntensor
  names is expected to be stored as named generic signature under\nthe key \"outputs\"
  in the model export.\nOnly tensors specified here will be run/fetched and returned,
  with the\nexception that when none is specified, all tensors specified in the\nnamed
  signature will be run/fetched and returned.\";}}s:11:\"description\";s:154:\"PredictRequest
  specifies which TensorFlow model to run, as well as\nhow inputs are mapped to tensors
  and how outputs are filtered before\nreturning to user.\";}s:22:\"servingPredictResponse\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":1:{s:7:\"outputs\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:35:\"#/definitions/tensorflowTensorProto\";}s:11:\"description\";s:15:\"Output
  tensors.\";}}s:11:\"description\";s:46:\"Response for PredictRequest on successful
  run.\";}s:17:\"servingRegression\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":1:{s:5:\"value\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"number\";s:6:\"format\";s:5:\"float\";}}s:11:\"description\";s:57:\"Regression
  result for a single item (tensorflow.Example).\";}s:24:\"servingRegressionRequest\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":2:{s:10:\"model_spec\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:30:\"#/definitions/servingModelSpec\";s:11:\"description\";s:20:\"Model
  Specification.\";}s:5:\"input\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:26:\"#/definitions/servingInput\";s:11:\"description\";s:11:\"Input
  data.\";}}}s:25:\"servingRegressionResponse\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":1:{s:6:\"result\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:37:\"#/definitions/servingRegressionResult\";}}}s:23:\"servingRegressionResult\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":1:{s:11:\"regressions\";O:8:\"stdClass\":2:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:31:\"#/definitions/servingRegression\";}}}s:11:\"description\";s:91:\"Contains
  one result per input example, in the same order as the input in\nRegressionRequest.\";}s:19:\"tensorflowBytesList\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":1:{s:5:\"value\";O:8:\"stdClass\":2:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"string\";s:6:\"format\";s:4:\"byte\";}}}s:11:\"description\";s:47:\"Containers
  to hold repeated fundamental values.\";}s:18:\"tensorflowDataType\";O:8:\"stdClass\":5:{s:4:\"type\";s:6:\"string\";s:4:\"enum\";a:41:{i:0;s:10:\"DT_INVALID\";i:1;s:8:\"DT_FLOAT\";i:2;s:9:\"DT_DOUBLE\";i:3;s:8:\"DT_INT32\";i:4;s:8:\"DT_UINT8\";i:5;s:8:\"DT_INT16\";i:6;s:7:\"DT_INT8\";i:7;s:9:\"DT_STRING\";i:8;s:12:\"DT_COMPLEX64\";i:9;s:8:\"DT_INT64\";i:10;s:7:\"DT_BOOL\";i:11;s:8:\"DT_QINT8\";i:12;s:9:\"DT_QUINT8\";i:13;s:9:\"DT_QINT32\";i:14;s:11:\"DT_BFLOAT16\";i:15;s:9:\"DT_QINT16\";i:16;s:10:\"DT_QUINT16\";i:17;s:9:\"DT_UINT16\";i:18;s:13:\"DT_COMPLEX128\";i:19;s:7:\"DT_HALF\";i:20;s:11:\"DT_RESOURCE\";i:21;s:12:\"DT_FLOAT_REF\";i:22;s:13:\"DT_DOUBLE_REF\";i:23;s:12:\"DT_INT32_REF\";i:24;s:12:\"DT_UINT8_REF\";i:25;s:12:\"DT_INT16_REF\";i:26;s:11:\"DT_INT8_REF\";i:27;s:13:\"DT_STRING_REF\";i:28;s:16:\"DT_COMPLEX64_REF\";i:29;s:12:\"DT_INT64_REF\";i:30;s:11:\"DT_BOOL_REF\";i:31;s:12:\"DT_QINT8_REF\";i:32;s:13:\"DT_QUINT8_REF\";i:33;s:13:\"DT_QINT32_REF\";i:34;s:15:\"DT_BFLOAT16_REF\";i:35;s:13:\"DT_QINT16_REF\";i:36;s:14:\"DT_QUINT16_REF\";i:37;s:13:\"DT_UINT16_REF\";i:38;s:17:\"DT_COMPLEX128_REF\";i:39;s:11:\"DT_HALF_REF\";i:40;s:15:\"DT_RESOURCE_REF\";}s:7:\"default\";s:10:\"DT_INVALID\";s:11:\"description\";s:335:\"-
  DT_INVALID: Not a legal value for DataType.  Used to indicate a DataType field\nhas
  not been set.\n - DT_FLOAT: Data types that all computation devices are expected
  to be\ncapable to support.\n - DT_FLOAT_REF: Do not use!  These are only for parameters.
  \ Every enum above\nshould have a corresponding value below (verified by types_test).\";s:5:\"title\";s:13:\"LINT.IfChange\";}s:17:\"tensorflowExample\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":1:{s:8:\"features\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:32:\"#/definitions/tensorflowFeatures\";}}}s:17:\"tensorflowFeature\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":3:{s:10:\"bytes_list\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:33:\"#/definitions/tensorflowBytesList\";}s:10:\"float_list\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:33:\"#/definitions/tensorflowFloatList\";}s:10:\"int64_list\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:33:\"#/definitions/tensorflowInt64List\";}}s:11:\"description\";s:35:\"Containers
  for non-sequential data.\";}s:18:\"tensorflowFeatures\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":1:{s:7:\"feature\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:31:\"#/definitions/tensorflowFeature\";}s:11:\"description\";s:33:\"Map
  from feature name to feature.\";}}}s:19:\"tensorflowFloatList\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":1:{s:5:\"value\";O:8:\"stdClass\":2:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"number\";s:6:\"format\";s:5:\"float\";}}}}s:19:\"tensorflowInt64List\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":1:{s:5:\"value\";O:8:\"stdClass\":2:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"string\";s:6:\"format\";s:5:\"int64\";}}}}s:24:\"tensorflowResourceHandle\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":5:{s:6:\"device\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"string\";s:11:\"description\";s:51:\"Unique
  name for the device containing the resource.\";}s:9:\"container\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"string\";s:11:\"description\";s:43:\"Container
  in which this resource is placed.\";}s:4:\"name\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"string\";s:11:\"description\";s:29:\"Unique
  name of this resource.\";}s:9:\"hash_code\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"string\";s:6:\"format\";s:6:\"uint64\";s:11:\"description\";s:99:\"Hash
  code for the type of the resource. Is only valid in the same device\nand in the
  same execution.\";}s:15:\"maybe_type_name\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"string\";s:11:\"description\";s:77:\"For
  debug-only, the name of the type pointed to by this handle, if\navailable.\";}}s:11:\"description\";s:167:\"Protocol
  buffer representing a handle to a tensorflow resource. Handles are\nnot valid across
  executions, but can be serialized back and forth from within\na single run.\";}s:21:\"tensorflowTensorProto\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":14:{s:5:\"dtype\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:32:\"#/definitions/tensorflowDataType\";}s:12:\"tensor_shape\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:40:\"#/definitions/tensorflowTensorShapeProto\";s:11:\"description\";s:62:\"Shape
  of the tensor.  TODO(touts): sort out the 0-rank issues.\";}s:14:\"version_number\";O:8:\"stdClass\":3:{s:4:\"type\";s:7:\"integer\";s:6:\"format\";s:5:\"int32\";s:11:\"description\";s:210:\"Version
  number.\n\nIn version 0, if the \"repeated xxx\" representations contain only one\nelement,
  that element is repeated to fill the shape.  This makes it easy\nto represent a
  constant Tensor with a single value.\";}s:14:\"tensor_content\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"string\";s:6:\"format\";s:4:\"byte\";s:11:\"description\";s:324:\"Serialized
  raw tensor content from either Tensor::AsProtoTensorContent or\nmemcpy in tensorflow::grpc::EncodeTensorToByteBuffer.
  This representation\ncan be used for all tensor types. The purpose of this representation
  is to\nreduce serialization overhead during RPC call by avoiding serialization of\nmany
  repeated small items.\";}s:8:\"half_val\";O:8:\"stdClass\":3:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":2:{s:4:\"type\";s:7:\"integer\";s:6:\"format\";s:5:\"int32\";}s:11:\"description\";s:112:\"DT_HALF.
  Note that since protobuf has no int16 type, we'll have some\npointless zero padding
  for each value here.\";}s:9:\"float_val\";O:8:\"stdClass\":3:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"number\";s:6:\"format\";s:5:\"float\";}s:11:\"description\";s:9:\"DT_FLOAT.\";}s:10:\"double_val\";O:8:\"stdClass\":3:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"number\";s:6:\"format\";s:6:\"double\";}s:11:\"description\";s:10:\"DT_DOUBLE.\";}s:7:\"int_val\";O:8:\"stdClass\":3:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":2:{s:4:\"type\";s:7:\"integer\";s:6:\"format\";s:5:\"int32\";}s:11:\"description\";s:38:\"DT_INT32,
  DT_INT16, DT_INT8, DT_UINT8.\";}s:10:\"string_val\";O:8:\"stdClass\":3:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"string\";s:6:\"format\";s:4:\"byte\";}s:5:\"title\";s:9:\"DT_STRING\";}s:12:\"scomplex_val\";O:8:\"stdClass\":3:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"number\";s:6:\"format\";s:5:\"float\";}s:11:\"description\";s:118:\"DT_COMPLEX64.
  scomplex_val(2*i) and scomplex_val(2*i+1) are real\nand imaginary parts of i-th
  single precision complex.\";}s:9:\"int64_val\";O:8:\"stdClass\":3:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"string\";s:6:\"format\";s:5:\"int64\";}s:5:\"title\";s:8:\"DT_INT64\";}s:8:\"bool_val\";O:8:\"stdClass\":3:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":2:{s:4:\"type\";s:7:\"boolean\";s:6:\"format\";s:7:\"boolean\";}s:5:\"title\";s:7:\"DT_BOOL\";}s:12:\"dcomplex_val\";O:8:\"stdClass\":3:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":2:{s:4:\"type\";s:6:\"number\";s:6:\"format\";s:6:\"double\";}s:11:\"description\";s:119:\"DT_COMPLEX128.
  dcomplex_val(2*i) and dcomplex_val(2*i+1) are real\nand imaginary parts of i-th
  double precision complex.\";}s:19:\"resource_handle_val\";O:8:\"stdClass\":3:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:38:\"#/definitions/tensorflowResourceHandle\";}s:5:\"title\";s:11:\"DT_RESOURCE\";}}s:11:\"description\";s:38:\"Protocol
  buffer representing a tensor.\";}s:26:\"tensorflowTensorShapeProto\";O:8:\"stdClass\":3:{s:4:\"type\";s:6:\"object\";s:10:\"properties\";O:8:\"stdClass\":2:{s:3:\"dim\";O:8:\"stdClass\":3:{s:4:\"type\";s:5:\"array\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:33:\"#/definitions/TensorShapeProtoDim\";}s:11:\"description\";s:542:\"Dimensions
  of the tensor, such as {\"input\", 30}, {\"output\", 40}\nfor a 30 x 40 2D tensor.
  \ If an entry has size -1, this\ncorresponds to a dimension of unknown size. The
  names are\noptional.\n\nThe order of entries in \"dim\" matters: It indicates the
  layout of the\nvalues in the tensor in-memory representation.\n\nThe first entry
  in \"dim\" is the outermost dimension used to layout the\nvalues, the last entry
  is the innermost dimension.  This matches the\nin-memory layout of RowMajor Eigen
  tensors.\n\nIf \"dim.size()\" > 0, \"unknown_rank\" must be false.\";}s:12:\"unknown_rank\";O:8:\"stdClass\":3:{s:4:\"type\";s:7:\"boolean\";s:6:\"format\";s:7:\"boolean\";s:11:\"description\";s:92:\"If
  true, the number of dimensions in the shape is unknown.\n\nIf true, \"dim.size()\"
  must be 0.\";}}s:11:\"description\";s:23:\"Dimensions of a tensor.\";}}"
...
