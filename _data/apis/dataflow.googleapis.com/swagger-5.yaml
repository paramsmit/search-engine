---
swagger: "2.0"
info: !php/object "O:8:\"stdClass\":11:{s:7:\"contact\";O:8:\"stdClass\":2:{s:4:\"name\";s:6:\"Google\";s:3:\"url\";s:18:\"https://google.com\";}s:11:\"description\";s:64:\"Manages
  Google Cloud Dataflow projects on Google Cloud Platform.\";s:5:\"title\";s:8:\"Dataflow\";s:7:\"version\";s:4:\"v1b3\";s:23:\"x-apiClientRegistration\";O:8:\"stdClass\":1:{s:3:\"url\";s:37:\"https://console.developers.google.com\";}s:6:\"x-logo\";O:8:\"stdClass\":1:{s:3:\"url\";s:116:\"https://api.apis.guru/v2/cache/logo/https_www.google.com_images_branding_googlelogo_2x_googlelogo_color_272x92dp.png\";}s:8:\"x-origin\";a:1:{i:0;O:8:\"stdClass\":4:{s:9:\"converter\";O:8:\"stdClass\":2:{s:3:\"url\";s:45:\"https://github.com/lucybot/api-spec-converter\";s:7:\"version\";s:5:\"2.6.2\";}s:6:\"format\";s:6:\"google\";s:3:\"url\";s:60:\"https://dataflow.googleapis.com/$discovery/rest?version=v1b3\";s:7:\"version\";s:2:\"v1\";}}s:11:\"x-preferred\";b:1;s:14:\"x-providerName\";s:14:\"googleapis.com\";s:13:\"x-serviceName\";s:8:\"dataflow\";s:10:\"x-datafire\";O:8:\"stdClass\":2:{s:4:\"name\";s:15:\"google_dataflow\";s:4:\"type\";s:7:\"openapi\";}}"
host: dataflow.googleapis.com
basePath: /
paths:
  /v1b3/projects/{projectId}/WorkerMessages:
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
    post:
      description: Send a worker_message to the service.
      operationId: projects.workerMessages
      parameters:
      - in: body
        name: body
        schema:
          $ref: '#/definitions/SendWorkerMessagesRequest'
      - description: The project to send the WorkerMessages to.
        in: path
        name: projectId
        required: true
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/SendWorkerMessagesResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
  /v1b3/projects/{projectId}/jobs:
    get:
      description: List the jobs of a project in a given region.
      operationId: projects.jobs.list
      parameters:
      - description: The kind of filter to use.
        enum:
        - UNKNOWN
        - ALL
        - TERMINATED
        - ACTIVE
        in: query
        name: filter
        type: string
      - description: The location that contains this job.
        in: query
        name: location
        type: string
      - description: If there are many jobs, limit response to at most this many.nThe
          actual number of jobs returned will be the lesser of max_responsesnand an
          unspecified server-defined limit.
        in: query
        name: pageSize
        type: integer
      - description: Set this to the 'next_page_token' field of a previous responsento
          request additional results in a long list.
        in: query
        name: pageToken
        type: string
      - description: The project which owns the jobs.
        in: path
        name: projectId
        required: true
        type: string
      - description: Level of information requested in response. Default is `JOB_VIEW_SUMMARY`.
        enum:
        - JOB_VIEW_UNKNOWN
        - JOB_VIEW_SUMMARY
        - JOB_VIEW_ALL
        - JOB_VIEW_DESCRIPTION
        in: query
        name: view
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/ListJobsResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
    post:
      description: Creates a Cloud Dataflow job.
      operationId: projects.jobs.create
      parameters:
      - in: body
        name: body
        schema:
          $ref: '#/definitions/Job'
      - description: The location that contains this job.
        in: query
        name: location
        type: string
      - description: The ID of the Cloud Platform project that the job belongs to.
        in: path
        name: projectId
        required: true
        type: string
      - description: Deprecated. This field is now in the Job message.
        in: query
        name: replaceJobId
        type: string
      - description: The level of information requested in response.
        enum:
        - JOB_VIEW_UNKNOWN
        - JOB_VIEW_SUMMARY
        - JOB_VIEW_ALL
        - JOB_VIEW_DESCRIPTION
        in: query
        name: view
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/Job'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
  /v1b3/projects/{projectId}/jobs/{jobId}:
    get:
      description: Gets the state of the specified Cloud Dataflow job.
      operationId: projects.jobs.get
      parameters:
      - description: The job ID.
        in: path
        name: jobId
        required: true
        type: string
      - description: The location that contains this job.
        in: query
        name: location
        type: string
      - description: The ID of the Cloud Platform project that the job belongs to.
        in: path
        name: projectId
        required: true
        type: string
      - description: The level of information requested in response.
        enum:
        - JOB_VIEW_UNKNOWN
        - JOB_VIEW_SUMMARY
        - JOB_VIEW_ALL
        - JOB_VIEW_DESCRIPTION
        in: query
        name: view
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/Job'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
    put:
      description: Updates the state of an existing Cloud Dataflow job.
      operationId: projects.jobs.update
      parameters:
      - in: body
        name: body
        schema:
          $ref: '#/definitions/Job'
      - description: The job ID.
        in: path
        name: jobId
        required: true
        type: string
      - description: The location that contains this job.
        in: query
        name: location
        type: string
      - description: The ID of the Cloud Platform project that the job belongs to.
        in: path
        name: projectId
        required: true
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/Job'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
  /v1b3/projects/{projectId}/jobs/{jobId}/debug/getConfig:
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
    post:
      description: Get encoded debug configuration for component. Not cacheable.
      operationId: projects.jobs.debug.getConfig
      parameters:
      - in: body
        name: body
        schema:
          $ref: '#/definitions/GetDebugConfigRequest'
      - description: The job id.
        in: path
        name: jobId
        required: true
        type: string
      - description: The project id.
        in: path
        name: projectId
        required: true
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/GetDebugConfigResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
  /v1b3/projects/{projectId}/jobs/{jobId}/debug/sendCapture:
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
    post:
      description: Send encoded debug capture data for component.
      operationId: projects.jobs.debug.sendCapture
      parameters:
      - in: body
        name: body
        schema:
          $ref: '#/definitions/SendDebugCaptureRequest'
      - description: The job id.
        in: path
        name: jobId
        required: true
        type: string
      - description: The project id.
        in: path
        name: projectId
        required: true
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/SendDebugCaptureResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
  /v1b3/projects/{projectId}/jobs/{jobId}/messages:
    get:
      description: Request the job status.
      operationId: projects.jobs.messages.list
      parameters:
      - description: Return only messages with timestamps < end_time. The default
          is nown(i.e. return up to the latest messages available).
        in: query
        name: endTime
        type: string
      - description: The job to get messages about.
        in: path
        name: jobId
        required: true
        type: string
      - description: The location which contains the job specified by job_id.
        in: query
        name: location
        type: string
      - description: Filter to only get messages with importance >= level
        enum:
        - JOB_MESSAGE_IMPORTANCE_UNKNOWN
        - JOB_MESSAGE_DEBUG
        - JOB_MESSAGE_DETAILED
        - JOB_MESSAGE_BASIC
        - JOB_MESSAGE_WARNING
        - JOB_MESSAGE_ERROR
        in: query
        name: minimumImportance
        type: string
      - description: If specified, determines the maximum number of messages tonreturn.  If
          unspecified, the service may choose an appropriatendefault, or may return
          an arbitrarily large number of results.
        in: query
        name: pageSize
        type: integer
      - description: If supplied, this should be the value of next_page_token returnednby
          an earlier call. This will cause the next page of results tonbe returned.
        in: query
        name: pageToken
        type: string
      - description: A project id.
        in: path
        name: projectId
        required: true
        type: string
      - description: If specified, return only messages with timestamps >= start_time.nThe
          default is the job creation time (i.e. beginning of messages).
        in: query
        name: startTime
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/ListJobMessagesResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
  /v1b3/projects/{projectId}/jobs/{jobId}/metrics:
    get:
      description: Request the job status.
      operationId: projects.jobs.getMetrics
      parameters:
      - description: The job to get messages for.
        in: path
        name: jobId
        required: true
        type: string
      - description: The location which contains the job specified by job_id.
        in: query
        name: location
        type: string
      - description: A project id.
        in: path
        name: projectId
        required: true
        type: string
      - description: Return only metric data that has changed since this time.nDefault
          is to return all information about all metrics for the job.
        in: query
        name: startTime
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/JobMetrics'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
  /v1b3/projects/{projectId}/jobs/{jobId}/workItems:lease:
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
    post:
      description: Leases a dataflow WorkItem to run.
      operationId: projects.jobs.workItems.lease
      parameters:
      - in: body
        name: body
        schema:
          $ref: '#/definitions/LeaseWorkItemRequest'
      - description: Identifies the workflow job this worker belongs to.
        in: path
        name: jobId
        required: true
        type: string
      - description: Identifies the project this worker belongs to.
        in: path
        name: projectId
        required: true
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/LeaseWorkItemResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
  /v1b3/projects/{projectId}/jobs/{jobId}/workItems:reportStatus:
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
    post:
      description: Reports the status of dataflow WorkItems leased by a worker.
      operationId: projects.jobs.workItems.reportStatus
      parameters:
      - in: body
        name: body
        schema:
          $ref: '#/definitions/ReportWorkItemStatusRequest'
      - description: The job which the WorkItem is part of.
        in: path
        name: jobId
        required: true
        type: string
      - description: The project which owns the WorkItem's job.
        in: path
        name: projectId
        required: true
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/ReportWorkItemStatusResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
  /v1b3/projects/{projectId}/jobs:aggregated:
    get:
      description: List the jobs of a project across all regions.
      operationId: projects.jobs.aggregated
      parameters:
      - description: The kind of filter to use.
        enum:
        - UNKNOWN
        - ALL
        - TERMINATED
        - ACTIVE
        in: query
        name: filter
        type: string
      - description: The location that contains this job.
        in: query
        name: location
        type: string
      - description: If there are many jobs, limit response to at most this many.nThe
          actual number of jobs returned will be the lesser of max_responsesnand an
          unspecified server-defined limit.
        in: query
        name: pageSize
        type: integer
      - description: Set this to the 'next_page_token' field of a previous responsento
          request additional results in a long list.
        in: query
        name: pageToken
        type: string
      - description: The project which owns the jobs.
        in: path
        name: projectId
        required: true
        type: string
      - description: Level of information requested in response. Default is `JOB_VIEW_SUMMARY`.
        enum:
        - JOB_VIEW_UNKNOWN
        - JOB_VIEW_SUMMARY
        - JOB_VIEW_ALL
        - JOB_VIEW_DESCRIPTION
        in: query
        name: view
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/ListJobsResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
  /v1b3/projects/{projectId}/locations/{location}/WorkerMessages:
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
    post:
      description: Send a worker_message to the service.
      operationId: projects.locations.workerMessages
      parameters:
      - in: body
        name: body
        schema:
          $ref: '#/definitions/SendWorkerMessagesRequest'
      - description: The location which contains the job
        in: path
        name: location
        required: true
        type: string
      - description: The project to send the WorkerMessages to.
        in: path
        name: projectId
        required: true
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/SendWorkerMessagesResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
  /v1b3/projects/{projectId}/locations/{location}/jobs:
    get:
      description: List the jobs of a project in a given region.
      operationId: projects.locations.jobs.list
      parameters:
      - description: The kind of filter to use.
        enum:
        - UNKNOWN
        - ALL
        - TERMINATED
        - ACTIVE
        in: query
        name: filter
        type: string
      - description: The location that contains this job.
        in: path
        name: location
        required: true
        type: string
      - description: If there are many jobs, limit response to at most this many.nThe
          actual number of jobs returned will be the lesser of max_responsesnand an
          unspecified server-defined limit.
        in: query
        name: pageSize
        type: integer
      - description: Set this to the 'next_page_token' field of a previous responsento
          request additional results in a long list.
        in: query
        name: pageToken
        type: string
      - description: The project which owns the jobs.
        in: path
        name: projectId
        required: true
        type: string
      - description: Level of information requested in response. Default is `JOB_VIEW_SUMMARY`.
        enum:
        - JOB_VIEW_UNKNOWN
        - JOB_VIEW_SUMMARY
        - JOB_VIEW_ALL
        - JOB_VIEW_DESCRIPTION
        in: query
        name: view
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/ListJobsResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
    post:
      description: Creates a Cloud Dataflow job.
      operationId: projects.locations.jobs.create
      parameters:
      - in: body
        name: body
        schema:
          $ref: '#/definitions/Job'
      - description: The location that contains this job.
        in: path
        name: location
        required: true
        type: string
      - description: The ID of the Cloud Platform project that the job belongs to.
        in: path
        name: projectId
        required: true
        type: string
      - description: Deprecated. This field is now in the Job message.
        in: query
        name: replaceJobId
        type: string
      - description: The level of information requested in response.
        enum:
        - JOB_VIEW_UNKNOWN
        - JOB_VIEW_SUMMARY
        - JOB_VIEW_ALL
        - JOB_VIEW_DESCRIPTION
        in: query
        name: view
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/Job'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
  /v1b3/projects/{projectId}/locations/{location}/jobs/{jobId}:
    get:
      description: Gets the state of the specified Cloud Dataflow job.
      operationId: projects.locations.jobs.get
      parameters:
      - description: The job ID.
        in: path
        name: jobId
        required: true
        type: string
      - description: The location that contains this job.
        in: path
        name: location
        required: true
        type: string
      - description: The ID of the Cloud Platform project that the job belongs to.
        in: path
        name: projectId
        required: true
        type: string
      - description: The level of information requested in response.
        enum:
        - JOB_VIEW_UNKNOWN
        - JOB_VIEW_SUMMARY
        - JOB_VIEW_ALL
        - JOB_VIEW_DESCRIPTION
        in: query
        name: view
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/Job'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
    put:
      description: Updates the state of an existing Cloud Dataflow job.
      operationId: projects.locations.jobs.update
      parameters:
      - in: body
        name: body
        schema:
          $ref: '#/definitions/Job'
      - description: The job ID.
        in: path
        name: jobId
        required: true
        type: string
      - description: The location that contains this job.
        in: path
        name: location
        required: true
        type: string
      - description: The ID of the Cloud Platform project that the job belongs to.
        in: path
        name: projectId
        required: true
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/Job'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
  /v1b3/projects/{projectId}/locations/{location}/jobs/{jobId}/debug/getConfig:
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
    post:
      description: Get encoded debug configuration for component. Not cacheable.
      operationId: projects.locations.jobs.debug.getConfig
      parameters:
      - in: body
        name: body
        schema:
          $ref: '#/definitions/GetDebugConfigRequest'
      - description: The job id.
        in: path
        name: jobId
        required: true
        type: string
      - description: The location which contains the job specified by job_id.
        in: path
        name: location
        required: true
        type: string
      - description: The project id.
        in: path
        name: projectId
        required: true
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/GetDebugConfigResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
  /v1b3/projects/{projectId}/locations/{location}/jobs/{jobId}/debug/sendCapture:
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
    post:
      description: Send encoded debug capture data for component.
      operationId: projects.locations.jobs.debug.sendCapture
      parameters:
      - in: body
        name: body
        schema:
          $ref: '#/definitions/SendDebugCaptureRequest'
      - description: The job id.
        in: path
        name: jobId
        required: true
        type: string
      - description: The location which contains the job specified by job_id.
        in: path
        name: location
        required: true
        type: string
      - description: The project id.
        in: path
        name: projectId
        required: true
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/SendDebugCaptureResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
  /v1b3/projects/{projectId}/locations/{location}/jobs/{jobId}/messages:
    get:
      description: Request the job status.
      operationId: projects.locations.jobs.messages.list
      parameters:
      - description: Return only messages with timestamps < end_time. The default
          is nown(i.e. return up to the latest messages available).
        in: query
        name: endTime
        type: string
      - description: The job to get messages about.
        in: path
        name: jobId
        required: true
        type: string
      - description: The location which contains the job specified by job_id.
        in: path
        name: location
        required: true
        type: string
      - description: Filter to only get messages with importance >= level
        enum:
        - JOB_MESSAGE_IMPORTANCE_UNKNOWN
        - JOB_MESSAGE_DEBUG
        - JOB_MESSAGE_DETAILED
        - JOB_MESSAGE_BASIC
        - JOB_MESSAGE_WARNING
        - JOB_MESSAGE_ERROR
        in: query
        name: minimumImportance
        type: string
      - description: If specified, determines the maximum number of messages tonreturn.  If
          unspecified, the service may choose an appropriatendefault, or may return
          an arbitrarily large number of results.
        in: query
        name: pageSize
        type: integer
      - description: If supplied, this should be the value of next_page_token returnednby
          an earlier call. This will cause the next page of results tonbe returned.
        in: query
        name: pageToken
        type: string
      - description: A project id.
        in: path
        name: projectId
        required: true
        type: string
      - description: If specified, return only messages with timestamps >= start_time.nThe
          default is the job creation time (i.e. beginning of messages).
        in: query
        name: startTime
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/ListJobMessagesResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
  /v1b3/projects/{projectId}/locations/{location}/jobs/{jobId}/metrics:
    get:
      description: Request the job status.
      operationId: projects.locations.jobs.getMetrics
      parameters:
      - description: The job to get messages for.
        in: path
        name: jobId
        required: true
        type: string
      - description: The location which contains the job specified by job_id.
        in: path
        name: location
        required: true
        type: string
      - description: A project id.
        in: path
        name: projectId
        required: true
        type: string
      - description: Return only metric data that has changed since this time.nDefault
          is to return all information about all metrics for the job.
        in: query
        name: startTime
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/JobMetrics'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
  /v1b3/projects/{projectId}/locations/{location}/jobs/{jobId}/workItems:lease:
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
    post:
      description: Leases a dataflow WorkItem to run.
      operationId: projects.locations.jobs.workItems.lease
      parameters:
      - in: body
        name: body
        schema:
          $ref: '#/definitions/LeaseWorkItemRequest'
      - description: Identifies the workflow job this worker belongs to.
        in: path
        name: jobId
        required: true
        type: string
      - description: The location which contains the WorkItem's job.
        in: path
        name: location
        required: true
        type: string
      - description: Identifies the project this worker belongs to.
        in: path
        name: projectId
        required: true
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/LeaseWorkItemResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
  /v1b3/projects/{projectId}/locations/{location}/jobs/{jobId}/workItems:reportStatus:
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
    post:
      description: Reports the status of dataflow WorkItems leased by a worker.
      operationId: projects.locations.jobs.workItems.reportStatus
      parameters:
      - in: body
        name: body
        schema:
          $ref: '#/definitions/ReportWorkItemStatusRequest'
      - description: The job which the WorkItem is part of.
        in: path
        name: jobId
        required: true
        type: string
      - description: The location which contains the WorkItem's job.
        in: path
        name: location
        required: true
        type: string
      - description: The project which owns the WorkItem's job.
        in: path
        name: projectId
        required: true
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/ReportWorkItemStatusResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
  /v1b3/projects/{projectId}/locations/{location}/templates:
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
    post:
      description: Creates a Cloud Dataflow job from a template.
      operationId: projects.locations.templates.create
      parameters:
      - in: body
        name: body
        schema:
          $ref: '#/definitions/CreateJobFromTemplateRequest'
      - description: The location to which to direct the request.
        in: path
        name: location
        required: true
        type: string
      - description: Required. The ID of the Cloud Platform project that the job belongs
          to.
        in: path
        name: projectId
        required: true
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/Job'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
  /v1b3/projects/{projectId}/locations/{location}/templates:get:
    get:
      description: Get the template associated with a template.
      operationId: projects.locations.templates.get
      parameters:
      - description: Required. A Cloud Storage path to the template from which toncreate
          the job.nMust be a valid Cloud Storage URL, beginning with `gs://`.
        in: query
        name: gcsPath
        type: string
      - description: The location to which to direct the request.
        in: path
        name: location
        required: true
        type: string
      - description: Required. The ID of the Cloud Platform project that the job belongs
          to.
        in: path
        name: projectId
        required: true
        type: string
      - description: The view to retrieve. Defaults to METADATA_ONLY.
        enum:
        - METADATA_ONLY
        in: query
        name: view
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/GetTemplateResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
  /v1b3/projects/{projectId}/locations/{location}/templates:launch:
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
    post:
      description: Launch a template.
      operationId: projects.locations.templates.launch
      parameters:
      - in: body
        name: body
        schema:
          $ref: '#/definitions/LaunchTemplateParameters'
      - description: Required. A Cloud Storage path to the template from which to
          createnthe job.nMust be valid Cloud Storage URL, beginning with 'gs://'.
        in: query
        name: gcsPath
        type: string
      - description: The location to which to direct the request.
        in: path
        name: location
        required: true
        type: string
      - description: Required. The ID of the Cloud Platform project that the job belongs
          to.
        in: path
        name: projectId
        required: true
        type: string
      - description: If true, the request is validated but not actually executed.nDefaults
          to false.
        in: query
        name: validateOnly
        type: boolean
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/LaunchTemplateResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
  /v1b3/projects/{projectId}/templates:
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
    post:
      description: Creates a Cloud Dataflow job from a template.
      operationId: projects.templates.create
      parameters:
      - in: body
        name: body
        schema:
          $ref: '#/definitions/CreateJobFromTemplateRequest'
      - description: Required. The ID of the Cloud Platform project that the job belongs
          to.
        in: path
        name: projectId
        required: true
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/Job'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
  /v1b3/projects/{projectId}/templates:get:
    get:
      description: Get the template associated with a template.
      operationId: projects.templates.get
      parameters:
      - description: Required. A Cloud Storage path to the template from which toncreate
          the job.nMust be a valid Cloud Storage URL, beginning with `gs://`.
        in: query
        name: gcsPath
        type: string
      - description: The location to which to direct the request.
        in: query
        name: location
        type: string
      - description: Required. The ID of the Cloud Platform project that the job belongs
          to.
        in: path
        name: projectId
        required: true
        type: string
      - description: The view to retrieve. Defaults to METADATA_ONLY.
        enum:
        - METADATA_ONLY
        in: query
        name: view
        type: string
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/GetTemplateResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
  /v1b3/projects/{projectId}/templates:launch:
    parameters:
    - $ref: '#/parameters/$.xgafv'
    - $ref: '#/parameters/access_token'
    - $ref: '#/parameters/alt'
    - $ref: '#/parameters/bearer_token'
    - $ref: '#/parameters/callback'
    - $ref: '#/parameters/fields'
    - $ref: '#/parameters/key'
    - $ref: '#/parameters/oauth_token'
    - $ref: '#/parameters/pp'
    - $ref: '#/parameters/prettyPrint'
    - $ref: '#/parameters/quotaUser'
    - $ref: '#/parameters/uploadType'
    - $ref: '#/parameters/upload_protocol'
    post:
      description: Launch a template.
      operationId: projects.templates.launch
      parameters:
      - in: body
        name: body
        schema:
          $ref: '#/definitions/LaunchTemplateParameters'
      - description: Required. A Cloud Storage path to the template from which to
          createnthe job.nMust be valid Cloud Storage URL, beginning with 'gs://'.
        in: query
        name: gcsPath
        type: string
      - description: The location to which to direct the request.
        in: query
        name: location
        type: string
      - description: Required. The ID of the Cloud Platform project that the job belongs
          to.
        in: path
        name: projectId
        required: true
        type: string
      - description: If true, the request is validated but not actually executed.nDefaults
          to false.
        in: query
        name: validateOnly
        type: boolean
      responses:
        200:
          description: Successful response
          schema:
            $ref: '#/definitions/LaunchTemplateResponse'
      security:
      - Oauth2:
        - https://www.googleapis.com/auth/cloud-platform
      - Oauth2:
        - https://www.googleapis.com/auth/compute
      - Oauth2:
        - https://www.googleapis.com/auth/compute.readonly
      - Oauth2:
        - https://www.googleapis.com/auth/userinfo.email
      tags:
      - projects
schemes:
- https
definitions: !php/object "O:8:\"stdClass\":127:{s:19:\"ApproximateProgress\";O:8:\"stdClass\":3:{s:11:\"description\";s:77:\"Obsolete
  in favor of ApproximateReportedProgress and ApproximateSplitRequest.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:15:\"percentComplete\";O:8:\"stdClass\":3:{s:11:\"description\";s:9:\"Obsolete.\";s:6:\"format\";s:5:\"float\";s:4:\"type\";s:6:\"number\";}s:8:\"position\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:22:\"#/definitions/Position\";s:11:\"description\";s:9:\"Obsolete.\";}s:13:\"remainingTime\";O:8:\"stdClass\":3:{s:11:\"description\";s:9:\"Obsolete.\";s:6:\"format\";s:15:\"google-duration\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:27:\"ApproximateReportedProgress\";O:8:\"stdClass\":3:{s:11:\"description\";s:49:\"A
  progress measurement of a WorkItem by a worker.\";s:10:\"properties\";O:8:\"stdClass\":4:{s:19:\"consumedParallelism\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:33:\"#/definitions/ReportedParallelism\";s:11:\"description\";s:377:\"Total
  amount of parallelism in the portion of input of this task that has\nalready been
  consumed and is no longer active. In the first two examples\nabove (see remaining_parallelism),
  the value should be 29 or 2\nrespectively.  The sum of remaining_parallelism and
  consumed_parallelism\nshould equal the total amount of parallelism in this work
  item.  If\nspecified, must be finite.\";}s:16:\"fractionConsumed\";O:8:\"stdClass\":3:{s:11:\"description\";s:135:\"Completion
  as fraction of the input consumed, from 0.0 (beginning, nothing\nconsumed), to 1.0
  (end of the input, entire input consumed).\";s:6:\"format\";s:6:\"double\";s:4:\"type\";s:6:\"number\";}s:8:\"position\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:22:\"#/definitions/Position\";s:11:\"description\";s:51:\"A
  Position within the work to represent a progress.\";}s:20:\"remainingParallelism\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:33:\"#/definitions/ReportedParallelism\";s:11:\"description\";s:1320:\"Total
  amount of parallelism in the input of this task that remains,\n(i.e. can be delegated
  to this task and any new tasks via dynamic\nsplitting). Always at least 1 for non-finished
  work items and 0 for\nfinished.\n\n\"Amount of parallelism\" refers to how many
  non-empty parts of the input\ncan be read in parallel. This does not necessarily
  equal number\nof records. An input that can be read in parallel down to the\nindividual
  records is called \"perfectly splittable\".\nAn example of non-perfectly parallelizable
  input is a block-compressed\nfile format where a block of records has to be read
  as a whole,\nbut different blocks can be read in parallel.\n\nExamples:\n* If we
  are processing record #30 (starting at 1) out of 50 in a perfectly\n  splittable
  50-record input, this value should be 21 (20 remaining + 1\n  current).\n* If we
  are reading through block 3 in a block-compressed file consisting\n  of 5 blocks,
  this value should be 3 (since blocks 4 and 5 can be\n  processed in parallel by
  new tasks via dynamic splitting and the current\n  task remains processing block
  3).\n* If we are reading through the last block in a block-compressed file,\n  or
  reading or processing the last record in a perfectly splittable\n  input, this value
  should be 1, because apart from the current task, no\n  additional remainder can
  be split off.\";}}s:4:\"type\";s:6:\"object\";}s:23:\"ApproximateSplitRequest\";O:8:\"stdClass\":3:{s:11:\"description\";s:76:\"A
  suggestion by the service to the worker to dynamically split the WorkItem.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:16:\"fractionConsumed\";O:8:\"stdClass\":3:{s:11:\"description\";s:104:\"A
  fraction at which to split the work item, from 0.0 (beginning of the\ninput) to
  1.0 (end of the input).\";s:6:\"format\";s:6:\"double\";s:4:\"type\";s:6:\"number\";}s:8:\"position\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:22:\"#/definitions/Position\";s:11:\"description\";s:43:\"A
  Position at which to split the work item.\";}}s:4:\"type\";s:6:\"object\";}s:16:\"AutoscalingEvent\";O:8:\"stdClass\":3:{s:11:\"description\";s:84:\"A
  structured message reporting an autoscaling decision made by the Dataflow\nservice.\";s:10:\"properties\";O:8:\"stdClass\":6:{s:17:\"currentNumWorkers\";O:8:\"stdClass\":3:{s:11:\"description\";s:42:\"The
  current number of workers the job has.\";s:6:\"format\";s:5:\"int64\";s:4:\"type\";s:6:\"string\";}s:11:\"description\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/StructuredMessage\";s:11:\"description\";s:175:\"A
  message describing why the system decided to adjust the current\nnumber of workers,
  why it failed, or why the system decided to\nnot make any changes to the number
  of workers.\";}s:9:\"eventType\";O:8:\"stdClass\":3:{s:11:\"description\";s:40:\"The
  type of autoscaling event to report.\";s:4:\"enum\";a:5:{i:0;s:12:\"TYPE_UNKNOWN\";i:1;s:26:\"TARGET_NUM_WORKERS_CHANGED\";i:2;s:27:\"CURRENT_NUM_WORKERS_CHANGED\";i:3;s:17:\"ACTUATION_FAILURE\";i:4;s:9:\"NO_CHANGE\";}s:4:\"type\";s:6:\"string\";}s:16:\"targetNumWorkers\";O:8:\"stdClass\":3:{s:11:\"description\";s:68:\"The
  target number of workers the worker pool wants to resize to use.\";s:6:\"format\";s:5:\"int64\";s:4:\"type\";s:6:\"string\";}s:4:\"time\";O:8:\"stdClass\":3:{s:11:\"description\";s:86:\"The
  time this event was emitted to indicate a new target or current\nnum_workers value.\";s:6:\"format\";s:15:\"google-datetime\";s:4:\"type\";s:6:\"string\";}s:10:\"workerPool\";O:8:\"stdClass\":2:{s:11:\"description\";s:130:\"A
  short and friendly name for the worker pool this event refers to,\npopulated from
  the value of PoolStageRelation::user_pool_name.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:19:\"AutoscalingSettings\";O:8:\"stdClass\":3:{s:11:\"description\";s:36:\"Settings
  for WorkerPool autoscaling.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:9:\"algorithm\";O:8:\"stdClass\":3:{s:11:\"description\";s:37:\"The
  algorithm to use for autoscaling.\";s:4:\"enum\";a:3:{i:0;s:29:\"AUTOSCALING_ALGORITHM_UNKNOWN\";i:1;s:26:\"AUTOSCALING_ALGORITHM_NONE\";i:2;s:27:\"AUTOSCALING_ALGORITHM_BASIC\";}s:4:\"type\";s:6:\"string\";}s:13:\"maxNumWorkers\";O:8:\"stdClass\":3:{s:11:\"description\";s:48:\"The
  maximum number of workers to cap scaling at.\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}}s:4:\"type\";s:6:\"object\";}s:7:\"CPUTime\";O:8:\"stdClass\":3:{s:11:\"description\";s:48:\"Modeled
  after information exposed by /proc/stat.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:4:\"rate\";O:8:\"stdClass\":3:{s:11:\"description\";s:77:\"Average
  CPU utilization rate (% non-idle cpu / second) since previous\nsample.\";s:6:\"format\";s:6:\"double\";s:4:\"type\";s:6:\"number\";}s:9:\"timestamp\";O:8:\"stdClass\":3:{s:11:\"description\";s:29:\"Timestamp
  of the measurement.\";s:6:\"format\";s:15:\"google-datetime\";s:4:\"type\";s:6:\"string\";}s:7:\"totalMs\";O:8:\"stdClass\":3:{s:11:\"description\";s:86:\"Total
  active CPU time across all cores (ie., non-idle) in milliseconds\nsince start-up.\";s:6:\"format\";s:6:\"uint64\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:15:\"ComponentSource\";O:8:\"stdClass\":3:{s:11:\"description\";s:78:\"Description
  of an interstitial value between transforms in an execution\nstage.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:48:\"Dataflow
  service generated name for this source.\";s:4:\"type\";s:6:\"string\";}s:29:\"originalTransformOrCollection\";O:8:\"stdClass\":2:{s:11:\"description\";s:106:\"User
  name for the original user transform or collection with which this\nsource is most
  closely associated.\";s:4:\"type\";s:6:\"string\";}s:8:\"userName\";O:8:\"stdClass\":2:{s:11:\"description\";s:72:\"Human-readable
  name for this transform; may be user or system generated.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:18:\"ComponentTransform\";O:8:\"stdClass\":3:{s:11:\"description\";s:66:\"Description
  of a transform executed as part of an execution stage.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:48:\"Dataflow
  service generated name for this source.\";s:4:\"type\";s:6:\"string\";}s:17:\"originalTransform\";O:8:\"stdClass\":2:{s:11:\"description\";s:95:\"User
  name for the original user transform with which this transform is\nmost closely
  associated.\";s:4:\"type\";s:6:\"string\";}s:8:\"userName\";O:8:\"stdClass\":2:{s:11:\"description\";s:72:\"Human-readable
  name for this transform; may be user or system generated.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:19:\"ComputationTopology\";O:8:\"stdClass\":3:{s:11:\"description\";s:52:\"All
  configuration data for a particular Computation.\";s:10:\"properties\";O:8:\"stdClass\":6:{s:13:\"computationId\";O:8:\"stdClass\":2:{s:11:\"description\";s:26:\"The
  ID of the computation.\";s:4:\"type\";s:6:\"string\";}s:6:\"inputs\";O:8:\"stdClass\":3:{s:11:\"description\";s:30:\"The
  inputs to the computation.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:28:\"#/definitions/StreamLocation\";}s:4:\"type\";s:5:\"array\";}s:9:\"keyRanges\";O:8:\"stdClass\":3:{s:11:\"description\";s:44:\"The
  key ranges processed by the computation.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:30:\"#/definitions/KeyRangeLocation\";}s:4:\"type\";s:5:\"array\";}s:7:\"outputs\";O:8:\"stdClass\":3:{s:11:\"description\";s:33:\"The
  outputs from the computation.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:28:\"#/definitions/StreamLocation\";}s:4:\"type\";s:5:\"array\";}s:13:\"stateFamilies\";O:8:\"stdClass\":3:{s:11:\"description\";s:24:\"The
  state family values.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:31:\"#/definitions/StateFamilyConfig\";}s:4:\"type\";s:5:\"array\";}s:15:\"systemStageName\";O:8:\"stdClass\":2:{s:11:\"description\";s:22:\"The
  system stage name.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:14:\"ConcatPosition\";O:8:\"stdClass\":3:{s:11:\"description\";s:178:\"A
  position that encapsulates an inner position and an index for the inner\nposition.
  A ConcatPosition can be used by a reader of a source that\nencapsulates a set of
  other sources.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:5:\"index\";O:8:\"stdClass\":3:{s:11:\"description\";s:26:\"Index
  of the inner source.\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}s:8:\"position\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:22:\"#/definitions/Position\";s:11:\"description\";s:33:\"Position
  within the inner source.\";}}s:4:\"type\";s:6:\"object\";}s:15:\"CounterMetadata\";O:8:\"stdClass\":3:{s:11:\"description\";s:74:\"CounterMetadata
  includes all static non-name non-value counter attributes.\";s:10:\"properties\";O:8:\"stdClass\":4:{s:11:\"description\";O:8:\"stdClass\":2:{s:11:\"description\";s:52:\"Human-readable
  description of the counter semantics.\";s:4:\"type\";s:6:\"string\";}s:4:\"kind\";O:8:\"stdClass\":3:{s:11:\"description\";s:25:\"Counter
  aggregation kind.\";s:4:\"enum\";a:10:{i:0;s:7:\"INVALID\";i:1;s:3:\"SUM\";i:2;s:3:\"MAX\";i:3;s:3:\"MIN\";i:4;s:4:\"MEAN\";i:5;s:2:\"OR\";i:6;s:3:\"AND\";i:7;s:3:\"SET\";i:8;s:12:\"DISTRIBUTION\";i:9;s:12:\"LATEST_VALUE\";}s:4:\"type\";s:6:\"string\";}s:10:\"otherUnits\";O:8:\"stdClass\":2:{s:11:\"description\";s:36:\"A
  string referring to the unit type.\";s:4:\"type\";s:6:\"string\";}s:13:\"standardUnits\";O:8:\"stdClass\":3:{s:11:\"description\";s:37:\"System
  defined Units, see above enum.\";s:4:\"enum\";a:8:{i:0;s:5:\"BYTES\";i:1;s:13:\"BYTES_PER_SEC\";i:2;s:12:\"MILLISECONDS\";i:3;s:12:\"MICROSECONDS\";i:4;s:11:\"NANOSECONDS\";i:5;s:14:\"TIMESTAMP_MSEC\";i:6;s:14:\"TIMESTAMP_USEC\";i:7;s:14:\"TIMESTAMP_NSEC\";}s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:21:\"CounterStructuredName\";O:8:\"stdClass\":3:{s:11:\"description\";s:137:\"Identifies
  a counter within a per-job namespace. Counters whose structured\nnames are the same
  get merged into a single value for the job.\";s:10:\"properties\";O:8:\"stdClass\":10:{s:17:\"componentStepName\";O:8:\"stdClass\":2:{s:11:\"description\";s:57:\"Name
  of the optimized step being executed by the workers.\";s:4:\"type\";s:6:\"string\";}s:17:\"executionStepName\";O:8:\"stdClass\":2:{s:11:\"description\";s:71:\"Name
  of the stage. An execution step contains multiple component steps.\";s:4:\"type\";s:6:\"string\";}s:10:\"inputIndex\";O:8:\"stdClass\":3:{s:11:\"description\";s:327:\"Index
  of an input collection that's being read from/written to as a side\ninput.\nThe
  index identifies a step's side inputs starting by 1 (e.g. the first\nside input
  has input_index 1, the third has input_index 3).\nSide inputs are identified by
  a pair of (original_step_name, input_index).\nThis field helps uniquely identify
  them.\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:107:\"Counter
  name. Not necessarily globally-unique, but unique within the\ncontext of the other
  fields.\nRequired.\";s:4:\"type\";s:6:\"string\";}s:6:\"origin\";O:8:\"stdClass\":3:{s:11:\"description\";s:42:\"One
  of the standard Origins defined above.\";s:4:\"enum\";a:2:{i:0;s:6:\"SYSTEM\";i:1;s:4:\"USER\";}s:4:\"type\";s:6:\"string\";}s:15:\"originNamespace\";O:8:\"stdClass\":2:{s:11:\"description\";s:70:\"A
  string containing a more specific namespace of the counter's origin.\";s:4:\"type\";s:6:\"string\";}s:26:\"originalRequestingStepName\";O:8:\"stdClass\":2:{s:11:\"description\";s:138:\"The
  step name requesting an operation, such as GBK.\nI.e. the ParDo causing a read/write
  from shuffle to occur, or a\nread from side inputs.\";s:4:\"type\";s:6:\"string\";}s:16:\"originalStepName\";O:8:\"stdClass\":2:{s:11:\"description\";s:84:\"System
  generated name of the original step in the user's graph, before\noptimization.\";s:4:\"type\";s:6:\"string\";}s:7:\"portion\";O:8:\"stdClass\":3:{s:11:\"description\";s:45:\"Portion
  of this counter, either key or value.\";s:4:\"enum\";a:3:{i:0;s:3:\"ALL\";i:1;s:3:\"KEY\";i:2;s:5:\"VALUE\";}s:4:\"type\";s:6:\"string\";}s:8:\"workerId\";O:8:\"stdClass\":2:{s:11:\"description\";s:26:\"ID
  of a particular worker.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:32:\"CounterStructuredNameAndMetadata\";O:8:\"stdClass\":3:{s:11:\"description\";s:85:\"A
  single message which encapsulates structured name and metadata for a given\ncounter.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:8:\"metadata\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:29:\"#/definitions/CounterMetadata\";s:11:\"description\";s:34:\"Metadata
  associated with a counter\";}s:4:\"name\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:35:\"#/definitions/CounterStructuredName\";s:11:\"description\";s:31:\"Structured
  name of the counter.\";}}s:4:\"type\";s:6:\"object\";}s:13:\"CounterUpdate\";O:8:\"stdClass\":3:{s:11:\"description\";s:42:\"An
  update to a Counter sent from a worker.\";s:10:\"properties\";O:8:\"stdClass\":15:{s:7:\"boolean\";O:8:\"stdClass\":2:{s:11:\"description\";s:26:\"Boolean
  value for And, Or.\";s:4:\"type\";s:7:\"boolean\";}s:10:\"cumulative\";O:8:\"stdClass\":2:{s:11:\"description\";s:214:\"True
  if this counter is reported as the total cumulative aggregate\nvalue accumulated
  since the worker started working on this WorkItem.\nBy default this is false, indicating
  that this counter is reported\nas a delta.\";s:4:\"type\";s:7:\"boolean\";}s:12:\"distribution\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/DistributionUpdate\";s:11:\"description\";s:17:\"Distribution
  data\";}s:13:\"floatingPoint\";O:8:\"stdClass\":3:{s:11:\"description\";s:39:\"Floating
  point value for Sum, Max, Min.\";s:6:\"format\";s:6:\"double\";s:4:\"type\";s:6:\"number\";}s:17:\"floatingPointList\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/FloatingPointList\";s:11:\"description\";s:40:\"List
  of floating point numbers, for Set.\";}s:17:\"floatingPointMean\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/FloatingPointMean\";s:11:\"description\";s:47:\"Floating
  point mean aggregation value for Mean.\";}s:7:\"integer\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:24:\"#/definitions/SplitInt64\";s:11:\"description\";s:32:\"Integer
  value for Sum, Max, Min.\";}s:12:\"integerGauge\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:26:\"#/definitions/IntegerGauge\";s:11:\"description\";s:10:\"Gauge
  data\";}s:11:\"integerList\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:25:\"#/definitions/IntegerList\";s:11:\"description\";s:26:\"List
  of integers, for Set.\";}s:11:\"integerMean\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:25:\"#/definitions/IntegerMean\";s:11:\"description\";s:40:\"Integer
  mean aggregation value for Mean.\";}s:8:\"internal\";O:8:\"stdClass\":1:{s:11:\"description\";s:67:\"Value
  for internally-defined counters used by the Dataflow service.\";}s:11:\"nameAndKind\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:25:\"#/definitions/NameAndKind\";s:11:\"description\";s:34:\"Counter
  name and aggregation type.\";}s:7:\"shortId\";O:8:\"stdClass\":3:{s:11:\"description\";s:136:\"The
  service-generated short identifier for this counter.\nThe short_id -> (name, metadata)
  mapping is constant for the lifetime of\na job.\";s:6:\"format\";s:5:\"int64\";s:4:\"type\";s:6:\"string\";}s:10:\"stringList\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:24:\"#/definitions/StringList\";s:11:\"description\";s:25:\"List
  of strings, for Set.\";}s:25:\"structuredNameAndMetadata\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:46:\"#/definitions/CounterStructuredNameAndMetadata\";s:11:\"description\";s:37:\"Counter
  structured name and metadata.\";}}s:4:\"type\";s:6:\"object\";}s:28:\"CreateJobFromTemplateRequest\";O:8:\"stdClass\":3:{s:11:\"description\";s:57:\"A
  request to create a Cloud Dataflow job from a template.\";s:10:\"properties\";O:8:\"stdClass\":5:{s:11:\"environment\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/RuntimeEnvironment\";s:11:\"description\";s:36:\"The
  runtime environment for the job.\";}s:7:\"gcsPath\";O:8:\"stdClass\":2:{s:11:\"description\";s:135:\"Required.
  A Cloud Storage path to the template from which to\ncreate the job.\nMust be a valid
  Cloud Storage URL, beginning with `gs://`.\";s:4:\"type\";s:6:\"string\";}s:7:\"jobName\";O:8:\"stdClass\":2:{s:11:\"description\";s:50:\"Required.
  The job name to use for the created job.\";s:4:\"type\";s:6:\"string\";}s:8:\"location\";O:8:\"stdClass\":2:{s:11:\"description\";s:44:\"The
  location to which to direct the request.\";s:4:\"type\";s:6:\"string\";}s:10:\"parameters\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:11:\"description\";s:42:\"The
  runtime parameters to pass to the job.\";s:4:\"type\";s:6:\"object\";}}s:4:\"type\";s:6:\"object\";}s:20:\"CustomSourceLocation\";O:8:\"stdClass\":3:{s:11:\"description\";s:42:\"Identifies
  the location of a custom souce.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:8:\"stateful\";O:8:\"stdClass\":2:{s:11:\"description\";s:32:\"Whether
  this source is stateful.\";s:4:\"type\";s:7:\"boolean\";}}s:4:\"type\";s:6:\"object\";}s:18:\"DataDiskAssignment\";O:8:\"stdClass\":3:{s:11:\"description\";s:45:\"Data
  disk assignment for a given VM instance.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:9:\"dataDisks\";O:8:\"stdClass\":3:{s:11:\"description\";s:266:\"Mounted
  data disks. The order is important a data disk's 0-based index in\nthis list defines
  which persistent directory the disk is mounted to, for\nexample the list of { \"myproject-1014-104817-4c2-harness-0-disk-0\"
  },\n{ \"myproject-1014-104817-4c2-harness-0-disk-1\" }.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:4:\"type\";s:5:\"array\";}s:10:\"vmInstance\";O:8:\"stdClass\":2:{s:11:\"description\";s:94:\"VM
  instance name the data disks mounted to, for example\n\"myproject-1014-104817-4c2-harness-0\".\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:13:\"DerivedSource\";O:8:\"stdClass\":3:{s:11:\"description\";s:234:\"Specification
  of one of the bundles produced as a result of splitting\na Source (e.g. when executing
  a SourceSplitRequest, or when\nsplitting an active task using WorkItemStatus.dynamic_source_split),\nrelative
  to the source being split.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:14:\"derivationMode\";O:8:\"stdClass\":3:{s:11:\"description\";s:52:\"What
  source to base the produced source on (if any).\";s:4:\"enum\";a:4:{i:0;s:30:\"SOURCE_DERIVATION_MODE_UNKNOWN\";i:1;s:34:\"SOURCE_DERIVATION_MODE_INDEPENDENT\";i:2;s:39:\"SOURCE_DERIVATION_MODE_CHILD_OF_CURRENT\";i:3;s:41:\"SOURCE_DERIVATION_MODE_SIBLING_OF_CURRENT\";}s:4:\"type\";s:6:\"string\";}s:6:\"source\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:20:\"#/definitions/Source\";s:11:\"description\";s:28:\"Specification
  of the source.\";}}s:4:\"type\";s:6:\"object\";}s:4:\"Disk\";O:8:\"stdClass\":3:{s:11:\"description\";s:47:\"Describes
  the data disk used by a workflow job.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:8:\"diskType\";O:8:\"stdClass\":2:{s:11:\"description\";s:909:\"Disk
  storage type, as defined by Google Compute Engine.  This\nmust be a disk type appropriate
  to the project and zone in which\nthe workers will run.  If unknown or unspecified,
  the service\nwill attempt to choose a reasonable default.\n\nFor example, the standard
  persistent disk type is a resource name\ntypically ending in \"pd-standard\".  If
  SSD persistent disks are\navailable, the resource name typically ends with \"pd-ssd\".
  \ The\nactual valid values are defined the Google Compute Engine API,\nnot by the
  Cloud Dataflow API; consult the Google Compute Engine\ndocumentation for more information
  about determining the set of\navailable disk types for a particular project and
  zone.\n\nGoogle Compute Engine Disk types are local to a particular\nproject in
  a particular zone, and so the resource name will\ntypically look something like
  this:\n\ncompute.googleapis.com/projects/project-id/zones/zone/diskTypes/pd-standard\";s:4:\"type\";s:6:\"string\";}s:10:\"mountPoint\";O:8:\"stdClass\":2:{s:11:\"description\";s:40:\"Directory
  in a VM where disk is mounted.\";s:4:\"type\";s:6:\"string\";}s:6:\"sizeGb\";O:8:\"stdClass\":3:{s:11:\"description\";s:101:\"Size
  of disk in GB.  If zero or unspecified, the service will\nattempt to choose a reasonable
  default.\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}}s:4:\"type\";s:6:\"object\";}s:11:\"DisplayData\";O:8:\"stdClass\":3:{s:11:\"description\";s:71:\"Data
  provided with a pipeline or transform to provide descriptive info.\";s:10:\"properties\";O:8:\"stdClass\":12:{s:9:\"boolValue\";O:8:\"stdClass\":2:{s:11:\"description\";s:48:\"Contains
  value if the data is of a boolean type.\";s:4:\"type\";s:7:\"boolean\";}s:13:\"durationValue\";O:8:\"stdClass\":3:{s:11:\"description\";s:47:\"Contains
  value if the data is of duration type.\";s:6:\"format\";s:15:\"google-duration\";s:4:\"type\";s:6:\"string\";}s:10:\"floatValue\";O:8:\"stdClass\":3:{s:11:\"description\";s:44:\"Contains
  value if the data is of float type.\";s:6:\"format\";s:5:\"float\";s:4:\"type\";s:6:\"number\";}s:10:\"int64Value\";O:8:\"stdClass\":3:{s:11:\"description\";s:44:\"Contains
  value if the data is of int64 type.\";s:6:\"format\";s:5:\"int64\";s:4:\"type\";s:6:\"string\";}s:14:\"javaClassValue\";O:8:\"stdClass\":2:{s:11:\"description\";s:49:\"Contains
  value if the data is of java class type.\";s:4:\"type\";s:6:\"string\";}s:3:\"key\";O:8:\"stdClass\":2:{s:11:\"description\";s:137:\"The
  key identifying the display data.\nThis is intended to be used as a label for the
  display data\nwhen viewed in a dax monitoring system.\";s:4:\"type\";s:6:\"string\";}s:5:\"label\";O:8:\"stdClass\":2:{s:11:\"description\";s:57:\"An
  optional label to display in a dax UI for the element.\";s:4:\"type\";s:6:\"string\";}s:9:\"namespace\";O:8:\"stdClass\":2:{s:11:\"description\";s:237:\"The
  namespace for the key. This is usually a class name or programming\nlanguage namespace
  (i.e. python module) which defines the display data.\nThis allows a dax monitoring
  system to specially handle the data\nand perform custom rendering.\";s:4:\"type\";s:6:\"string\";}s:13:\"shortStrValue\";O:8:\"stdClass\":2:{s:11:\"description\";s:303:\"A
  possible additional shorter value to display.\nFor example a java_class_name_value
  of com.mypackage.MyDoFn\nwill be stored with MyDoFn as the short_str_value and\ncom.mypackage.MyDoFn
  as the java_class_name value.\nshort_str_value can be displayed and java_class_name_value\nwill
  be displayed as a tooltip.\";s:4:\"type\";s:6:\"string\";}s:8:\"strValue\";O:8:\"stdClass\":2:{s:11:\"description\";s:45:\"Contains
  value if the data is of string type.\";s:4:\"type\";s:6:\"string\";}s:14:\"timestampValue\";O:8:\"stdClass\":3:{s:11:\"description\";s:48:\"Contains
  value if the data is of timestamp type.\";s:6:\"format\";s:15:\"google-datetime\";s:4:\"type\";s:6:\"string\";}s:3:\"url\";O:8:\"stdClass\":2:{s:11:\"description\";s:21:\"An
  optional full URL.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:18:\"DistributionUpdate\";O:8:\"stdClass\":3:{s:11:\"description\";s:43:\"A
  metric value representing a distribution.\";s:10:\"properties\";O:8:\"stdClass\":6:{s:5:\"count\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:24:\"#/definitions/SplitInt64\";s:11:\"description\";s:64:\"The
  count of the number of elements present in the distribution.\";}s:9:\"histogram\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:23:\"#/definitions/Histogram\";s:11:\"description\";s:58:\"(Optional)
  Histogram of value counts for the distribution.\";}s:3:\"max\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:24:\"#/definitions/SplitInt64\";s:11:\"description\";s:46:\"The
  maximum value present in the distribution.\";}s:3:\"min\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:24:\"#/definitions/SplitInt64\";s:11:\"description\";s:46:\"The
  minimum value present in the distribution.\";}s:3:\"sum\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:24:\"#/definitions/SplitInt64\";s:11:\"description\";s:141:\"Use
  an int64 since we'd prefer the added precision. If overflow is a common\nproblem
  we can detect it and use an additional int64 or a double.\";}s:12:\"sumOfSquares\";O:8:\"stdClass\":3:{s:11:\"description\";s:66:\"Use
  a double since the sum of squares is likely to overflow int64.\";s:6:\"format\";s:6:\"double\";s:4:\"type\";s:6:\"number\";}}s:4:\"type\";s:6:\"object\";}s:18:\"DynamicSourceSplit\";O:8:\"stdClass\":3:{s:11:\"description\";s:168:\"When
  a task splits using WorkItemStatus.dynamic_source_split, this\nmessage describes
  the two parts of the split relative to the\ndescription of the current task's input.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:7:\"primary\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/DerivedSource\";s:11:\"description\";s:121:\"Primary
  part (continued to be processed by worker).\nSpecified relative to the previously-current
  source.\nBecomes current.\";}s:8:\"residual\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/DerivedSource\";s:11:\"description\";s:98:\"Residual
  part (returned to the pool of work).\nSpecified relative to the previously-current
  source.\";}}s:4:\"type\";s:6:\"object\";}s:11:\"Environment\";O:8:\"stdClass\":3:{s:11:\"description\";s:55:\"Describes
  the environment in which a Dataflow Job runs.\";s:10:\"properties\";O:8:\"stdClass\":10:{s:24:\"clusterManagerApiService\";O:8:\"stdClass\":2:{s:11:\"description\";s:208:\"The
  type of cluster manager API to use.  If unknown or\nunspecified, the service will
  attempt to choose a reasonable\ndefault.  This should be in the form of the API
  service name,\ne.g. \"compute.googleapis.com\".\";s:4:\"type\";s:6:\"string\";}s:7:\"dataset\";O:8:\"stdClass\":2:{s:11:\"description\";s:172:\"The
  dataset for the current project where various workflow\nrelated tables are stored.\n\nThe
  supported resource type is:\n\nGoogle BigQuery:\n  bigquery.googleapis.com/{dataset}\";s:4:\"type\";s:6:\"string\";}s:11:\"experiments\";O:8:\"stdClass\":3:{s:11:\"description\";s:34:\"The
  list of experiments to enable.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:4:\"type\";s:5:\"array\";}s:19:\"internalExperiments\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:61:\"Properties
  of the object. Contains field @type with type URL.\";}s:11:\"description\";s:22:\"Experimental
  settings.\";s:4:\"type\";s:6:\"object\";}s:18:\"sdkPipelineOptions\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Properties
  of the object.\";}s:11:\"description\";s:224:\"The Cloud Dataflow SDK pipeline options
  specified by the user. These\noptions are passed through the service and are used
  to recreate the\nSDK pipeline options on the worker in a language agnostic and platform\nindependent
  way.\";s:4:\"type\";s:6:\"object\";}s:19:\"serviceAccountEmail\";O:8:\"stdClass\":2:{s:11:\"description\";s:69:\"Identity
  to run virtual machines as. Defaults to the default account.\";s:4:\"type\";s:6:\"string\";}s:17:\"tempStoragePrefix\";O:8:\"stdClass\":2:{s:11:\"description\";s:542:\"The
  prefix of the resources the system should use for temporary\nstorage.  The system
  will append the suffix \"/temp-{JOBNAME} to\nthis resource prefix, where {JOBNAME}
  is the value of the\njob_name field.  The resulting bucket and object prefix is
  used\nas the prefix of the resources used to store temporary data\nneeded during
  the job execution.  NOTE: This will override the\nvalue in taskrunner_settings.\nThe
  supported resource type is:\n\nGoogle Cloud Storage:\n\n  storage.googleapis.com/{bucket}/{object}\n
  \ bucket.storage.googleapis.com/{object}\";s:4:\"type\";s:6:\"string\";}s:9:\"userAgent\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Properties
  of the object.\";}s:11:\"description\";s:56:\"A description of the process that
  generated the request.\";s:4:\"type\";s:6:\"object\";}s:7:\"version\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Properties
  of the object.\";}s:11:\"description\";s:111:\"A structure describing which components
  and their versions of the service\nare required in order to run the job.\";s:4:\"type\";s:6:\"object\";}s:11:\"workerPools\";O:8:\"stdClass\":3:{s:11:\"description\";s:108:\"The
  worker pools. At least one \"harness\" worker pool must be\nspecified in order for
  the job to have workers.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:24:\"#/definitions/WorkerPool\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:19:\"ExecutionStageState\";O:8:\"stdClass\":3:{s:11:\"description\";s:63:\"A
  message describing the state of a particular execution stage.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:16:\"currentStateTime\";O:8:\"stdClass\":3:{s:11:\"description\";s:55:\"The
  time at which the stage transitioned to this state.\";s:6:\"format\";s:15:\"google-datetime\";s:4:\"type\";s:6:\"string\";}s:18:\"executionStageName\";O:8:\"stdClass\":2:{s:11:\"description\";s:32:\"The
  name of the execution stage.\";s:4:\"type\";s:6:\"string\";}s:19:\"executionStageState\";O:8:\"stdClass\":3:{s:11:\"description\";s:65:\"Executions
  stage states allow the same set of values as JobState.\";s:4:\"enum\";a:11:{i:0;s:17:\"JOB_STATE_UNKNOWN\";i:1;s:17:\"JOB_STATE_STOPPED\";i:2;s:17:\"JOB_STATE_RUNNING\";i:3;s:14:\"JOB_STATE_DONE\";i:4;s:16:\"JOB_STATE_FAILED\";i:5;s:19:\"JOB_STATE_CANCELLED\";i:6;s:17:\"JOB_STATE_UPDATED\";i:7;s:18:\"JOB_STATE_DRAINING\";i:8;s:17:\"JOB_STATE_DRAINED\";i:9;s:17:\"JOB_STATE_PENDING\";i:10;s:20:\"JOB_STATE_CANCELLING\";}s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:21:\"ExecutionStageSummary\";O:8:\"stdClass\":3:{s:11:\"description\";s:208:\"Description
  of the composing transforms, names/ids, and input/outputs of a\nstage of execution.
  \ Some composing transforms and sources may have been\ngenerated by the Dataflow
  service during execution planning.\";s:10:\"properties\";O:8:\"stdClass\":7:{s:15:\"componentSource\";O:8:\"stdClass\":3:{s:11:\"description\";s:72:\"Collections
  produced and consumed by component transforms of this stage.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:29:\"#/definitions/ComponentSource\";}s:4:\"type\";s:5:\"array\";}s:18:\"componentTransform\";O:8:\"stdClass\":3:{s:11:\"description\";s:46:\"Transforms
  that comprise this execution stage.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:32:\"#/definitions/ComponentTransform\";}s:4:\"type\";s:5:\"array\";}s:2:\"id\";O:8:\"stdClass\":2:{s:11:\"description\";s:45:\"Dataflow
  service generated id for this stage.\";s:4:\"type\";s:6:\"string\";}s:11:\"inputSource\";O:8:\"stdClass\":3:{s:11:\"description\";s:29:\"Input
  sources for this stage.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:25:\"#/definitions/StageSource\";}s:4:\"type\";s:5:\"array\";}s:4:\"kind\";O:8:\"stdClass\":3:{s:11:\"description\";s:41:\"Type
  of tranform this stage is executing.\";s:4:\"enum\";a:9:{i:0;s:12:\"UNKNOWN_KIND\";i:1;s:11:\"PAR_DO_KIND\";i:2;s:17:\"GROUP_BY_KEY_KIND\";i:3;s:12:\"FLATTEN_KIND\";i:4;s:9:\"READ_KIND\";i:5;s:10:\"WRITE_KIND\";i:6;s:13:\"CONSTANT_KIND\";i:7;s:14:\"SINGLETON_KIND\";i:8;s:12:\"SHUFFLE_KIND\";}s:4:\"type\";s:6:\"string\";}s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:47:\"Dataflow
  service generated name for this stage.\";s:4:\"type\";s:6:\"string\";}s:12:\"outputSource\";O:8:\"stdClass\":3:{s:11:\"description\";s:30:\"Output
  sources for this stage.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:25:\"#/definitions/StageSource\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:14:\"FailedLocation\";O:8:\"stdClass\":3:{s:11:\"description\";s:65:\"Indicates
  which location failed to respond to a request for data.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:32:\"The
  name of the failed location.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:18:\"FlattenInstruction\";O:8:\"stdClass\":3:{s:11:\"description\";s:76:\"An
  instruction that copies its inputs (zero or more) to its (single) output.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:6:\"inputs\";O:8:\"stdClass\":3:{s:11:\"description\";s:48:\"Describes
  the inputs to the flatten instruction.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:30:\"#/definitions/InstructionInput\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:17:\"FloatingPointList\";O:8:\"stdClass\":3:{s:11:\"description\";s:61:\"A
  metric value representing a list of floating point numbers.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:8:\"elements\";O:8:\"stdClass\":3:{s:11:\"description\";s:21:\"Elements
  of the list.\";s:5:\"items\";O:8:\"stdClass\":2:{s:6:\"format\";s:6:\"double\";s:4:\"type\";s:6:\"number\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:17:\"FloatingPointMean\";O:8:\"stdClass\":3:{s:11:\"description\";s:62:\"A
  representation of a floating point mean metric contribution.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:5:\"count\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:24:\"#/definitions/SplitInt64\";s:11:\"description\";s:38:\"The
  number of values being aggregated.\";}s:3:\"sum\";O:8:\"stdClass\":3:{s:11:\"description\";s:39:\"The
  sum of all values being aggregated.\";s:6:\"format\";s:6:\"double\";s:4:\"type\";s:6:\"number\";}}s:4:\"type\";s:6:\"object\";}s:21:\"GetDebugConfigRequest\";O:8:\"stdClass\":3:{s:11:\"description\";s:57:\"Request
  to get updated debug configuration for component.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:11:\"componentId\";O:8:\"stdClass\":2:{s:11:\"description\";s:69:\"The
  internal component id for which debug configuration is\nrequested.\";s:4:\"type\";s:6:\"string\";}s:8:\"location\";O:8:\"stdClass\":2:{s:11:\"description\";s:56:\"The
  location which contains the job specified by job_id.\";s:4:\"type\";s:6:\"string\";}s:8:\"workerId\";O:8:\"stdClass\":2:{s:11:\"description\";s:33:\"The
  worker id, i.e., VM hostname.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:22:\"GetDebugConfigResponse\";O:8:\"stdClass\":3:{s:11:\"description\";s:46:\"Response
  to a get debug configuration request.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:6:\"config\";O:8:\"stdClass\":2:{s:11:\"description\";s:60:\"The
  encoded debug configuration for the requested component.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:19:\"GetTemplateResponse\";O:8:\"stdClass\":3:{s:11:\"description\";s:38:\"The
  response to a GetTemplate request.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:8:\"metadata\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:30:\"#/definitions/TemplateMetadata\";s:11:\"description\";s:78:\"The
  template metadata describing the template name, available\nparameters, etc.\";}s:6:\"status\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:20:\"#/definitions/Status\";s:11:\"description\";s:109:\"The
  status of the get template request. Any problems with the\nrequest will be indicated
  in the error_details.\";}}s:4:\"type\";s:6:\"object\";}s:9:\"Histogram\";O:8:\"stdClass\":3:{s:11:\"description\";s:367:\"Histogram
  of value counts for a distribution.\n\nBuckets have an inclusive lower bound and
  exclusive upper bound and use\n\"1,2,5 bucketing\": The first bucket range is from
  [0,1) and all subsequent\nbucket boundaries are powers of ten multiplied by 1, 2,
  or 5. Thus, bucket\nboundaries are 0, 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000,
  ...\nNegative values are not supported.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:12:\"bucketCounts\";O:8:\"stdClass\":3:{s:11:\"description\";s:237:\"Counts
  of values in each bucket. For efficiency, prefix and trailing\nbuckets with count
  = 0 are elided. Buckets can store the full range of\nvalues of an unsigned long,
  with ULLONG_MAX falling into the 59th bucket\nwith range [1e19, 2e19).\";s:5:\"items\";O:8:\"stdClass\":2:{s:6:\"format\";s:5:\"int64\";s:4:\"type\";s:6:\"string\";}s:4:\"type\";s:5:\"array\";}s:17:\"firstBucketOffset\";O:8:\"stdClass\":3:{s:11:\"description\";s:172:\"Starting
  index of first stored bucket. The non-inclusive upper-bound of\nthe ith bucket is
  given by:\n  pow(10,(i-first_bucket_offset)/3) * (1,2,5)[(i-first_bucket_offset)%3]\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}}s:4:\"type\";s:6:\"object\";}s:16:\"InstructionInput\";O:8:\"stdClass\":3:{s:11:\"description\";s:82:\"An
  input of an instruction, as a reference to an output of a\nproducer instruction.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:9:\"outputNum\";O:8:\"stdClass\":3:{s:11:\"description\";s:51:\"The
  output index (origin zero) within the producer.\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}s:24:\"producerInstructionIndex\";O:8:\"stdClass\":3:{s:11:\"description\";s:208:\"The
  index (origin zero) of the parallel instruction that produces\nthe output to be
  consumed by this input.  This index is relative\nto the list of instructions in
  this input's instruction's\ncontaining MapTask.\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}}s:4:\"type\";s:6:\"object\";}s:17:\"InstructionOutput\";O:8:\"stdClass\":3:{s:11:\"description\";s:28:\"An
  output of an instruction.\";s:10:\"properties\";O:8:\"stdClass\":6:{s:5:\"codec\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Properties
  of the object.\";}s:11:\"description\";s:62:\"The codec to use to encode data being
  written via this output.\";s:4:\"type\";s:6:\"object\";}s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:38:\"The
  user-provided name of this output.\";s:4:\"type\";s:6:\"string\";}s:17:\"onlyCountKeyBytes\";O:8:\"stdClass\":2:{s:11:\"description\";s:102:\"For
  system-generated byte and mean byte metrics, certain instructions\nshould only report
  the key size.\";s:4:\"type\";s:7:\"boolean\";}s:19:\"onlyCountValueBytes\";O:8:\"stdClass\":2:{s:11:\"description\";s:104:\"For
  system-generated byte and mean byte metrics, certain instructions\nshould only report
  the value size.\";s:4:\"type\";s:7:\"boolean\";}s:12:\"originalName\";O:8:\"stdClass\":2:{s:11:\"description\";s:142:\"System-defined
  name for this output in the original workflow graph.\nOutputs that do not contribute
  to an original instruction do not set this.\";s:4:\"type\";s:6:\"string\";}s:10:\"systemName\";O:8:\"stdClass\":2:{s:11:\"description\";s:63:\"System-defined
  name of this output.\nUnique across the workflow.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:12:\"IntegerGauge\";O:8:\"stdClass\":3:{s:11:\"description\";s:58:\"A
  metric value representing temporal values of a variable.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:9:\"timestamp\";O:8:\"stdClass\":3:{s:11:\"description\";s:72:\"The
  time at which this value was measured. Measured as msecs from epoch.\";s:6:\"format\";s:15:\"google-datetime\";s:4:\"type\";s:6:\"string\";}s:5:\"value\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:24:\"#/definitions/SplitInt64\";s:11:\"description\";s:52:\"The
  value of the variable represented by this gauge.\";}}s:4:\"type\";s:6:\"object\";}s:11:\"IntegerList\";O:8:\"stdClass\":3:{s:11:\"description\";s:47:\"A
  metric value representing a list of integers.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:8:\"elements\";O:8:\"stdClass\":3:{s:11:\"description\";s:21:\"Elements
  of the list.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:24:\"#/definitions/SplitInt64\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:11:\"IntegerMean\";O:8:\"stdClass\":3:{s:11:\"description\";s:56:\"A
  representation of an integer mean metric contribution.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:5:\"count\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:24:\"#/definitions/SplitInt64\";s:11:\"description\";s:38:\"The
  number of values being aggregated.\";}s:3:\"sum\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:24:\"#/definitions/SplitInt64\";s:11:\"description\";s:39:\"The
  sum of all values being aggregated.\";}}s:4:\"type\";s:6:\"object\";}s:3:\"Job\";O:8:\"stdClass\":3:{s:11:\"description\";s:54:\"Defines
  a job to be run by the Cloud Dataflow service.\";s:10:\"properties\";O:8:\"stdClass\":20:{s:15:\"clientRequestId\";O:8:\"stdClass\":2:{s:11:\"description\";s:457:\"The
  client's unique identifier of the job, re-used across retried attempts.\nIf this
  field is set, the service will ensure its uniqueness.\nThe request to create a job
  will fail if the service has knowledge of a\npreviously submitted job with the same
  client's ID and job name.\nThe caller may use this field to ensure idempotence of
  job\ncreation across retried attempts to create a job.\nBy default, the field is
  empty and, in that case, the service ignores it.\";s:4:\"type\";s:6:\"string\";}s:10:\"createTime\";O:8:\"stdClass\":3:{s:11:\"description\";s:98:\"The
  timestamp when the job was initially created. Immutable and set by the\nCloud Dataflow
  service.\";s:6:\"format\";s:15:\"google-datetime\";s:4:\"type\";s:6:\"string\";}s:12:\"currentState\";O:8:\"stdClass\":3:{s:11:\"description\";s:355:\"The
  current state of the job.\n\nJobs are created in the `JOB_STATE_STOPPED` state unless
  otherwise\nspecified.\n\nA job in the `JOB_STATE_RUNNING` state may asynchronously
  enter a\nterminal state. After a job has reached a terminal state, no\nfurther state
  updates may be made.\n\nThis field may be mutated by the Cloud Dataflow service;\ncallers
  cannot mutate it.\";s:4:\"enum\";a:11:{i:0;s:17:\"JOB_STATE_UNKNOWN\";i:1;s:17:\"JOB_STATE_STOPPED\";i:2;s:17:\"JOB_STATE_RUNNING\";i:3;s:14:\"JOB_STATE_DONE\";i:4;s:16:\"JOB_STATE_FAILED\";i:5;s:19:\"JOB_STATE_CANCELLED\";i:6;s:17:\"JOB_STATE_UPDATED\";i:7;s:18:\"JOB_STATE_DRAINING\";i:8;s:17:\"JOB_STATE_DRAINED\";i:9;s:17:\"JOB_STATE_PENDING\";i:10;s:20:\"JOB_STATE_CANCELLING\";}s:4:\"type\";s:6:\"string\";}s:16:\"currentStateTime\";O:8:\"stdClass\":3:{s:11:\"description\";s:48:\"The
  timestamp associated with the current state.\";s:6:\"format\";s:15:\"google-datetime\";s:4:\"type\";s:6:\"string\";}s:11:\"environment\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:25:\"#/definitions/Environment\";s:11:\"description\";s:28:\"The
  environment for the job.\";}s:13:\"executionInfo\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:30:\"#/definitions/JobExecutionInfo\";s:11:\"description\";s:11:\"Deprecated.\";}s:2:\"id\";O:8:\"stdClass\":2:{s:11:\"description\";s:142:\"The
  unique ID of this job.\n\nThis field is set by the Cloud Dataflow service when the
  Job is\ncreated, and is immutable for the life of the job.\";s:4:\"type\";s:6:\"string\";}s:6:\"labels\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:11:\"description\";s:369:\"User-defined
  labels for this job.\n\nThe labels map can contain no more than 64 entries.  Entries
  of the labels\nmap are UTF8 strings that comply with the following restrictions:\n\n*
  Keys must conform to regexp:  \\p{Ll}\\p{Lo}{0,62}\n* Values must conform to regexp:
  \ [\\p{Ll}\\p{Lo}\\p{N}_-]{0,63}\n* Both keys and values are additionally constrained
  to be <= 128 bytes in\nsize.\";s:4:\"type\";s:6:\"object\";}s:8:\"location\";O:8:\"stdClass\":2:{s:11:\"description\";s:36:\"The
  location that contains this job.\";s:4:\"type\";s:6:\"string\";}s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:317:\"The
  user-specified Cloud Dataflow job name.\n\nOnly one Job with a given name may exist
  in a project at any\ngiven time. If a caller attempts to create a Job with the same\nname
  as an already-existing Job, the attempt returns the\nexisting Job.\n\nThe name must
  match the regular expression\n`[a-z]([-a-z0-9]{0,38}[a-z0-9])?`\";s:4:\"type\";s:6:\"string\";}s:19:\"pipelineDescription\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:33:\"#/definitions/PipelineDescription\";s:11:\"description\";s:236:\"Preliminary
  field: The format of this data may change at any time.\nA description of the user
  pipeline and stages through which it is executed.\nCreated by Cloud Dataflow service.
  \ Only retrieved with\nJOB_VIEW_DESCRIPTION or JOB_VIEW_ALL.\";}s:9:\"projectId\";O:8:\"stdClass\":2:{s:11:\"description\";s:61:\"The
  ID of the Cloud Platform project that the job belongs to.\";s:4:\"type\";s:6:\"string\";}s:12:\"replaceJobId\";O:8:\"stdClass\":2:{s:11:\"description\";s:259:\"If
  this job is an update of an existing job, this field is the job ID\nof the job it
  replaced.\n\nWhen sending a `CreateJobRequest`, you can update a job by specifying
  it\nhere. The job named here is stopped, and its intermediate state is\ntransferred
  to this job.\";s:4:\"type\";s:6:\"string\";}s:15:\"replacedByJobId\";O:8:\"stdClass\":2:{s:11:\"description\";s:127:\"If
  another job is an update of this job (and thus, this job is in\n`JOB_STATE_UPDATED`),
  this field contains the ID of that job.\";s:4:\"type\";s:6:\"string\";}s:14:\"requestedState\";O:8:\"stdClass\":3:{s:11:\"description\";s:349:\"The
  job's requested state.\n\n`UpdateJob` may be used to switch between the `JOB_STATE_STOPPED`
  and\n`JOB_STATE_RUNNING` states, by setting requested_state.  `UpdateJob` may\nalso
  be used to directly set a job's requested state to\n`JOB_STATE_CANCELLED` or `JOB_STATE_DONE`,
  irrevocably terminating the\njob if it has not already reached a terminal state.\";s:4:\"enum\";a:11:{i:0;s:17:\"JOB_STATE_UNKNOWN\";i:1;s:17:\"JOB_STATE_STOPPED\";i:2;s:17:\"JOB_STATE_RUNNING\";i:3;s:14:\"JOB_STATE_DONE\";i:4;s:16:\"JOB_STATE_FAILED\";i:5;s:19:\"JOB_STATE_CANCELLED\";i:6;s:17:\"JOB_STATE_UPDATED\";i:7;s:18:\"JOB_STATE_DRAINING\";i:8;s:17:\"JOB_STATE_DRAINED\";i:9;s:17:\"JOB_STATE_PENDING\";i:10;s:20:\"JOB_STATE_CANCELLING\";}s:4:\"type\";s:6:\"string\";}s:11:\"stageStates\";O:8:\"stdClass\":3:{s:11:\"description\";s:82:\"This
  field may be mutated by the Cloud Dataflow service;\ncallers cannot mutate it.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:33:\"#/definitions/ExecutionStageState\";}s:4:\"type\";s:5:\"array\";}s:5:\"steps\";O:8:\"stdClass\":3:{s:11:\"description\";s:51:\"The
  top-level steps that constitute the entire job.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:18:\"#/definitions/Step\";}s:4:\"type\";s:5:\"array\";}s:9:\"tempFiles\";O:8:\"stdClass\":3:{s:11:\"description\";s:333:\"A
  set of files the system should be aware of that are used\nfor temporary storage.
  These temporary files will be\nremoved on job completion.\nNo duplicates are allowed.\nNo
  file patterns are supported.\n\nThe supported files are:\n\nGoogle Cloud Storage:\n\n
  \  storage.googleapis.com/{bucket}/{object}\n   bucket.storage.googleapis.com/{object}\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:4:\"type\";s:5:\"array\";}s:20:\"transformNameMapping\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:11:\"description\";s:111:\"The
  map of transform name prefixes of the job to be replaced to the\ncorresponding name
  prefixes of the new job.\";s:4:\"type\";s:6:\"object\";}s:4:\"type\";O:8:\"stdClass\":3:{s:11:\"description\";s:31:\"The
  type of Cloud Dataflow job.\";s:4:\"enum\";a:3:{i:0;s:16:\"JOB_TYPE_UNKNOWN\";i:1;s:14:\"JOB_TYPE_BATCH\";i:2;s:18:\"JOB_TYPE_STREAMING\";}s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:16:\"JobExecutionInfo\";O:8:\"stdClass\":3:{s:11:\"description\";s:113:\"Additional
  information about how a Cloud Dataflow job will be executed that\nisn't contained
  in the submitted job.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:6:\"stages\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:35:\"#/definitions/JobExecutionStageInfo\";}s:11:\"description\";s:62:\"A
  mapping from each stage to the information about that stage.\";s:4:\"type\";s:6:\"object\";}}s:4:\"type\";s:6:\"object\";}s:21:\"JobExecutionStageInfo\";O:8:\"stdClass\":3:{s:11:\"description\";s:90:\"Contains
  information about how a particular\ngoogle.dataflow.v1beta3.Step will be executed.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:8:\"stepName\";O:8:\"stdClass\":3:{s:11:\"description\";s:146:\"The
  steps associated with the execution stage.\nNote that stages may have several steps,
  and that a given step\nmight be run by more than one stage.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:10:\"JobMessage\";O:8:\"stdClass\":3:{s:11:\"description\";s:50:\"A
  particular message pertaining to a Dataflow job.\";s:10:\"properties\";O:8:\"stdClass\":4:{s:2:\"id\";O:8:\"stdClass\":2:{s:11:\"description\";s:11:\"Deprecated.\";s:4:\"type\";s:6:\"string\";}s:17:\"messageImportance\";O:8:\"stdClass\":3:{s:11:\"description\";s:32:\"Importance
  level of the message.\";s:4:\"enum\";a:6:{i:0;s:30:\"JOB_MESSAGE_IMPORTANCE_UNKNOWN\";i:1;s:17:\"JOB_MESSAGE_DEBUG\";i:2;s:20:\"JOB_MESSAGE_DETAILED\";i:3;s:17:\"JOB_MESSAGE_BASIC\";i:4;s:19:\"JOB_MESSAGE_WARNING\";i:5;s:17:\"JOB_MESSAGE_ERROR\";}s:4:\"type\";s:6:\"string\";}s:11:\"messageText\";O:8:\"stdClass\":2:{s:11:\"description\";s:24:\"The
  text of the message.\";s:4:\"type\";s:6:\"string\";}s:4:\"time\";O:8:\"stdClass\":3:{s:11:\"description\";s:29:\"The
  timestamp of the message.\";s:6:\"format\";s:15:\"google-datetime\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:10:\"JobMetrics\";O:8:\"stdClass\":3:{s:11:\"description\";s:330:\"JobMetrics
  contains a collection of metrics descibing the detailed progress\nof a Dataflow
  job. Metrics correspond to user-defined and system-defined\nmetrics in the job.\n\nThis
  resource captures only the most recent values of each metric;\ntime-series data
  can be queried for them (under the same metric names)\nfrom Cloud Monitoring.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:10:\"metricTime\";O:8:\"stdClass\":3:{s:11:\"description\";s:48:\"Timestamp
  as of which metric values are current.\";s:6:\"format\";s:15:\"google-datetime\";s:4:\"type\";s:6:\"string\";}s:7:\"metrics\";O:8:\"stdClass\":3:{s:11:\"description\";s:25:\"All
  metrics for this job.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:26:\"#/definitions/MetricUpdate\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:26:\"KeyRangeDataDiskAssignment\";O:8:\"stdClass\":3:{s:11:\"description\";s:164:\"Data
  disk assignment information for a specific key-range of a sharded\ncomputation.\nCurrently
  we only support UTF-8 character splits to simplify encoding into\nJSON.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:8:\"dataDisk\";O:8:\"stdClass\":2:{s:11:\"description\";s:230:\"The
  name of the data disk where data for this range is stored.\nThis name is local to
  the Google Cloud Platform project and uniquely\nidentifies the disk within that
  project, for example\n\"myproject-1014-104817-4c2-harness-0-disk-1\".\";s:4:\"type\";s:6:\"string\";}s:3:\"end\";O:8:\"stdClass\":2:{s:11:\"description\";s:37:\"The
  end (exclusive) of the key range.\";s:4:\"type\";s:6:\"string\";}s:5:\"start\";O:8:\"stdClass\":2:{s:11:\"description\";s:39:\"The
  start (inclusive) of the key range.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:16:\"KeyRangeLocation\";O:8:\"stdClass\":3:{s:11:\"description\";s:152:\"Location
  information for a specific key-range of a sharded computation.\nCurrently we only
  support UTF-8 character splits to simplify encoding into\nJSON.\";s:10:\"properties\";O:8:\"stdClass\":5:{s:8:\"dataDisk\";O:8:\"stdClass\":2:{s:11:\"description\";s:230:\"The
  name of the data disk where data for this range is stored.\nThis name is local to
  the Google Cloud Platform project and uniquely\nidentifies the disk within that
  project, for example\n\"myproject-1014-104817-4c2-harness-0-disk-1\".\";s:4:\"type\";s:6:\"string\";}s:16:\"deliveryEndpoint\";O:8:\"stdClass\":2:{s:11:\"description\";s:114:\"The
  physical location of this range assignment to be used for\nstreaming computation
  cross-worker message delivery.\";s:4:\"type\";s:6:\"string\";}s:29:\"deprecatedPersistentDirectory\";O:8:\"stdClass\":2:{s:11:\"description\";s:122:\"DEPRECATED.
  The location of the persistent state for this range, as a\npersistent directory
  in the worker local filesystem.\";s:4:\"type\";s:6:\"string\";}s:3:\"end\";O:8:\"stdClass\":2:{s:11:\"description\";s:37:\"The
  end (exclusive) of the key range.\";s:4:\"type\";s:6:\"string\";}s:5:\"start\";O:8:\"stdClass\":2:{s:11:\"description\";s:39:\"The
  start (inclusive) of the key range.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:24:\"LaunchTemplateParameters\";O:8:\"stdClass\":3:{s:11:\"description\";s:53:\"Parameters
  to provide to the template being launched.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:11:\"environment\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/RuntimeEnvironment\";s:11:\"description\";s:36:\"The
  runtime environment for the job.\";}s:7:\"jobName\";O:8:\"stdClass\":2:{s:11:\"description\";s:50:\"Required.
  The job name to use for the created job.\";s:4:\"type\";s:6:\"string\";}s:10:\"parameters\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:11:\"description\";s:42:\"The
  runtime parameters to pass to the job.\";s:4:\"type\";s:6:\"object\";}}s:4:\"type\";s:6:\"object\";}s:22:\"LaunchTemplateResponse\";O:8:\"stdClass\":3:{s:11:\"description\";s:45:\"Response
  to the request to launch a template.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:3:\"job\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:17:\"#/definitions/Job\";s:11:\"description\";s:98:\"The
  job that was launched, if the request was not a dry run and\nthe job was successfully
  launched.\";}}s:4:\"type\";s:6:\"object\";}s:20:\"LeaseWorkItemRequest\";O:8:\"stdClass\":3:{s:11:\"description\";s:27:\"Request
  to lease WorkItems.\";s:10:\"properties\";O:8:\"stdClass\":6:{s:17:\"currentWorkerTime\";O:8:\"stdClass\":3:{s:11:\"description\";s:36:\"The
  current timestamp at the worker.\";s:6:\"format\";s:15:\"google-datetime\";s:4:\"type\";s:6:\"string\";}s:8:\"location\";O:8:\"stdClass\":2:{s:11:\"description\";s:47:\"The
  location which contains the WorkItem's job.\";s:4:\"type\";s:6:\"string\";}s:22:\"requestedLeaseDuration\";O:8:\"stdClass\":3:{s:11:\"description\";s:25:\"The
  initial lease period.\";s:6:\"format\";s:15:\"google-duration\";s:4:\"type\";s:6:\"string\";}s:13:\"workItemTypes\";O:8:\"stdClass\":3:{s:11:\"description\";s:25:\"Filter
  for WorkItem type.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:4:\"type\";s:5:\"array\";}s:18:\"workerCapabilities\";O:8:\"stdClass\":3:{s:11:\"description\";s:86:\"Worker
  capabilities. WorkItems might be limited to workers with specific\ncapabilities.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:4:\"type\";s:5:\"array\";}s:8:\"workerId\";O:8:\"stdClass\":2:{s:11:\"description\";s:97:\"Identifies
  the worker leasing work -- typically the ID of the\nvirtual machine running the
  worker.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:21:\"LeaseWorkItemResponse\";O:8:\"stdClass\":3:{s:11:\"description\";s:41:\"Response
  to a request to lease WorkItems.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:9:\"workItems\";O:8:\"stdClass\":3:{s:11:\"description\";s:31:\"A
  list of the leased WorkItems.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:22:\"#/definitions/WorkItem\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:23:\"ListJobMessagesResponse\";O:8:\"stdClass\":3:{s:11:\"description\";s:43:\"Response
  to a request to list job messages.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:17:\"autoscalingEvents\";O:8:\"stdClass\":3:{s:11:\"description\";s:48:\"Autoscaling
  events in ascending timestamp order.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:30:\"#/definitions/AutoscalingEvent\";}s:4:\"type\";s:5:\"array\";}s:11:\"jobMessages\";O:8:\"stdClass\":3:{s:11:\"description\";s:38:\"Messages
  in ascending timestamp order.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:24:\"#/definitions/JobMessage\";}s:4:\"type\";s:5:\"array\";}s:13:\"nextPageToken\";O:8:\"stdClass\":2:{s:11:\"description\";s:63:\"The
  token to obtain the next page of results if there are more.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:16:\"ListJobsResponse\";O:8:\"stdClass\":3:{s:11:\"description\";s:134:\"Response
  to a request to list Cloud Dataflow jobs.  This may be a partial\nresponse, depending
  on the page size in the ListJobsRequest.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:14:\"failedLocation\";O:8:\"stdClass\":3:{s:11:\"description\";s:66:\"Zero
  or more messages describing locations that failed to respond.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:28:\"#/definitions/FailedLocation\";}s:4:\"type\";s:5:\"array\";}s:4:\"jobs\";O:8:\"stdClass\":3:{s:11:\"description\";s:42:\"A
  subset of the requested job information.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:17:\"#/definitions/Job\";}s:4:\"type\";s:5:\"array\";}s:13:\"nextPageToken\";O:8:\"stdClass\":2:{s:11:\"description\";s:59:\"Set
  if there may be more results than fit in this response.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:7:\"MapTask\";O:8:\"stdClass\":3:{s:11:\"description\";s:278:\"MapTask
  consists of an ordered set of instructions, each of which\ndescribes one particular
  low-level operation for the worker to\nperform in order to accomplish the MapTask's
  WorkItem.\n\nEach instruction must appear in the list before any instructions which\ndepends
  on its output.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:12:\"instructions\";O:8:\"stdClass\":3:{s:11:\"description\";s:32:\"The
  instructions in the MapTask.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:33:\"#/definitions/ParallelInstruction\";}s:4:\"type\";s:5:\"array\";}s:9:\"stageName\";O:8:\"stdClass\":2:{s:11:\"description\";s:85:\"System-defined
  name of the stage containing this MapTask.\nUnique across the workflow.\";s:4:\"type\";s:6:\"string\";}s:10:\"systemName\";O:8:\"stdClass\":2:{s:11:\"description\";s:64:\"System-defined
  name of this MapTask.\nUnique across the workflow.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:13:\"MetricShortId\";O:8:\"stdClass\":3:{s:11:\"description\";s:96:\"The
  metric short id is returned to the user alongside an offset into\nReportWorkItemStatusRequest\";s:10:\"properties\";O:8:\"stdClass\":2:{s:11:\"metricIndex\";O:8:\"stdClass\":3:{s:11:\"description\";s:83:\"The
  index of the corresponding metric in\nthe ReportWorkItemStatusRequest. Required.\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}s:7:\"shortId\";O:8:\"stdClass\":3:{s:11:\"description\";s:54:\"The
  service-generated short identifier for the metric.\";s:6:\"format\";s:5:\"int64\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:20:\"MetricStructuredName\";O:8:\"stdClass\":3:{s:11:\"description\";s:73:\"Identifies
  a metric, by describing the source which generated the\nmetric.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:7:\"context\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:11:\"description\";s:335:\"Zero
  or more labeled fields which identify the part of the job this\nmetric is associated
  with, such as the name of a step or collection.\n\nFor example, built-in counters
  associated with steps will have\ncontext['step'] = <step-name>. Counters associated
  with PCollections\nin the SDK will have context['pcollection'] = <pcollection-name>.\";s:4:\"type\";s:6:\"object\";}s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:27:\"Worker-defined
  metric name.\";s:4:\"type\";s:6:\"string\";}s:6:\"origin\";O:8:\"stdClass\":2:{s:11:\"description\";s:143:\"Origin
  (namespace) of metric name. May be blank for user-define metrics;\nwill be \"dataflow\"
  for metrics defined by the Dataflow service or SDK.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:12:\"MetricUpdate\";O:8:\"stdClass\":3:{s:11:\"description\";s:32:\"Describes
  the state of a metric.\";s:10:\"properties\";O:8:\"stdClass\":11:{s:10:\"cumulative\";O:8:\"stdClass\":2:{s:11:\"description\";s:253:\"True
  if this metric is reported as the total cumulative aggregate\nvalue accumulated
  since the worker started working on this WorkItem.\nBy default this is false, indicating
  that this metric is reported\nas a delta that is not associated with any WorkItem.\";s:4:\"type\";s:7:\"boolean\";}s:12:\"distribution\";O:8:\"stdClass\":1:{s:11:\"description\";s:73:\"A
  struct value describing properties of a distribution of numeric values.\";}s:5:\"gauge\";O:8:\"stdClass\":1:{s:11:\"description\";s:155:\"A
  struct value describing properties of a Gauge.\nMetrics of gauge type show the value
  of a metric across time, and is\naggregated based on the newest value.\";}s:8:\"internal\";O:8:\"stdClass\":1:{s:11:\"description\";s:73:\"Worker-computed
  aggregate value for internal use by the Dataflow\nservice.\";}s:4:\"kind\";O:8:\"stdClass\":2:{s:11:\"description\";s:275:\"Metric
  aggregation kind.  The possible metric aggregation kinds are\n\"Sum\", \"Max\",
  \"Min\", \"Mean\", \"Set\", \"And\", \"Or\", and \"Distribution\".\nThe specified
  aggregation kind is case-insensitive.\n\nIf omitted, this is not an aggregated value
  but instead\na single metric sample value.\";s:4:\"type\";s:6:\"string\";}s:9:\"meanCount\";O:8:\"stdClass\":1:{s:11:\"description\";s:238:\"Worker-computed
  aggregate value for the \"Mean\" aggregation kind.\nThis holds the count of the
  aggregated values and is used in combination\nwith mean_sum above to obtain the
  actual mean aggregate value.\nThe only possible value type is Long.\";}s:7:\"meanSum\";O:8:\"stdClass\":1:{s:11:\"description\";s:251:\"Worker-computed
  aggregate value for the \"Mean\" aggregation kind.\nThis holds the sum of the aggregated
  values and is used in combination\nwith mean_count below to obtain the actual mean
  aggregate value.\nThe only possible value types are Long and Double.\";}s:4:\"name\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:34:\"#/definitions/MetricStructuredName\";s:11:\"description\";s:19:\"Name
  of the metric.\";}s:6:\"scalar\";O:8:\"stdClass\":1:{s:11:\"description\";s:148:\"Worker-computed
  aggregate value for aggregation kinds \"Sum\", \"Max\", \"Min\",\n\"And\", and \"Or\".
  \ The possible value types are Long, Double, and Boolean.\";}s:3:\"set\";O:8:\"stdClass\":1:{s:11:\"description\";s:238:\"Worker-computed
  aggregate value for the \"Set\" aggregation kind.  The only\npossible value type
  is a list of Values whose type can be Long, Double,\nor String, according to the
  metric's type.  All Values in the list must\nbe of the same type.\";}s:10:\"updateTime\";O:8:\"stdClass\":3:{s:11:\"description\";s:147:\"Timestamp
  associated with the metric value. Optional when workers are\nreporting work progress;
  it will be filled in responses from the\nmetrics API.\";s:6:\"format\";s:15:\"google-datetime\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:15:\"MountedDataDisk\";O:8:\"stdClass\":3:{s:11:\"description\";s:28:\"Describes
  mounted data disk.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:8:\"dataDisk\";O:8:\"stdClass\":2:{s:11:\"description\";s:194:\"The
  name of the data disk.\nThis name is local to the Google Cloud Platform project
  and uniquely\nidentifies the disk within that project, for example\n\"myproject-1014-104817-4c2-harness-0-disk-1\".\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:15:\"MultiOutputInfo\";O:8:\"stdClass\":3:{s:11:\"description\";s:51:\"Information
  about an output of a multi-output DoFn.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:3:\"tag\";O:8:\"stdClass\":2:{s:11:\"description\";s:117:\"The
  id of the tag the user code will emit to this output by; this\nshould correspond
  to the tag of some SideInputInfo.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:11:\"NameAndKind\";O:8:\"stdClass\":3:{s:11:\"description\";s:31:\"Basic
  metadata about a counter.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:4:\"kind\";O:8:\"stdClass\":3:{s:11:\"description\";s:25:\"Counter
  aggregation kind.\";s:4:\"enum\";a:10:{i:0;s:7:\"INVALID\";i:1;s:3:\"SUM\";i:2;s:3:\"MAX\";i:3;s:3:\"MIN\";i:4;s:4:\"MEAN\";i:5;s:2:\"OR\";i:6;s:3:\"AND\";i:7;s:3:\"SET\";i:8;s:12:\"DISTRIBUTION\";i:9;s:12:\"LATEST_VALUE\";}s:4:\"type\";s:6:\"string\";}s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:20:\"Name
  of the counter.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:7:\"Package\";O:8:\"stdClass\":3:{s:11:\"description\";s:445:\"The
  packages that must be installed in order for a worker to run the\nsteps of the Cloud
  Dataflow job that will be assigned to its worker\npool.\n\nThis is the mechanism
  by which the Cloud Dataflow SDK causes code to\nbe loaded onto the workers. For
  example, the Cloud Dataflow Java SDK\nmight use this to install jars containing
  the user's code and all of the\nvarious dependencies (libraries, data files, etc.)
  required in order\nfor that code to run.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:8:\"location\";O:8:\"stdClass\":2:{s:11:\"description\";s:161:\"The
  resource to read the package from. The supported resource type is:\n\nGoogle Cloud
  Storage:\n\n  storage.googleapis.com/{bucket}\n  bucket.storage.googleapis.com/\";s:4:\"type\";s:6:\"string\";}s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:24:\"The
  name of the package.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:16:\"ParDoInstruction\";O:8:\"stdClass\":3:{s:11:\"description\";s:145:\"An
  instruction that does a ParDo operation.\nTakes one main input and zero or more
  side inputs, and produces\nzero or more outputs.\nRuns user code.\";s:10:\"properties\";O:8:\"stdClass\":5:{s:5:\"input\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:30:\"#/definitions/InstructionInput\";s:11:\"description\";s:10:\"The
  input.\";}s:16:\"multiOutputInfos\";O:8:\"stdClass\":3:{s:11:\"description\";s:66:\"Information
  about each of the outputs, if user_fn is a  MultiDoFn.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:29:\"#/definitions/MultiOutputInfo\";}s:4:\"type\";s:5:\"array\";}s:10:\"numOutputs\";O:8:\"stdClass\":3:{s:11:\"description\";s:22:\"The
  number of outputs.\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}s:10:\"sideInputs\";O:8:\"stdClass\":3:{s:11:\"description\";s:25:\"Zero
  or more side inputs.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:27:\"#/definitions/SideInputInfo\";}s:4:\"type\";s:5:\"array\";}s:6:\"userFn\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Properties
  of the object.\";}s:11:\"description\";s:28:\"The user function to invoke.\";s:4:\"type\";s:6:\"object\";}}s:4:\"type\";s:6:\"object\";}s:19:\"ParallelInstruction\";O:8:\"stdClass\":3:{s:11:\"description\";s:54:\"Describes
  a particular operation comprising a MapTask.\";s:10:\"properties\";O:8:\"stdClass\":9:{s:7:\"flatten\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/FlattenInstruction\";s:11:\"description\";s:48:\"Additional
  information for Flatten instructions.\";}s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:37:\"User-provided
  name of this operation.\";s:4:\"type\";s:6:\"string\";}s:12:\"originalName\";O:8:\"stdClass\":2:{s:11:\"description\";s:69:\"System-defined
  name for the operation in the original workflow graph.\";s:4:\"type\";s:6:\"string\";}s:7:\"outputs\";O:8:\"stdClass\":3:{s:11:\"description\";s:41:\"Describes
  the outputs of the instruction.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:31:\"#/definitions/InstructionOutput\";}s:4:\"type\";s:5:\"array\";}s:5:\"parDo\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:30:\"#/definitions/ParDoInstruction\";s:11:\"description\";s:46:\"Additional
  information for ParDo instructions.\";}s:17:\"partialGroupByKey\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:42:\"#/definitions/PartialGroupByKeyInstruction\";s:11:\"description\";s:58:\"Additional
  information for PartialGroupByKey instructions.\";}s:4:\"read\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:29:\"#/definitions/ReadInstruction\";s:11:\"description\";s:45:\"Additional
  information for Read instructions.\";}s:10:\"systemName\";O:8:\"stdClass\":2:{s:11:\"description\";s:66:\"System-defined
  name of this operation.\nUnique across the workflow.\";s:4:\"type\";s:6:\"string\";}s:5:\"write\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:30:\"#/definitions/WriteInstruction\";s:11:\"description\";s:46:\"Additional
  information for Write instructions.\";}}s:4:\"type\";s:6:\"object\";}s:9:\"Parameter\";O:8:\"stdClass\":3:{s:11:\"description\";s:45:\"Structured
  data associated with this message.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:3:\"key\";O:8:\"stdClass\":2:{s:11:\"description\";s:31:\"Key
  or name for this parameter.\";s:4:\"type\";s:6:\"string\";}s:5:\"value\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Value
  for this parameter.\";}}s:4:\"type\";s:6:\"object\";}s:17:\"ParameterMetadata\";O:8:\"stdClass\":3:{s:11:\"description\";s:34:\"Metadata
  for a specific parameter.\";s:10:\"properties\";O:8:\"stdClass\":5:{s:8:\"helpText\";O:8:\"stdClass\":2:{s:11:\"description\";s:53:\"Required.
  The help text to display for the parameter.\";s:4:\"type\";s:6:\"string\";}s:10:\"isOptional\";O:8:\"stdClass\":2:{s:11:\"description\";s:63:\"Optional.
  Whether the parameter is optional. Defaults to false.\";s:4:\"type\";s:7:\"boolean\";}s:5:\"label\";O:8:\"stdClass\":2:{s:11:\"description\";s:49:\"Required.
  The label to display for the parameter.\";s:4:\"type\";s:6:\"string\";}s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:36:\"Required.
  The name of the parameter.\";s:4:\"type\";s:6:\"string\";}s:7:\"regexes\";O:8:\"stdClass\":3:{s:11:\"description\";s:48:\"Optional.
  Regexes that the parameter must match.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:28:\"PartialGroupByKeyInstruction\";O:8:\"stdClass\":3:{s:11:\"description\";s:74:\"An
  instruction that does a partial group-by-key.\nOne input and one output.\";s:10:\"properties\";O:8:\"stdClass\":6:{s:5:\"input\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:30:\"#/definitions/InstructionInput\";s:11:\"description\";s:60:\"Describes
  the input to the partial group-by-key instruction.\";}s:17:\"inputElementCodec\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Properties
  of the object.\";}s:11:\"description\";s:65:\"The codec to use for interpreting
  an element in the input PTable.\";s:4:\"type\";s:6:\"object\";}s:35:\"originalCombineValuesInputStoreName\";O:8:\"stdClass\":2:{s:11:\"description\";s:131:\"If
  this instruction includes a combining function this is the name of the\nintermediate
  store between the GBK and the CombineValues.\";s:4:\"type\";s:6:\"string\";}s:29:\"originalCombineValuesStepName\";O:8:\"stdClass\":2:{s:11:\"description\";s:130:\"If
  this instruction includes a combining function, this is the name of the\nCombineValues
  instruction lifted into this instruction.\";s:4:\"type\";s:6:\"string\";}s:10:\"sideInputs\";O:8:\"stdClass\":3:{s:11:\"description\";s:25:\"Zero
  or more side inputs.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:27:\"#/definitions/SideInputInfo\";}s:4:\"type\";s:5:\"array\";}s:16:\"valueCombiningFn\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Properties
  of the object.\";}s:11:\"description\";s:39:\"The value combining function to invoke.\";s:4:\"type\";s:6:\"object\";}}s:4:\"type\";s:6:\"object\";}s:19:\"PipelineDescription\";O:8:\"stdClass\":3:{s:11:\"description\";s:209:\"A
  descriptive representation of submitted pipeline as well as the executed\nform.
  \ This data is provided by the Dataflow service for ease of visualizing\nthe pipeline
  and interpretting Dataflow provided metrics.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:11:\"displayData\";O:8:\"stdClass\":3:{s:11:\"description\";s:28:\"Pipeline
  level display data.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:25:\"#/definitions/DisplayData\";}s:4:\"type\";s:5:\"array\";}s:22:\"executionPipelineStage\";O:8:\"stdClass\":3:{s:11:\"description\";s:55:\"Description
  of each stage of execution of the pipeline.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:35:\"#/definitions/ExecutionStageSummary\";}s:4:\"type\";s:5:\"array\";}s:25:\"originalPipelineTransform\";O:8:\"stdClass\":3:{s:11:\"description\";s:75:\"Description
  of each transform in the pipeline and collections between them.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:30:\"#/definitions/TransformSummary\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:8:\"Position\";O:8:\"stdClass\":3:{s:11:\"description\";s:172:\"Position
  defines a position within a collection of data.  The value\ncan be either the end
  position, a key (used with ordered\ncollections), a byte offset, or a record index.\";s:10:\"properties\";O:8:\"stdClass\":6:{s:10:\"byteOffset\";O:8:\"stdClass\":3:{s:11:\"description\";s:26:\"Position
  is a byte offset.\";s:6:\"format\";s:5:\"int64\";s:4:\"type\";s:6:\"string\";}s:14:\"concatPosition\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/ConcatPosition\";s:11:\"description\";s:35:\"CloudPosition
  is a concat position.\";}s:3:\"end\";O:8:\"stdClass\":2:{s:11:\"description\";s:93:\"Position
  is past all other positions. Also useful for the end\nposition of an unbounded range.\";s:4:\"type\";s:7:\"boolean\";}s:3:\"key\";O:8:\"stdClass\":2:{s:11:\"description\";s:52:\"Position
  is a string key, ordered lexicographically.\";s:4:\"type\";s:6:\"string\";}s:11:\"recordIndex\";O:8:\"stdClass\":3:{s:11:\"description\";s:27:\"Position
  is a record index.\";s:6:\"format\";s:5:\"int64\";s:4:\"type\";s:6:\"string\";}s:15:\"shufflePosition\";O:8:\"stdClass\":2:{s:11:\"description\";s:77:\"CloudPosition
  is a base64 encoded BatchShufflePosition (with FIXED\nsharding).\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:14:\"PubsubLocation\";O:8:\"stdClass\":3:{s:11:\"description\";s:98:\"Identifies
  a pubsub location to use for transferring data into or\nout of a streaming Dataflow
  job.\";s:10:\"properties\";O:8:\"stdClass\":7:{s:12:\"dropLateData\";O:8:\"stdClass\":2:{s:11:\"description\";s:57:\"Indicates
  whether the pipeline allows late-arriving data.\";s:4:\"type\";s:7:\"boolean\";}s:7:\"idLabel\";O:8:\"stdClass\":2:{s:11:\"description\";s:131:\"If
  set, contains a pubsub label from which to extract record ids.\nIf left empty, record
  deduplication will be strictly best effort.\";s:4:\"type\";s:6:\"string\";}s:12:\"subscription\";O:8:\"stdClass\":2:{s:11:\"description\";s:108:\"A
  pubsub subscription, in the form of\n\"pubsub.googleapis.com/subscriptions/<project-id>/<subscription-name>\"\";s:4:\"type\";s:6:\"string\";}s:14:\"timestampLabel\";O:8:\"stdClass\":2:{s:11:\"description\";s:137:\"If
  set, contains a pubsub label from which to extract record timestamps.\nIf left empty,
  record timestamps will be generated upon arrival.\";s:4:\"type\";s:6:\"string\";}s:5:\"topic\";O:8:\"stdClass\":2:{s:11:\"description\";s:87:\"A
  pubsub topic, in the form of\n\"pubsub.googleapis.com/topics/<project-id>/<topic-name>\"\";s:4:\"type\";s:6:\"string\";}s:20:\"trackingSubscription\";O:8:\"stdClass\":2:{s:11:\"description\";s:121:\"If
  set, specifies the pubsub subscription that will be used for tracking\ncustom time
  timestamps for watermark estimation.\";s:4:\"type\";s:6:\"string\";}s:14:\"withAttributes\";O:8:\"stdClass\":2:{s:11:\"description\";s:64:\"If
  true, then the client has requested to get pubsub attributes.\";s:4:\"type\";s:7:\"boolean\";}}s:4:\"type\";s:6:\"object\";}s:15:\"ReadInstruction\";O:8:\"stdClass\":3:{s:11:\"description\";s:72:\"An
  instruction that reads records.\nTakes no inputs, produces one output.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:6:\"source\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:20:\"#/definitions/Source\";s:11:\"description\";s:24:\"The
  source to read from.\";}}s:4:\"type\";s:6:\"object\";}s:27:\"ReportWorkItemStatusRequest\";O:8:\"stdClass\":3:{s:11:\"description\";s:42:\"Request
  to report the status of WorkItems.\";s:10:\"properties\";O:8:\"stdClass\":4:{s:17:\"currentWorkerTime\";O:8:\"stdClass\":3:{s:11:\"description\";s:36:\"The
  current timestamp at the worker.\";s:6:\"format\";s:15:\"google-datetime\";s:4:\"type\";s:6:\"string\";}s:8:\"location\";O:8:\"stdClass\":2:{s:11:\"description\";s:47:\"The
  location which contains the WorkItem's job.\";s:4:\"type\";s:6:\"string\";}s:16:\"workItemStatuses\";O:8:\"stdClass\":3:{s:11:\"description\";s:178:\"The
  order is unimportant, except that the order of the\nWorkItemServiceState messages
  in the ReportWorkItemStatusResponse\ncorresponds to the order of WorkItemStatus
  messages here.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:28:\"#/definitions/WorkItemStatus\";}s:4:\"type\";s:5:\"array\";}s:8:\"workerId\";O:8:\"stdClass\":2:{s:11:\"description\";s:226:\"The
  ID of the worker reporting the WorkItem status.  If this\ndoes not match the ID
  of the worker which the Dataflow service\nbelieves currently has the lease on the
  WorkItem, the report\nwill be dropped (with an error response).\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:28:\"ReportWorkItemStatusResponse\";O:8:\"stdClass\":3:{s:11:\"description\";s:58:\"Response
  from a request to report the status of WorkItems.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:21:\"workItemServiceStates\";O:8:\"stdClass\":3:{s:11:\"description\";s:214:\"A
  set of messages indicating the service-side state for each\nWorkItem whose status
  was reported, in the same order as the\nWorkItemStatus messages in the ReportWorkItemStatusRequest
  which\nresulting in this response.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:34:\"#/definitions/WorkItemServiceState\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:19:\"ReportedParallelism\";O:8:\"stdClass\":3:{s:11:\"description\";s:82:\"Represents
  the level of parallelism in a WorkItem's input,\nreported by the worker.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:10:\"isInfinite\";O:8:\"stdClass\":2:{s:11:\"description\";s:315:\"Specifies
  whether the parallelism is infinite. If true, \"value\" is\nignored.\nInfinite parallelism
  means the service will assume that the work item\ncan always be split into more
  non-empty work items by dynamic splitting.\nThis is a work-around for lack of support
  for infinity by the current\nJSON-based Java RPC stack.\";s:4:\"type\";s:7:\"boolean\";}s:5:\"value\";O:8:\"stdClass\":3:{s:11:\"description\";s:56:\"Specifies
  the level of parallelism in case it is finite.\";s:6:\"format\";s:6:\"double\";s:4:\"type\";s:6:\"number\";}}s:4:\"type\";s:6:\"object\";}s:25:\"ResourceUtilizationReport\";O:8:\"stdClass\":3:{s:11:\"description\";s:169:\"Worker
  metrics exported from workers. This contains resource utilization\nmetrics accumulated
  from a variety of sources. For more information, see\ngo/df-resource-signals.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:7:\"cpuTime\";O:8:\"stdClass\":3:{s:11:\"description\";s:24:\"CPU
  utilization samples.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:21:\"#/definitions/CPUTime\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:33:\"ResourceUtilizationReportResponse\";O:8:\"stdClass\":3:{s:11:\"description\";s:70:\"Service-side
  response to WorkerMessage reporting resource utilization.\";s:10:\"properties\";O:8:\"stdClass\":0:{}s:4:\"type\";s:6:\"object\";}s:18:\"RuntimeEnvironment\";O:8:\"stdClass\":3:{s:11:\"description\";s:41:\"The
  environment values to set at runtime.\";s:10:\"properties\";O:8:\"stdClass\":9:{s:21:\"additionalExperiments\";O:8:\"stdClass\":3:{s:11:\"description\";s:40:\"Additional
  experiment flags for the job.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:4:\"type\";s:5:\"array\";}s:23:\"bypassTempDirValidation\";O:8:\"stdClass\":2:{s:11:\"description\";s:88:\"Whether
  to bypass the safety checks for the job's temporary directory.\nUse with caution.\";s:4:\"type\";s:7:\"boolean\";}s:11:\"machineType\";O:8:\"stdClass\":2:{s:11:\"description\";s:94:\"The
  machine type to use for the job. Defaults to the value from the\ntemplate if not
  specified.\";s:4:\"type\";s:6:\"string\";}s:10:\"maxWorkers\";O:8:\"stdClass\":3:{s:11:\"description\";s:125:\"The
  maximum number of Google Compute Engine instances to be made\navailable to your
  pipeline during execution, from 1 to 1000.\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}s:7:\"network\";O:8:\"stdClass\":2:{s:11:\"description\";s:108:\"Network
  to which VMs will be assigned.  If empty or unspecified,\nthe service will use the
  network \"default\".\";s:4:\"type\";s:6:\"string\";}s:19:\"serviceAccountEmail\";O:8:\"stdClass\":2:{s:11:\"description\";s:59:\"The
  email address of the service account to run the job as.\";s:4:\"type\";s:6:\"string\";}s:10:\"subnetwork\";O:8:\"stdClass\":2:{s:11:\"description\";s:122:\"Subnetwork
  to which VMs will be assigned, if desired.  Expected to be of\nthe form \"regions/REGION/subnetworks/SUBNETWORK\".\";s:4:\"type\";s:6:\"string\";}s:12:\"tempLocation\";O:8:\"stdClass\":2:{s:11:\"description\";s:109:\"The
  Cloud Storage path to use for temporary files.\nMust be a valid Cloud Storage URL,
  beginning with `gs://`.\";s:4:\"type\";s:6:\"string\";}s:4:\"zone\";O:8:\"stdClass\":2:{s:11:\"description\";s:158:\"The
  Compute Engine [availability\nzone](https://cloud.google.com/compute/docs/regions-zones/regions-zones)\nfor
  launching worker instances to run your pipeline.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:23:\"SendDebugCaptureRequest\";O:8:\"stdClass\":3:{s:11:\"description\";s:42:\"Request
  to send encoded debug information.\";s:10:\"properties\";O:8:\"stdClass\":4:{s:11:\"componentId\";O:8:\"stdClass\":2:{s:11:\"description\";s:62:\"The
  internal component id for which debug information is sent.\";s:4:\"type\";s:6:\"string\";}s:4:\"data\";O:8:\"stdClass\":2:{s:11:\"description\";s:30:\"The
  encoded debug information.\";s:4:\"type\";s:6:\"string\";}s:8:\"location\";O:8:\"stdClass\":2:{s:11:\"description\";s:56:\"The
  location which contains the job specified by job_id.\";s:4:\"type\";s:6:\"string\";}s:8:\"workerId\";O:8:\"stdClass\":2:{s:11:\"description\";s:33:\"The
  worker id, i.e., VM hostname.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:24:\"SendDebugCaptureResponse\";O:8:\"stdClass\":3:{s:11:\"description\";s:43:\"Response
  to a send capture request.\nnothing\";s:10:\"properties\";O:8:\"stdClass\":0:{}s:4:\"type\";s:6:\"object\";}s:25:\"SendWorkerMessagesRequest\";O:8:\"stdClass\":3:{s:11:\"description\";s:53:\"A
  request for sending worker messages to the service.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:8:\"location\";O:8:\"stdClass\":2:{s:11:\"description\";s:35:\"The
  location which contains the job\";s:4:\"type\";s:6:\"string\";}s:14:\"workerMessages\";O:8:\"stdClass\":3:{s:11:\"description\";s:27:\"The
  WorkerMessages to send.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:27:\"#/definitions/WorkerMessage\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:26:\"SendWorkerMessagesResponse\";O:8:\"stdClass\":3:{s:11:\"description\";s:36:\"The
  response to the worker messages.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:22:\"workerMessageResponses\";O:8:\"stdClass\":3:{s:11:\"description\";s:44:\"The
  servers response to the worker messages.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:35:\"#/definitions/WorkerMessageResponse\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:10:\"SeqMapTask\";O:8:\"stdClass\":3:{s:11:\"description\";s:42:\"Describes
  a particular function to invoke.\";s:10:\"properties\";O:8:\"stdClass\":6:{s:6:\"inputs\";O:8:\"stdClass\":3:{s:11:\"description\";s:37:\"Information
  about each of the inputs.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:27:\"#/definitions/SideInputInfo\";}s:4:\"type\";s:5:\"array\";}s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:46:\"The
  user-provided name of the SeqDo operation.\";s:4:\"type\";s:6:\"string\";}s:11:\"outputInfos\";O:8:\"stdClass\":3:{s:11:\"description\";s:38:\"Information
  about each of the outputs.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:34:\"#/definitions/SeqMapTaskOutputInfo\";}s:4:\"type\";s:5:\"array\";}s:9:\"stageName\";O:8:\"stdClass\":2:{s:11:\"description\";s:92:\"System-defined
  name of the stage containing the SeqDo operation.\nUnique across the workflow.\";s:4:\"type\";s:6:\"string\";}s:10:\"systemName\";O:8:\"stdClass\":2:{s:11:\"description\";s:71:\"System-defined
  name of the SeqDo operation.\nUnique across the workflow.\";s:4:\"type\";s:6:\"string\";}s:6:\"userFn\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Properties
  of the object.\";}s:11:\"description\";s:28:\"The user function to invoke.\";s:4:\"type\";s:6:\"object\";}}s:4:\"type\";s:6:\"object\";}s:20:\"SeqMapTaskOutputInfo\";O:8:\"stdClass\":3:{s:11:\"description\";s:44:\"Information
  about an output of a SeqMapTask.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:4:\"sink\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:18:\"#/definitions/Sink\";s:11:\"description\";s:38:\"The
  sink to write the output value to.\";}s:3:\"tag\";O:8:\"stdClass\":2:{s:11:\"description\";s:66:\"The
  id of the TupleTag the user code will tag the output value by.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:9:\"ShellTask\";O:8:\"stdClass\":3:{s:11:\"description\";s:67:\"A
  task which consists of a shell command for the worker to execute.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:7:\"command\";O:8:\"stdClass\":2:{s:11:\"description\";s:25:\"The
  shell command to run.\";s:4:\"type\";s:6:\"string\";}s:8:\"exitCode\";O:8:\"stdClass\":3:{s:11:\"description\";s:23:\"Exit
  code for the task.\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}}s:4:\"type\";s:6:\"object\";}s:13:\"SideInputInfo\";O:8:\"stdClass\":3:{s:11:\"description\";s:66:\"Information
  about a side input of a DoFn or an input of a SeqDoFn.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:4:\"kind\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Properties
  of the object.\";}s:11:\"description\";s:61:\"How to interpret the source element(s)
  as a side input value.\";s:4:\"type\";s:6:\"object\";}s:7:\"sources\";O:8:\"stdClass\":3:{s:11:\"description\";s:219:\"The
  source(s) to read element(s) from to get the value of this side input.\nIf more
  than one source, then the elements are taken from the\nsources, in the specified
  order if order matters.\nAt least one source is required.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:20:\"#/definitions/Source\";}s:4:\"type\";s:5:\"array\";}s:3:\"tag\";O:8:\"stdClass\":2:{s:11:\"description\";s:122:\"The
  id of the tag the user code will access this side input by;\nthis should correspond
  to the tag of some MultiOutputInfo.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:4:\"Sink\";O:8:\"stdClass\":3:{s:11:\"description\";s:50:\"A
  sink that records can be encoded and written to.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:5:\"codec\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Properties
  of the object.\";}s:11:\"description\";s:52:\"The codec to use to encode data written
  to the sink.\";s:4:\"type\";s:6:\"object\";}s:4:\"spec\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Properties
  of the object.\";}s:11:\"description\";s:42:\"The sink to write to, plus its parameters.\";s:4:\"type\";s:6:\"object\";}}s:4:\"type\";s:6:\"object\";}s:6:\"Source\";O:8:\"stdClass\":3:{s:11:\"description\";s:51:\"A
  source that records can be read and decoded from.\";s:10:\"properties\";O:8:\"stdClass\":5:{s:9:\"baseSpecs\";O:8:\"stdClass\":3:{s:11:\"description\";s:433:\"While
  splitting, sources may specify the produced bundles\nas differences against another
  source, in order to save backend-side\nmemory and allow bigger jobs. For details,
  see SourceSplitRequest.\nTo support this use case, the full set of parameters of
  the source\nis logically obtained by taking the latest explicitly specified value\nof
  each parameter in the order:\nbase_specs (later items win), spec (overrides anything
  in base_specs).\";s:5:\"items\";O:8:\"stdClass\":2:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Properties
  of the object.\";}s:4:\"type\";s:6:\"object\";}s:4:\"type\";s:5:\"array\";}s:5:\"codec\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Properties
  of the object.\";}s:11:\"description\";s:53:\"The codec to use to decode data read
  from the source.\";s:4:\"type\";s:6:\"object\";}s:20:\"doesNotNeedSplitting\";O:8:\"stdClass\":2:{s:11:\"description\";s:771:\"Setting
  this value to true hints to the framework that the source\ndoesn't need splitting,
  and using SourceSplitRequest on it would\nyield SOURCE_SPLIT_OUTCOME_USE_CURRENT.\n\nE.g.
  a file splitter may set this to true when splitting a single file\ninto a set of
  byte ranges of appropriate size, and set this\nto false when splitting a filepattern
  into individual files.\nHowever, for efficiency, a file splitter may decide to produce\nfile
  subranges directly from the filepattern to avoid a splitting\nround-trip.\n\nSee
  SourceSplitRequest for an overview of the splitting process.\n\nThis field is meaningful
  only in the Source objects populated\nby the user (e.g. when filling in a DerivedSource).\nSource
  objects supplied by the framework to the user don't have\nthis field populated.\";s:4:\"type\";s:7:\"boolean\";}s:8:\"metadata\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/SourceMetadata\";s:11:\"description\";s:343:\"Optionally,
  metadata for this source can be supplied right away,\navoiding a SourceGetMetadataOperation
  roundtrip\n(see SourceOperationRequest).\n\nThis field is meaningful only in the
  Source objects populated\nby the user (e.g. when filling in a DerivedSource).\nSource
  objects supplied by the framework to the user don't have\nthis field populated.\";}s:4:\"spec\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Properties
  of the object.\";}s:11:\"description\";s:45:\"The source to read from, plus its
  parameters.\";s:4:\"type\";s:6:\"object\";}}s:4:\"type\";s:6:\"object\";}s:10:\"SourceFork\";O:8:\"stdClass\":3:{s:11:\"description\";s:42:\"DEPRECATED
  in favor of DynamicSourceSplit.\";s:10:\"properties\";O:8:\"stdClass\":4:{s:7:\"primary\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:30:\"#/definitions/SourceSplitShard\";s:11:\"description\";s:10:\"DEPRECATED\";}s:13:\"primarySource\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/DerivedSource\";s:11:\"description\";s:10:\"DEPRECATED\";}s:8:\"residual\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:30:\"#/definitions/SourceSplitShard\";s:11:\"description\";s:10:\"DEPRECATED\";}s:14:\"residualSource\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/DerivedSource\";s:11:\"description\";s:10:\"DEPRECATED\";}}s:4:\"type\";s:6:\"object\";}s:24:\"SourceGetMetadataRequest\";O:8:\"stdClass\":3:{s:11:\"description\";s:52:\"A
  request to compute the SourceMetadata of a Source.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:6:\"source\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:20:\"#/definitions/Source\";s:11:\"description\";s:62:\"Specification
  of the source whose metadata should be computed.\";}}s:4:\"type\";s:6:\"object\";}s:25:\"SourceGetMetadataResponse\";O:8:\"stdClass\":3:{s:11:\"description\";s:43:\"The
  result of a SourceGetMetadataOperation.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:8:\"metadata\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/SourceMetadata\";s:11:\"description\";s:22:\"The
  computed metadata.\";}}s:4:\"type\";s:6:\"object\";}s:14:\"SourceMetadata\";O:8:\"stdClass\":3:{s:11:\"description\";s:89:\"Metadata
  about a Source useful for automatically optimizing\nand tuning the pipeline, etc.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:18:\"estimatedSizeBytes\";O:8:\"stdClass\":3:{s:11:\"description\";s:207:\"An
  estimate of the total size (in bytes) of the data that would be\nread from this
  source.  This estimate is in terms of external storage\nsize, before any decompression
  or other processing done by the reader.\";s:6:\"format\";s:5:\"int64\";s:4:\"type\";s:6:\"string\";}s:8:\"infinite\";O:8:\"stdClass\":2:{s:11:\"description\";s:92:\"Specifies
  that the size of this source is known to be infinite\n(this is a streaming source).\";s:4:\"type\";s:7:\"boolean\";}s:18:\"producesSortedKeys\";O:8:\"stdClass\":2:{s:11:\"description\";s:114:\"Whether
  this source is known to produce key/value pairs with\nthe (encoded) keys in lexicographically
  sorted order.\";s:4:\"type\";s:7:\"boolean\";}}s:4:\"type\";s:6:\"object\";}s:22:\"SourceOperationRequest\";O:8:\"stdClass\":3:{s:11:\"description\";s:114:\"A
  work item that represents the different operations that can be\nperformed on a user-defined
  Source specification.\";s:10:\"properties\";O:8:\"stdClass\":6:{s:11:\"getMetadata\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/SourceGetMetadataRequest\";s:11:\"description\";s:59:\"Information
  about a request to get metadata about a source.\";}s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:59:\"User-provided
  name of the Read instruction for this source.\";s:4:\"type\";s:6:\"string\";}s:12:\"originalName\";O:8:\"stdClass\":2:{s:11:\"description\";s:92:\"System-defined
  name for the Read instruction for this source\nin the original workflow graph.\";s:4:\"type\";s:6:\"string\";}s:5:\"split\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/SourceSplitRequest\";s:11:\"description\";s:46:\"Information
  about a request to split a source.\";}s:9:\"stageName\";O:8:\"stdClass\":2:{s:11:\"description\";s:93:\"System-defined
  name of the stage containing the source operation.\nUnique across the workflow.\";s:4:\"type\";s:6:\"string\";}s:10:\"systemName\";O:8:\"stdClass\":2:{s:11:\"description\";s:88:\"System-defined
  name of the Read instruction for this source.\nUnique across the workflow.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:23:\"SourceOperationResponse\";O:8:\"stdClass\":3:{s:11:\"description\";s:130:\"The
  result of a SourceOperationRequest, specified in\nReportWorkItemStatusRequest.source_operation
  when the work item\nis completed.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:11:\"getMetadata\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:39:\"#/definitions/SourceGetMetadataResponse\";s:11:\"description\";s:55:\"A
  response to a request to get metadata about a source.\";}s:5:\"split\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:33:\"#/definitions/SourceSplitResponse\";s:11:\"description\";s:42:\"A
  response to a request to split a source.\";}}s:4:\"type\";s:6:\"object\";}s:18:\"SourceSplitOptions\";O:8:\"stdClass\":3:{s:11:\"description\";s:99:\"Hints
  for splitting a Source into bundles (parts for parallel\nprocessing) using SourceSplitRequest.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:22:\"desiredBundleSizeBytes\";O:8:\"stdClass\":3:{s:11:\"description\";s:115:\"The
  source should be split into a set of bundles where the estimated size\nof each is
  approximately this many bytes.\";s:6:\"format\";s:5:\"int64\";s:4:\"type\";s:6:\"string\";}s:21:\"desiredShardSizeBytes\";O:8:\"stdClass\":3:{s:11:\"description\";s:49:\"DEPRECATED
  in favor of desired_bundle_size_bytes.\";s:6:\"format\";s:5:\"int64\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:18:\"SourceSplitRequest\";O:8:\"stdClass\":3:{s:11:\"description\";s:717:\"Represents
  the operation to split a high-level Source specification\ninto bundles (parts for
  parallel processing).\n\nAt a high level, splitting of a source into bundles happens
  as follows:\nSourceSplitRequest is applied to the source. If it returns\nSOURCE_SPLIT_OUTCOME_USE_CURRENT,
  no further splitting happens and the source\nis used \"as is\". Otherwise, splitting
  is applied recursively to each\nproduced DerivedSource.\n\nAs an optimization, for
  any Source, if its does_not_need_splitting is\ntrue, the framework assumes that
  splitting this source would return\nSOURCE_SPLIT_OUTCOME_USE_CURRENT, and doesn't
  initiate a SourceSplitRequest.\nThis applies both to the initial source being split
  and to bundles\nproduced from it.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:7:\"options\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/SourceSplitOptions\";s:11:\"description\";s:39:\"Hints
  for tuning the splitting process.\";}s:6:\"source\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:20:\"#/definitions/Source\";s:11:\"description\";s:40:\"Specification
  of the source to be split.\";}}s:4:\"type\";s:6:\"object\";}s:19:\"SourceSplitResponse\";O:8:\"stdClass\":3:{s:11:\"description\";s:37:\"The
  response to a SourceSplitRequest.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:7:\"bundles\";O:8:\"stdClass\":3:{s:11:\"description\";s:204:\"If
  outcome is SPLITTING_HAPPENED, then this is a list of bundles\ninto which the source
  was split. Otherwise this field is ignored.\nThis list can be empty, which means
  the source represents an empty input.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:27:\"#/definitions/DerivedSource\";}s:4:\"type\";s:5:\"array\";}s:7:\"outcome\";O:8:\"stdClass\":3:{s:11:\"description\";s:312:\"Indicates
  whether splitting happened and produced a list of bundles.\nIf this is USE_CURRENT_SOURCE_AS_IS,
  the current source should\nbe processed \"as is\" without splitting. \"bundles\"
  is ignored in this case.\nIf this is SPLITTING_HAPPENED, then \"bundles\" contains
  a list of\nbundles into which the source was split.\";s:4:\"enum\";a:3:{i:0;s:28:\"SOURCE_SPLIT_OUTCOME_UNKNOWN\";i:1;s:32:\"SOURCE_SPLIT_OUTCOME_USE_CURRENT\";i:2;s:39:\"SOURCE_SPLIT_OUTCOME_SPLITTING_HAPPENED\";}s:4:\"type\";s:6:\"string\";}s:6:\"shards\";O:8:\"stdClass\":3:{s:11:\"description\";s:31:\"DEPRECATED
  in favor of bundles.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:30:\"#/definitions/SourceSplitShard\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:16:\"SourceSplitShard\";O:8:\"stdClass\":3:{s:11:\"description\";s:37:\"DEPRECATED
  in favor of DerivedSource.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:14:\"derivationMode\";O:8:\"stdClass\":3:{s:11:\"description\";s:10:\"DEPRECATED\";s:4:\"enum\";a:4:{i:0;s:30:\"SOURCE_DERIVATION_MODE_UNKNOWN\";i:1;s:34:\"SOURCE_DERIVATION_MODE_INDEPENDENT\";i:2;s:39:\"SOURCE_DERIVATION_MODE_CHILD_OF_CURRENT\";i:3;s:41:\"SOURCE_DERIVATION_MODE_SIBLING_OF_CURRENT\";}s:4:\"type\";s:6:\"string\";}s:6:\"source\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:20:\"#/definitions/Source\";s:11:\"description\";s:10:\"DEPRECATED\";}}s:4:\"type\";s:6:\"object\";}s:10:\"SplitInt64\";O:8:\"stdClass\":3:{s:11:\"description\";s:87:\"A
  representation of an int64, n, that is immune to precision loss when\nencoded in
  JSON.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:8:\"highBits\";O:8:\"stdClass\":3:{s:11:\"description\";s:49:\"The
  high order bits, including the sign: n >> 32.\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}s:7:\"lowBits\";O:8:\"stdClass\":3:{s:11:\"description\";s:35:\"The
  low order bits: n & 0xffffffff.\";s:6:\"format\";s:6:\"uint32\";s:4:\"type\";s:7:\"integer\";}}s:4:\"type\";s:6:\"object\";}s:11:\"StageSource\";O:8:\"stdClass\":3:{s:11:\"description\";s:56:\"Description
  of an input or output of an execution stage.\";s:10:\"properties\";O:8:\"stdClass\":4:{s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:48:\"Dataflow
  service generated name for this source.\";s:4:\"type\";s:6:\"string\";}s:29:\"originalTransformOrCollection\";O:8:\"stdClass\":2:{s:11:\"description\";s:106:\"User
  name for the original user transform or collection with which this\nsource is most
  closely associated.\";s:4:\"type\";s:6:\"string\";}s:9:\"sizeBytes\";O:8:\"stdClass\":3:{s:11:\"description\";s:34:\"Size
  of the source, if measurable.\";s:6:\"format\";s:5:\"int64\";s:4:\"type\";s:6:\"string\";}s:8:\"userName\";O:8:\"stdClass\":2:{s:11:\"description\";s:69:\"Human-readable
  name for this source; may be user or system generated.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:17:\"StateFamilyConfig\";O:8:\"stdClass\":3:{s:11:\"description\";s:27:\"State
  family configuration.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:6:\"isRead\";O:8:\"stdClass\":2:{s:11:\"description\";s:53:\"If
  true, this family corresponds to a read operation.\";s:4:\"type\";s:7:\"boolean\";}s:11:\"stateFamily\";O:8:\"stdClass\":2:{s:11:\"description\";s:23:\"The
  state family value.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:6:\"Status\";O:8:\"stdClass\":3:{s:11:\"description\";s:2437:\"The
  `Status` type defines a logical error model that is suitable for different\nprogramming
  environments, including REST APIs and RPC APIs. It is used by\n[gRPC](https://github.com/grpc).
  The error model is designed to be:\n\n- Simple to use and understand for most users\n-
  Flexible enough to meet unexpected needs\n\n# Overview\n\nThe `Status` message contains
  three pieces of data: error code, error message,\nand error details. The error code
  should be an enum value of\ngoogle.rpc.Code, but it may accept additional error
  codes if needed.  The\nerror message should be a developer-facing English message
  that helps\ndevelopers *understand* and *resolve* the error. If a localized user-facing\nerror
  message is needed, put the localized message in the error details or\nlocalize it
  in the client. The optional error details may contain arbitrary\ninformation about
  the error. There is a predefined set of error detail types\nin the package `google.rpc`
  that can be used for common error conditions.\n\n# Language mapping\n\nThe `Status`
  message is the logical representation of the error model, but it\nis not necessarily
  the actual wire format. When the `Status` message is\nexposed in different client
  libraries and different wire protocols, it can be\nmapped differently. For example,
  it will likely be mapped to some exceptions\nin Java, but more likely mapped to
  some error codes in C.\n\n# Other uses\n\nThe error model and the `Status` message
  can be used in a variety of\nenvironments, either with or without APIs, to provide
  a\nconsistent developer experience across different environments.\n\nExample uses
  of this error model include:\n\n- Partial errors. If a service needs to return partial
  errors to the client,\n    it may embed the `Status` in the normal response to indicate
  the partial\n    errors.\n\n- Workflow errors. A typical workflow has multiple steps.
  Each step may\n    have a `Status` message for error reporting.\n\n- Batch operations.
  If a client uses batch request and batch response, the\n    `Status` message should
  be used directly inside batch response, one for\n    each error sub-response.\n\n-
  Asynchronous operations. If an API call embeds asynchronous operation\n    results
  in its response, the status of those operations should be\n    represented directly
  using the `Status` message.\n\n- Logging. If some API errors are stored in logs,
  the message `Status` could\n    be used directly after any stripping needed for
  security/privacy reasons.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:4:\"code\";O:8:\"stdClass\":3:{s:11:\"description\";s:66:\"The
  status code, which should be an enum value of google.rpc.Code.\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}s:7:\"details\";O:8:\"stdClass\":3:{s:11:\"description\";s:105:\"A
  list of messages that carry the error details.  There is a common set of\nmessage
  types for APIs to use.\";s:5:\"items\";O:8:\"stdClass\":2:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:61:\"Properties
  of the object. Contains field @type with type URL.\";}s:4:\"type\";s:6:\"object\";}s:4:\"type\";s:5:\"array\";}s:7:\"message\";O:8:\"stdClass\":2:{s:11:\"description\";s:188:\"A
  developer-facing error message, which should be in English. Any\nuser-facing error
  message should be localized and sent in the\ngoogle.rpc.Status.details field, or
  localized by the client.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:4:\"Step\";O:8:\"stdClass\":3:{s:11:\"description\";s:865:\"Defines
  a particular step within a Cloud Dataflow job.\n\nA job consists of multiple steps,
  each of which performs some\nspecific operation as part of the overall job.  Data
  is typically\npassed from one step to another as part of the job.\n\nHere's an example
  of a sequence of steps which together implement a\nMap-Reduce job:\n\n  * Read a
  collection of data from some source, parsing the\n    collection's elements.\n\n
  \ * Validate the elements.\n\n  * Apply a user-defined function to map each element
  to some value\n    and extract an element-specific key value.\n\n  * Group elements
  with the same key into a single element with\n    that key, transforming a multiply-keyed
  collection into a\n    uniquely-keyed collection.\n\n  * Write the elements out
  to some data sink.\n\nNote that the Cloud Dataflow service may be used to run many
  different\ntypes of jobs, not just Map-Reduce.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:4:\"kind\";O:8:\"stdClass\":2:{s:11:\"description\";s:43:\"The
  kind of step in the Cloud Dataflow job.\";s:4:\"type\";s:6:\"string\";}s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:127:\"The
  name that identifies the step. This must be unique for each\nstep with respect to
  all other steps in the Cloud Dataflow job.\";s:4:\"type\";s:6:\"string\";}s:10:\"properties\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Properties
  of the object.\";}s:11:\"description\";s:174:\"Named properties associated with
  the step. Each kind of\npredefined step has its own required set of properties.\nMust
  be provided on Create.  Only retrieved with JOB_VIEW_ALL.\";s:4:\"type\";s:6:\"object\";}}s:4:\"type\";s:6:\"object\";}s:14:\"StreamLocation\";O:8:\"stdClass\":3:{s:11:\"description\";s:101:\"Describes
  a stream of data, either as input to be processed or as\noutput of a streaming Dataflow
  job.\";s:10:\"properties\";O:8:\"stdClass\":4:{s:20:\"customSourceLocation\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:34:\"#/definitions/CustomSourceLocation\";s:11:\"description\";s:30:\"The
  stream is a custom source.\";}s:14:\"pubsubLocation\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/PubsubLocation\";s:11:\"description\";s:30:\"The
  stream is a pubsub stream.\";}s:17:\"sideInputLocation\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:40:\"#/definitions/StreamingSideInputLocation\";s:11:\"description\";s:37:\"The
  stream is a streaming side input.\";}s:22:\"streamingStageLocation\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:36:\"#/definitions/StreamingStageLocation\";s:11:\"description\";s:84:\"The
  stream is part of another computation within the current\nstreaming Dataflow job.\";}}s:4:\"type\";s:6:\"object\";}s:26:\"StreamingComputationConfig\";O:8:\"stdClass\":3:{s:11:\"description\";s:61:\"Configuration
  information for a single streaming computation.\";s:10:\"properties\";O:8:\"stdClass\":4:{s:13:\"computationId\";O:8:\"stdClass\":2:{s:11:\"description\";s:39:\"Unique
  identifier for this computation.\";s:4:\"type\";s:6:\"string\";}s:12:\"instructions\";O:8:\"stdClass\":3:{s:11:\"description\";s:43:\"Instructions
  that comprise the computation.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:33:\"#/definitions/ParallelInstruction\";}s:4:\"type\";s:5:\"array\";}s:9:\"stageName\";O:8:\"stdClass\":2:{s:11:\"description\";s:31:\"Stage
  name of this computation.\";s:4:\"type\";s:6:\"string\";}s:10:\"systemName\";O:8:\"stdClass\":2:{s:11:\"description\";s:41:\"System
  defined name for this computation.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:26:\"StreamingComputationRanges\";O:8:\"stdClass\":3:{s:11:\"description\";s:85:\"Describes
  full or partial data disk assignment information of the computation\nranges.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:13:\"computationId\";O:8:\"stdClass\":2:{s:11:\"description\";s:26:\"The
  ID of the computation.\";s:4:\"type\";s:6:\"string\";}s:16:\"rangeAssignments\";O:8:\"stdClass\":3:{s:11:\"description\";s:55:\"Data
  disk assignments for ranges from this computation.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:40:\"#/definitions/KeyRangeDataDiskAssignment\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:24:\"StreamingComputationTask\";O:8:\"stdClass\":3:{s:11:\"description\";s:102:\"A
  task which describes what action should be performed for the specified\nstreaming
  computation ranges.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:17:\"computationRanges\";O:8:\"stdClass\":3:{s:11:\"description\";s:69:\"Contains
  ranges of a streaming computation this task should apply to.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:40:\"#/definitions/StreamingComputationRanges\";}s:4:\"type\";s:5:\"array\";}s:9:\"dataDisks\";O:8:\"stdClass\":3:{s:11:\"description\";s:58:\"Describes
  the set of data disks this task should apply to.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:29:\"#/definitions/MountedDataDisk\";}s:4:\"type\";s:5:\"array\";}s:8:\"taskType\";O:8:\"stdClass\":3:{s:11:\"description\";s:37:\"A
  type of streaming computation task.\";s:4:\"enum\";a:3:{i:0;s:34:\"STREAMING_COMPUTATION_TASK_UNKNOWN\";i:1;s:31:\"STREAMING_COMPUTATION_TASK_STOP\";i:2;s:32:\"STREAMING_COMPUTATION_TASK_START\";}s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:19:\"StreamingConfigTask\";O:8:\"stdClass\":3:{s:11:\"description\";s:73:\"A
  task that carries configuration information for streaming computations.\";s:10:\"properties\";O:8:\"stdClass\":4:{s:27:\"streamingComputationConfigs\";O:8:\"stdClass\":3:{s:11:\"description\";s:45:\"Set
  of computation configuration information.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:40:\"#/definitions/StreamingComputationConfig\";}s:4:\"type\";s:5:\"array\";}s:28:\"userStepToStateFamilyNameMap\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:11:\"description\";s:43:\"Map
  from user step names to state families.\";s:4:\"type\";s:6:\"object\";}s:23:\"windmillServiceEndpoint\";O:8:\"stdClass\":2:{s:11:\"description\";s:174:\"If
  present, the worker must use this endpoint to communicate with Windmill\nService
  dispatchers, otherwise the worker must continue to use whatever\nendpoint it had
  been using.\";s:4:\"type\";s:6:\"string\";}s:19:\"windmillServicePort\";O:8:\"stdClass\":3:{s:11:\"description\";s:152:\"If
  present, the worker must use this port to communicate with Windmill\nService dispatchers.
  Only applicable when windmill_service_endpoint is\nspecified.\";s:6:\"format\";s:5:\"int64\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:18:\"StreamingSetupTask\";O:8:\"stdClass\":3:{s:11:\"description\";s:58:\"A
  task which initializes part of a streaming Dataflow job.\";s:10:\"properties\";O:8:\"stdClass\":4:{s:5:\"drain\";O:8:\"stdClass\":2:{s:11:\"description\";s:29:\"The
  user has requested drain.\";s:4:\"type\";s:7:\"boolean\";}s:15:\"receiveWorkPort\";O:8:\"stdClass\":3:{s:11:\"description\";s:101:\"The
  TCP port on which the worker should listen for messages from\nother streaming computation
  workers.\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}s:28:\"streamingComputationTopology\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/TopologyConfig\";s:11:\"description\";s:50:\"The
  global topology of the streaming Dataflow job.\";}s:17:\"workerHarnessPort\";O:8:\"stdClass\":3:{s:11:\"description\";s:80:\"The
  TCP port used by the worker to communicate with the Dataflow\nworker harness.\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}}s:4:\"type\";s:6:\"object\";}s:26:\"StreamingSideInputLocation\";O:8:\"stdClass\":3:{s:11:\"description\";s:50:\"Identifies
  the location of a streaming side input.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:11:\"stateFamily\";O:8:\"stdClass\":2:{s:11:\"description\";s:60:\"Identifies
  the state family where this side input is stored.\";s:4:\"type\";s:6:\"string\";}s:3:\"tag\";O:8:\"stdClass\":2:{s:11:\"description\";s:71:\"Identifies
  the particular side input within the streaming Dataflow job.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:22:\"StreamingStageLocation\";O:8:\"stdClass\":3:{s:11:\"description\";s:91:\"Identifies
  the location of a streaming computation stage, for\nstage-to-stage communication.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:8:\"streamId\";O:8:\"stdClass\":2:{s:11:\"description\";s:67:\"Identifies
  the particular stream within the streaming Dataflow\njob.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:10:\"StringList\";O:8:\"stdClass\":3:{s:11:\"description\";s:46:\"A
  metric value representing a list of strings.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:8:\"elements\";O:8:\"stdClass\":3:{s:11:\"description\";s:21:\"Elements
  of the list.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:17:\"StructuredMessage\";O:8:\"stdClass\":3:{s:11:\"description\";s:170:\"A
  rich message format, including a human readable string, a key for\nidentifying the
  message, and structured data associated with the message for\nprogrammatic consumption.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:10:\"messageKey\";O:8:\"stdClass\":2:{s:11:\"description\";s:101:\"Idenfier
  for this message type.  Used by external systems to\ninternationalize or personalize
  message.\";s:4:\"type\";s:6:\"string\";}s:11:\"messageText\";O:8:\"stdClass\":2:{s:11:\"description\";s:34:\"Human-readable
  version of message.\";s:4:\"type\";s:6:\"string\";}s:10:\"parameters\";O:8:\"stdClass\":3:{s:11:\"description\";s:49:\"The
  structured data associated with this message.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:23:\"#/definitions/Parameter\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:18:\"TaskRunnerSettings\";O:8:\"stdClass\":3:{s:11:\"description\";s:34:\"Taskrunner
  configuration settings.\";s:10:\"properties\";O:8:\"stdClass\":19:{s:15:\"alsologtostderr\";O:8:\"stdClass\":2:{s:11:\"description\";s:51:\"Whether
  to also send taskrunner log info to stderr.\";s:4:\"type\";s:7:\"boolean\";}s:11:\"baseTaskDir\";O:8:\"stdClass\":2:{s:11:\"description\";s:60:\"The
  location on the worker for task-specific subdirectories.\";s:4:\"type\";s:6:\"string\";}s:7:\"baseUrl\";O:8:\"stdClass\":2:{s:11:\"description\";s:409:\"The
  base URL for the taskrunner to use when accessing Google Cloud APIs.\n\nWhen workers
  access Google Cloud APIs, they logically do so via\nrelative URLs.  If this field
  is specified, it supplies the base\nURL to use for resolving these relative URLs.
  \ The normative\nalgorithm used is defined by RFC 1808, \"Relative Uniform Resource\nLocators\".\n\nIf
  not specified, the default value is \"http://www.googleapis.com/\"\";s:4:\"type\";s:6:\"string\";}s:20:\"commandlinesFileName\";O:8:\"stdClass\":2:{s:11:\"description\";s:44:\"The
  file to store preprocessing commands in.\";s:4:\"type\";s:6:\"string\";}s:19:\"continueOnException\";O:8:\"stdClass\":2:{s:11:\"description\";s:54:\"Whether
  to continue taskrunner if an exception is hit.\";s:4:\"type\";s:7:\"boolean\";}s:18:\"dataflowApiVersion\";O:8:\"stdClass\":2:{s:11:\"description\";s:40:\"The
  API version of endpoint, e.g. \"v1b3\"\";s:4:\"type\";s:6:\"string\";}s:14:\"harnessCommand\";O:8:\"stdClass\":2:{s:11:\"description\";s:41:\"The
  command to launch the worker harness.\";s:4:\"type\";s:6:\"string\";}s:12:\"languageHint\";O:8:\"stdClass\":2:{s:11:\"description\";s:31:\"The
  suggested backend language.\";s:4:\"type\";s:6:\"string\";}s:6:\"logDir\";O:8:\"stdClass\":2:{s:11:\"description\";s:38:\"The
  directory on the VM to store logs.\";s:4:\"type\";s:6:\"string\";}s:18:\"logToSerialconsole\";O:8:\"stdClass\":2:{s:11:\"description\";s:79:\"Whether
  to send taskrunner log info to Google Compute Engine VM serial\nconsole.\";s:4:\"type\";s:7:\"boolean\";}s:17:\"logUploadLocation\";O:8:\"stdClass\":2:{s:11:\"description\";s:226:\"Indicates
  where to put logs.  If this is not specified, the logs\nwill not be uploaded.\n\nThe
  supported resource type is:\n\nGoogle Cloud Storage:\n  storage.googleapis.com/{bucket}/{object}\n
  \ bucket.storage.googleapis.com/{object}\";s:4:\"type\";s:6:\"string\";}s:11:\"oauthScopes\";O:8:\"stdClass\":3:{s:11:\"description\";s:94:\"The
  OAuth2 scopes to be requested by the taskrunner in order to\naccess the Cloud Dataflow
  API.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:4:\"type\";s:5:\"array\";}s:22:\"parallelWorkerSettings\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/WorkerSettings\";s:11:\"description\";s:52:\"The
  settings to pass to the parallel worker harness.\";}s:24:\"streamingWorkerMainClass\";O:8:\"stdClass\":2:{s:11:\"description\";s:37:\"The
  streaming worker main class name.\";s:4:\"type\";s:6:\"string\";}s:9:\"taskGroup\";O:8:\"stdClass\":2:{s:11:\"description\";s:89:\"The
  UNIX group ID on the worker VM to use for tasks launched by\ntaskrunner; e.g. \"wheel\".\";s:4:\"type\";s:6:\"string\";}s:8:\"taskUser\";O:8:\"stdClass\":2:{s:11:\"description\";s:87:\"The
  UNIX user ID on the worker VM to use for tasks launched by\ntaskrunner; e.g. \"root\".\";s:4:\"type\";s:6:\"string\";}s:17:\"tempStoragePrefix\";O:8:\"stdClass\":2:{s:11:\"description\";s:216:\"The
  prefix of the resources the taskrunner should use for\ntemporary storage.\n\nThe
  supported resource type is:\n\nGoogle Cloud Storage:\n  storage.googleapis.com/{bucket}/{object}\n
  \ bucket.storage.googleapis.com/{object}\";s:4:\"type\";s:6:\"string\";}s:4:\"vmId\";O:8:\"stdClass\":2:{s:11:\"description\";s:24:\"The
  ID string of the VM.\";s:4:\"type\";s:6:\"string\";}s:16:\"workflowFileName\";O:8:\"stdClass\":2:{s:11:\"description\";s:34:\"The
  file to store the workflow in.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:16:\"TemplateMetadata\";O:8:\"stdClass\":3:{s:11:\"description\";s:31:\"Metadata
  describing a template.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:11:\"description\";O:8:\"stdClass\":2:{s:11:\"description\";s:40:\"Optional.
  A description of the template.\";s:4:\"type\";s:6:\"string\";}s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:35:\"Required.
  The name of the template.\";s:4:\"type\";s:6:\"string\";}s:10:\"parameters\";O:8:\"stdClass\":3:{s:11:\"description\";s:32:\"The
  parameters for the template.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:31:\"#/definitions/ParameterMetadata\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:14:\"TopologyConfig\";O:8:\"stdClass\":3:{s:11:\"description\";s:102:\"Global
  topology of the streaming Dataflow job, including all\ncomputations and their sharded
  locations.\";s:10:\"properties\";O:8:\"stdClass\":5:{s:12:\"computations\";O:8:\"stdClass\":3:{s:11:\"description\";s:58:\"The
  computations associated with a streaming Dataflow job.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:33:\"#/definitions/ComputationTopology\";}s:4:\"type\";s:5:\"array\";}s:19:\"dataDiskAssignments\";O:8:\"stdClass\":3:{s:11:\"description\";s:47:\"The
  disks assigned to a streaming Dataflow job.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:32:\"#/definitions/DataDiskAssignment\";}s:4:\"type\";s:5:\"array\";}s:17:\"forwardingKeyBits\";O:8:\"stdClass\":3:{s:11:\"description\";s:68:\"The
  size (in bits) of keys that will be assigned to source messages.\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}s:22:\"persistentStateVersion\";O:8:\"stdClass\":3:{s:11:\"description\";s:36:\"Version
  number for persistent state.\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}s:29:\"userStageToComputationNameMap\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:11:\"description\";s:50:\"Maps
  user stage names to stable computation names.\";s:4:\"type\";s:6:\"object\";}}s:4:\"type\";s:6:\"object\";}s:16:\"TransformSummary\";O:8:\"stdClass\":3:{s:11:\"description\";s:70:\"Description
  of the type, names/ids, and input/outputs for a transform.\";s:10:\"properties\";O:8:\"stdClass\":6:{s:11:\"displayData\";O:8:\"stdClass\":3:{s:11:\"description\";s:32:\"Transform-specific
  display data.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:25:\"#/definitions/DisplayData\";}s:4:\"type\";s:5:\"array\";}s:2:\"id\";O:8:\"stdClass\":2:{s:11:\"description\";s:44:\"SDK
  generated id of this transform instance.\";s:4:\"type\";s:6:\"string\";}s:19:\"inputCollectionName\";O:8:\"stdClass\":3:{s:11:\"description\";s:55:\"User
  names for all collection inputs to this transform.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:4:\"type\";s:5:\"array\";}s:4:\"kind\";O:8:\"stdClass\":3:{s:11:\"description\";s:18:\"Type
  of transform.\";s:4:\"enum\";a:9:{i:0;s:12:\"UNKNOWN_KIND\";i:1;s:11:\"PAR_DO_KIND\";i:2;s:17:\"GROUP_BY_KEY_KIND\";i:3;s:12:\"FLATTEN_KIND\";i:4;s:9:\"READ_KIND\";i:5;s:10:\"WRITE_KIND\";i:6;s:13:\"CONSTANT_KIND\";i:7;s:14:\"SINGLETON_KIND\";i:8;s:12:\"SHUFFLE_KIND\";}s:4:\"type\";s:6:\"string\";}s:4:\"name\";O:8:\"stdClass\":2:{s:11:\"description\";s:47:\"User
  provided name for this transform instance.\";s:4:\"type\";s:6:\"string\";}s:20:\"outputCollectionName\";O:8:\"stdClass\":3:{s:11:\"description\";s:57:\"User
  \ names for all collection outputs to this transform.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:4:\"type\";s:5:\"array\";}}s:4:\"type\";s:6:\"object\";}s:8:\"WorkItem\";O:8:\"stdClass\":3:{s:11:\"description\";s:83:\"WorkItem
  represents basic information about a WorkItem to be executed\nin the cloud.\";s:10:\"properties\";O:8:\"stdClass\":15:{s:13:\"configuration\";O:8:\"stdClass\":2:{s:11:\"description\";s:51:\"Work
  item-specific configuration as an opaque blob.\";s:4:\"type\";s:6:\"string\";}s:2:\"id\";O:8:\"stdClass\":3:{s:11:\"description\";s:25:\"Identifies
  this WorkItem.\";s:6:\"format\";s:5:\"int64\";s:4:\"type\";s:6:\"string\";}s:18:\"initialReportIndex\";O:8:\"stdClass\":3:{s:11:\"description\";s:67:\"The
  initial index to use when reporting the status of the WorkItem.\";s:6:\"format\";s:5:\"int64\";s:4:\"type\";s:6:\"string\";}s:5:\"jobId\";O:8:\"stdClass\":2:{s:11:\"description\";s:53:\"Identifies
  the workflow job this WorkItem belongs to.\";s:4:\"type\";s:6:\"string\";}s:15:\"leaseExpireTime\";O:8:\"stdClass\":3:{s:11:\"description\";s:45:\"Time
  when the lease on this Work will expire.\";s:6:\"format\";s:15:\"google-datetime\";s:4:\"type\";s:6:\"string\";}s:7:\"mapTask\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:21:\"#/definitions/MapTask\";s:11:\"description\";s:45:\"Additional
  information for MapTask WorkItems.\";}s:8:\"packages\";O:8:\"stdClass\":3:{s:11:\"description\";s:80:\"Any
  required packages that need to be fetched in order to execute\nthis WorkItem.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:21:\"#/definitions/Package\";}s:4:\"type\";s:5:\"array\";}s:9:\"projectId\";O:8:\"stdClass\":2:{s:11:\"description\";s:54:\"Identifies
  the cloud project this WorkItem belongs to.\";s:4:\"type\";s:6:\"string\";}s:20:\"reportStatusInterval\";O:8:\"stdClass\":3:{s:11:\"description\";s:31:\"Recommended
  reporting interval.\";s:6:\"format\";s:15:\"google-duration\";s:4:\"type\";s:6:\"string\";}s:10:\"seqMapTask\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:24:\"#/definitions/SeqMapTask\";s:11:\"description\";s:48:\"Additional
  information for SeqMapTask WorkItems.\";}s:9:\"shellTask\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:23:\"#/definitions/ShellTask\";s:11:\"description\";s:47:\"Additional
  information for ShellTask WorkItems.\";}s:19:\"sourceOperationTask\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:36:\"#/definitions/SourceOperationRequest\";s:11:\"description\";s:54:\"Additional
  information for source operation WorkItems.\";}s:24:\"streamingComputationTask\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/StreamingComputationTask\";s:11:\"description\";s:62:\"Additional
  information for StreamingComputationTask WorkItems.\";}s:19:\"streamingConfigTask\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:33:\"#/definitions/StreamingConfigTask\";s:11:\"description\";s:57:\"Additional
  information for StreamingConfigTask WorkItems.\";}s:18:\"streamingSetupTask\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/StreamingSetupTask\";s:11:\"description\";s:56:\"Additional
  information for StreamingSetupTask WorkItems.\";}}s:4:\"type\";s:6:\"object\";}s:20:\"WorkItemServiceState\";O:8:\"stdClass\":3:{s:11:\"description\";s:91:\"The
  Dataflow service's idea of the current state of a WorkItem\nbeing processed by a
  worker.\";s:10:\"properties\";O:8:\"stdClass\":8:{s:11:\"harnessData\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Properties
  of the object.\";}s:11:\"description\";s:78:\"Other data returned by the service,
  specific to the particular\nworker harness.\";s:4:\"type\";s:6:\"object\";}s:15:\"leaseExpireTime\";O:8:\"stdClass\":3:{s:11:\"description\";s:44:\"Time
  at which the current lease will expire.\";s:6:\"format\";s:15:\"google-datetime\";s:4:\"type\";s:6:\"string\";}s:13:\"metricShortId\";O:8:\"stdClass\":3:{s:11:\"description\";s:333:\"The
  short ids that workers should use in subsequent metric updates.\nWorkers should
  strive to use short ids whenever possible, but it is ok\nto request the short_id
  again if a worker lost track of it\n(e.g. if the worker is recovering from a crash).\nNOTE:
  it is possible that the response may have short ids for a subset\nof the metrics.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:27:\"#/definitions/MetricShortId\";}s:4:\"type\";s:5:\"array\";}s:15:\"nextReportIndex\";O:8:\"stdClass\":3:{s:11:\"description\";s:181:\"The
  index value to use for the next report sent by the worker.\nNote: If the report
  call fails for whatever reason, the worker should\nreuse this index for subsequent
  report attempts.\";s:6:\"format\";s:5:\"int64\";s:4:\"type\";s:6:\"string\";}s:20:\"reportStatusInterval\";O:8:\"stdClass\":3:{s:11:\"description\";s:35:\"New
  recommended reporting interval.\";s:6:\"format\";s:15:\"google-duration\";s:4:\"type\";s:6:\"string\";}s:12:\"splitRequest\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/ApproximateSplitRequest\";s:11:\"description\";s:105:\"The
  progress point in the WorkItem where the Dataflow service\nsuggests that the worker
  truncate the task.\";}s:18:\"suggestedStopPoint\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:33:\"#/definitions/ApproximateProgress\";s:11:\"description\";s:37:\"DEPRECATED
  in favor of split_request.\";}s:21:\"suggestedStopPosition\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:22:\"#/definitions/Position\";s:11:\"description\";s:23:\"Obsolete,
  always empty.\";}}s:4:\"type\";s:6:\"object\";}s:14:\"WorkItemStatus\";O:8:\"stdClass\":3:{s:11:\"description\";s:69:\"Conveys
  a worker's progress through the work described by a WorkItem.\";s:10:\"properties\";O:8:\"stdClass\":14:{s:9:\"completed\";O:8:\"stdClass\":2:{s:11:\"description\";s:68:\"True
  if the WorkItem was completed (successfully or unsuccessfully).\";s:4:\"type\";s:7:\"boolean\";}s:14:\"counterUpdates\";O:8:\"stdClass\":3:{s:11:\"description\";s:41:\"Worker
  output counters for this WorkItem.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:27:\"#/definitions/CounterUpdate\";}s:4:\"type\";s:5:\"array\";}s:18:\"dynamicSourceSplit\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/DynamicSourceSplit\";s:11:\"description\";s:35:\"See
  documentation of stop_position.\";}s:6:\"errors\";O:8:\"stdClass\":3:{s:11:\"description\";s:145:\"Specifies
  errors which occurred during processing.  If errors are\nprovided, and completed
  = true, then the WorkItem is considered\nto have failed.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:20:\"#/definitions/Status\";}s:4:\"type\";s:5:\"array\";}s:13:\"metricUpdates\";O:8:\"stdClass\":3:{s:11:\"description\";s:39:\"DEPRECATED
  in favor of counter_updates.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:26:\"#/definitions/MetricUpdate\";}s:4:\"type\";s:5:\"array\";}s:8:\"progress\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:33:\"#/definitions/ApproximateProgress\";s:11:\"description\";s:41:\"DEPRECATED
  in favor of reported_progress.\";}s:11:\"reportIndex\";O:8:\"stdClass\":3:{s:11:\"description\";s:671:\"The
  report index.  When a WorkItem is leased, the lease will\ncontain an initial report
  index.  When a WorkItem's status is\nreported to the system, the report should be
  sent with\nthat report index, and the response will contain the index the\nworker
  should use for the next report.  Reports received with\nunexpected index values
  will be rejected by the service.\n\nIn order to preserve idempotency, the worker
  should not alter the\ncontents of a report, even if the worker must submit the same\nreport
  multiple times before getting back a response.  The worker\nshould not submit a
  subsequent report until the response for the\nprevious report had been received
  from the service.\";s:6:\"format\";s:5:\"int64\";s:4:\"type\";s:6:\"string\";}s:16:\"reportedProgress\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:41:\"#/definitions/ApproximateReportedProgress\";s:11:\"description\";s:44:\"The
  worker's progress through this WorkItem.\";}s:22:\"requestedLeaseDuration\";O:8:\"stdClass\":3:{s:11:\"description\";s:49:\"Amount
  of time the worker requests for its lease.\";s:6:\"format\";s:15:\"google-duration\";s:4:\"type\";s:6:\"string\";}s:10:\"sourceFork\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:24:\"#/definitions/SourceFork\";s:11:\"description\";s:44:\"DEPRECATED
  in favor of dynamic_source_split.\";}s:23:\"sourceOperationResponse\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/SourceOperationResponse\";s:11:\"description\";s:119:\"If
  the work item represented a SourceOperationRequest, and the work\nis completed,
  contains the result of the operation.\";}s:12:\"stopPosition\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:22:\"#/definitions/Position\";s:11:\"description\";s:1642:\"A
  worker may split an active map task in two parts, \"primary\" and\n\"residual\",
  continuing to process the primary part and returning the\nresidual part into the
  pool of available work.\nThis event is called a \"dynamic split\" and is critical
  to the dynamic\nwork rebalancing feature. The two obtained sub-tasks are called\n\"parts\"
  of the split.\nThe parts, if concatenated, must represent the same input as would\nbe
  read by the current task if the split did not happen.\nThe exact way in which the
  original task is decomposed into the two\nparts is specified either as a position
  demarcating them\n(stop_position), or explicitly as two DerivedSources, if this\ntask
  consumes a user-defined source type (dynamic_source_split).\n\nThe \"current\" task
  is adjusted as a result of the split: after a task\nwith range [A, B) sends a stop_position
  update at C, its range is\nconsidered to be [A, C), e.g.:\n* Progress should be
  interpreted relative to the new range, e.g.\n  \"75% completed\" means \"75% of
  [A, C) completed\"\n* The worker should interpret proposed_stop_position relative
  to the\n  new range, e.g. \"split at 68%\" should be interpreted as\n  \"split at
  68% of [A, C)\".\n* If the worker chooses to split again using stop_position, only\n
  \ stop_positions in [A, C) will be accepted.\n* Etc.\ndynamic_source_split has similar
  semantics: e.g., if a task with\nsource S splits using dynamic_source_split into
  {P, R}\n(where P and R must be together equivalent to S), then subsequent\nprogress
  and proposed_stop_position should be interpreted relative\nto P, and in a potential
  subsequent dynamic_source_split into {P', R'},\nP' and R' must be together equivalent
  to P, etc.\";}s:29:\"totalThrottlerWaitTimeSeconds\";O:8:\"stdClass\":3:{s:11:\"description\";s:64:\"Total
  time the worker spent being throttled by external systems.\";s:6:\"format\";s:6:\"double\";s:4:\"type\";s:6:\"number\";}s:10:\"workItemId\";O:8:\"stdClass\":2:{s:11:\"description\";s:24:\"Identifies
  the WorkItem.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:18:\"WorkerHealthReport\";O:8:\"stdClass\":3:{s:11:\"description\";s:176:\"WorkerHealthReport
  contains information about the health of a worker.\n\nThe VM should be identified
  by the labels attached to the WorkerMessage that\nthis health ping belongs to.\";s:10:\"properties\";O:8:\"stdClass\":4:{s:4:\"pods\";O:8:\"stdClass\":3:{s:11:\"description\";s:214:\"The
  pods running on the worker. See:\nhttp://kubernetes.io/v1.1/docs/api-reference/v1/definitions.html#_v1_pod\n\nThis
  field is used by the worker to send the status of the indvidual\ncontainers running
  on each worker.\";s:5:\"items\";O:8:\"stdClass\":2:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Properties
  of the object.\";}s:4:\"type\";s:6:\"object\";}s:4:\"type\";s:5:\"array\";}s:14:\"reportInterval\";O:8:\"stdClass\":3:{s:11:\"description\";s:160:\"The
  interval at which the worker is sending health reports.\nThe default value of 0
  should be interpreted as the field is not being\nexplicitly set by the worker.\";s:6:\"format\";s:15:\"google-duration\";s:4:\"type\";s:6:\"string\";}s:11:\"vmIsHealthy\";O:8:\"stdClass\":2:{s:11:\"description\";s:26:\"Whether
  the VM is healthy.\";s:4:\"type\";s:7:\"boolean\";}s:13:\"vmStartupTime\";O:8:\"stdClass\":3:{s:11:\"description\";s:27:\"The
  time the VM was booted.\";s:6:\"format\";s:15:\"google-datetime\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:26:\"WorkerHealthReportResponse\";O:8:\"stdClass\":3:{s:11:\"description\";s:100:\"WorkerHealthReportResponse
  contains information returned to the worker\nin response to a health ping.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:14:\"reportInterval\";O:8:\"stdClass\":3:{s:11:\"description\";s:184:\"A
  positive value indicates the worker should change its reporting interval\nto the
  specified value.\n\nThe default value of zero means no change in report rate is
  requested by\nthe server.\";s:6:\"format\";s:15:\"google-duration\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:20:\"WorkerLifecycleEvent\";O:8:\"stdClass\":3:{s:11:\"description\";s:353:\"A
  report of an event in a worker's lifecycle.\nThe proto contains one event, because
  the worker is expected to\nasynchronously send each message immediately after the
  event.\nDue to this asynchrony, messages may arrive out of order (or missing), and
  it\nis up to the consumer to interpret.\nThe timestamp of the event is in the enclosing
  WorkerMessage proto.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:18:\"containerStartTime\";O:8:\"stdClass\":3:{s:11:\"description\";s:130:\"The
  start time of this container. All events will report this so that\nevents can be
  grouped together across container/VM restarts.\";s:6:\"format\";s:15:\"google-datetime\";s:4:\"type\";s:6:\"string\";}s:5:\"event\";O:8:\"stdClass\":3:{s:11:\"description\";s:25:\"The
  event being reported.\";s:4:\"enum\";a:8:{i:0;s:13:\"UNKNOWN_EVENT\";i:1;s:8:\"OS_START\";i:2;s:15:\"CONTAINER_START\";i:3;s:10:\"NETWORK_UP\";i:4;s:28:\"STAGING_FILES_DOWNLOAD_START\";i:5;s:29:\"STAGING_FILES_DOWNLOAD_FINISH\";i:6;s:17:\"SDK_INSTALL_START\";i:7;s:18:\"SDK_INSTALL_FINISH\";}s:4:\"type\";s:6:\"string\";}s:8:\"metadata\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:11:\"description\";s:79:\"Other
  stats that can accompany an event. E.g.\n{ \"downloaded_bytes\" : \"123456\" }\";s:4:\"type\";s:6:\"object\";}}s:4:\"type\";s:6:\"object\";}s:13:\"WorkerMessage\";O:8:\"stdClass\":3:{s:11:\"description\";s:65:\"WorkerMessage
  provides information to the backend about a worker.\";s:10:\"properties\";O:8:\"stdClass\":7:{s:6:\"labels\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:11:\"description\";s:412:\"Labels
  are used to group WorkerMessages.\nFor example, a worker_message about a particular
  container\nmight have the labels:\n{ \"JOB_ID\": \"2015-04-22\",\n  \"WORKER_ID\":
  \"wordcount-vm-2015\u2026\"\n  \"CONTAINER_TYPE\": \"worker\",\n  \"CONTAINER_ID\":
  \"ac1234def\"}\nLabel tags typically correspond to Label enum values. However, for
  ease\nof development other strings can be used as tags. LABEL_UNSPECIFIED should\nnot
  be used here.\";s:4:\"type\";s:6:\"object\";}s:4:\"time\";O:8:\"stdClass\":3:{s:11:\"description\";s:36:\"The
  timestamp of the worker_message.\";s:6:\"format\";s:15:\"google-datetime\";s:4:\"type\";s:6:\"string\";}s:18:\"workerHealthReport\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/WorkerHealthReport\";s:11:\"description\";s:23:\"The
  health of a worker.\";}s:20:\"workerLifecycleEvent\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:34:\"#/definitions/WorkerLifecycleEvent\";s:11:\"description\";s:34:\"Record
  of worker lifecycle events.\";}s:17:\"workerMessageCode\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/WorkerMessageCode\";s:11:\"description\";s:22:\"A
  worker message code.\";}s:13:\"workerMetrics\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:39:\"#/definitions/ResourceUtilizationReport\";s:11:\"description\";s:37:\"Resource
  metrics reported by workers.\";}s:20:\"workerShutdownNotice\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:34:\"#/definitions/WorkerShutdownNotice\";s:11:\"description\";s:27:\"Shutdown
  notice by workers.\";}}s:4:\"type\";s:6:\"object\";}s:17:\"WorkerMessageCode\";O:8:\"stdClass\":3:{s:11:\"description\";s:382:\"A
  message code is used to report status and error messages to the service.\nThe message
  codes are intended to be machine readable. The service will\ntake care of translating
  these into user understandable messages if\nnecessary.\n\nExample use cases:\n  1.
  Worker processes reporting successful startup.\n  2. Worker processes reporting
  specific errors (e.g. package staging\n     failure).\";s:10:\"properties\";O:8:\"stdClass\":2:{s:4:\"code\";O:8:\"stdClass\":2:{s:11:\"description\";s:451:\"The
  code is a string intended for consumption by a machine that identifies\nthe type
  of message being sent.\nExamples:\n 1. \"HARNESS_STARTED\" might be used to indicate
  the worker harness has\n     started.\n 2. \"GCS_DOWNLOAD_ERROR\" might be used
  to indicate an error downloading\n    a GCS file as part of the boot process of
  one of the worker containers.\n\nThis is a string and not an enum to make it easy
  to add new codes without\nwaiting for an API change.\";s:4:\"type\";s:6:\"string\";}s:10:\"parameters\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:25:\"Properties
  of the object.\";}s:11:\"description\";s:849:\"Parameters contains specific information
  about the code.\n\nThis is a struct to allow parameters of different types.\n\nExamples:\n
  1. For a \"HARNESS_STARTED\" message parameters might provide the name\n    of the
  worker and additional data like timing information.\n 2. For a \"GCS_DOWNLOAD_ERROR\"
  parameters might contain fields listing\n    the GCS objects being downloaded and
  fields containing errors.\n\nIn general complex data structures should be avoided.
  If a worker\nneeds to send a specific and complicated data structure then please\nconsider
  defining a new proto and adding it to the data oneof in\nWorkerMessageResponse.\n\nConventions:\n
  Parameters should only be used for information that isn't typically passed\n as
  a label.\n hostname and other worker identifiers should almost always be passed\n
  as labels since they will be included on most messages.\";s:4:\"type\";s:6:\"object\";}}s:4:\"type\";s:6:\"object\";}s:21:\"WorkerMessageResponse\";O:8:\"stdClass\":3:{s:11:\"description\";s:78:\"A
  worker_message response allows the server to pass information to the\nsender.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:26:\"workerHealthReportResponse\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:40:\"#/definitions/WorkerHealthReportResponse\";s:11:\"description\";s:51:\"The
  service's response to a worker's health report.\";}s:21:\"workerMetricsResponse\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:47:\"#/definitions/ResourceUtilizationReportResponse\";s:11:\"description\";s:65:\"Service's
  response to reporting worker metrics (currently empty).\";}s:28:\"workerShutdownNoticeResponse\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:42:\"#/definitions/WorkerShutdownNoticeResponse\";s:11:\"description\";s:56:\"Service's
  response to shutdown notice (currently empty).\";}}s:4:\"type\";s:6:\"object\";}s:10:\"WorkerPool\";O:8:\"stdClass\":3:{s:11:\"description\";s:301:\"Describes
  one particular pool of Cloud Dataflow workers to be\ninstantiated by the Cloud Dataflow
  service in order to perform the\ncomputations required by a job.  Note that a workflow
  job may use\nmultiple pools, in order to match the various computational\nrequirements
  of the various stages of the job.\";s:10:\"properties\";O:8:\"stdClass\":21:{s:19:\"autoscalingSettings\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:33:\"#/definitions/AutoscalingSettings\";s:11:\"description\";s:44:\"Settings
  for autoscaling of this WorkerPool.\";}s:9:\"dataDisks\";O:8:\"stdClass\":3:{s:11:\"description\";s:50:\"Data
  disks that are used by a VM in this workflow.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:18:\"#/definitions/Disk\";}s:4:\"type\";s:5:\"array\";}s:17:\"defaultPackageSet\";O:8:\"stdClass\":3:{s:11:\"description\";s:167:\"The
  default package set to install.  This allows the service to\nselect a default set
  of packages which are useful to worker\nharnesses written in a particular language.\";s:4:\"enum\";a:4:{i:0;s:27:\"DEFAULT_PACKAGE_SET_UNKNOWN\";i:1;s:24:\"DEFAULT_PACKAGE_SET_NONE\";i:2;s:24:\"DEFAULT_PACKAGE_SET_JAVA\";i:3;s:26:\"DEFAULT_PACKAGE_SET_PYTHON\";}s:4:\"type\";s:6:\"string\";}s:10:\"diskSizeGb\";O:8:\"stdClass\":3:{s:11:\"description\";s:115:\"Size
  of root disk for VMs, in GB.  If zero or unspecified, the service will\nattempt
  to choose a reasonable default.\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}s:15:\"diskSourceImage\";O:8:\"stdClass\":2:{s:11:\"description\";s:39:\"Fully
  qualified source image for disks.\";s:4:\"type\";s:6:\"string\";}s:8:\"diskType\";O:8:\"stdClass\":2:{s:11:\"description\";s:109:\"Type
  of root disk for VMs.  If empty or unspecified, the service will\nattempt to choose
  a reasonable default.\";s:4:\"type\";s:6:\"string\";}s:15:\"ipConfiguration\";O:8:\"stdClass\":3:{s:11:\"description\";s:25:\"Configuration
  for VM IPs.\";s:4:\"enum\";a:3:{i:0;s:21:\"WORKER_IP_UNSPECIFIED\";i:1;s:16:\"WORKER_IP_PUBLIC\";i:2;s:17:\"WORKER_IP_PRIVATE\";}s:4:\"type\";s:6:\"string\";}s:4:\"kind\";O:8:\"stdClass\":2:{s:11:\"description\";s:82:\"The
  kind of the worker pool; currently only `harness` and `shuffle`\nare supported.\";s:4:\"type\";s:6:\"string\";}s:11:\"machineType\";O:8:\"stdClass\":2:{s:11:\"description\";s:119:\"Machine
  type (e.g. \"n1-standard-1\").  If empty or unspecified, the\nservice will attempt
  to choose a reasonable default.\";s:4:\"type\";s:6:\"string\";}s:8:\"metadata\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:11:\"description\";s:49:\"Metadata
  to set on the Google Compute Engine VMs.\";s:4:\"type\";s:6:\"object\";}s:7:\"network\";O:8:\"stdClass\":2:{s:11:\"description\";s:108:\"Network
  to which VMs will be assigned.  If empty or unspecified,\nthe service will use the
  network \"default\".\";s:4:\"type\";s:6:\"string\";}s:19:\"numThreadsPerWorker\";O:8:\"stdClass\":3:{s:11:\"description\";s:219:\"The
  number of threads per worker harness. If empty or unspecified, the\nservice will
  choose a number of threads (according to the number of cores\non the selected machine
  type for batch, or 1 by convention for streaming).\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}s:10:\"numWorkers\";O:8:\"stdClass\":3:{s:11:\"description\";s:161:\"Number
  of Google Compute Engine workers in this pool needed to\nexecute the job.  If zero
  or unspecified, the service will\nattempt to choose a reasonable default.\";s:6:\"format\";s:5:\"int32\";s:4:\"type\";s:7:\"integer\";}s:17:\"onHostMaintenance\";O:8:\"stdClass\":2:{s:11:\"description\";s:84:\"The
  action to take on host maintenance, as defined by the Google\nCompute Engine API.\";s:4:\"type\";s:6:\"string\";}s:8:\"packages\";O:8:\"stdClass\":3:{s:11:\"description\";s:36:\"Packages
  to be installed on workers.\";s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:21:\"#/definitions/Package\";}s:4:\"type\";s:5:\"array\";}s:8:\"poolArgs\";O:8:\"stdClass\":3:{s:20:\"additionalProperties\";O:8:\"stdClass\":1:{s:11:\"description\";s:61:\"Properties
  of the object. Contains field @type with type URL.\";}s:11:\"description\";s:37:\"Extra
  arguments for this worker pool.\";s:4:\"type\";s:6:\"object\";}s:10:\"subnetwork\";O:8:\"stdClass\":2:{s:11:\"description\";s:122:\"Subnetwork
  to which VMs will be assigned, if desired.  Expected to be of\nthe form \"regions/REGION/subnetworks/SUBNETWORK\".\";s:4:\"type\";s:6:\"string\";}s:18:\"taskrunnerSettings\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/TaskRunnerSettings\";s:11:\"description\";s:135:\"Settings
  passed through to Google Compute Engine workers when\nusing the standard Dataflow
  task runner.  Users should ignore\nthis field.\";}s:14:\"teardownPolicy\";O:8:\"stdClass\":3:{s:11:\"description\";s:760:\"Sets
  the policy for determining when to turndown worker pool.\nAllowed values are: `TEARDOWN_ALWAYS`,
  `TEARDOWN_ON_SUCCESS`, and\n`TEARDOWN_NEVER`.\n`TEARDOWN_ALWAYS` means workers are
  always torn down regardless of whether\nthe job succeeds. `TEARDOWN_ON_SUCCESS`
  means workers are torn down\nif the job succeeds. `TEARDOWN_NEVER` means the workers
  are never torn\ndown.\n\nIf the workers are not torn down by the service, they will\ncontinue
  to run and use Google Compute Engine VM resources in the\nuser's project until they
  are explicitly terminated by the user.\nBecause of this, Google recommends using
  the `TEARDOWN_ALWAYS`\npolicy except for small, manually supervised test jobs.\n\nIf
  unknown or unspecified, the service will attempt to choose a reasonable\ndefault.\";s:4:\"enum\";a:4:{i:0;s:23:\"TEARDOWN_POLICY_UNKNOWN\";i:1;s:15:\"TEARDOWN_ALWAYS\";i:2;s:19:\"TEARDOWN_ON_SUCCESS\";i:3;s:14:\"TEARDOWN_NEVER\";}s:4:\"type\";s:6:\"string\";}s:27:\"workerHarnessContainerImage\";O:8:\"stdClass\":2:{s:11:\"description\";s:120:\"Required.
  Docker container image that executes the Cloud Dataflow worker\nharness, residing
  in Google Container Registry.\";s:4:\"type\";s:6:\"string\";}s:4:\"zone\";O:8:\"stdClass\":2:{s:11:\"description\";s:115:\"Zone
  to run the worker pools in.  If empty or unspecified, the service\nwill attempt
  to choose a reasonable default.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:14:\"WorkerSettings\";O:8:\"stdClass\":3:{s:11:\"description\";s:52:\"Provides
  data to pass through to the worker harness.\";s:10:\"properties\";O:8:\"stdClass\":6:{s:7:\"baseUrl\";O:8:\"stdClass\":2:{s:11:\"description\";s:382:\"The
  base URL for accessing Google Cloud APIs.\n\nWhen workers access Google Cloud APIs,
  they logically do so via\nrelative URLs.  If this field is specified, it supplies
  the base\nURL to use for resolving these relative URLs.  The normative\nalgorithm
  used is defined by RFC 1808, \"Relative Uniform Resource\nLocators\".\n\nIf not
  specified, the default value is \"http://www.googleapis.com/\"\";s:4:\"type\";s:6:\"string\";}s:16:\"reportingEnabled\";O:8:\"stdClass\":2:{s:11:\"description\";s:53:\"Whether
  to send work progress updates to the service.\";s:4:\"type\";s:7:\"boolean\";}s:11:\"servicePath\";O:8:\"stdClass\":2:{s:11:\"description\";s:96:\"The
  Cloud Dataflow service path relative to the root URL, for example,\n\"dataflow/v1b3/projects\".\";s:4:\"type\";s:6:\"string\";}s:18:\"shuffleServicePath\";O:8:\"stdClass\":2:{s:11:\"description\";s:82:\"The
  Shuffle service path relative to the root URL, for example,\n\"shuffle/v1beta1\".\";s:4:\"type\";s:6:\"string\";}s:17:\"tempStoragePrefix\";O:8:\"stdClass\":2:{s:11:\"description\";s:213:\"The
  prefix of the resources the system should use for temporary\nstorage.\n\nThe supported
  resource type is:\n\nGoogle Cloud Storage:\n\n  storage.googleapis.com/{bucket}/{object}\n
  \ bucket.storage.googleapis.com/{object}\";s:4:\"type\";s:6:\"string\";}s:8:\"workerId\";O:8:\"stdClass\":2:{s:11:\"description\";s:43:\"The
  ID of the worker running this pipeline.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:20:\"WorkerShutdownNotice\";O:8:\"stdClass\":3:{s:11:\"description\";s:152:\"Shutdown
  notification from workers. This is to be sent by the shutdown\nscript of the worker
  VM so that the backend knows that the VM is being\nshut down.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:6:\"reason\";O:8:\"stdClass\":2:{s:11:\"description\";s:203:\"The
  reason for the worker shutdown.\nCurrent possible values are:\n  \"UNKNOWN\": shutdown
  reason is unknown.\n  \"PREEMPTION\": shutdown reason is preemption.\nOther possible
  reasons may be added in the future.\";s:4:\"type\";s:6:\"string\";}}s:4:\"type\";s:6:\"object\";}s:28:\"WorkerShutdownNoticeResponse\";O:8:\"stdClass\":3:{s:11:\"description\";s:63:\"Service-side
  response to WorkerMessage issuing shutdown notice.\";s:10:\"properties\";O:8:\"stdClass\":0:{}s:4:\"type\";s:6:\"object\";}s:16:\"WriteInstruction\";O:8:\"stdClass\":3:{s:11:\"description\";s:73:\"An
  instruction that writes records.\nTakes one input, produces no outputs.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:5:\"input\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:30:\"#/definitions/InstructionInput\";s:11:\"description\";s:10:\"The
  input.\";}s:4:\"sink\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:18:\"#/definitions/Sink\";s:11:\"description\";s:21:\"The
  sink to write to.\";}}s:4:\"type\";s:6:\"object\";}}"
...
