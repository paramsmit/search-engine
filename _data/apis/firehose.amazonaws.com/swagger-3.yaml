---
swagger: "2.0"
info: !php/object "O:8:\"stdClass\":14:{s:7:\"contact\";O:8:\"stdClass\":4:{s:5:\"email\";s:23:\"mike.ralphson@gmail.com\";s:4:\"name\";s:13:\"Mike
  Ralphson\";s:3:\"url\";s:38:\"https://github.com/mermade/aws2openapi\";s:9:\"x-twitter\";s:12:\"PermittedSoc\";}s:11:\"description\";s:303:\"<fullname>Amazon
  Kinesis Data Firehose API Reference</fullname> <p>Amazon Kinesis Data Firehose is
  a fully managed service that delivers real-time streaming data to destinations such
  as Amazon Simple Storage Service (Amazon S3), Amazon Elasticsearch Service (Amazon
  ES), Amazon Redshift, and Splunk.</p>\";s:7:\"license\";O:8:\"stdClass\":2:{s:4:\"name\";s:18:\"Apache
  2.0 License\";s:3:\"url\";s:31:\"http://www.apache.org/licenses/\";}s:14:\"termsOfService\";s:37:\"https://aws.amazon.com/service-terms/\";s:5:\"title\";s:23:\"Amazon
  Kinesis Firehose\";s:7:\"version\";s:10:\"2015-08-04\";s:23:\"x-apiClientRegistration\";O:8:\"stdClass\":1:{s:3:\"url\";s:79:\"https://portal.aws.amazon.com/gp/aws/developer/registration/index.html?nc2=h_ct\";}s:21:\"x-apisguru-categories\";a:1:{i:0;s:5:\"cloud\";}s:6:\"x-logo\";O:8:\"stdClass\":2:{s:15:\"backgroundColor\";s:7:\"#FFFFFF\";s:3:\"url\";s:81:\"https://api.apis.guru/v2/cache/logo/https_twitter.com_awscloud_profile_image.jpeg\";}s:8:\"x-origin\";a:1:{i:0;O:8:\"stdClass\":4:{s:11:\"contentType\";s:16:\"application/json\";s:9:\"converter\";O:8:\"stdClass\":2:{s:3:\"url\";s:38:\"https://github.com/mermade/aws2openapi\";s:7:\"version\";s:5:\"1.0.0\";}s:3:\"url\";s:92:\"https://raw.githubusercontent.com/aws/aws-sdk-js/master/apis/firehose-2015-08-04.normal.json\";s:17:\"x-apisguru-direct\";b:1;}}s:11:\"x-preferred\";b:1;s:14:\"x-providerName\";s:13:\"amazonaws.com\";s:9:\"x-release\";s:2:\"v4\";s:13:\"x-serviceName\";s:8:\"firehose\";}"
host: firehose.amazonaws.com
basePath: /
paths: ~
produces:
- application/json
schemes:
- https
- http
definitions: !php/object "O:8:\"stdClass\":157:{s:12:\"AWSKMSKeyARN\";O:8:\"stdClass\":4:{s:9:\"maxLength\";i:512;s:9:\"minLength\";i:1;s:7:\"pattern\";s:6:\"arn:.*\";s:4:\"type\";s:6:\"string\";}s:14:\"BlockSizeBytes\";O:8:\"stdClass\":2:{s:7:\"minimum\";i:67108864;s:4:\"type\";s:7:\"integer\";}s:13:\"BooleanObject\";O:8:\"stdClass\":1:{s:4:\"type\";s:7:\"boolean\";}s:9:\"BucketARN\";O:8:\"stdClass\":4:{s:9:\"maxLength\";i:2048;s:9:\"minLength\";i:1;s:7:\"pattern\";s:6:\"arn:.*\";s:4:\"type\";s:6:\"string\";}s:14:\"BufferingHints\";O:8:\"stdClass\":3:{s:11:\"description\";s:216:\"Describes
  hints for the buffering to perform before delivering data to the destination. These
  options are treated as hints, and therefore Kinesis Data Firehose might choose to
  use different values when it is optimal.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:17:\"IntervalInSeconds\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/IntervalInSeconds\";s:11:\"description\";s:133:\"Buffer
  incoming data for the specified period of time, in seconds, before delivering it
  to the destination. The default value is 300.\";}s:9:\"SizeInMBs\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:23:\"#/definitions/SizeInMBs\";s:11:\"description\";s:362:\"<p>Buffer
  incoming data to the specified size, in MBs, before delivering it to the destination.
  The default value is 5.</p> <p>We recommend setting this parameter to a value greater
  than the amount of data you typically ingest into the delivery stream in 10 seconds.
  For example, if you typically ingest data at 1 MB/sec, the value should be 10 MB
  or higher.</p>\";}}s:4:\"type\";s:6:\"object\";}s:24:\"CloudWatchLoggingOptions\";O:8:\"stdClass\":3:{s:11:\"description\";s:73:\"Describes
  the Amazon CloudWatch logging options for your delivery stream.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:7:\"Enabled\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/BooleanObject\";s:11:\"description\";s:39:\"Enables
  or disables CloudWatch logging.\";}s:12:\"LogGroupName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:26:\"#/definitions/LogGroupName\";s:11:\"description\";s:95:\"The
  CloudWatch group name for logging. This value is required if CloudWatch logging
  is enabled.\";}s:13:\"LogStreamName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/LogStreamName\";s:11:\"description\";s:100:\"The
  CloudWatch log stream name for logging. This value is required if CloudWatch logging
  is enabled.\";}}s:4:\"type\";s:6:\"object\";}s:14:\"ClusterJDBCURL\";O:8:\"stdClass\":3:{s:9:\"minLength\";i:1;s:7:\"pattern\";s:110:\"jdbc:(redshift|postgresql)://((?!-)[A-Za-z0-9-]{1,63}(?<!-)\\.)+redshift\\.amazonaws\\.com:\\d{1,5}/[a-zA-Z0-9_$]+\";s:4:\"type\";s:6:\"string\";}s:23:\"ColumnToJsonKeyMappings\";O:8:\"stdClass\":2:{s:5:\"items\";O:8:\"stdClass\":2:{s:10:\"properties\";O:8:\"stdClass\":2:{s:3:\"key\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:45:\"#/definitions/NonEmptyStringWithoutWhitespace\";}s:5:\"value\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:28:\"#/definitions/NonEmptyString\";}}s:4:\"type\";s:6:\"object\";}s:4:\"type\";s:5:\"array\";}s:17:\"CompressionFormat\";O:8:\"stdClass\":2:{s:4:\"enum\";a:4:{i:0;s:12:\"UNCOMPRESSED\";i:1;s:4:\"GZIP\";i:2;s:3:\"ZIP\";i:3;s:6:\"Snappy\";}s:4:\"type\";s:6:\"string\";}s:31:\"ConcurrentModificationException\";O:8:\"stdClass\":0:{}s:11:\"CopyCommand\";O:8:\"stdClass\":4:{s:11:\"description\";s:58:\"Describes
  a <code>COPY</code> command for Amazon Redshift.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:11:\"CopyOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:25:\"#/definitions/CopyOptions\";s:11:\"description\";s:1111:\"<p>Optional
  parameters to use with the Amazon Redshift <code>COPY</code> command. For more information,
  see the \"Optional Parameters\" section of <a href=\"http://docs.aws.amazon.com/redshift/latest/dg/r_COPY.html\">Amazon
  Redshift COPY command</a>. Some possible examples that would apply to Kinesis Data
  Firehose are as follows:</p> <p> <code>delimiter '\\t' lzop;</code> - fields are
  delimited with \"\\t\" (TAB character) and compressed using lzop.</p> <p> <code>delimiter
  '|'</code> - fields are delimited with \"|\" (this is the default delimiter).</p>
  <p> <code>delimiter '|' escape</code> - the delimiter should be escaped.</p> <p>
  <code>fixedwidth 'venueid:3,venuename:25,venuecity:12,venuestate:2,venueseats:6'</code>
  - fields are fixed width in the source, with each width specified after every column
  in the table.</p> <p> <code>JSON 's3://mybucket/jsonpaths.txt'</code> - data is
  in JSON format, and the path specified is the format of the data.</p> <p>For more
  examples, see <a href=\"http://docs.aws.amazon.com/redshift/latest/dg/r_COPY_command_examples.html\">Amazon
  Redshift COPY command examples</a>.</p>\";}s:16:\"DataTableColumns\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:30:\"#/definitions/DataTableColumns\";s:11:\"description\";s:39:\"A
  comma-separated list of column names.\";}s:13:\"DataTableName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/DataTableName\";s:11:\"description\";s:75:\"The
  name of the target table. The table must already exist in the database.\";}}s:8:\"required\";a:1:{i:0;s:13:\"DataTableName\";}s:4:\"type\";s:6:\"object\";}s:11:\"CopyOptions\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:25:\"CreateDeliveryStreamInput\";O:8:\"stdClass\":3:{s:10:\"properties\";O:8:\"stdClass\":9:{s:18:\"DeliveryStreamName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/DeliveryStreamName\";s:11:\"description\";s:228:\"The
  name of the delivery stream. This name must be unique per AWS account in the same
  AWS Region. If the delivery streams are in different accounts or different Regions,
  you can have multiple delivery streams with the same name.\";}s:18:\"DeliveryStreamType\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/DeliveryStreamType\";s:11:\"description\";s:311:\"<p>The
  delivery stream type. This parameter can be one of the following values:</p> <ul>
  <li> <p> <code>DirectPut</code>: Provider applications access the delivery stream
  directly.</p> </li> <li> <p> <code>KinesisStreamAsSource</code>: The delivery stream
  uses a Kinesis data stream as a source.</p> </li> </ul>\";}s:37:\"ElasticsearchDestinationConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:51:\"#/definitions/ElasticsearchDestinationConfiguration\";s:11:\"description\";s:67:\"The
  destination in Amazon ES. You can specify only one destination.\";}s:34:\"ExtendedS3DestinationConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:48:\"#/definitions/ExtendedS3DestinationConfiguration\";s:11:\"description\";s:67:\"The
  destination in Amazon S3. You can specify only one destination.\";}s:32:\"KinesisStreamSourceConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:46:\"#/definitions/KinesisStreamSourceConfiguration\";s:11:\"description\";s:217:\"When
  a Kinesis data stream is used as the source for the delivery stream, a <a>KinesisStreamSourceConfiguration</a>
  containing the Kinesis data stream Amazon Resource Name (ARN) and the role ARN for
  the source stream.\";}s:32:\"RedshiftDestinationConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:46:\"#/definitions/RedshiftDestinationConfiguration\";s:11:\"description\";s:73:\"The
  destination in Amazon Redshift. You can specify only one destination.\";}s:26:\"S3DestinationConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:40:\"#/definitions/S3DestinationConfiguration\";s:11:\"description\";s:80:\"[Deprecated]
  The destination in Amazon S3. You can specify only one destination.\";}s:30:\"SplunkDestinationConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:44:\"#/definitions/SplunkDestinationConfiguration\";s:11:\"description\";s:64:\"The
  destination in Splunk. You can specify only one destination.\";}s:4:\"Tags\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:43:\"#/definitions/TagDeliveryStreamInputTagList\";s:11:\"description\";s:567:\"<p>A
  set of tags to assign to the delivery stream. A tag is a key-value pair that you
  can define and assign to AWS resources. Tags are metadata. For example, you can
  add friendly names and descriptions or other types of information that can help
  you distinguish the delivery stream. For more information about tags, see <a href=\"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html\">Using
  Cost Allocation Tags</a> in the AWS Billing and Cost Management User Guide.</p>
  <p>You can specify up to 50 tags when creating a delivery stream.</p>\";}}s:8:\"required\";a:1:{i:0;s:18:\"DeliveryStreamName\";}s:4:\"type\";s:6:\"object\";}s:26:\"CreateDeliveryStreamOutput\";O:8:\"stdClass\":2:{s:10:\"properties\";O:8:\"stdClass\":1:{s:17:\"DeliveryStreamARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/DeliveryStreamARN\";s:11:\"description\";s:31:\"The
  ARN of the delivery stream.\";}}s:4:\"type\";s:6:\"object\";}s:4:\"Data\";O:8:\"stdClass\":3:{s:9:\"maxLength\";i:1024000;s:9:\"minLength\";i:0;s:4:\"type\";s:6:\"string\";}s:33:\"DataFormatConversionConfiguration\";O:8:\"stdClass\":3:{s:11:\"description\";s:542:\"Specifies
  that you want Kinesis Data Firehose to convert data from the JSON format to the
  Parquet or ORC format before writing it to Amazon S3. Kinesis Data Firehose uses
  the serializer and deserializer that you specify, in addition to the column information
  from the AWS Glue table, to deserialize your input data from JSON and then serialize
  it to the Parquet or ORC format. For more information, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/record-format-conversion.html\">Kinesis
  Data Firehose Record Format Conversion</a>.\";s:10:\"properties\";O:8:\"stdClass\":4:{s:7:\"Enabled\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/BooleanObject\";s:11:\"description\";s:144:\"Defaults
  to <code>true</code>. Set it to <code>false</code> if you want to disable format
  conversion while preserving the configuration details.\";}s:24:\"InputFormatConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/InputFormatConfiguration\";s:11:\"description\";s:115:\"Specifies
  the deserializer that you want Kinesis Data Firehose to use to convert the format
  of your data from JSON.\";}s:25:\"OutputFormatConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:39:\"#/definitions/OutputFormatConfiguration\";s:11:\"description\";s:132:\"Specifies
  the serializer that you want Kinesis Data Firehose to use to convert the format
  of your data to the Parquet or ORC format.\";}s:19:\"SchemaConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:33:\"#/definitions/SchemaConfiguration\";s:11:\"description\";s:79:\"Specifies
  the AWS Glue Data Catalog table that contains the column information.\";}}s:4:\"type\";s:6:\"object\";}s:16:\"DataTableColumns\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:13:\"DataTableName\";O:8:\"stdClass\":2:{s:9:\"minLength\";i:1;s:4:\"type\";s:6:\"string\";}s:25:\"DeleteDeliveryStreamInput\";O:8:\"stdClass\":3:{s:10:\"properties\";O:8:\"stdClass\":1:{s:18:\"DeliveryStreamName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/DeliveryStreamName\";s:11:\"description\";s:32:\"The
  name of the delivery stream.\";}}s:8:\"required\";a:1:{i:0;s:18:\"DeliveryStreamName\";}s:4:\"type\";s:6:\"object\";}s:26:\"DeleteDeliveryStreamOutput\";O:8:\"stdClass\":2:{s:10:\"properties\";O:8:\"stdClass\":0:{}s:4:\"type\";s:6:\"object\";}s:22:\"DeliveryStartTimestamp\";O:8:\"stdClass\":2:{s:6:\"format\";s:9:\"date-time\";s:4:\"type\";s:6:\"string\";}s:17:\"DeliveryStreamARN\";O:8:\"stdClass\":4:{s:9:\"maxLength\";i:512;s:9:\"minLength\";i:1;s:7:\"pattern\";s:6:\"arn:.*\";s:4:\"type\";s:6:\"string\";}s:25:\"DeliveryStreamDescription\";O:8:\"stdClass\":4:{s:11:\"description\";s:45:\"Contains
  information about a delivery stream.\";s:10:\"properties\";O:8:\"stdClass\":11:{s:15:\"CreateTimestamp\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:23:\"#/definitions/Timestamp\";s:11:\"description\";s:55:\"The
  date and time that the delivery stream was created.\";}s:17:\"DeliveryStreamARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/DeliveryStreamARN\";s:11:\"description\";s:226:\"The
  Amazon Resource Name (ARN) of the delivery stream. For more information, see <a
  href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:37:\"DeliveryStreamEncryptionConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:51:\"#/definitions/DeliveryStreamEncryptionConfiguration\";s:11:\"description\";s:74:\"Indicates
  the server-side encryption (SSE) status for the delivery stream.\";}s:18:\"DeliveryStreamName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/DeliveryStreamName\";s:11:\"description\";s:32:\"The
  name of the delivery stream.\";}s:20:\"DeliveryStreamStatus\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:34:\"#/definitions/DeliveryStreamStatus\";s:11:\"description\";s:34:\"The
  status of the delivery stream.\";}s:18:\"DeliveryStreamType\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/DeliveryStreamType\";s:11:\"description\";s:301:\"<p>The
  delivery stream type. This can be one of the following values:</p> <ul> <li> <p>
  <code>DirectPut</code>: Provider applications access the delivery stream directly.</p>
  </li> <li> <p> <code>KinesisStreamAsSource</code>: The delivery stream uses a Kinesis
  data stream as a source.</p> </li> </ul>\";}s:12:\"Destinations\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:40:\"#/definitions/DestinationDescriptionList\";s:11:\"description\";s:17:\"The
  destinations.\";}s:19:\"HasMoreDestinations\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/BooleanObject\";s:11:\"description\";s:64:\"Indicates
  whether there are more destinations available to list.\";}s:19:\"LastUpdateTimestamp\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:23:\"#/definitions/Timestamp\";s:11:\"description\";s:60:\"The
  date and time that the delivery stream was last updated.\";}s:6:\"Source\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/SourceDescription\";s:11:\"description\";s:164:\"If
  the <code>DeliveryStreamType</code> parameter is <code>KinesisStreamAsSource</code>,
  a <a>SourceDescription</a> object describing the source Kinesis data stream.\";}s:9:\"VersionId\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/DeliveryStreamVersionId\";s:11:\"description\";s:264:\"Each
  time the destination is updated for a delivery stream, the version ID is changed,
  and the current version ID is required when updating the destination. This is so
  that the service knows it is applying the changes to the correct version of the
  delivery stream.\";}}s:8:\"required\";a:7:{i:0;s:18:\"DeliveryStreamName\";i:1;s:17:\"DeliveryStreamARN\";i:2;s:20:\"DeliveryStreamStatus\";i:3;s:18:\"DeliveryStreamType\";i:4;s:9:\"VersionId\";i:5;s:12:\"Destinations\";i:6;s:19:\"HasMoreDestinations\";}s:4:\"type\";s:6:\"object\";}s:37:\"DeliveryStreamEncryptionConfiguration\";O:8:\"stdClass\":3:{s:11:\"description\";s:74:\"Indicates
  the server-side encryption (SSE) status for the delivery stream.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:6:\"Status\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:44:\"#/definitions/DeliveryStreamEncryptionStatus\";s:11:\"description\";s:144:\"For
  a full description of the different values of this status, see <a>StartDeliveryStreamEncryption</a>
  and <a>StopDeliveryStreamEncryption</a>.\";}}s:4:\"type\";s:6:\"object\";}s:30:\"DeliveryStreamEncryptionStatus\";O:8:\"stdClass\":2:{s:4:\"enum\";a:4:{i:0;s:7:\"ENABLED\";i:1;s:8:\"ENABLING\";i:2;s:8:\"DISABLED\";i:3;s:9:\"DISABLING\";}s:4:\"type\";s:6:\"string\";}s:18:\"DeliveryStreamName\";O:8:\"stdClass\":4:{s:9:\"maxLength\";i:64;s:9:\"minLength\";i:1;s:7:\"pattern\";s:15:\"[a-zA-Z0-9_.-]+\";s:4:\"type\";s:6:\"string\";}s:22:\"DeliveryStreamNameList\";O:8:\"stdClass\":2:{s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:32:\"#/definitions/DeliveryStreamName\";}s:4:\"type\";s:5:\"array\";}s:20:\"DeliveryStreamStatus\";O:8:\"stdClass\":2:{s:4:\"enum\";a:3:{i:0;s:8:\"CREATING\";i:1;s:8:\"DELETING\";i:2;s:6:\"ACTIVE\";}s:4:\"type\";s:6:\"string\";}s:18:\"DeliveryStreamType\";O:8:\"stdClass\":2:{s:4:\"enum\";a:2:{i:0;s:9:\"DirectPut\";i:1;s:21:\"KinesisStreamAsSource\";}s:4:\"type\";s:6:\"string\";}s:23:\"DeliveryStreamVersionId\";O:8:\"stdClass\":4:{s:9:\"maxLength\";i:50;s:9:\"minLength\";i:1;s:7:\"pattern\";s:6:\"[0-9]+\";s:4:\"type\";s:6:\"string\";}s:27:\"DescribeDeliveryStreamInput\";O:8:\"stdClass\":3:{s:10:\"properties\";O:8:\"stdClass\":3:{s:18:\"DeliveryStreamName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/DeliveryStreamName\";s:11:\"description\";s:32:\"The
  name of the delivery stream.\";}s:27:\"ExclusiveStartDestinationId\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/DestinationId\";s:11:\"description\";s:141:\"The
  ID of the destination to start returning the destination information. Kinesis Data
  Firehose supports one destination per delivery stream.\";}s:5:\"Limit\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:46:\"#/definitions/DescribeDeliveryStreamInputLimit\";s:11:\"description\";s:100:\"The
  limit on the number of destinations to return. You can have one destination per
  delivery stream.\";}}s:8:\"required\";a:1:{i:0;s:18:\"DeliveryStreamName\";}s:4:\"type\";s:6:\"object\";}s:32:\"DescribeDeliveryStreamInputLimit\";O:8:\"stdClass\":3:{s:7:\"maximum\";i:10000;s:7:\"minimum\";i:1;s:4:\"type\";s:7:\"integer\";}s:28:\"DescribeDeliveryStreamOutput\";O:8:\"stdClass\":3:{s:10:\"properties\";O:8:\"stdClass\":1:{s:25:\"DeliveryStreamDescription\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:39:\"#/definitions/DeliveryStreamDescription\";s:11:\"description\";s:38:\"Information
  about the delivery stream.\";}}s:8:\"required\";a:1:{i:0;s:25:\"DeliveryStreamDescription\";}s:4:\"type\";s:6:\"object\";}s:12:\"Deserializer\";O:8:\"stdClass\":3:{s:11:\"description\";s:465:\"The
  deserializer you want Kinesis Data Firehose to use for converting the input data
  from JSON. Kinesis Data Firehose then serializes the data to its final format using
  the <a>Serializer</a>. Kinesis Data Firehose supports two types of deserializers:
  the <a href=\"https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-JSON\">Apache
  Hive JSON SerDe</a> and the <a href=\"https://github.com/rcongiu/Hive-JSON-Serde\">OpenX
  JSON SerDe</a>.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:13:\"HiveJsonSerDe\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/HiveJsonSerDe\";s:11:\"description\";s:346:\"The
  native Hive / HCatalog JsonSerDe. Used by Kinesis Data Firehose for deserializing
  data, which means converting it from the JSON format in preparation for serializing
  it to the Parquet or ORC format. This is one of two deserializers you can choose,
  depending on which one offers the functionality you need. The other option is the
  OpenX SerDe.\";}s:14:\"OpenXJsonSerDe\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/OpenXJsonSerDe\";s:11:\"description\";s:346:\"The
  OpenX SerDe. Used by Kinesis Data Firehose for deserializing data, which means converting
  it from the JSON format in preparation for serializing it to the Parquet or ORC
  format. This is one of two deserializers you can choose, depending on which one
  offers the functionality you need. The other option is the native Hive / HCatalog
  JsonSerDe.\";}}s:4:\"type\";s:6:\"object\";}s:22:\"DestinationDescription\";O:8:\"stdClass\":4:{s:11:\"description\";s:48:\"Describes
  the destination for a delivery stream.\";s:10:\"properties\";O:8:\"stdClass\":6:{s:13:\"DestinationId\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/DestinationId\";s:11:\"description\";s:26:\"The
  ID of the destination.\";}s:35:\"ElasticsearchDestinationDescription\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:49:\"#/definitions/ElasticsearchDestinationDescription\";s:11:\"description\";s:29:\"The
  destination in Amazon ES.\";}s:32:\"ExtendedS3DestinationDescription\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:46:\"#/definitions/ExtendedS3DestinationDescription\";s:11:\"description\";s:29:\"The
  destination in Amazon S3.\";}s:30:\"RedshiftDestinationDescription\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:44:\"#/definitions/RedshiftDestinationDescription\";s:11:\"description\";s:35:\"The
  destination in Amazon Redshift.\";}s:24:\"S3DestinationDescription\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/S3DestinationDescription\";s:11:\"description\";s:42:\"[Deprecated]
  The destination in Amazon S3.\";}s:28:\"SplunkDestinationDescription\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:42:\"#/definitions/SplunkDestinationDescription\";s:11:\"description\";s:26:\"The
  destination in Splunk.\";}}s:8:\"required\";a:1:{i:0;s:13:\"DestinationId\";}s:4:\"type\";s:6:\"object\";}s:26:\"DestinationDescriptionList\";O:8:\"stdClass\":2:{s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:36:\"#/definitions/DestinationDescription\";}s:4:\"type\";s:5:\"array\";}s:13:\"DestinationId\";O:8:\"stdClass\":3:{s:9:\"maxLength\";i:100;s:9:\"minLength\";i:1;s:4:\"type\";s:6:\"string\";}s:27:\"ElasticsearchBufferingHints\";O:8:\"stdClass\":3:{s:11:\"description\";s:87:\"Describes
  the buffering to perform before delivering data to the Amazon ES destination.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:17:\"IntervalInSeconds\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:53:\"#/definitions/ElasticsearchBufferingIntervalInSeconds\";s:11:\"description\";s:145:\"Buffer
  incoming data for the specified period of time, in seconds, before delivering it
  to the destination. The default value is 300 (5 minutes).\";}s:9:\"SizeInMBs\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:45:\"#/definitions/ElasticsearchBufferingSizeInMBs\";s:11:\"description\";s:362:\"<p>Buffer
  incoming data to the specified size, in MBs, before delivering it to the destination.
  The default value is 5.</p> <p>We recommend setting this parameter to a value greater
  than the amount of data you typically ingest into the delivery stream in 10 seconds.
  For example, if you typically ingest data at 1 MB/sec, the value should be 10 MB
  or higher.</p>\";}}s:4:\"type\";s:6:\"object\";}s:39:\"ElasticsearchBufferingIntervalInSeconds\";O:8:\"stdClass\":3:{s:7:\"maximum\";i:900;s:7:\"minimum\";i:60;s:4:\"type\";s:7:\"integer\";}s:31:\"ElasticsearchBufferingSizeInMBs\";O:8:\"stdClass\":3:{s:7:\"maximum\";i:100;s:7:\"minimum\";i:1;s:4:\"type\";s:7:\"integer\";}s:37:\"ElasticsearchDestinationConfiguration\";O:8:\"stdClass\":4:{s:11:\"description\";s:58:\"Describes
  the configuration of a destination in Amazon ES.\";s:10:\"properties\";O:8:\"stdClass\":11:{s:14:\"BufferingHints\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:41:\"#/definitions/ElasticsearchBufferingHints\";s:11:\"description\";s:122:\"The
  buffering options. If no value is specified, the default values for <code>ElasticsearchBufferingHints</code>
  are used.\";}s:24:\"CloudWatchLoggingOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/CloudWatchLoggingOptions\";s:11:\"description\";s:63:\"The
  Amazon CloudWatch logging options for your delivery stream.\";}s:9:\"DomainARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:36:\"#/definitions/ElasticsearchDomainARN\";s:11:\"description\";s:434:\"The
  ARN of the Amazon ES domain. The IAM role must have permissions for\_<code>DescribeElasticsearchDomain</code>,
  <code>DescribeElasticsearchDomains</code>, and <code>DescribeElasticsearchDomainConfig</code>\_after
  assuming the role specified in <b>RoleARN</b>. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:9:\"IndexName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:36:\"#/definitions/ElasticsearchIndexName\";s:11:\"description\";s:29:\"The
  Elasticsearch index name.\";}s:19:\"IndexRotationPeriod\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:46:\"#/definitions/ElasticsearchIndexRotationPeriod\";s:11:\"description\";s:360:\"The
  Elasticsearch index rotation period. Index rotation appends a timestamp to the <code>IndexName</code>
  to facilitate the expiration of old data. For more information, see <a href=\"http://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#es-index-rotation\">Index
  Rotation for the Amazon ES Destination</a>. The default value is\_<code>OneDay</code>.\";}s:23:\"ProcessingConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/ProcessingConfiguration\";s:11:\"description\";s:34:\"The
  data processing configuration.\";}s:12:\"RetryOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:39:\"#/definitions/ElasticsearchRetryOptions\";s:11:\"description\";s:131:\"The
  retry behavior in case Kinesis Data Firehose is unable to deliver documents to Amazon
  ES. The default value is 300 (5 minutes).\";}s:7:\"RoleARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:21:\"#/definitions/RoleARN\";s:11:\"description\";s:494:\"The
  Amazon Resource Name (ARN) of the IAM role to be assumed by Kinesis Data Firehose
  for calling the Amazon ES Configuration API and for indexing documents. For more
  information, see <a href=\"http://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-s3\">Grant
  Kinesis Data Firehose Access to an Amazon S3 Destination</a> and <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:12:\"S3BackupMode\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:39:\"#/definitions/ElasticsearchS3BackupMode\";s:11:\"description\";s:705:\"Defines
  how documents should be delivered to Amazon S3. When it is set to <code>FailedDocumentsOnly</code>,
  Kinesis Data Firehose writes any documents that could not be indexed to the configured
  Amazon S3 destination, with <code>elasticsearch-failed/</code> appended to the key
  prefix. When set to <code>AllDocuments</code>, Kinesis Data Firehose delivers all
  incoming records to Amazon S3, and also writes failed documents with <code>elasticsearch-failed/</code>
  appended to the prefix. For more information, see <a href=\"http://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#es-s3-backup\">Amazon
  S3 Backup for the Amazon ES Destination</a>. Default value is <code>FailedDocumentsOnly</code>.\";}s:15:\"S3Configuration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:40:\"#/definitions/S3DestinationConfiguration\";s:11:\"description\";s:52:\"The
  configuration for the backup Amazon S3 location.\";}s:8:\"TypeName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:35:\"#/definitions/ElasticsearchTypeName\";s:11:\"description\";s:231:\"The
  Elasticsearch type name. For Elasticsearch 6.x, there can be only one type per index.
  If you try to specify a new type for an existing index that already has another
  type, Kinesis Data Firehose returns an error during run time.\";}}s:8:\"required\";a:5:{i:0;s:7:\"RoleARN\";i:1;s:9:\"DomainARN\";i:2;s:9:\"IndexName\";i:3;s:8:\"TypeName\";i:4;s:15:\"S3Configuration\";}s:4:\"type\";s:6:\"object\";}s:35:\"ElasticsearchDestinationDescription\";O:8:\"stdClass\":3:{s:11:\"description\";s:41:\"The
  destination description in Amazon ES.\";s:10:\"properties\";O:8:\"stdClass\":11:{s:14:\"BufferingHints\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:41:\"#/definitions/ElasticsearchBufferingHints\";s:11:\"description\";s:22:\"The
  buffering options.\";}s:24:\"CloudWatchLoggingOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/CloudWatchLoggingOptions\";s:11:\"description\";s:38:\"The
  Amazon CloudWatch logging options.\";}s:9:\"DomainARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:36:\"#/definitions/ElasticsearchDomainARN\";s:11:\"description\";s:204:\"The
  ARN of the Amazon ES domain. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:9:\"IndexName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:36:\"#/definitions/ElasticsearchIndexName\";s:11:\"description\";s:29:\"The
  Elasticsearch index name.\";}s:19:\"IndexRotationPeriod\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:46:\"#/definitions/ElasticsearchIndexRotationPeriod\";s:11:\"description\";s:39:\"The
  Elasticsearch index rotation period\";}s:23:\"ProcessingConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/ProcessingConfiguration\";s:11:\"description\";s:34:\"The
  data processing configuration.\";}s:12:\"RetryOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:39:\"#/definitions/ElasticsearchRetryOptions\";s:11:\"description\";s:28:\"The
  Amazon ES retry options.\";}s:7:\"RoleARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:21:\"#/definitions/RoleARN\";s:11:\"description\";s:226:\"The
  Amazon Resource Name (ARN) of the AWS credentials. For more information, see <a
  href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:12:\"S3BackupMode\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:39:\"#/definitions/ElasticsearchS3BackupMode\";s:11:\"description\";s:26:\"The
  Amazon S3 backup mode.\";}s:24:\"S3DestinationDescription\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/S3DestinationDescription\";s:11:\"description\";s:26:\"The
  Amazon S3 destination.\";}s:8:\"TypeName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:35:\"#/definitions/ElasticsearchTypeName\";s:11:\"description\";s:28:\"The
  Elasticsearch type name.\";}}s:4:\"type\";s:6:\"object\";}s:30:\"ElasticsearchDestinationUpdate\";O:8:\"stdClass\":3:{s:11:\"description\";s:51:\"Describes
  an update for a destination in Amazon ES.\";s:10:\"properties\";O:8:\"stdClass\":10:{s:14:\"BufferingHints\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:41:\"#/definitions/ElasticsearchBufferingHints\";s:11:\"description\";s:122:\"The
  buffering options. If no value is specified, <code>ElasticsearchBufferingHints</code>
  object default values are used. \";}s:24:\"CloudWatchLoggingOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/CloudWatchLoggingOptions\";s:11:\"description\";s:56:\"The
  CloudWatch logging options for your delivery stream.\";}s:9:\"DomainARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:36:\"#/definitions/ElasticsearchDomainARN\";s:11:\"description\";s:444:\"The
  ARN of the Amazon ES domain. The IAM role must have permissions for\_<code>DescribeElasticsearchDomain</code>,
  <code>DescribeElasticsearchDomains</code>, and <code>DescribeElasticsearchDomainConfig</code>\_after
  assuming the IAM role specified in <code>RoleARN</code>. For more information, see
  <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:9:\"IndexName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:36:\"#/definitions/ElasticsearchIndexName\";s:11:\"description\";s:29:\"The
  Elasticsearch index name.\";}s:19:\"IndexRotationPeriod\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:46:\"#/definitions/ElasticsearchIndexRotationPeriod\";s:11:\"description\";s:352:\"The
  Elasticsearch index rotation period. Index rotation appends a timestamp to <code>IndexName</code>
  to facilitate the expiration of old data. For more information, see <a href=\"http://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#es-index-rotation\">Index
  Rotation for the Amazon ES Destination</a>. Default value is\_<code>OneDay</code>.\";}s:23:\"ProcessingConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/ProcessingConfiguration\";s:11:\"description\";s:34:\"The
  data processing configuration.\";}s:12:\"RetryOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:39:\"#/definitions/ElasticsearchRetryOptions\";s:11:\"description\";s:131:\"The
  retry behavior in case Kinesis Data Firehose is unable to deliver documents to Amazon
  ES. The default value is 300 (5 minutes).\";}s:7:\"RoleARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:21:\"#/definitions/RoleARN\";s:11:\"description\";s:494:\"The
  Amazon Resource Name (ARN) of the IAM role to be assumed by Kinesis Data Firehose
  for calling the Amazon ES Configuration API and for indexing documents. For more
  information, see <a href=\"http://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-s3\">Grant
  Kinesis Data Firehose Access to an Amazon S3 Destination</a> and <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:8:\"S3Update\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:33:\"#/definitions/S3DestinationUpdate\";s:11:\"description\";s:26:\"The
  Amazon S3 destination.\";}s:8:\"TypeName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:35:\"#/definitions/ElasticsearchTypeName\";s:11:\"description\";s:230:\"The
  Elasticsearch type name. For Elasticsearch 6.x, there can be only one type per index.
  If you try to specify a new type for an existing index that already has another
  type, Kinesis Data Firehose returns an error during runtime.\";}}s:4:\"type\";s:6:\"object\";}s:22:\"ElasticsearchDomainARN\";O:8:\"stdClass\":4:{s:9:\"maxLength\";i:512;s:9:\"minLength\";i:1;s:7:\"pattern\";s:6:\"arn:.*\";s:4:\"type\";s:6:\"string\";}s:22:\"ElasticsearchIndexName\";O:8:\"stdClass\":3:{s:9:\"maxLength\";i:80;s:9:\"minLength\";i:1;s:4:\"type\";s:6:\"string\";}s:32:\"ElasticsearchIndexRotationPeriod\";O:8:\"stdClass\":2:{s:4:\"enum\";a:5:{i:0;s:10:\"NoRotation\";i:1;s:7:\"OneHour\";i:2;s:6:\"OneDay\";i:3;s:7:\"OneWeek\";i:4;s:8:\"OneMonth\";}s:4:\"type\";s:6:\"string\";}s:35:\"ElasticsearchRetryDurationInSeconds\";O:8:\"stdClass\":3:{s:7:\"maximum\";i:7200;s:7:\"minimum\";i:0;s:4:\"type\";s:7:\"integer\";}s:25:\"ElasticsearchRetryOptions\";O:8:\"stdClass\":3:{s:11:\"description\";s:100:\"Configures
  retry behavior in case Kinesis Data Firehose is unable to deliver documents to Amazon
  ES.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:17:\"DurationInSeconds\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:49:\"#/definitions/ElasticsearchRetryDurationInSeconds\";s:11:\"description\";s:318:\"After
  an initial failure to deliver to Amazon ES, the total amount of time during which
  Kinesis Data Firehose retries delivery (including the first attempt). After this
  time has elapsed, the failed documents are written to Amazon S3. Default value is
  300 seconds (5 minutes). A value of 0 (zero) results in no retries.\";}}s:4:\"type\";s:6:\"object\";}s:25:\"ElasticsearchS3BackupMode\";O:8:\"stdClass\":2:{s:4:\"enum\";a:2:{i:0;s:19:\"FailedDocumentsOnly\";i:1;s:12:\"AllDocuments\";}s:4:\"type\";s:6:\"string\";}s:21:\"ElasticsearchTypeName\";O:8:\"stdClass\":3:{s:9:\"maxLength\";i:100;s:9:\"minLength\";i:1;s:4:\"type\";s:6:\"string\";}s:23:\"EncryptionConfiguration\";O:8:\"stdClass\":3:{s:11:\"description\";s:56:\"Describes
  the encryption for a destination in Amazon S3.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:19:\"KMSEncryptionConfig\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:33:\"#/definitions/KMSEncryptionConfig\";s:11:\"description\";s:19:\"The
  encryption key.\";}s:18:\"NoEncryptionConfig\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/NoEncryptionConfig\";s:11:\"description\";s:91:\"Specifically
  override existing encryption information to ensure that no encryption is used.\";}}s:4:\"type\";s:6:\"object\";}s:9:\"ErrorCode\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:12:\"ErrorMessage\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:17:\"ErrorOutputPrefix\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:34:\"ExtendedS3DestinationConfiguration\";O:8:\"stdClass\":4:{s:11:\"description\";s:58:\"Describes
  the configuration of a destination in Amazon S3.\";s:10:\"properties\";O:8:\"stdClass\":12:{s:9:\"BucketARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:23:\"#/definitions/BucketARN\";s:11:\"description\";s:197:\"The
  ARN of the S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:14:\"BufferingHints\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/BufferingHints\";s:11:\"description\";s:21:\"The
  buffering option.\";}s:24:\"CloudWatchLoggingOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/CloudWatchLoggingOptions\";s:11:\"description\";s:63:\"The
  Amazon CloudWatch logging options for your delivery stream.\";}s:17:\"CompressionFormat\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/CompressionFormat\";s:11:\"description\";s:78:\"The
  compression format. If no value is specified, the default is UNCOMPRESSED.\";}s:33:\"DataFormatConversionConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:47:\"#/definitions/DataFormatConversionConfiguration\";s:11:\"description\";s:142:\"The
  serializer, deserializer, and schema for converting data from the JSON format to
  the Parquet or ORC format before writing it to Amazon S3.\";}s:23:\"EncryptionConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/EncryptionConfiguration\";s:11:\"description\";s:85:\"The
  encryption configuration. If no value is specified, the default is no encryption.\";}s:17:\"ErrorOutputPrefix\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/ErrorOutputPrefix\";s:11:\"description\";s:159:\"A
  prefix that Kinesis Data Firehose evaluates and adds to failed records before writing
  them to S3. This prefix appears immediately following the bucket name. \";}s:6:\"Prefix\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:20:\"#/definitions/Prefix\";s:11:\"description\";s:455:\"The
  \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered Amazon
  S3 files. You can specify an extra prefix to be added in front of the time format
  prefix. If the prefix ends with a slash, it appears as a folder in the S3 bucket.
  For more information, see <a href=\"http://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#s3-object-name\">Amazon
  S3 Object Name Format</a> in the <i>Amazon Kinesis Data Firehose Developer Guide</i>.\";}s:23:\"ProcessingConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/ProcessingConfiguration\";s:11:\"description\";s:34:\"The
  data processing configuration.\";}s:7:\"RoleARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:21:\"#/definitions/RoleARN\";s:11:\"description\";s:226:\"The
  Amazon Resource Name (ARN) of the AWS credentials. For more information, see <a
  href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:21:\"S3BackupConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:40:\"#/definitions/S3DestinationConfiguration\";s:11:\"description\";s:42:\"The
  configuration for backup in Amazon S3.\";}s:12:\"S3BackupMode\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:26:\"#/definitions/S3BackupMode\";s:11:\"description\";s:26:\"The
  Amazon S3 backup mode.\";}}s:8:\"required\";a:2:{i:0;s:7:\"RoleARN\";i:1;s:9:\"BucketARN\";}s:4:\"type\";s:6:\"object\";}s:32:\"ExtendedS3DestinationDescription\";O:8:\"stdClass\":4:{s:11:\"description\";s:37:\"Describes
  a destination in Amazon S3.\";s:10:\"properties\";O:8:\"stdClass\":12:{s:9:\"BucketARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:23:\"#/definitions/BucketARN\";s:11:\"description\";s:197:\"The
  ARN of the S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:14:\"BufferingHints\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/BufferingHints\";s:11:\"description\";s:21:\"The
  buffering option.\";}s:24:\"CloudWatchLoggingOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/CloudWatchLoggingOptions\";s:11:\"description\";s:63:\"The
  Amazon CloudWatch logging options for your delivery stream.\";}s:17:\"CompressionFormat\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/CompressionFormat\";s:11:\"description\";s:91:\"The
  compression format. If no value is specified, the default is <code>UNCOMPRESSED</code>.\";}s:33:\"DataFormatConversionConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:47:\"#/definitions/DataFormatConversionConfiguration\";s:11:\"description\";s:142:\"The
  serializer, deserializer, and schema for converting data from the JSON format to
  the Parquet or ORC format before writing it to Amazon S3.\";}s:23:\"EncryptionConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/EncryptionConfiguration\";s:11:\"description\";s:85:\"The
  encryption configuration. If no value is specified, the default is no encryption.\";}s:17:\"ErrorOutputPrefix\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/ErrorOutputPrefix\";s:11:\"description\";s:158:\"A
  prefix that Kinesis Data Firehose evaluates and adds to failed records before writing
  them to S3. This prefix appears immediately following the bucket name.\";}s:6:\"Prefix\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:20:\"#/definitions/Prefix\";s:11:\"description\";s:455:\"The
  \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered Amazon
  S3 files. You can specify an extra prefix to be added in front of the time format
  prefix. If the prefix ends with a slash, it appears as a folder in the S3 bucket.
  For more information, see <a href=\"http://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#s3-object-name\">Amazon
  S3 Object Name Format</a> in the <i>Amazon Kinesis Data Firehose Developer Guide</i>.\";}s:23:\"ProcessingConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/ProcessingConfiguration\";s:11:\"description\";s:34:\"The
  data processing configuration.\";}s:7:\"RoleARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:21:\"#/definitions/RoleARN\";s:11:\"description\";s:226:\"The
  Amazon Resource Name (ARN) of the AWS credentials. For more information, see <a
  href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:19:\"S3BackupDescription\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/S3DestinationDescription\";s:11:\"description\";s:42:\"The
  configuration for backup in Amazon S3.\";}s:12:\"S3BackupMode\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:26:\"#/definitions/S3BackupMode\";s:11:\"description\";s:26:\"The
  Amazon S3 backup mode.\";}}s:8:\"required\";a:5:{i:0;s:7:\"RoleARN\";i:1;s:9:\"BucketARN\";i:2;s:14:\"BufferingHints\";i:3;s:17:\"CompressionFormat\";i:4;s:23:\"EncryptionConfiguration\";}s:4:\"type\";s:6:\"object\";}s:27:\"ExtendedS3DestinationUpdate\";O:8:\"stdClass\":3:{s:11:\"description\";s:51:\"Describes
  an update for a destination in Amazon S3.\";s:10:\"properties\";O:8:\"stdClass\":12:{s:9:\"BucketARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:23:\"#/definitions/BucketARN\";s:11:\"description\";s:197:\"The
  ARN of the S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:14:\"BufferingHints\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/BufferingHints\";s:11:\"description\";s:21:\"The
  buffering option.\";}s:24:\"CloudWatchLoggingOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/CloudWatchLoggingOptions\";s:11:\"description\";s:63:\"The
  Amazon CloudWatch logging options for your delivery stream.\";}s:17:\"CompressionFormat\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/CompressionFormat\";s:11:\"description\";s:92:\"The
  compression format. If no value is specified, the default is <code>UNCOMPRESSED</code>.
  \";}s:33:\"DataFormatConversionConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:47:\"#/definitions/DataFormatConversionConfiguration\";s:11:\"description\";s:142:\"The
  serializer, deserializer, and schema for converting data from the JSON format to
  the Parquet or ORC format before writing it to Amazon S3.\";}s:23:\"EncryptionConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/EncryptionConfiguration\";s:11:\"description\";s:85:\"The
  encryption configuration. If no value is specified, the default is no encryption.\";}s:17:\"ErrorOutputPrefix\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/ErrorOutputPrefix\";s:11:\"description\";s:158:\"A
  prefix that Kinesis Data Firehose evaluates and adds to failed records before writing
  them to S3. This prefix appears immediately following the bucket name.\";}s:6:\"Prefix\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:20:\"#/definitions/Prefix\";s:11:\"description\";s:455:\"The
  \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered Amazon
  S3 files. You can specify an extra prefix to be added in front of the time format
  prefix. If the prefix ends with a slash, it appears as a folder in the S3 bucket.
  For more information, see <a href=\"http://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#s3-object-name\">Amazon
  S3 Object Name Format</a> in the <i>Amazon Kinesis Data Firehose Developer Guide</i>.\";}s:23:\"ProcessingConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/ProcessingConfiguration\";s:11:\"description\";s:34:\"The
  data processing configuration.\";}s:7:\"RoleARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:21:\"#/definitions/RoleARN\";s:11:\"description\";s:226:\"The
  Amazon Resource Name (ARN) of the AWS credentials. For more information, see <a
  href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:12:\"S3BackupMode\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:26:\"#/definitions/S3BackupMode\";s:11:\"description\";s:42:\"Enables
  or disables Amazon S3 backup mode.\";}s:14:\"S3BackupUpdate\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:33:\"#/definitions/S3DestinationUpdate\";s:11:\"description\";s:37:\"The
  Amazon S3 destination for backup.\";}}s:4:\"type\";s:6:\"object\";}s:33:\"HECAcknowledgmentTimeoutInSeconds\";O:8:\"stdClass\":3:{s:7:\"maximum\";i:600;s:7:\"minimum\";i:180;s:4:\"type\";s:7:\"integer\";}s:11:\"HECEndpoint\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:15:\"HECEndpointType\";O:8:\"stdClass\":2:{s:4:\"enum\";a:2:{i:0;s:3:\"Raw\";i:1;s:5:\"Event\";}s:4:\"type\";s:6:\"string\";}s:8:\"HECToken\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:13:\"HiveJsonSerDe\";O:8:\"stdClass\":3:{s:11:\"description\";s:346:\"The
  native Hive / HCatalog JsonSerDe. Used by Kinesis Data Firehose for deserializing
  data, which means converting it from the JSON format in preparation for serializing
  it to the Parquet or ORC format. This is one of two deserializers you can choose,
  depending on which one offers the functionality you need. The other option is the
  OpenX SerDe.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:16:\"TimestampFormats\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:35:\"#/definitions/ListOfNonEmptyStrings\";s:11:\"description\";s:577:\"Indicates
  how you want Kinesis Data Firehose to parse the date and timestamps that may be
  present in your input data JSON. To specify these format strings, follow the pattern
  syntax of JodaTime's DateTimeFormat format strings. For more information, see <a
  href=\"https://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html\">Class
  DateTimeFormat</a>. You can also use the special value <code>millis</code> to parse
  timestamps in epoch milliseconds. If you don't specify a format, Kinesis Data Firehose
  uses <code>java.sql.Timestamp::valueOf</code> by default.\";}}s:4:\"type\";s:6:\"object\";}s:24:\"InputFormatConfiguration\";O:8:\"stdClass\":3:{s:11:\"description\";s:83:\"Specifies
  the deserializer you want to use to convert the format of the input data.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:12:\"Deserializer\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:26:\"#/definitions/Deserializer\";s:11:\"description\";s:164:\"Specifies
  which deserializer to use. You can choose either the Apache Hive JSON SerDe or the
  OpenX JSON SerDe. If both are non-null, the server rejects the request.\";}}s:4:\"type\";s:6:\"object\";}s:17:\"IntervalInSeconds\";O:8:\"stdClass\":3:{s:7:\"maximum\";i:900;s:7:\"minimum\";i:60;s:4:\"type\";s:7:\"integer\";}s:24:\"InvalidArgumentException\";O:8:\"stdClass\":0:{}s:19:\"KMSEncryptionConfig\";O:8:\"stdClass\":4:{s:11:\"description\";s:59:\"Describes
  an encryption key for a destination in Amazon S3.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:12:\"AWSKMSKeyARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:26:\"#/definitions/AWSKMSKeyARN\";s:11:\"description\";s:297:\"The
  Amazon Resource Name (ARN) of the encryption key. Must belong to the same AWS Region
  as the destination Amazon S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}}s:8:\"required\";a:1:{i:0;s:12:\"AWSKMSKeyARN\";}s:4:\"type\";s:6:\"object\";}s:16:\"KinesisStreamARN\";O:8:\"stdClass\":4:{s:9:\"maxLength\";i:512;s:9:\"minLength\";i:1;s:7:\"pattern\";s:6:\"arn:.*\";s:4:\"type\";s:6:\"string\";}s:32:\"KinesisStreamSourceConfiguration\";O:8:\"stdClass\":4:{s:11:\"description\";s:116:\"The
  stream and role Amazon Resource Names (ARNs) for a Kinesis data stream used as the
  source for a delivery stream.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:16:\"KinesisStreamARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:30:\"#/definitions/KinesisStreamARN\";s:11:\"description\";s:224:\"The
  ARN of the source Kinesis data stream. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-kinesis-streams\">Amazon
  Kinesis Data Streams ARN Format</a>.\";}s:7:\"RoleARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:21:\"#/definitions/RoleARN\";s:11:\"description\";s:258:\"The
  ARN of the role that provides access to the source Kinesis data stream. For more
  information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-iam\">AWS
  Identity and Access Management (IAM) ARN Format</a>.\";}}s:8:\"required\";a:2:{i:0;s:16:\"KinesisStreamARN\";i:1;s:7:\"RoleARN\";}s:4:\"type\";s:6:\"object\";}s:30:\"KinesisStreamSourceDescription\";O:8:\"stdClass\":3:{s:11:\"description\";s:99:\"Details
  about a Kinesis data stream used as the source for a Kinesis Data Firehose delivery
  stream.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:22:\"DeliveryStartTimestamp\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:36:\"#/definitions/DeliveryStartTimestamp\";s:11:\"description\";s:106:\"Kinesis
  Data Firehose starts retrieving records from the Kinesis data stream starting with
  this timestamp.\";}s:16:\"KinesisStreamARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:30:\"#/definitions/KinesisStreamARN\";s:11:\"description\";s:247:\"The
  Amazon Resource Name (ARN) of the source Kinesis data stream. For more information,
  see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-kinesis-streams\">Amazon
  Kinesis Data Streams ARN Format</a>.\";}s:7:\"RoleARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:21:\"#/definitions/RoleARN\";s:11:\"description\";s:242:\"The
  ARN of the role used by the source Kinesis data stream. For more information, see
  <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-iam\">AWS
  Identity and Access Management (IAM) ARN Format</a>.\";}}s:4:\"type\";s:6:\"object\";}s:22:\"LimitExceededException\";O:8:\"stdClass\":0:{}s:24:\"ListDeliveryStreamsInput\";O:8:\"stdClass\":2:{s:10:\"properties\";O:8:\"stdClass\":3:{s:18:\"DeliveryStreamType\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/DeliveryStreamType\";s:11:\"description\";s:410:\"<p>The
  delivery stream type. This can be one of the following values:</p> <ul> <li> <p>
  <code>DirectPut</code>: Provider applications access the delivery stream directly.</p>
  </li> <li> <p> <code>KinesisStreamAsSource</code>: The delivery stream uses a Kinesis
  data stream as a source.</p> </li> </ul> <p>This parameter is optional. If this
  parameter is omitted, delivery streams of all types are returned.</p>\";}s:32:\"ExclusiveStartDeliveryStreamName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/DeliveryStreamName\";s:11:\"description\";s:243:\"The
  list of delivery streams returned by this call to <code>ListDeliveryStreams</code>
  will start with the delivery stream whose name comes alphabetically immediately
  after the name you specify in <code>ExclusiveStartDeliveryStreamName</code>.\";}s:5:\"Limit\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:43:\"#/definitions/ListDeliveryStreamsInputLimit\";s:11:\"description\";s:72:\"The
  maximum number of delivery streams to list. The default value is 10.\";}}s:4:\"type\";s:6:\"object\";}s:29:\"ListDeliveryStreamsInputLimit\";O:8:\"stdClass\":3:{s:7:\"maximum\";i:10000;s:7:\"minimum\";i:1;s:4:\"type\";s:7:\"integer\";}s:25:\"ListDeliveryStreamsOutput\";O:8:\"stdClass\":3:{s:10:\"properties\";O:8:\"stdClass\":2:{s:19:\"DeliveryStreamNames\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:36:\"#/definitions/DeliveryStreamNameList\";s:11:\"description\";s:34:\"The
  names of the delivery streams.\";}s:22:\"HasMoreDeliveryStreams\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/BooleanObject\";s:11:\"description\";s:68:\"Indicates
  whether there are more delivery streams available to list.\";}}s:8:\"required\";a:2:{i:0;s:19:\"DeliveryStreamNames\";i:1;s:22:\"HasMoreDeliveryStreams\";}s:4:\"type\";s:6:\"object\";}s:21:\"ListOfNonEmptyStrings\";O:8:\"stdClass\":2:{s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:28:\"#/definitions/NonEmptyString\";}s:4:\"type\";s:5:\"array\";}s:38:\"ListOfNonEmptyStringsWithoutWhitespace\";O:8:\"stdClass\":2:{s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:45:\"#/definitions/NonEmptyStringWithoutWhitespace\";}s:4:\"type\";s:5:\"array\";}s:30:\"ListTagsForDeliveryStreamInput\";O:8:\"stdClass\":3:{s:10:\"properties\";O:8:\"stdClass\":3:{s:18:\"DeliveryStreamName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/DeliveryStreamName\";s:11:\"description\";s:60:\"The
  name of the delivery stream whose tags you want to list.\";}s:20:\"ExclusiveStartTagKey\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:20:\"#/definitions/TagKey\";s:11:\"description\";s:190:\"The
  key to use as the starting point for the list of tags. If you set this parameter,
  <code>ListTagsForDeliveryStream</code> gets all tags that occur after <code>ExclusiveStartTagKey</code>.\";}s:5:\"Limit\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:49:\"#/definitions/ListTagsForDeliveryStreamInputLimit\";s:11:\"description\";s:286:\"The
  number of tags to return. If this number is less than the total number of tags associated
  with the delivery stream, <code>HasMoreTags</code> is set to <code>true</code> in
  the response. To list additional tags, set <code>ExclusiveStartTagKey</code> to
  the last key in the response. \";}}s:8:\"required\";a:1:{i:0;s:18:\"DeliveryStreamName\";}s:4:\"type\";s:6:\"object\";}s:35:\"ListTagsForDeliveryStreamInputLimit\";O:8:\"stdClass\":3:{s:7:\"maximum\";i:50;s:7:\"minimum\";i:1;s:4:\"type\";s:7:\"integer\";}s:31:\"ListTagsForDeliveryStreamOutput\";O:8:\"stdClass\":3:{s:10:\"properties\";O:8:\"stdClass\":2:{s:11:\"HasMoreTags\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/BooleanObject\";s:11:\"description\";s:227:\"If
  this is <code>true</code> in the response, more tags are available. To list the
  remaining tags, set <code>ExclusiveStartTagKey</code> to the key of the last tag
  returned and call <code>ListTagsForDeliveryStream</code> again.\";}s:4:\"Tags\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:52:\"#/definitions/ListTagsForDeliveryStreamOutputTagList\";s:11:\"description\";s:175:\"A
  list of tags associated with <code>DeliveryStreamName</code>, starting with the
  first tag after <code>ExclusiveStartTagKey</code> and up to the specified <code>Limit</code>.\";}}s:8:\"required\";a:2:{i:0;s:4:\"Tags\";i:1;s:11:\"HasMoreTags\";}s:4:\"type\";s:6:\"object\";}s:38:\"ListTagsForDeliveryStreamOutputTagList\";O:8:\"stdClass\":4:{s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:17:\"#/definitions/Tag\";}s:8:\"maxItems\";i:50;s:8:\"minItems\";i:0;s:4:\"type\";s:5:\"array\";}s:12:\"LogGroupName\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:13:\"LogStreamName\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:18:\"NoEncryptionConfig\";O:8:\"stdClass\":2:{s:4:\"enum\";a:1:{i:0;s:12:\"NoEncryption\";}s:4:\"type\";s:6:\"string\";}s:14:\"NonEmptyString\";O:8:\"stdClass\":2:{s:7:\"pattern\";s:11:\"^(?!\\s*$).+\";s:4:\"type\";s:6:\"string\";}s:31:\"NonEmptyStringWithoutWhitespace\";O:8:\"stdClass\":2:{s:7:\"pattern\";s:5:\"^\\S+$\";s:4:\"type\";s:6:\"string\";}s:24:\"NonNegativeIntegerObject\";O:8:\"stdClass\":2:{s:7:\"minimum\";i:0;s:4:\"type\";s:7:\"integer\";}s:14:\"OpenXJsonSerDe\";O:8:\"stdClass\":3:{s:11:\"description\";s:346:\"The
  OpenX SerDe. Used by Kinesis Data Firehose for deserializing data, which means converting
  it from the JSON format in preparation for serializing it to the Parquet or ORC
  format. This is one of two deserializers you can choose, depending on which one
  offers the functionality you need. The other option is the native Hive / HCatalog
  JsonSerDe.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:15:\"CaseInsensitive\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/BooleanObject\";s:11:\"description\";s:133:\"When
  set to <code>true</code>, which is the default, Kinesis Data Firehose converts JSON
  keys to lowercase before deserializing them.\";}s:23:\"ColumnToJsonKeyMappings\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/ColumnToJsonKeyMappings\";s:11:\"description\";s:354:\"Maps
  column names to JSON keys that aren't identical to the column names. This is useful
  when the JSON contains keys that are Hive keywords. For example, <code>timestamp</code>
  is a Hive keyword. If you have a JSON key named <code>timestamp</code>, set this
  parameter to <code>{\"ts\": \"timestamp\"}</code> to map this key to a column named
  <code>ts</code>.\";}s:34:\"ConvertDotsInJsonKeysToUnderscores\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/BooleanObject\";s:11:\"description\";s:403:\"<p>When
  set to <code>true</code>, specifies that the names of the keys include dots and
  that you want Kinesis Data Firehose to replace them with underscores. This is useful
  because Apache Hive does not allow dots in column names. For example, if the JSON
  contains a key whose name is \"a.b\", you can define the column name to be \"a_b\"
  when using this option.</p> <p>The default is <code>false</code>.</p>\";}}s:4:\"type\";s:6:\"object\";}s:14:\"OrcCompression\";O:8:\"stdClass\":2:{s:4:\"enum\";a:3:{i:0;s:4:\"NONE\";i:1;s:4:\"ZLIB\";i:2;s:6:\"SNAPPY\";}s:4:\"type\";s:6:\"string\";}s:16:\"OrcFormatVersion\";O:8:\"stdClass\":2:{s:4:\"enum\";a:2:{i:0;s:5:\"V0_11\";i:1;s:5:\"V0_12\";}s:4:\"type\";s:6:\"string\";}s:17:\"OrcRowIndexStride\";O:8:\"stdClass\":2:{s:7:\"minimum\";i:1000;s:4:\"type\";s:7:\"integer\";}s:8:\"OrcSerDe\";O:8:\"stdClass\":3:{s:11:\"description\";s:170:\"A
  serializer to use for converting data to the ORC format before storing it in Amazon
  S3. For more information, see <a href=\"https://orc.apache.org/docs/\">Apache ORC</a>.\";s:10:\"properties\";O:8:\"stdClass\":10:{s:14:\"BlockSizeBytes\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/BlockSizeBytes\";s:11:\"description\";s:253:\"The
  Hadoop Distributed File System (HDFS) block size. This is useful if you intend to
  copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and
  the minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.\";}s:18:\"BloomFilterColumns\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:52:\"#/definitions/ListOfNonEmptyStringsWithoutWhitespace\";s:11:\"description\";s:116:\"The
  column names for which you want Kinesis Data Firehose to create bloom filters. The
  default is <code>null</code>.\";}s:35:\"BloomFilterFalsePositiveProbability\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:24:\"#/definitions/Proportion\";s:11:\"description\";s:165:\"The
  Bloom filter false positive probability (FPP). The lower the FPP, the bigger the
  Bloom filter. The default value is 0.05, the minimum is 0, and the maximum is 1.\";}s:11:\"Compression\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/OrcCompression\";s:11:\"description\";s:81:\"The
  compression code to use over data blocks. The default is <code>SNAPPY</code>.\";}s:22:\"DictionaryKeyThreshold\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:24:\"#/definitions/Proportion\";s:11:\"description\";s:247:\"Represents
  the fraction of the total number of non-null rows. To turn off dictionary encoding,
  set this fraction to a number that is less than the number of distinct keys in a
  dictionary. To always use dictionary encoding, set this threshold to 1.\";}s:13:\"EnablePadding\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/BooleanObject\";s:11:\"description\";s:227:\"Set
  this to <code>true</code> to indicate that you want stripes to be padded to the
  HDFS block boundaries. This is useful if you intend to copy the data from Amazon
  S3 to HDFS before querying. The default is <code>false</code>.\";}s:13:\"FormatVersion\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:30:\"#/definitions/OrcFormatVersion\";s:11:\"description\";s:135:\"The
  version of the file to write. The possible values are <code>V0_11</code> and <code>V0_12</code>.
  The default is <code>V0_12</code>.\";}s:16:\"PaddingTolerance\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:24:\"#/definitions/Proportion\";s:11:\"description\";s:723:\"<p>A
  number between 0 and 1 that defines the tolerance for block padding as a decimal
  fraction of stripe size. The default value is 0.05, which means 5 percent of stripe
  size.</p> <p>For the default values of 64 MiB ORC stripes and 256 MiB HDFS blocks,
  the default block padding tolerance of 5 percent reserves a maximum of 3.2 MiB for
  padding within the 256 MiB block. In such a case, if the available size within the
  block is more than 3.2 MiB, a new, smaller stripe is inserted to fit within that
  space. This ensures that no stripe crosses block boundaries and causes remote reads
  within a node-local task.</p> <p>Kinesis Data Firehose ignores this parameter when
  <a>OrcSerDe$EnablePadding</a> is <code>false</code>.</p>\";}s:14:\"RowIndexStride\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/OrcRowIndexStride\";s:11:\"description\";s:89:\"The
  number of rows between index entries. The default is 10,000 and the minimum is 1,000.\";}s:15:\"StripeSizeBytes\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/OrcStripeSizeBytes\";s:11:\"description\";s:83:\"The
  number of bytes in each stripe. The default is 64 MiB and the minimum is 8 MiB.\";}}s:4:\"type\";s:6:\"object\";}s:18:\"OrcStripeSizeBytes\";O:8:\"stdClass\":2:{s:7:\"minimum\";i:8388608;s:4:\"type\";s:7:\"integer\";}s:25:\"OutputFormatConfiguration\";O:8:\"stdClass\":3:{s:11:\"description\";s:136:\"Specifies
  the serializer that you want Kinesis Data Firehose to use to convert the format
  of your data before it writes it to Amazon S3.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:10:\"Serializer\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:24:\"#/definitions/Serializer\";s:11:\"description\";s:146:\"Specifies
  which serializer to use. You can choose either the ORC SerDe or the Parquet SerDe.
  If both are non-null, the server rejects the request.\";}}s:4:\"type\";s:6:\"object\";}s:18:\"ParquetCompression\";O:8:\"stdClass\":2:{s:4:\"enum\";a:3:{i:0;s:12:\"UNCOMPRESSED\";i:1;s:4:\"GZIP\";i:2;s:6:\"SNAPPY\";}s:4:\"type\";s:6:\"string\";}s:20:\"ParquetPageSizeBytes\";O:8:\"stdClass\":2:{s:7:\"minimum\";i:65536;s:4:\"type\";s:7:\"integer\";}s:12:\"ParquetSerDe\";O:8:\"stdClass\":3:{s:11:\"description\";s:198:\"A
  serializer to use for converting data to the Parquet format before storing it in
  Amazon S3. For more information, see <a href=\"https://parquet.apache.org/documentation/latest/\">Apache
  Parquet</a>.\";s:10:\"properties\";O:8:\"stdClass\":6:{s:14:\"BlockSizeBytes\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/BlockSizeBytes\";s:11:\"description\";s:253:\"The
  Hadoop Distributed File System (HDFS) block size. This is useful if you intend to
  copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and
  the minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.\";}s:11:\"Compression\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/ParquetCompression\";s:11:\"description\";s:318:\"The
  compression code to use over data blocks. The possible values are <code>UNCOMPRESSED</code>,
  <code>SNAPPY</code>, and <code>GZIP</code>, with the default being <code>SNAPPY</code>.
  Use <code>SNAPPY</code> for higher decompression speed. Use <code>GZIP</code> if
  the compression ration is more important than speed.\";}s:27:\"EnableDictionaryCompression\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/BooleanObject\";s:11:\"description\";s:51:\"Indicates
  whether to enable dictionary compression.\";}s:15:\"MaxPaddingBytes\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/NonNegativeIntegerObject\";s:11:\"description\";s:143:\"The
  maximum amount of padding to apply. This is useful if you intend to copy the data
  from Amazon S3 to HDFS before querying. The default is 0.\";}s:13:\"PageSizeBytes\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:34:\"#/definitions/ParquetPageSizeBytes\";s:11:\"description\";s:197:\"The
  Parquet page size. Column chunks are divided into pages. A page is conceptually
  an indivisible unit (in terms of compression and encoding). The minimum value is
  64 KiB and the default is 1 MiB.\";}s:13:\"WriterVersion\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:34:\"#/definitions/ParquetWriterVersion\";s:11:\"description\";s:139:\"Indicates
  the version of row format to output. The possible values are <code>V1</code> and
  <code>V2</code>. The default is <code>V1</code>.\";}}s:4:\"type\";s:6:\"object\";}s:20:\"ParquetWriterVersion\";O:8:\"stdClass\":2:{s:4:\"enum\";a:2:{i:0;s:2:\"V1\";i:1;s:2:\"V2\";}s:4:\"type\";s:6:\"string\";}s:8:\"Password\";O:8:\"stdClass\":3:{s:6:\"format\";s:8:\"password\";s:9:\"minLength\";i:6;s:4:\"type\";s:6:\"string\";}s:6:\"Prefix\";O:8:\"stdClass\":1:{s:4:\"type\";s:6:\"string\";}s:23:\"ProcessingConfiguration\";O:8:\"stdClass\":3:{s:11:\"description\";s:42:\"Describes
  a data processing configuration.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:7:\"Enabled\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/BooleanObject\";s:11:\"description\";s:36:\"Enables
  or disables data processing.\";}s:10:\"Processors\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/ProcessorList\";s:11:\"description\";s:20:\"The
  data processors.\";}}s:4:\"type\";s:6:\"object\";}s:9:\"Processor\";O:8:\"stdClass\":4:{s:11:\"description\";s:27:\"Describes
  a data processor.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:10:\"Parameters\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:36:\"#/definitions/ProcessorParameterList\";s:11:\"description\";s:25:\"The
  processor parameters.\";}s:4:\"Type\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/ProcessorType\";s:11:\"description\";s:22:\"The
  type of processor.\";}}s:8:\"required\";a:1:{i:0;s:4:\"Type\";}s:4:\"type\";s:6:\"object\";}s:13:\"ProcessorList\";O:8:\"stdClass\":2:{s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:23:\"#/definitions/Processor\";}s:4:\"type\";s:5:\"array\";}s:18:\"ProcessorParameter\";O:8:\"stdClass\":4:{s:11:\"description\";s:34:\"Describes
  the processor parameter.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:13:\"ParameterName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:36:\"#/definitions/ProcessorParameterName\";s:11:\"description\";s:26:\"The
  name of the parameter.\";}s:14:\"ParameterValue\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/ProcessorParameterValue\";s:11:\"description\";s:20:\"The
  parameter value.\";}}s:8:\"required\";a:2:{i:0;s:13:\"ParameterName\";i:1;s:14:\"ParameterValue\";}s:4:\"type\";s:6:\"object\";}s:22:\"ProcessorParameterList\";O:8:\"stdClass\":2:{s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:32:\"#/definitions/ProcessorParameter\";}s:4:\"type\";s:5:\"array\";}s:22:\"ProcessorParameterName\";O:8:\"stdClass\":2:{s:4:\"enum\";a:5:{i:0;s:9:\"LambdaArn\";i:1;s:15:\"NumberOfRetries\";i:2;s:7:\"RoleArn\";i:3;s:15:\"BufferSizeInMBs\";i:4;s:23:\"BufferIntervalInSeconds\";}s:4:\"type\";s:6:\"string\";}s:23:\"ProcessorParameterValue\";O:8:\"stdClass\":3:{s:9:\"maxLength\";i:512;s:9:\"minLength\";i:1;s:4:\"type\";s:6:\"string\";}s:13:\"ProcessorType\";O:8:\"stdClass\":2:{s:4:\"enum\";a:1:{i:0;s:6:\"Lambda\";}s:4:\"type\";s:6:\"string\";}s:10:\"Proportion\";O:8:\"stdClass\":4:{s:6:\"format\";s:6:\"double\";s:7:\"maximum\";i:1;s:7:\"minimum\";i:0;s:4:\"type\";s:6:\"number\";}s:19:\"PutRecordBatchInput\";O:8:\"stdClass\":3:{s:10:\"properties\";O:8:\"stdClass\":2:{s:18:\"DeliveryStreamName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/DeliveryStreamName\";s:11:\"description\";s:32:\"The
  name of the delivery stream.\";}s:7:\"Records\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:44:\"#/definitions/PutRecordBatchRequestEntryList\";s:11:\"description\";s:20:\"One
  or more records.\";}}s:8:\"required\";a:2:{i:0;s:18:\"DeliveryStreamName\";i:1;s:7:\"Records\";}s:4:\"type\";s:6:\"object\";}s:20:\"PutRecordBatchOutput\";O:8:\"stdClass\":3:{s:10:\"properties\";O:8:\"stdClass\":3:{s:9:\"Encrypted\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/BooleanObject\";s:11:\"description\";s:81:\"Indicates
  whether server-side encryption (SSE) was enabled during this operation.\";}s:14:\"FailedPutCount\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/NonNegativeIntegerObject\";s:11:\"description\";s:239:\"The
  number of records that might have failed processing. This number might be greater
  than 0 even if the <a>PutRecordBatch</a> call succeeds. Check <code>FailedPutCount</code>
  to determine whether there are records that you need to resend.\";}s:16:\"RequestResponses\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:45:\"#/definitions/PutRecordBatchResponseEntryList\";s:11:\"description\";s:121:\"The
  results array. For each record, the index of the response element is the same as
  the index used in the request array.\";}}s:8:\"required\";a:2:{i:0;s:14:\"FailedPutCount\";i:1;s:16:\"RequestResponses\";}s:4:\"type\";s:6:\"object\";}s:30:\"PutRecordBatchRequestEntryList\";O:8:\"stdClass\":4:{s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:20:\"#/definitions/Record\";}s:8:\"maxItems\";i:500;s:8:\"minItems\";i:1;s:4:\"type\";s:5:\"array\";}s:27:\"PutRecordBatchResponseEntry\";O:8:\"stdClass\":3:{s:11:\"description\";s:281:\"Contains
  the result for an individual record from a <a>PutRecordBatch</a> request. If the
  record is successfully added to your delivery stream, it receives a record ID. If
  the record fails to be added to your delivery stream, the result includes an error
  code and an error message.\";s:10:\"properties\";O:8:\"stdClass\":3:{s:9:\"ErrorCode\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:23:\"#/definitions/ErrorCode\";s:11:\"description\";s:47:\"The
  error code for an individual record result.\";}s:12:\"ErrorMessage\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:26:\"#/definitions/ErrorMessage\";s:11:\"description\";s:50:\"The
  error message for an individual record result.\";}s:8:\"RecordId\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:33:\"#/definitions/PutResponseRecordId\";s:11:\"description\";s:21:\"The
  ID of the record.\";}}s:4:\"type\";s:6:\"object\";}s:31:\"PutRecordBatchResponseEntryList\";O:8:\"stdClass\":4:{s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:41:\"#/definitions/PutRecordBatchResponseEntry\";}s:8:\"maxItems\";i:500;s:8:\"minItems\";i:1;s:4:\"type\";s:5:\"array\";}s:14:\"PutRecordInput\";O:8:\"stdClass\":3:{s:10:\"properties\";O:8:\"stdClass\":2:{s:18:\"DeliveryStreamName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/DeliveryStreamName\";s:11:\"description\";s:32:\"The
  name of the delivery stream.\";}s:6:\"Record\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:20:\"#/definitions/Record\";s:11:\"description\";s:11:\"The
  record.\";}}s:8:\"required\";a:2:{i:0;s:18:\"DeliveryStreamName\";i:1;s:6:\"Record\";}s:4:\"type\";s:6:\"object\";}s:15:\"PutRecordOutput\";O:8:\"stdClass\":3:{s:10:\"properties\";O:8:\"stdClass\":2:{s:9:\"Encrypted\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/BooleanObject\";s:11:\"description\";s:81:\"Indicates
  whether server-side encryption (SSE) was enabled during this operation.\";}s:8:\"RecordId\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:33:\"#/definitions/PutResponseRecordId\";s:11:\"description\";s:21:\"The
  ID of the record.\";}}s:8:\"required\";a:1:{i:0;s:8:\"RecordId\";}s:4:\"type\";s:6:\"object\";}s:19:\"PutResponseRecordId\";O:8:\"stdClass\":2:{s:9:\"minLength\";i:1;s:4:\"type\";s:6:\"string\";}s:6:\"Record\";O:8:\"stdClass\":4:{s:11:\"description\";s:38:\"The
  unit of data in a delivery stream.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:4:\"Data\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:18:\"#/definitions/Data\";s:11:\"description\";s:140:\"The
  data blob, which is base64-encoded when the blob is serialized. The maximum size
  of the data blob, before base64-encoding, is 1,000 KiB.\";}}s:8:\"required\";a:1:{i:0;s:4:\"Data\";}s:4:\"type\";s:6:\"object\";}s:32:\"RedshiftDestinationConfiguration\";O:8:\"stdClass\":4:{s:11:\"description\";s:64:\"Describes
  the configuration of a destination in Amazon Redshift.\";s:10:\"properties\";O:8:\"stdClass\":11:{s:24:\"CloudWatchLoggingOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/CloudWatchLoggingOptions\";s:11:\"description\";s:56:\"The
  CloudWatch logging options for your delivery stream.\";}s:14:\"ClusterJDBCURL\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/ClusterJDBCURL\";s:11:\"description\";s:31:\"The
  database connection string.\";}s:11:\"CopyCommand\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:25:\"#/definitions/CopyCommand\";s:11:\"description\";s:30:\"The
  <code>COPY</code> command.\";}s:8:\"Password\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:22:\"#/definitions/Password\";s:11:\"description\";s:18:\"The
  user password.\";}s:23:\"ProcessingConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/ProcessingConfiguration\";s:11:\"description\";s:34:\"The
  data processing configuration.\";}s:12:\"RetryOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:34:\"#/definitions/RedshiftRetryOptions\";s:11:\"description\";s:135:\"The
  retry behavior in case Kinesis Data Firehose is unable to deliver documents to Amazon
  Redshift. Default value is 3600 (60 minutes).\";}s:7:\"RoleARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:21:\"#/definitions/RoleARN\";s:11:\"description\";s:226:\"The
  Amazon Resource Name (ARN) of the AWS credentials. For more information, see <a
  href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:21:\"S3BackupConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:40:\"#/definitions/S3DestinationConfiguration\";s:11:\"description\";s:42:\"The
  configuration for backup in Amazon S3.\";}s:12:\"S3BackupMode\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:34:\"#/definitions/RedshiftS3BackupMode\";s:11:\"description\";s:26:\"The
  Amazon S3 backup mode.\";}s:15:\"S3Configuration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:40:\"#/definitions/S3DestinationConfiguration\";s:11:\"description\";s:463:\"<p>The
  configuration for the intermediate Amazon S3 location from which Amazon Redshift
  obtains data. Restrictions are described in the topic for <a>CreateDeliveryStream</a>.</p>
  <p>The compression formats <code>SNAPPY</code> or <code>ZIP</code> cannot be specified
  in <code>RedshiftDestinationConfiguration.S3Configuration</code> because the Amazon
  Redshift <code>COPY</code> operation that reads from the S3 bucket doesn't support
  these compression formats.</p>\";}s:8:\"Username\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:22:\"#/definitions/Username\";s:11:\"description\";s:21:\"The
  name of the user.\";}}s:8:\"required\";a:6:{i:0;s:7:\"RoleARN\";i:1;s:14:\"ClusterJDBCURL\";i:2;s:11:\"CopyCommand\";i:3;s:8:\"Username\";i:4;s:8:\"Password\";i:5;s:15:\"S3Configuration\";}s:4:\"type\";s:6:\"object\";}s:30:\"RedshiftDestinationDescription\";O:8:\"stdClass\":4:{s:11:\"description\";s:43:\"Describes
  a destination in Amazon Redshift.\";s:10:\"properties\";O:8:\"stdClass\":10:{s:24:\"CloudWatchLoggingOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/CloudWatchLoggingOptions\";s:11:\"description\";s:63:\"The
  Amazon CloudWatch logging options for your delivery stream.\";}s:14:\"ClusterJDBCURL\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/ClusterJDBCURL\";s:11:\"description\";s:31:\"The
  database connection string.\";}s:11:\"CopyCommand\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:25:\"#/definitions/CopyCommand\";s:11:\"description\";s:30:\"The
  <code>COPY</code> command.\";}s:23:\"ProcessingConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/ProcessingConfiguration\";s:11:\"description\";s:34:\"The
  data processing configuration.\";}s:12:\"RetryOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:34:\"#/definitions/RedshiftRetryOptions\";s:11:\"description\";s:135:\"The
  retry behavior in case Kinesis Data Firehose is unable to deliver documents to Amazon
  Redshift. Default value is 3600 (60 minutes).\";}s:7:\"RoleARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:21:\"#/definitions/RoleARN\";s:11:\"description\";s:226:\"The
  Amazon Resource Name (ARN) of the AWS credentials. For more information, see <a
  href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:19:\"S3BackupDescription\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/S3DestinationDescription\";s:11:\"description\";s:42:\"The
  configuration for backup in Amazon S3.\";}s:12:\"S3BackupMode\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:34:\"#/definitions/RedshiftS3BackupMode\";s:11:\"description\";s:26:\"The
  Amazon S3 backup mode.\";}s:24:\"S3DestinationDescription\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/S3DestinationDescription\";s:11:\"description\";s:26:\"The
  Amazon S3 destination.\";}s:8:\"Username\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:22:\"#/definitions/Username\";s:11:\"description\";s:21:\"The
  name of the user.\";}}s:8:\"required\";a:5:{i:0;s:7:\"RoleARN\";i:1;s:14:\"ClusterJDBCURL\";i:2;s:11:\"CopyCommand\";i:3;s:8:\"Username\";i:4;s:24:\"S3DestinationDescription\";}s:4:\"type\";s:6:\"object\";}s:25:\"RedshiftDestinationUpdate\";O:8:\"stdClass\":3:{s:11:\"description\";s:57:\"Describes
  an update for a destination in Amazon Redshift.\";s:10:\"properties\";O:8:\"stdClass\":11:{s:24:\"CloudWatchLoggingOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/CloudWatchLoggingOptions\";s:11:\"description\";s:63:\"The
  Amazon CloudWatch logging options for your delivery stream.\";}s:14:\"ClusterJDBCURL\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/ClusterJDBCURL\";s:11:\"description\";s:31:\"The
  database connection string.\";}s:11:\"CopyCommand\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:25:\"#/definitions/CopyCommand\";s:11:\"description\";s:30:\"The
  <code>COPY</code> command.\";}s:8:\"Password\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:22:\"#/definitions/Password\";s:11:\"description\";s:18:\"The
  user password.\";}s:23:\"ProcessingConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/ProcessingConfiguration\";s:11:\"description\";s:34:\"The
  data processing configuration.\";}s:12:\"RetryOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:34:\"#/definitions/RedshiftRetryOptions\";s:11:\"description\";s:135:\"The
  retry behavior in case Kinesis Data Firehose is unable to deliver documents to Amazon
  Redshift. Default value is 3600 (60 minutes).\";}s:7:\"RoleARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:21:\"#/definitions/RoleARN\";s:11:\"description\";s:226:\"The
  Amazon Resource Name (ARN) of the AWS credentials. For more information, see <a
  href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:12:\"S3BackupMode\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:34:\"#/definitions/RedshiftS3BackupMode\";s:11:\"description\";s:26:\"The
  Amazon S3 backup mode.\";}s:14:\"S3BackupUpdate\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:33:\"#/definitions/S3DestinationUpdate\";s:11:\"description\";s:37:\"The
  Amazon S3 destination for backup.\";}s:8:\"S3Update\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:33:\"#/definitions/S3DestinationUpdate\";s:11:\"description\";s:304:\"<p>The
  Amazon S3 destination.</p> <p>The compression formats <code>SNAPPY</code> or <code>ZIP</code>
  cannot be specified in <code>RedshiftDestinationUpdate.S3Update</code> because the
  Amazon Redshift <code>COPY</code> operation that reads from the S3 bucket doesn't
  support these compression formats.</p>\";}s:8:\"Username\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:22:\"#/definitions/Username\";s:11:\"description\";s:21:\"The
  name of the user.\";}}s:4:\"type\";s:6:\"object\";}s:30:\"RedshiftRetryDurationInSeconds\";O:8:\"stdClass\":3:{s:7:\"maximum\";i:7200;s:7:\"minimum\";i:0;s:4:\"type\";s:7:\"integer\";}s:20:\"RedshiftRetryOptions\";O:8:\"stdClass\":3:{s:11:\"description\";s:106:\"Configures
  retry behavior in case Kinesis Data Firehose is unable to deliver documents to Amazon
  Redshift.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:17:\"DurationInSeconds\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:44:\"#/definitions/RedshiftRetryDurationInSeconds\";s:11:\"description\";s:368:\"The
  length of time during which Kinesis Data Firehose retries delivery after a failure,
  starting from the initial request and including the first attempt. The default value
  is 3600 seconds (60 minutes). Kinesis Data Firehose does not retry if the value
  of <code>DurationInSeconds</code> is 0 (zero) or if the first delivery attempt takes
  longer than the current value.\";}}s:4:\"type\";s:6:\"object\";}s:20:\"RedshiftS3BackupMode\";O:8:\"stdClass\":2:{s:4:\"enum\";a:2:{i:0;s:8:\"Disabled\";i:1;s:7:\"Enabled\";}s:4:\"type\";s:6:\"string\";}s:22:\"ResourceInUseException\";O:8:\"stdClass\":0:{}s:25:\"ResourceNotFoundException\";O:8:\"stdClass\":0:{}s:7:\"RoleARN\";O:8:\"stdClass\":4:{s:9:\"maxLength\";i:512;s:9:\"minLength\";i:1;s:7:\"pattern\";s:6:\"arn:.*\";s:4:\"type\";s:6:\"string\";}s:12:\"S3BackupMode\";O:8:\"stdClass\":2:{s:4:\"enum\";a:2:{i:0;s:8:\"Disabled\";i:1;s:7:\"Enabled\";}s:4:\"type\";s:6:\"string\";}s:26:\"S3DestinationConfiguration\";O:8:\"stdClass\":4:{s:11:\"description\";s:58:\"Describes
  the configuration of a destination in Amazon S3.\";s:10:\"properties\";O:8:\"stdClass\":8:{s:9:\"BucketARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:23:\"#/definitions/BucketARN\";s:11:\"description\";s:197:\"The
  ARN of the S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:14:\"BufferingHints\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/BufferingHints\";s:11:\"description\";s:107:\"The
  buffering option. If no value is specified, <code>BufferingHints</code> object default
  values are used.\";}s:24:\"CloudWatchLoggingOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/CloudWatchLoggingOptions\";s:11:\"description\";s:56:\"The
  CloudWatch logging options for your delivery stream.\";}s:17:\"CompressionFormat\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/CompressionFormat\";s:11:\"description\";s:335:\"<p>The
  compression format. If no value is specified, the default is <code>UNCOMPRESSED</code>.</p>
  <p>The compression formats <code>SNAPPY</code> or <code>ZIP</code> cannot be specified
  for Amazon Redshift destinations because they are not supported by the Amazon Redshift
  <code>COPY</code> operation that reads from the S3 bucket.</p>\";}s:23:\"EncryptionConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/EncryptionConfiguration\";s:11:\"description\";s:85:\"The
  encryption configuration. If no value is specified, the default is no encryption.\";}s:17:\"ErrorOutputPrefix\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/ErrorOutputPrefix\";s:11:\"description\";s:158:\"A
  prefix that Kinesis Data Firehose evaluates and adds to failed records before writing
  them to S3. This prefix appears immediately following the bucket name.\";}s:6:\"Prefix\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:20:\"#/definitions/Prefix\";s:11:\"description\";s:455:\"The
  \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered Amazon
  S3 files. You can specify an extra prefix to be added in front of the time format
  prefix. If the prefix ends with a slash, it appears as a folder in the S3 bucket.
  For more information, see <a href=\"http://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#s3-object-name\">Amazon
  S3 Object Name Format</a> in the <i>Amazon Kinesis Data Firehose Developer Guide</i>.\";}s:7:\"RoleARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:21:\"#/definitions/RoleARN\";s:11:\"description\";s:226:\"The
  Amazon Resource Name (ARN) of the AWS credentials. For more information, see <a
  href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}}s:8:\"required\";a:2:{i:0;s:7:\"RoleARN\";i:1;s:9:\"BucketARN\";}s:4:\"type\";s:6:\"object\";}s:24:\"S3DestinationDescription\";O:8:\"stdClass\":4:{s:11:\"description\";s:37:\"Describes
  a destination in Amazon S3.\";s:10:\"properties\";O:8:\"stdClass\":8:{s:9:\"BucketARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:23:\"#/definitions/BucketARN\";s:11:\"description\";s:197:\"The
  ARN of the S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:14:\"BufferingHints\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/BufferingHints\";s:11:\"description\";s:107:\"The
  buffering option. If no value is specified, <code>BufferingHints</code> object default
  values are used.\";}s:24:\"CloudWatchLoggingOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/CloudWatchLoggingOptions\";s:11:\"description\";s:63:\"The
  Amazon CloudWatch logging options for your delivery stream.\";}s:17:\"CompressionFormat\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/CompressionFormat\";s:11:\"description\";s:91:\"The
  compression format. If no value is specified, the default is <code>UNCOMPRESSED</code>.\";}s:23:\"EncryptionConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/EncryptionConfiguration\";s:11:\"description\";s:85:\"The
  encryption configuration. If no value is specified, the default is no encryption.\";}s:17:\"ErrorOutputPrefix\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/ErrorOutputPrefix\";s:11:\"description\";s:158:\"A
  prefix that Kinesis Data Firehose evaluates and adds to failed records before writing
  them to S3. This prefix appears immediately following the bucket name.\";}s:6:\"Prefix\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:20:\"#/definitions/Prefix\";s:11:\"description\";s:455:\"The
  \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered Amazon
  S3 files. You can specify an extra prefix to be added in front of the time format
  prefix. If the prefix ends with a slash, it appears as a folder in the S3 bucket.
  For more information, see <a href=\"http://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#s3-object-name\">Amazon
  S3 Object Name Format</a> in the <i>Amazon Kinesis Data Firehose Developer Guide</i>.\";}s:7:\"RoleARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:21:\"#/definitions/RoleARN\";s:11:\"description\";s:226:\"The
  Amazon Resource Name (ARN) of the AWS credentials. For more information, see <a
  href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}}s:8:\"required\";a:5:{i:0;s:7:\"RoleARN\";i:1;s:9:\"BucketARN\";i:2;s:14:\"BufferingHints\";i:3;s:17:\"CompressionFormat\";i:4;s:23:\"EncryptionConfiguration\";}s:4:\"type\";s:6:\"object\";}s:19:\"S3DestinationUpdate\";O:8:\"stdClass\":3:{s:11:\"description\";s:51:\"Describes
  an update for a destination in Amazon S3.\";s:10:\"properties\";O:8:\"stdClass\":8:{s:9:\"BucketARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:23:\"#/definitions/BucketARN\";s:11:\"description\";s:197:\"The
  ARN of the S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}s:14:\"BufferingHints\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:28:\"#/definitions/BufferingHints\";s:11:\"description\";s:107:\"The
  buffering option. If no value is specified, <code>BufferingHints</code> object default
  values are used.\";}s:24:\"CloudWatchLoggingOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/CloudWatchLoggingOptions\";s:11:\"description\";s:56:\"The
  CloudWatch logging options for your delivery stream.\";}s:17:\"CompressionFormat\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/CompressionFormat\";s:11:\"description\";s:335:\"<p>The
  compression format. If no value is specified, the default is <code>UNCOMPRESSED</code>.</p>
  <p>The compression formats <code>SNAPPY</code> or <code>ZIP</code> cannot be specified
  for Amazon Redshift destinations because they are not supported by the Amazon Redshift
  <code>COPY</code> operation that reads from the S3 bucket.</p>\";}s:23:\"EncryptionConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/EncryptionConfiguration\";s:11:\"description\";s:85:\"The
  encryption configuration. If no value is specified, the default is no encryption.\";}s:17:\"ErrorOutputPrefix\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:31:\"#/definitions/ErrorOutputPrefix\";s:11:\"description\";s:158:\"A
  prefix that Kinesis Data Firehose evaluates and adds to failed records before writing
  them to S3. This prefix appears immediately following the bucket name.\";}s:6:\"Prefix\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:20:\"#/definitions/Prefix\";s:11:\"description\";s:455:\"The
  \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered Amazon
  S3 files. You can specify an extra prefix to be added in front of the time format
  prefix. If the prefix ends with a slash, it appears as a folder in the S3 bucket.
  For more information, see <a href=\"http://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#s3-object-name\">Amazon
  S3 Object Name Format</a> in the <i>Amazon Kinesis Data Firehose Developer Guide</i>.\";}s:7:\"RoleARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:21:\"#/definitions/RoleARN\";s:11:\"description\";s:226:\"The
  Amazon Resource Name (ARN) of the AWS credentials. For more information, see <a
  href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon
  Resource Names (ARNs) and AWS Service Namespaces</a>.\";}}s:4:\"type\";s:6:\"object\";}s:19:\"SchemaConfiguration\";O:8:\"stdClass\":3:{s:11:\"description\";s:117:\"Specifies
  the schema to which you want Kinesis Data Firehose to configure your data before
  it writes it to Amazon S3.\";s:10:\"properties\";O:8:\"stdClass\":6:{s:9:\"CatalogId\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:45:\"#/definitions/NonEmptyStringWithoutWhitespace\";s:11:\"description\";s:101:\"The
  ID of the AWS Glue Data Catalog. If you don't supply this, the AWS account ID is
  used by default.\";}s:12:\"DatabaseName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:45:\"#/definitions/NonEmptyStringWithoutWhitespace\";s:11:\"description\";s:89:\"Specifies
  the name of the AWS Glue database that contains the schema for the output data.\";}s:6:\"Region\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:45:\"#/definitions/NonEmptyStringWithoutWhitespace\";s:11:\"description\";s:70:\"If
  you don't specify an AWS Region, the default is the current Region.\";}s:7:\"RoleARN\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:45:\"#/definitions/NonEmptyStringWithoutWhitespace\";s:11:\"description\";s:172:\"The
  role that Kinesis Data Firehose can use to access AWS Glue. This role must be in
  the same account you use for Kinesis Data Firehose. Cross-account roles aren't allowed.\";}s:9:\"TableName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:45:\"#/definitions/NonEmptyStringWithoutWhitespace\";s:11:\"description\";s:100:\"Specifies
  the AWS Glue table that contains the column information that constitutes your data
  schema.\";}s:9:\"VersionId\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:45:\"#/definitions/NonEmptyStringWithoutWhitespace\";s:11:\"description\";s:256:\"Specifies
  the table version for the output data schema. If you don't specify this version
  ID, or if you set it to <code>LATEST</code>, Kinesis Data Firehose uses the most
  recent version. This means that any updates to the table are automatically picked
  up.\";}}s:4:\"type\";s:6:\"object\";}s:10:\"Serializer\";O:8:\"stdClass\":3:{s:11:\"description\";s:448:\"The
  serializer that you want Kinesis Data Firehose to use to convert data to the target
  format before writing it to Amazon S3. Kinesis Data Firehose supports two types
  of serializers: the <a href=\"https://hive.apache.org/javadocs/r1.2.2/api/org/apache/hadoop/hive/ql/io/orc/OrcSerde.html\">ORC
  SerDe</a> and the <a href=\"https://hive.apache.org/javadocs/r1.2.2/api/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.html\">Parquet
  SerDe</a>.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:8:\"OrcSerDe\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:22:\"#/definitions/OrcSerDe\";s:11:\"description\";s:170:\"A
  serializer to use for converting data to the ORC format before storing it in Amazon
  S3. For more information, see <a href=\"https://orc.apache.org/docs/\">Apache ORC</a>.\";}s:12:\"ParquetSerDe\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:26:\"#/definitions/ParquetSerDe\";s:11:\"description\";s:198:\"A
  serializer to use for converting data to the Parquet format before storing it in
  Amazon S3. For more information, see <a href=\"https://parquet.apache.org/documentation/latest/\">Apache
  Parquet</a>.\";}}s:4:\"type\";s:6:\"object\";}s:27:\"ServiceUnavailableException\";O:8:\"stdClass\":0:{}s:9:\"SizeInMBs\";O:8:\"stdClass\":3:{s:7:\"maximum\";i:128;s:7:\"minimum\";i:1;s:4:\"type\";s:7:\"integer\";}s:17:\"SourceDescription\";O:8:\"stdClass\":3:{s:11:\"description\";s:99:\"Details
  about a Kinesis data stream used as the source for a Kinesis Data Firehose delivery
  stream.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:30:\"KinesisStreamSourceDescription\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:44:\"#/definitions/KinesisStreamSourceDescription\";s:11:\"description\";s:83:\"The
  <a>KinesisStreamSourceDescription</a> value for the source Kinesis data stream.\";}}s:4:\"type\";s:6:\"object\";}s:30:\"SplunkDestinationConfiguration\";O:8:\"stdClass\":4:{s:11:\"description\";s:55:\"Describes
  the configuration of a destination in Splunk.\";s:10:\"properties\";O:8:\"stdClass\":9:{s:24:\"CloudWatchLoggingOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/CloudWatchLoggingOptions\";s:11:\"description\";s:63:\"The
  Amazon CloudWatch logging options for your delivery stream.\";}s:33:\"HECAcknowledgmentTimeoutInSeconds\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:47:\"#/definitions/HECAcknowledgmentTimeoutInSeconds\";s:11:\"description\";s:264:\"The
  amount of time that Kinesis Data Firehose waits to receive an acknowledgment from
  Splunk after it sends it data. At the end of the timeout period, Kinesis Data Firehose
  either tries to send the data again or considers it an error, based on your retry
  settings.\";}s:11:\"HECEndpoint\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:25:\"#/definitions/HECEndpoint\";s:11:\"description\";s:87:\"The
  HTTP Event Collector (HEC) endpoint to which Kinesis Data Firehose sends your data.\";}s:15:\"HECEndpointType\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:29:\"#/definitions/HECEndpointType\";s:11:\"description\";s:41:\"This
  type can be either \"Raw\" or \"Event.\"\";}s:8:\"HECToken\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:22:\"#/definitions/HECToken\";s:11:\"description\";s:91:\"This
  is a GUID that you obtain from your Splunk cluster when you create a new HEC endpoint.\";}s:23:\"ProcessingConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/ProcessingConfiguration\";s:11:\"description\";s:34:\"The
  data processing configuration.\";}s:12:\"RetryOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/SplunkRetryOptions\";s:11:\"description\";s:152:\"The
  retry behavior in case Kinesis Data Firehose is unable to deliver data to Splunk,
  or if it doesn't receive an acknowledgment of receipt from Splunk.\";}s:12:\"S3BackupMode\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/SplunkS3BackupMode\";s:11:\"description\";s:410:\"Defines
  how documents should be delivered to Amazon S3. When set to <code>FailedDocumentsOnly</code>,
  Kinesis Data Firehose writes any data that could not be indexed to the configured
  Amazon S3 destination. When set to <code>AllDocuments</code>, Kinesis Data Firehose
  delivers all incoming records to Amazon S3, and also writes failed documents to
  Amazon S3. Default value is <code>FailedDocumentsOnly</code>. \";}s:15:\"S3Configuration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:40:\"#/definitions/S3DestinationConfiguration\";s:11:\"description\";s:52:\"The
  configuration for the backup Amazon S3 location.\";}}s:8:\"required\";a:4:{i:0;s:11:\"HECEndpoint\";i:1;s:15:\"HECEndpointType\";i:2;s:8:\"HECToken\";i:3;s:15:\"S3Configuration\";}s:4:\"type\";s:6:\"object\";}s:28:\"SplunkDestinationDescription\";O:8:\"stdClass\":3:{s:11:\"description\";s:34:\"Describes
  a destination in Splunk.\";s:10:\"properties\";O:8:\"stdClass\":9:{s:24:\"CloudWatchLoggingOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/CloudWatchLoggingOptions\";s:11:\"description\";s:63:\"The
  Amazon CloudWatch logging options for your delivery stream.\";}s:33:\"HECAcknowledgmentTimeoutInSeconds\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:47:\"#/definitions/HECAcknowledgmentTimeoutInSeconds\";s:11:\"description\";s:264:\"The
  amount of time that Kinesis Data Firehose waits to receive an acknowledgment from
  Splunk after it sends it data. At the end of the timeout period, Kinesis Data Firehose
  either tries to send the data again or considers it an error, based on your retry
  settings.\";}s:11:\"HECEndpoint\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:25:\"#/definitions/HECEndpoint\";s:11:\"description\";s:87:\"The
  HTTP Event Collector (HEC) endpoint to which Kinesis Data Firehose sends your data.\";}s:15:\"HECEndpointType\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:29:\"#/definitions/HECEndpointType\";s:11:\"description\";s:41:\"This
  type can be either \"Raw\" or \"Event.\"\";}s:8:\"HECToken\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:22:\"#/definitions/HECToken\";s:11:\"description\";s:78:\"A
  GUID you obtain from your Splunk cluster when you create a new HEC endpoint.\";}s:23:\"ProcessingConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/ProcessingConfiguration\";s:11:\"description\";s:34:\"The
  data processing configuration.\";}s:12:\"RetryOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/SplunkRetryOptions\";s:11:\"description\";s:151:\"The
  retry behavior in case Kinesis Data Firehose is unable to deliver data to Splunk
  or if it doesn't receive an acknowledgment of receipt from Splunk.\";}s:12:\"S3BackupMode\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/SplunkS3BackupMode\";s:11:\"description\";s:410:\"Defines
  how documents should be delivered to Amazon S3. When set to <code>FailedDocumentsOnly</code>,
  Kinesis Data Firehose writes any data that could not be indexed to the configured
  Amazon S3 destination. When set to <code>AllDocuments</code>, Kinesis Data Firehose
  delivers all incoming records to Amazon S3, and also writes failed documents to
  Amazon S3. Default value is <code>FailedDocumentsOnly</code>. \";}s:24:\"S3DestinationDescription\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/S3DestinationDescription\";s:11:\"description\";s:30:\"The
  Amazon S3 destination.&gt;\";}}s:4:\"type\";s:6:\"object\";}s:23:\"SplunkDestinationUpdate\";O:8:\"stdClass\":3:{s:11:\"description\";s:48:\"Describes
  an update for a destination in Splunk.\";s:10:\"properties\";O:8:\"stdClass\":9:{s:24:\"CloudWatchLoggingOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:38:\"#/definitions/CloudWatchLoggingOptions\";s:11:\"description\";s:63:\"The
  Amazon CloudWatch logging options for your delivery stream.\";}s:33:\"HECAcknowledgmentTimeoutInSeconds\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:47:\"#/definitions/HECAcknowledgmentTimeoutInSeconds\";s:11:\"description\";s:261:\"The
  amount of time that Kinesis Data Firehose waits to receive an acknowledgment from
  Splunk after it sends data. At the end of the timeout period, Kinesis Data Firehose
  either tries to send the data again or considers it an error, based on your retry
  settings.\";}s:11:\"HECEndpoint\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:25:\"#/definitions/HECEndpoint\";s:11:\"description\";s:87:\"The
  HTTP Event Collector (HEC) endpoint to which Kinesis Data Firehose sends your data.\";}s:15:\"HECEndpointType\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:29:\"#/definitions/HECEndpointType\";s:11:\"description\";s:41:\"This
  type can be either \"Raw\" or \"Event.\"\";}s:8:\"HECToken\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:22:\"#/definitions/HECToken\";s:11:\"description\";s:83:\"A
  GUID that you obtain from your Splunk cluster when you create a new HEC endpoint.\";}s:23:\"ProcessingConfiguration\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/ProcessingConfiguration\";s:11:\"description\";s:34:\"The
  data processing configuration.\";}s:12:\"RetryOptions\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/SplunkRetryOptions\";s:11:\"description\";s:151:\"The
  retry behavior in case Kinesis Data Firehose is unable to deliver data to Splunk
  or if it doesn't receive an acknowledgment of receipt from Splunk.\";}s:12:\"S3BackupMode\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/SplunkS3BackupMode\";s:11:\"description\";s:410:\"Defines
  how documents should be delivered to Amazon S3. When set to <code>FailedDocumentsOnly</code>,
  Kinesis Data Firehose writes any data that could not be indexed to the configured
  Amazon S3 destination. When set to <code>AllDocuments</code>, Kinesis Data Firehose
  delivers all incoming records to Amazon S3, and also writes failed documents to
  Amazon S3. Default value is <code>FailedDocumentsOnly</code>. \";}s:8:\"S3Update\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:33:\"#/definitions/S3DestinationUpdate\";s:11:\"description\";s:66:\"Your
  update to the configuration of the backup Amazon S3 location.\";}}s:4:\"type\";s:6:\"object\";}s:28:\"SplunkRetryDurationInSeconds\";O:8:\"stdClass\":3:{s:7:\"maximum\";i:7200;s:7:\"minimum\";i:0;s:4:\"type\";s:7:\"integer\";}s:18:\"SplunkRetryOptions\";O:8:\"stdClass\":3:{s:11:\"description\";s:153:\"Configures
  retry behavior in case Kinesis Data Firehose is unable to deliver documents to Splunk,
  or if it doesn't receive an acknowledgment from Splunk.\";s:10:\"properties\";O:8:\"stdClass\":1:{s:17:\"DurationInSeconds\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:42:\"#/definitions/SplunkRetryDurationInSeconds\";s:11:\"description\";s:270:\"The
  total amount of time that Kinesis Data Firehose spends on retries. This duration
  starts after the initial attempt to send data to Splunk fails. It doesn't include
  the periods during which Kinesis Data Firehose waits for acknowledgment from Splunk
  after each attempt.\";}}s:4:\"type\";s:6:\"object\";}s:18:\"SplunkS3BackupMode\";O:8:\"stdClass\":2:{s:4:\"enum\";a:2:{i:0;s:16:\"FailedEventsOnly\";i:1;s:9:\"AllEvents\";}s:4:\"type\";s:6:\"string\";}s:34:\"StartDeliveryStreamEncryptionInput\";O:8:\"stdClass\":3:{s:10:\"properties\";O:8:\"stdClass\":1:{s:18:\"DeliveryStreamName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/DeliveryStreamName\";s:11:\"description\";s:90:\"The
  name of the delivery stream for which you want to enable server-side encryption
  (SSE).\";}}s:8:\"required\";a:1:{i:0;s:18:\"DeliveryStreamName\";}s:4:\"type\";s:6:\"object\";}s:35:\"StartDeliveryStreamEncryptionOutput\";O:8:\"stdClass\":2:{s:10:\"properties\";O:8:\"stdClass\":0:{}s:4:\"type\";s:6:\"object\";}s:33:\"StopDeliveryStreamEncryptionInput\";O:8:\"stdClass\":3:{s:10:\"properties\";O:8:\"stdClass\":1:{s:18:\"DeliveryStreamName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/DeliveryStreamName\";s:11:\"description\";s:91:\"The
  name of the delivery stream for which you want to disable server-side encryption
  (SSE).\";}}s:8:\"required\";a:1:{i:0;s:18:\"DeliveryStreamName\";}s:4:\"type\";s:6:\"object\";}s:34:\"StopDeliveryStreamEncryptionOutput\";O:8:\"stdClass\":2:{s:10:\"properties\";O:8:\"stdClass\":0:{}s:4:\"type\";s:6:\"object\";}s:3:\"Tag\";O:8:\"stdClass\":4:{s:11:\"description\";s:82:\"Metadata
  that you can assign to a delivery stream, consisting of a key-value pair.\";s:10:\"properties\";O:8:\"stdClass\":2:{s:3:\"Key\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:20:\"#/definitions/TagKey\";s:11:\"description\";s:136:\"A
  unique identifier for the tag. Maximum length: 128 characters. Valid characters:
  Unicode letters, digits, white space, _ . / = + - % @\";}s:5:\"Value\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:22:\"#/definitions/TagValue\";s:11:\"description\";s:172:\"An
  optional string, which you can use to describe or define the tag. Maximum length:
  256 characters. Valid characters: Unicode letters, digits, white space, _ . / =
  + - % @\";}}s:8:\"required\";a:1:{i:0;s:3:\"Key\";}s:4:\"type\";s:6:\"object\";}s:22:\"TagDeliveryStreamInput\";O:8:\"stdClass\":3:{s:10:\"properties\";O:8:\"stdClass\":2:{s:18:\"DeliveryStreamName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/DeliveryStreamName\";s:11:\"description\";s:66:\"The
  name of the delivery stream to which you want to add the tags.\";}s:4:\"Tags\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:43:\"#/definitions/TagDeliveryStreamInputTagList\";s:11:\"description\";s:51:\"A
  set of key-value pairs to use to create the tags.\";}}s:8:\"required\";a:2:{i:0;s:18:\"DeliveryStreamName\";i:1;s:4:\"Tags\";}s:4:\"type\";s:6:\"object\";}s:29:\"TagDeliveryStreamInputTagList\";O:8:\"stdClass\":4:{s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:17:\"#/definitions/Tag\";}s:8:\"maxItems\";i:50;s:8:\"minItems\";i:1;s:4:\"type\";s:5:\"array\";}s:23:\"TagDeliveryStreamOutput\";O:8:\"stdClass\":2:{s:10:\"properties\";O:8:\"stdClass\":0:{}s:4:\"type\";s:6:\"object\";}s:6:\"TagKey\";O:8:\"stdClass\":3:{s:9:\"maxLength\";i:128;s:9:\"minLength\";i:1;s:4:\"type\";s:6:\"string\";}s:10:\"TagKeyList\";O:8:\"stdClass\":4:{s:5:\"items\";O:8:\"stdClass\":1:{s:4:\"$ref\";s:20:\"#/definitions/TagKey\";}s:8:\"maxItems\";i:50;s:8:\"minItems\";i:1;s:4:\"type\";s:5:\"array\";}s:8:\"TagValue\";O:8:\"stdClass\":3:{s:9:\"maxLength\";i:256;s:9:\"minLength\";i:0;s:4:\"type\";s:6:\"string\";}s:9:\"Timestamp\";O:8:\"stdClass\":2:{s:6:\"format\";s:9:\"date-time\";s:4:\"type\";s:6:\"string\";}s:24:\"UntagDeliveryStreamInput\";O:8:\"stdClass\":3:{s:10:\"properties\";O:8:\"stdClass\":2:{s:18:\"DeliveryStreamName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/DeliveryStreamName\";s:11:\"description\";s:32:\"The
  name of the delivery stream.\";}s:7:\"TagKeys\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:24:\"#/definitions/TagKeyList\";s:11:\"description\";s:79:\"A
  list of tag keys. Each corresponding tag is removed from the delivery stream.\";}}s:8:\"required\";a:2:{i:0;s:18:\"DeliveryStreamName\";i:1;s:7:\"TagKeys\";}s:4:\"type\";s:6:\"object\";}s:25:\"UntagDeliveryStreamOutput\";O:8:\"stdClass\":2:{s:10:\"properties\";O:8:\"stdClass\":0:{}s:4:\"type\";s:6:\"object\";}s:22:\"UpdateDestinationInput\";O:8:\"stdClass\":3:{s:10:\"properties\";O:8:\"stdClass\":8:{s:30:\"CurrentDeliveryStreamVersionId\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/DeliveryStreamVersionId\";s:11:\"description\";s:442:\"Obtain
  this value from the <code>VersionId</code> result of <a>DeliveryStreamDescription</a>.
  This value is required, and helps the service perform conditional operations. For
  example, if there is an interleaving update and this value is null, then the update
  destination fails. After the update is successful, the <code>VersionId</code> value
  is updated. The service then performs a merge of the old configuration with the
  new configuration.\";}s:18:\"DeliveryStreamName\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:32:\"#/definitions/DeliveryStreamName\";s:11:\"description\";s:32:\"The
  name of the delivery stream.\";}s:13:\"DestinationId\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:27:\"#/definitions/DestinationId\";s:11:\"description\";s:26:\"The
  ID of the destination.\";}s:30:\"ElasticsearchDestinationUpdate\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:44:\"#/definitions/ElasticsearchDestinationUpdate\";s:11:\"description\";s:51:\"Describes
  an update for a destination in Amazon ES.\";}s:27:\"ExtendedS3DestinationUpdate\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:41:\"#/definitions/ExtendedS3DestinationUpdate\";s:11:\"description\";s:51:\"Describes
  an update for a destination in Amazon S3.\";}s:25:\"RedshiftDestinationUpdate\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:39:\"#/definitions/RedshiftDestinationUpdate\";s:11:\"description\";s:57:\"Describes
  an update for a destination in Amazon Redshift.\";}s:19:\"S3DestinationUpdate\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:33:\"#/definitions/S3DestinationUpdate\";s:11:\"description\";s:64:\"[Deprecated]
  Describes an update for a destination in Amazon S3.\";}s:23:\"SplunkDestinationUpdate\";O:8:\"stdClass\":2:{s:4:\"$ref\";s:37:\"#/definitions/SplunkDestinationUpdate\";s:11:\"description\";s:48:\"Describes
  an update for a destination in Splunk.\";}}s:8:\"required\";a:3:{i:0;s:18:\"DeliveryStreamName\";i:1;s:30:\"CurrentDeliveryStreamVersionId\";i:2;s:13:\"DestinationId\";}s:4:\"type\";s:6:\"object\";}s:23:\"UpdateDestinationOutput\";O:8:\"stdClass\":2:{s:10:\"properties\";O:8:\"stdClass\":0:{}s:4:\"type\";s:6:\"object\";}s:8:\"Username\";O:8:\"stdClass\":3:{s:6:\"format\";s:8:\"password\";s:9:\"minLength\";i:1;s:4:\"type\";s:6:\"string\";}}"
...
